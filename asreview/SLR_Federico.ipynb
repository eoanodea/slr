{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che si occupa di sovrascrivere un dataframe per selezione e rinomina colonne\n",
    "\n",
    "def select_and_rename_columns(df, cols, names):\n",
    "    res = df[cols].copy()\n",
    "    res = res.rename(columns=names).copy()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che cambia l'item type\n",
    "\n",
    "def replace_item_type(df, col, values):\n",
    "    df[col] = df[col].replace(values)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che elimina tutti i valori NaN\n",
    "\n",
    "def fill_na(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = df[column].fillna('')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione che aggiunge una nuova colonna per ogni IC ed EC e imposta si o no come valore se l'inclusion/exclusion criteria Ã¨ presente nelle note\n",
    "\n",
    "def add_and_fill_columns(df, nincl, nexcl, suffix, colnotes):\n",
    "    criteria = []\n",
    "    for i in range(1,nincl+1):\n",
    "        col = 'IC'+str(i)+' '+suffix\n",
    "        criteria.append(col)\n",
    "        df[col] = pd.NA\n",
    "    \n",
    "    for e in range(1,nexcl+1):\n",
    "        col = 'EC'+str(e)+' '+suffix\n",
    "        criteria.append(col)\n",
    "        df[col] = pd.NA\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        notes = row[colnotes]\n",
    "        for c in criteria:\n",
    "            crit = c.split(' ')[0]\n",
    "            if crit in notes:\n",
    "                df.at[index, c] = 'yes'\n",
    "            else:\n",
    "                df.at[index, c] = 'no'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_paper_inclusion(df, column_name, new_column_name):\n",
    "    df[new_column_name] = df[column_name].apply(lambda x: 'Include' if x == 1.0 else 'Exclude' if x == 0.0 else 'Rejected by ASReview')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_df(df, cols, names, itype_colname, colvalues, nincl, nexcl, suffix, colnotes, inclcol, newcolname):\n",
    "    df = select_and_rename_columns(df, cols, names)\n",
    "    df = replace_item_type(df, itype_colname, colvalues)\n",
    "    df = fill_na(df)\n",
    "    df = add_and_fill_columns(df, nincl, nexcl, suffix, colnotes)\n",
    "    df = convert_paper_inclusion(df, inclcol, newcolname)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_two_datasets(df1, df2, join_column):\n",
    "    # Merge the datasets on the predefined column\n",
    "    merged_df = pd.merge(df1, df2, on=join_column, suffixes=('_df1', '_df2'))\n",
    "\n",
    "    # Eliminate repeated columns\n",
    "    for column in merged_df.columns:\n",
    "        if column.endswith('_df1') or column.endswith('_df2'):\n",
    "            base_column = column.split('_')[0]\n",
    "            if base_column in merged_df.columns:\n",
    "                merged_df.drop(column, axis=1, inplace=True)\n",
    "            else:\n",
    "                merged_df.rename(columns={column: base_column}, inplace=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters\n",
    "colname = 'Item Type'\n",
    "colvalues = {'CONF': 'conferencePaper', 'JOUR': 'journalArticle'}\n",
    "nincl = 6 # Number of inclusion criteria\n",
    "nexcl = 5 # Number of exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe Federico\n",
    "\n",
    "dataF = pd.read_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Federico.csv')\n",
    "colsfl = ['record_id', 'type_of_reference', 'title', 'authors', 'abstract', 'doi', 'exported_notes_1', 'included', 'asreview_ranking'] # Columns to keep\n",
    "namesfl = {'type_of_reference':'Item Type', 'title':'Title', 'authors':'Authors', 'doi':'DOI', 'abstract':'Abstract', 'included':'Paper Inclusion Federico', 'exported_notes_1':'Notes Federico', 'asreview_ranking':'Ranking Federico'} # New names for the columns\n",
    "suffix = 'Federico' # Suffix for the inclusion/exclusion criteria columns\n",
    "colnotes = 'Notes Federico' # Column containing the notes\n",
    "inclcol = 'Paper Inclusion Federico' # Column containing the inclusion/exclusion decision\n",
    "newcolname = 'Decision Federico' # New column name for the inclusion/exclusion decision\n",
    "\n",
    "dff = create_clean_df(dataF, colsfl, namesfl, colname, colvalues, nincl, nexcl, suffix, colnotes, inclcol, newcolname) # Cleaned dataframe\n",
    "dff.to_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Federico_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe Lorenzo\n",
    "\n",
    "dataL = pd.read_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Lorenzo.csv')\n",
    "colsfl = ['record_id', 'type_of_reference', 'title', 'authors', 'abstract', 'doi', 'exported_notes_1', 'included', 'asreview_ranking']\n",
    "namesfl = {'type_of_reference':'Item Type', 'title':'Title', 'authors':'Authors', 'doi':'DOI', 'abstract':'Abstract', 'included':'Paper Inclusion Lorenzo', 'exported_notes_1':'Notes Lorenzo', 'asreview_ranking':'Ranking Lorenzo'}\n",
    "suffix = 'Lorenzo'\n",
    "colnotes = 'Notes Lorenzo'\n",
    "inclcol = 'Paper Inclusion Lorenzo' # Column containing the inclusion/exclusion decision\n",
    "newcolname = 'Decision Lorenzo' # New column name for the inclusion/exclusion decision\n",
    "\n",
    "dfl = create_clean_df(dataL, colsfl, namesfl, colname, colvalues, nincl, nexcl, suffix, colnotes, inclcol, newcolname) # Cleaned dataframe\n",
    "dfl.to_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Lorenzo_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe Beatrice\n",
    "\n",
    "dataB = pd.read_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Beatrice.csv')\n",
    "colsb = ['record_id', 'Item Type', 'Title', 'Author', 'Abstract Note', 'DOI', 'exported_notes_1', 'included', 'asreview_ranking']\n",
    "namesb = {'Author':'Authors', 'included':'Paper Inclusion Beatrice', 'exported_notes_1':'Notes Beatrice', 'Abstract Note':'Abstract', 'asreview_ranking':'Ranking Beatrice'}\n",
    "suffix = 'Beatrice'\n",
    "colnotes = 'Notes Beatrice'\n",
    "inclcol = 'Paper Inclusion Beatrice' # Column containing the inclusion/exclusion decision\n",
    "newcolname = 'Decision Beatrice' # New column name for the inclusion/exclusion decision\n",
    "\n",
    "dfb = create_clean_df(dataB, colsb, namesb, colname, colvalues, nincl, nexcl, suffix, colnotes, inclcol, newcolname) # Cleaned dataframe\n",
    "dfb.to_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Beatrice_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'record_id'\n",
    "\n",
    "final = join_two_datasets(dff, dfl, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = join_two_datasets(final, dfb, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the specified columns to the end of the dataframe\n",
    "cols_to_move = ['Decision Federico', 'Decision Lorenzo', 'Decision Beatrice']\n",
    "final = final[[col for col in final if col not in cols_to_move] + cols_to_move]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_columns_not_in_list(df, columns_to_keep):\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "final = eliminate_columns_not_in_list(final, ['record_id', 'Item Type', 'Title', 'Authors', 'DOI', 'Notes Federico', 'Notes Lorenzo', 'Notes Beatrice', 'Decision Federico', 'Decision Lorenzo', 'Decision Beatrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_final_decision(row):\n",
    "    decisions = [row['Decision Federico'], row['Decision Lorenzo'], row['Decision Beatrice']]\n",
    "    \n",
    "    if all(decision == 'Include' for decision in decisions):  # If all decisions are 'Include'\n",
    "        return 'Include'\n",
    "    elif all(decision in ['Exclude', 'Rejected by ASReview'] for decision in decisions):  # If all decisions are 'Exclude' or 'Rejected by ASReview'\n",
    "        return 'Exclude'\n",
    "    elif row['Decision Federico'] == 'Include' and all(decision in ['Exclude', 'Rejected by ASReview'] for decision in decisions[1:]):  # If Federico says 'Include' and the others say 'Exclude' or 'Rejected by ASReview'\n",
    "        return 'Maybe'\n",
    "    elif row['Decision Federico'] in ['Exclude', 'Rejected by ASReview'] and 'Include' in decisions[1:]:  # If Federico says 'Exclude' or 'Rejected by ASReview' and at least one of the others says 'Include'\n",
    "        return 'Maybe'\n",
    "    elif row['Decision Federico'] == 'Include' and 'Include' in decisions[1:]:  # If Federico says 'Include' and at least one of the others says 'Include'\n",
    "        return 'Include'\n",
    "    else:\n",
    "        return 'Maybe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_final_decision(row):\n",
    "    if row['Intermediate Decision'] == 'Include':\n",
    "        return 'Accept'\n",
    "    elif row['Intermediate Decision'] == 'Exclude':\n",
    "        return 'Reject'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = eliminate_columns_not_in_list(final, ['record_id', 'Item Type', 'Title', 'Authors', 'DOI', 'Notes Federico', 'Notes Lorenzo', 'Notes Beatrice', 'Decision Federico', 'Decision Lorenzo', 'Decision Beatrice'])\n",
    "final['Intermediate Decision'] = final.apply(calculate_final_decision, axis=1)\n",
    "final['Final Decision'] = final.apply(determine_final_decision, axis=1)\n",
    "final.to_csv(r'C:\\Users\\ROBECAPU\\Desktop\\SLR Federico\\Final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
