"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"7I276PRY","journalArticle","","Lee, J.; Lee, E.","","Concerto: Dynamic Processor Scaling for Distributed Data Systems with Replication","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152893965&partnerID=40&md5=17b07cf96ec5014b135659d14b643c16","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N8MMQKBI","journalArticle","","Yu, G.; Chen, P.; Zheng, Z.","","Microscaler: Cost-effective Scaling for Microservice Applications in the Cloud with an Online Learning Approach","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152899663&partnerID=40&md5=3f976483d64a3921d4744594dfd7fd2b","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Z8PMTJ5","journalArticle","","Nunes, J.P.K.S.; Bianchi, T.; Iwazaki, A.Y.; Yumi Nakagawa, E.","","State of the Art on Microservices Autoscaling: An Overview","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152945254&partnerID=40&md5=0c94550016431536c44d5c576456f868","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A6CNYHV4","journalArticle","","Koschel, A.; Bertram, M.; Bischof, R.; Schulze, K.; Schaaf, M.; Astrova, I.","","A Look at Service Meshes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152899368&partnerID=40&md5=ae873a97b27551e01770900057775d86","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW5XZCUZ","journalArticle","","GhatrehSamani, D.; Denninnart, C.; Bacik, J.; Salehi, M.A.","","The Art of CPU-Pinning: Evaluating and Improving the Performance of Virtualization and Containerization Platforms","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152902834&partnerID=40&md5=7577bbb4e9265cdbdda74e6606c8f509","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4KCPCVF","journalArticle","","Li, W.; Lemieux, Y.; Zhao, Z.; Han, Y.","","Service Mesh: Challenges, State of the Art, and Future Research Opportunities","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152918160&partnerID=40&md5=eaba2e6d3392b7a7ab39dcbc3a0aa180","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HT8EHW4L","journalArticle","","","","A Service Mesh for Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152940191&partnerID=40&md5=ccc5fb89a90c1ecdc06fe036da60dadc","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GMU2YCWU","journalArticle","2025","Devey, K.; Hunt, D.; MacNamara, C.","","Power Management - Technology Overview","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140956119&partnerID=40&md5=f29610258cb4972de6128d3f6cf36de6","","2025","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XPKN54JN","journalArticle","2004","","","Intel Corporation Enhanced SpeedStep® Technology for the Intel ® Pentium ® M Processor White Paper","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152933943&partnerID=40&md5=b794b477ace6efb945c869cd9b736be8","","2004","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7LSCGAA","journalArticle","","Schöne, R.; Ilsche, T.; Bielert, M.; Gocht, A.; Hackenberg, D.","","Energy Efficiency Features of the Intel Skylake-SP Processor and Their Impact on Performance","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152934125&partnerID=40&md5=d246c91fdd6f5ddb8faeaadd01681118","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKFR6ZZA","journalArticle","","","","Microservices-framework-benchmark","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152944158&partnerID=40&md5=139f58eeb8869be94b790b024d25554e","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8P5ZGDJ9","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152937873&partnerID=40&md5=1240468af2a3a798a680668ead25291a","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5I9XS3PE","journalArticle","2018","Torquato, M.; Umesh, I.M.; Maciel, P.","Models for availability and power consumption evaluation of a private cloud with VMM rejuvenation enabled by VM Live Migration","Journal of Supercomputing","","","10.1007/s11227-018-2485-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050183501&doi=10.1007%2fs11227-018-2485-4&partnerID=40&md5=8bfcb412dc10cf373fbf828d3180d49a","Software aging affects the availability of Virtual Machine Monitor (VMM), one of the main components of virtualized environments. Software aging causes internal software degradation due to bugs activation and accumulation during its execution. Software rejuvenation implemented through Virtual Machine (VM) Live Migration may be applied to cope with software aging effects on cloud computing system. Another relevant problem is the power consumption of using software rejuvenation techniques in the virtualized environments. This paper presents availability models based on Stochastic Petri Nets to evaluate two VM Live Migration approaches. These approaches are based on the redundancy schemes: Warm-Standby and Cold-Standby. In the Cold-Standby migration, the migration target machine is started only before the VM Live Migration. In the Warm-Standby Migration, the migration target machine runs along with the source migration machine. Results show that VM Live Migration causes a significant improvement in system availability. Scenarios with a heavy workload present an annual downtime reduction of 164 h. The availability comparison between two approaches reveals that the Cold-Standby approach has a slightly better result due to the decrease in the total number of VM Live Migrations. The power consumption results show that Cold-Standby approach is more efficient in power consumption. In all the observed scenarios, the costs savings by using Cold-Standby approach exceed 40%. The highlights of this paper are: i) a comprehensive model for availability evaluation of cloud computing with VMM rejuvenation through VM migration scheduling; ii) sensitivity analysis to define proper rejuvenation scheduling to maximize system availability and iii) power consumption comparison of the two adopted migration approaches. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","2018","2025-10-22 19:07:31","2025-10-22 19:07:31","","4817-4841","","9","74","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Electric power utilization; Virtualized environment; Energy efficiency; Cloud computing; Program debugging; Virtual reality; Green computing; Virtual machine; Sensitivity analysis; Network security; Stochastic systems; Stochastic models; Availability; Petri nets; Machine components; System availability; Comprehensive model; Endocrinology; Live migrations; Power consumption; Software aging; Software aging and rejuvenation; Software rejuvenation; Stochastic Petri Nets; Virtual machine monitors; VM Live Migration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M77QJQX3","journalArticle","","","","MicroK8s the Lightweight Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180914125&partnerID=40&md5=096fabfceda5a670575e9d0602c952aa","","","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VFTA6CIW","conferencePaper","2020","Valera, H.H.A.; Dalmau, M.; Roose, P.; Larracoechea, J.; Herzog, C.","DRACeo: A smart simulator to deploy energy saving methods in microservices based networks","","","","10.1109/WETICE49692.2020.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100714002&doi=10.1109%2fWETICE49692.2020.00026&partnerID=40&md5=6dde8162ca929d1cfeb833956e56d257","Nowadays, many researchers work to identify microservices-based application deployments and scheduling solutions to save energy without decreasing functional QoS. In this work, we present DRACeo: A simulator that allows facing this challenge in a simple and efficient way, enabling its users to focus uniquely on microservices deployment/scheduling algorithms and its hardware/software repercussions (load vs. energy consumption) without worrying about low-level network configurations or operating system issues. DRACeo is able to deploy and schedule (move, duplicate, start/stop) microservices and their dependencies on various devices with software and hardware heterogeneity (CPU, bandwidth, RAM, Battery, etc.), taking into account various scheduling heuristics algorithms: centralized vs non-centralized. To do this, DRACeo allows deploying custom network topologies based on client-server schemes or p2p distributions, where devices can (dis)appear, turn on/off obeying random circumstances or user strategies. Finally, the simulator performs relevant operations such as QoS definition, resource monitoring, calculation of energy saved and consumption tracking (at device and network level). We tested some ideas based on our previous work 'Kaligreen' to demonstrate the effectiveness of DRACeo. © 2020 IEEE.","2020","2025-10-22 19:07:31","2025-10-22 19:07:31","","94-99","","","2020-September","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Scheduling; microservices; Energy utilization; Energy conservation; CPU; Software and hardwares; Application deployment; energy; middleware; Network topology; consumption; hard disk; network; prototype; simulator; Energy saving methods; Hardware/software; Network configuration; Resource monitoring; Scheduling heuristics; Simulators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE","","","","","","","","","","","","","","",""
"IDXHMNKJ","conferencePaper","2020","Khatami, A.A.; Purwanto, Y.; Ruriawan, M.F.","High availability storage server with kubernetes","","","","10.1109/ICITSI50517.2020.9264928","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099602167&doi=10.1109%2fICITSI50517.2020.9264928&partnerID=40&md5=70774a9615802659a5569457ca139864","High availability server (HAS) is a concept in which the server resources continuously available through any interference of the virtual and physical server. HAS is widely used for various purposes such as online trading services, business and Big Data needs. To optimize storage, it needs a special way to minimize costs incurred and be able to optimize the existing server. This research has implemented a system of high availability server using Kubernetes and distributed storage. The system was capable of meeting the resource requests even though one instance was interrupted. And if an instance was down, the services stored in the cluster could still be accessed through other instances. Based on the reliability and availability testing, the system was capable of meeting the high availability criteria, by reaching an uptime rate of 100%.  © 2020 IEEE.","2020","2025-10-22 19:07:31","2025-10-22 19:07:31","","74-78","","","","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; Big data; Container; Server resources; Digital storage; High availability; Availability; Reliability and availability; Distributed storage; High availability server; Online trading; Resource request; Storage servers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 International Conference on Information Technology Systems and Innovation, ICITSI 2020 - Proceedings","","","","","","","","","","","","","","",""
"4CUIMMA4","conferencePaper","2021","Liu, Z.; Yu, H.; Fan, G.; Chen, L.","Reliability Modeling and Analysis of Hospital Information System Based on Microservices","","","","10.1109/PIC53636.2021.9687027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125802205&doi=10.1109%2fPIC53636.2021.9687027&partnerID=40&md5=a20e3378ecbb0a3ec75761621ef1d3f2","In recent years, modern hospital has a large scale, complex relationship, and hospital information system (HIS) due to rapid development of computer networks. But there is still a big gap for reliable use of clinical information and management system, especially in terms of fault prevention. The microservice architecture has great advantages for development and delivery of complex system. This paper proposes a novel microservice reliability model (MSRM) for HIS based on the formalism of Predicate Petri net (PrT net). First, microservice reliability requirement design is given and PrT net is used to model the reliability of microservice, and the corresponding syntax and semantics are also presented. Then the redundancy and circuit breaker is designed by using PrT net, a composition strategy is proposed and the reliability of microservices is analyzed qualitatively and quantitatively. Based on the constructed MSRM, the correctness of PrT net modeling and effectiveness of the strategies have been proven theoretically. Finally, a public healthcare case is used to explain modeling process, and verify the effectiveness of proposed method. Experimental results show that the strategy for HIS microservice reliability is effective.  © 2021 IEEE.","2021","2025-10-22 19:07:31","2025-10-22 19:07:31","","313-318","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Large-scales; Network architecture; Complex networks; Microservice architecture; Semantics; Electric circuit breakers; Redundancy; Petri nets; Reliability modelling; Software reliability; Software-Reliability; Information systems; Information use; Reliability analysis; Clinical information system; Clinical management systems; Complex relationships; Fault prevention; Hospital Information System; Hospital information systems; Hospitals; Microservice Architecture; Modelling and analysis; Petri Net; Software Reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2021 IEEE International Conference on Progress in Informatics and Computing, PIC 2021","","","","","","","","","","","","","","",""
"I2FTPSW8","journalArticle","2022","Kharchenko, V.; Ponochovnyi, Y.; Ivanchenko, O.; Fesenko, H.; Illiashenko, O.","Combining Markov and Semi-Markov Modelling for Assessing Availability and Cybersecurity of Cloud and IoT Systems","Cryptography","","","10.3390/cryptography6030044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138621888&doi=10.3390%2fcryptography6030044&partnerID=40&md5=fa1924ba1c16710cc2317e22bc285df0","This paper suggests a strategy (C5) for assessing cloud and IoT system (CIS) dependability, availability, and cybersecurity based on the continuous collection, comparison, choice, and combination of Markov and semi-Markov models (MMs and SMMs). It proposes the systematic building of an adequate and accurate model to evaluate CISs considering (1) continuous evolution of the model(s) together with systems induced by changes in the CIS or physical and cyber environment parameters; (2) the necessity of collecting data on faults, failures, vulnerabilities, cyber-attacks, privacy violations, and patches to obtain actual data for assessment; (3) renewing the model set based on analysis of CIS operation; (4) the possibility of choice and utilizing “off-the-shelf” models with understandable techniques for their development to assure improved accuracy of assessment; (5) renewing the models during application of CIS by time, component or mixed combining, taking into consideration different operation and maintenance events. The results obtained were algorithms for data collection and analysis, choice, and combining appropriate MM and SMMs and their different types, such as multi-fragmental and multiphase models, considering changing failure rates, cyber-attack parameters, periodical maintenance, etc. To provide and verify the approach, several private and public clouds and IoT systems were researched and discussed in the context of C5 and proposed algorithms. © 2022 by the authors.","2022","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","3","6","","","","","","","","","","","","","Scopus","","","","","","","","cloud; cybersecurity; IoT; availability; Markov modelling; semi-Markov modelling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4K6S2DU","journalArticle","2022","Silva, F.A.; Brito, C.; Araújo, G.; Fé, I.; Tyan, M.; Lee, J.-W.; Nguyen, T.A.; Maciel, P.R.M.","Model-Driven Impact Quantification of Energy Resource Redundancy and Server Rejuvenation on the Dependability of Medical Sensor Networks in Smart Hospitals","Sensors","","","10.3390/s22041595","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125551176&doi=10.3390%2fs22041595&partnerID=40&md5=24cbf38a6bb22995fa90ef4b436f35af","The spread of the Coronavirus (COVID-19) pandemic across countries all over the world urges governments to revolutionize the traditional medical hospitals/centers to provide sustainable and trustworthy medical services to patients under the pressure of the huge overload on the computing systems of wireless sensor networks (WSNs) for medical monitoring as well as treatment services of medical professionals. Uncertain malfunctions in any part of the medical computing infrastructure, from its power system in a remote area to the local computing systems at a smart hospital, can cause critical failures in medical monitoring services, which could lead to a fatal loss of human life in the worst case. Therefore, early design in the medical computing infrastructure’s power and computing systems needs to carefully consider the dependability characteristics, including the reliability and availability of the WSNs in smart hospitals under an uncertain outage of any part of the energy resources or failures of computing servers, especially due to software aging. In that regard, we propose reliability and availability models adopting stochastic Petri net (SPN) to quantify the impact of energy resources and server rejuvenation on the dependability of medical sensor networks. Three different availability models (A, B, and C) are developed in accordance with various operational configurations of a smart hospital’s computing infrastructure to assimilate the impact of energy resource redundancy and server rejuvenation techniques for high availability. Moreover, a comprehensive sensitivity analysis is performed to investigate the components that impose the greatest impact on the system availability. The analysis results indicate different impacts of the considered configurations on the WSN’s operational availability in smart hospitals, particularly 99.40%, 99.53%, and 99.64% for the configurations A, B, and C, respectively. This result highlights the difference of 21 h of downtime per year when comparing the worst with the best case. This study can help leverage the early design of smart hospitals considering its wireless medical sensor networks’ dependability in quality of service to cope with overloading medical services in world-wide virus pandemics. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2022","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","4","22","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Power; Internet of things; Wireless sensor networks; Software testing; Sensitivity analysis; Internet of Things (IoT); Internet of thing; human; Stochastic systems; Computing system; Energy resources; Stochastic models; Availability; Petri nets; Computing infrastructures; reproducibility; Humans; Reliability and availability; Viruses; Hospitals; Stochastic Petri Nets; COVID-19; Early designs; hospital; Medical sensor networks; Medical services; Patient treatment; rejuvenation; Rejuvenation; Reproducibility of Results; SARS-CoV-2; Smart hospital; Stochastic Petri net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2APH4FR8","journalArticle","2022","Wang, J.C.","Understanding the energy consumption of information and communications equipment: A case study of schools in Taiwan","Energy","","","10.1016/j.energy.2022.123701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127003046&doi=10.1016%2fj.energy.2022.123701&partnerID=40&md5=ace624b945b90e3c1069e17296292f0f","Information and communications technology (ICT) equipment is often used to help conserve energy, but such equipment also requires energy to operate. This study investigated the energy consumption of ICT in 28 secondary schools (SSs) and 98 elementary schools (ESs) in Taiwan. The average annual energy consumption of ICT equipment is 28,162 kWh and 20,888 kWh per SS and ES, respectively; per unit floor area, this is estimated to be 60.5 and 27.5 Wh/m2/year, respectively. ICT accounted for 7.3%–7.7% of the total energy consumption of each school. Projection, computer, and network equipment together account for more than 90% of the total electricity consumed by ICT equipment. The total energy consumption of ICT equipment is positively correlated with school type and size. The study established three multiple regression models to investigate the total energy consumption of ICT equipment per school, per class, and per student, and the models all exhibited statistical significance. The energy consumption is highly correlated with usage time and power dissipation. Equipment procurement and energy consumption management play key roles in the energy conservation. This study may serve as references for school administrators evaluating energy conservation effectiveness. © 2022 Elsevier Ltd","2022","2025-10-22 19:07:31","2025-10-22 19:07:31","","","","","249","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Energy-consumption; Energy consumption; Energy conservation; Information and Communication Technologies; ICT; Sustainable development; spatiotemporal analysis; Information and communication; sustainable development; Case-studies; building; Communication equipments; electricity; Elementary schools; Energy audit; energy conservation; information and communication technology; multiple regression; Regression analysis; Schools; Secondary schools; Taiwan; Technology equipment; Total energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7S4IALB6","journalArticle","2021","Xu, M.; Toosi, A.N.; Buyya, R.","A Self-Adaptive Approach for Managing Applications and Harnessing Renewable Energy for Sustainable Cloud Computing","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2020.3014943","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089367582&doi=10.1109%2fTSUSC.2020.3014943&partnerID=40&md5=2f433e3f8ac589be591826822a62d110","Rapid adoption of Cloud computing for hosting services and its success is primarily attributed to its attractive features such as elasticity, availability and pay-as-you-go pricing model. However, the huge amount of energy consumed by cloud data centers makes it to be one of the fastest growing sources of carbon emissions. Approaches for improving the energy efficiency include enhancing the resource utilization to reduce resource wastage and applying the renewable energy as the energy supply. This work aims to reduce the carbon footprint of the data centers by reducing the usage of brown energy and maximizing the usage of renewable energy. Taking advantage of microservices and renewable energy, we propose a self-adaptive approach for the resource management of interactive workloads and batch workloads. To ensure the quality of service of workloads, a brownout-based algorithm for interactive workloads and a deferring algorithm for batch workloads are proposed. We have implemented the proposed approach in a prototype system and evaluated it with web services under real traces. The results illustrate our approach can reduce the brown energy usage by 21 percent and improve the renewable energy usage by 10 percent.  © 2020 IEEE.","2021","2025-10-22 19:07:31","2025-10-22 19:07:31","","544-558","","4","6","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Microservices; Cloud computing; QoS; Resource management; Cloud data centers; Web services; Resource utilizations; Carbon footprint; Environmental impact; Brownout; Carbon emissions; Renewable energies; Energy supplies; Prototype system; Renewable energy efficiency; Renewable energy resources; Self adaptive approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RL26J9N","journalArticle","2022","Melo, C.; Araujo, J.; Dantas, J.; Pereira, P.; Maciel, P.","A model-based approach for planning blockchain service provisioning","Computing","","","10.1007/s00607-021-00956-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106450322&doi=10.1007%2fs00607-021-00956-4&partnerID=40&md5=4b59752a6a9500e06bb22ca9ccf03e6a","Recently, the blockchain-as-a-service paradigm arose, and many works have evaluated the performance issues related to it. However, not as much has been done regarding Dependability attributes, which have ever been a crucial topic on service provisioning, let it be either public or private infrastructures. This paper presents the blockchain provisioning planning tool (BPPT), a framework to evaluate the availability, deployment, and maintenance costs of Hyperledger Fabric-based applications over private computational infrastructures. The BPPT uses continuous time markov chain (CTMC) and reliability block diagram (RBD) models as an evaluation method of Hyperledger Fabric’s environments and determines distributed applications’ deployment feasibility and endorsement policies related to the platform. We also present case studies that may help those interested in paradigm changes to decide whether they should migrate from old to new technology. Some of the obtained results pointed-out that the AND endorsement, which requires that all nodes sign the authenticity of a transaction, has the highest deployment and maintenance costs, as well as the lowest availability values due to operational requirements, already an OR endorsement, which needs that at least one available node signs the transaction, provides the best relationship between the evaluated metrics. The KooN endorsement (that requires that K out of N nodes signs a transaction authenticity) is a more general model that supports analyzing midterm configurations, besides the two extreme configurations, that is, to AND and OR arrangements. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.","2022","2025-10-22 19:07:31","2025-10-22 19:07:31","","315-337","","2","104","","","","","","","","","","","","","Scopus","","","","","","","","Infrastructure as a service (IaaS); Costs; Distributed applications; Authentication; Performance issues; Model based approach; Blockchain; Availability; Maintenance; Reliability block diagrams; Service provisioning; Computational infrastructure; Continuous time Markov chain; Continuous time systems; Fabric; Framework; Markov chains; Operational requirements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CW55SD2N","journalArticle","2019","Zhang, R.; Chen, Y.; Dong, B.; Tian, F.; Zheng, Q.","A Genetic Algorithm-Based Energy-Efficient Container Placement Strategy in CaaS","IEEE Access","","","10.1109/ACCESS.2019.2937553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090845423&doi=10.1109%2fACCESS.2019.2937553&partnerID=40&md5=25bbbc9a62d74b7a5a06cb7c854d05f0","Container placement (CP) is a nontrivial problem in Container as a Service (CaaS). Many works in the literature solve it by using linear server energy-consumption models. However, the solutions of using a linear model makes different CPs indistinguishable with regard to energy consumption in a homogeneous host environment that has a same amount of active hosts. As such, these solutions are energy inefficient. In this paper, we demonstrate that an energy-saving gain can be achieved by optimizing the placement of containers under a nonlinear energy consumption model. Specifically, we leverage a strategy based on genetic algorithm (GA) to search the optimal solution. Unfortunately, the conventional GA incurs performance degradation when the virtual machine (VM) resource utilization is high. In order to solve this problem, we propose an improved genetic algorithm called IGA for efficiently searching the optimal CP solution by introducing two different exchange mutation operations and constructing a function as the control parameter to selectively control the usage of the two operations. Extensive experiments are carried out under different settings, and their results show that our strategy is better than the existing CP strategies, i.e., spread and binpack, on energy efficiency target. In addition, the introduced IGA is experimentally proved to be more effective compared with the First Fit, Particle Swarm Optimization (PSO) algorithm and conventional GA. Moreover, the results validate that our proposed strategy can search new CP solutions with better fitness and alleviate the performance degradation caused by the conventional GA when the VM resource utilization is high.  © 2013 IEEE.","2019","2025-10-22 19:07:31","2025-10-22 19:07:31","","121360-121373","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Performance degradation; Energy utilization; Green computing; Virtual machine; Resource utilizations; Genetic algorithms; Placement strategy; Energy consumption model; CaaS; container placement; Control parameters; exchange mutation operation; genetic algorithm; Mutation operations; Optimal solutions; Particle swarm optimization (PSO); Particle swarm optimization algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NTYHCDPU","journalArticle","2022","Nguyen, T.A.; Kim, M.; Lee, J.; Min, D.; Lee, J.-W.; Kim, D.","Performability evaluation of switch-over Moving Target Defence mechanisms in a Software Defined Networking using stochastic reward nets","Journal of Network and Computer Applications","","","10.1016/j.jnca.2021.103267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124069551&doi=10.1016%2fj.jnca.2021.103267&partnerID=40&md5=80ab24eaaf028fc2bb7da607bd915790","It is essential to comprehend different aspects of performability of a system adopting Moving Target Defence (MTD) techniques. A number of previous works showed significant progress on security effectiveness evaluation for MTD mechanisms. While, a lesser amount of studies considered the impact of running MTD mechanisms on system dependability metrics, exposing a critical missing on the comprehension of pros and cons of MTD mechanisms in terms of security and dependability. In this paper, we present comprehensive modelling and analysis of time-based switch-over MTD strategies complying with IP shuffling techniques deployed in a Software Defined Network (SDN) using stochastic reward net (SRN). To investigate the impact of MTD strategies along with system availability on service performance metrics, we propose performability SRN models for various switch-over MTD strategies. The modelled behaviours of the switch-over MTD strategies are based on the integration of service management policies (drop/accept) with time-based switch-over policies (zero-time, fixed-time, and variable-time waiting policies) Critical performability metrics are comprehensively evaluated, including (i) system availability, downtime minutes, and Capacity-oriented Availability (COA) of a service, (ii) service throughput, (iii) response time of a job, (iv) average utilization of a server, (v) number of lost jobs, and (vi) operational cost (power consumption and business profit loss). The analysis results reveal sophisticated operational system behaviours and the impact of MTD strategies on system performability metrics. This study can help design and plan the development and adoption of MTD strategies in practice regarding the trade-offs between security and performability assurance. © 2021 Elsevier Ltd","2022","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","199","","","","","","","","","","","","","Scopus","","","","","","","","Economic and social effects; Network security; Stochastic systems; Availability; Defence mechanisms; Defense strategy; Defense techniques; Moving Target Defence; Moving target defense; Performability; Performability evaluation; Software Defined Network; Software defined networking; Software-defined networkings; Software-defined networks; Stochastic reward net; Stochastic reward nets; Time based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7GU3I3Y","conferencePaper","2020","Fieni, G.; Rouvoy, R.; Seinturier, L.","SmartWatts: Self-Calibrating Software-Defined Power Meter for Containers","","","","10.1109/CCGrid49817.2020.00-45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089066048&doi=10.1109%2fCCGrid49817.2020.00-45&partnerID=40&md5=deb42170a0a6e9d2bdabd86291a95a19","Fine-grained power monitoring of software activities becomes unavoidable to maximize the power usage efficiency of data centers. In particular, achieving an optimal scheduling of containers requires the deployment of software-defined power meters to go beyond the granularity of hardware power monitoring sensors, such as Power Distribution Units (PDU) or Intel's Running Average Power Limit (RAPL), to deliver power estimations of activities at the granularity of software containers. However, the definition of the underlying power models that estimate the power consumption remains a long and fragile process that is tightly coupled to the host machine.To overcome these limitations, this paper introduces SmartWatts: a lightweight power monitoring system that adopts online calibration to automatically adjust the CPU and DRAM power models in order to maximize the accuracy of runtime power estimations of containers. Unlike state-of-the-art techniques, SmartWatts does not require any a priori training phase or hardware equipment to configure the power models and can therefore be deployed on a wide range of machines including the latest power optimizations, at no cost. © 2020 IEEE.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","479-488","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Multitasking; Cluster computing; Energy; Power Optimization; Average power limit; Power model; Fine-grained power; On-line calibration; Optical parametric oscillators; Optimal scheduling; Power distribution units; Power estimations; State-of-the-art techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGRID 2020","","","","","","","","","","","","","","",""
"QTGR5UUQ","conferencePaper","2021","Merino, X.; Otero, C.; Nieves-Acaron, D.; Luchterhand, B.","Towards orchestration in the cloud-fog continuum","","","","10.1109/SoutheastCon45413.2021.9401822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105021688&doi=10.1109%2fSoutheastCon45413.2021.9401822&partnerID=40&md5=72d794e2096ac67db4e11b6c554282c8","The growth of the Internet-of-Things has led to a rise in the need of computing power, storage, and network resources. As more data are being generated at the edge of the networks, the cloud model that enabled the affordable, on-demand, lease of these resources is ill-fitted to handle the volume and variety of data traveling to the core of the cloud and back. Some applications further showcase the limitations of the cloud by requiring strict low-latency communication and location awareness. Fog computing has been proposed as a solution to these issues that stem from the cloud's centralization. The fog is an emerging computing paradigm, conceived as an extension to the cloud, that aims to facilitate the creation of scalable infrastructures in the vicinity of the end-user. By decentralizing resources, it promises to optimize bandwidth consumption at the core and edge of the network while reducing latency between the service and the end-user. In this paper, we identify the requirements needed to orchestrate loads in the Cloud-Fog continuum and propose an architecture, built on available, open-source, components, that orchestrates loads with consideration to their geographical needs. We provide several levels of features (DNS-like service discovery, service mesh, health checks, encryption-as-a-service, among others) available to the operator and evaluate their quality-of-service implications, with respect to network latency and bandwidth, when compared to a simple deployment baseline. © 2021 IEEE.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","2021-March","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Cloud-computing; Internet of things; Computer architecture; Network architecture; Storage resources; Architecture; Bandwidth; End-users; Computing power; Digital storage; Cryptography; Fog computing; IoT; Orchestration; Fog; Latency; Power networks; Power resources; Power storage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Conference Proceedings - IEEE SOUTHEASTCON","","","","","","","","","","","","","","",""
"5GVJIWC3","journalArticle","2021","Nguyen, T.A.; Min, D.; Choi, E.; Lee, J.-W.","Dependability and Security Quantification of an Internet of Medical Things Infrastructure Based on Cloud-Fog-Edge Continuum for Healthcare Monitoring Using Hierarchical Models","IEEE Internet of Things Journal","","","10.1109/JIOT.2021.3081420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107208881&doi=10.1109%2fJIOT.2021.3081420&partnerID=40&md5=fd55804226f60d1f43322f8ac6c140e4","Rising aggressive virus pandemics urge to conduct studies on dependability and security of modern computing systems to secure autonomous and continuous operations of healthcare systems. In that regard, we propose to quantify dependability and security measures of an Internet-of-Medical Things (IoMT) infrastructure relied on an integrated physical architecture of cloud/fog/edge (CFE) computing paradigms in this article. We propose a reliability/availability quantification methodology for the IoMT infrastructure using a hierarchical model of three levels: 1) fault tree (FT) of overall IoMT infrastructure consisting of CFE member systems; 2) FT of subsystems within CFE member systems; and 3) continuous-time Markov chain (CTMC) models of components/devices in the subsystems. We incorporate a number of failure modes for the underlying subsystems, including Mandel-bug related failures and non-Mandel bugs related failure, as well as failures due to cyber-security attacks on software subsystems. Five case-studies of configuration alternation and four operational scenarios of the IoMT infrastructure are considered to comprehend the dependability characteristics of the IoMT physical infrastructure. The metrics of interest include reliability over time, steady state availability (SSA), sensitivity of SSA wrt. selected mean time to failure-equivalent (MTTFeq) and mean time to recovery-equivalent (MTTReq), and sensitivity of SSA wrt. frequencies of cyber-security attacks on software subsystems. The analysis results help comprehend operational behaviors and properties of a typical IoMT infrastructure. The findings of this study can improve the design and implementation of real-world IoMT infrastructures consisting of cloud, fog, and edge computing paradigms.  © 2014 IEEE.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","15704-15748","","21","8","","","","","","","","","","","","","Scopus","","","","","","","","Design and implementations; cloud computing; Program debugging; Hierarchical systems; fog computing; edge computing; Computing paradigm; Availability; reliability; Health care; Computer viruses; Continuous operation; cyber security attack; e-health monitoring; Health-care system; Healthcare monitoring; hierarchical model; Hierarchical model; Internet of Medical Things (IoMT); Physical architecture; Security of data; Software subsystem; Viruses","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMTTQWEV","conferencePaper","2021","Camboim, K.; Ferreira, J.; Melo, C.; Araujo, J.; Alencar, F.; MacIel, P.","Dependability and Sustainability Evaluation of Data Center Electrical Architectures","","","","10.1109/SysCon48628.2021.9447132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111427864&doi=10.1109%2fSysCon48628.2021.9447132&partnerID=40&md5=37bbb7c8fbaf87657f14801ed5cf6cc1","Faced with the demand to maintain the high availability of data centers (DC), companies are being pressured to seek sustainable alternatives, given that these infrastructures consume a total of 1% of all electricity worldwide [1]. In a time of pandemic (COVID-19), when the digital economy has assumed an even greater share of representativeness, DCs and telecommunications companies need to meet the requisitions of 'everything-as-a-service'. Linked to this are the large amounts of carbon dioxide (CO2) emitted into the atmosphere due to the production and consumption of energy caused by these infrastructures. Given the above, this paper proposes models of energy flow and reliability block diagrams to quantity the environmental impact from different raw materials used to feed the data center loads and computes sustainability and dependability metrics for the entire DC's power infrastructure. According to the specifications for classifying the tiers, this study's hybrid modeling is performed to represent four different electrical architectures. From the model evaluations, we compare whether the availability achieved corresponds to the minimum availability suggested for each tier and show the emissions of CO2 in the atmosphere for each tier over a year. Besides, we apply a parametric sensitivity analysis technique to identify the most critical components for the modeled systems' availability.  © 2021 IEEE.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Critical component; Energy Efficiency; High availability; Sensitivity analysis; Environmental impact; Sustainable development; Sustainability; Carbon dioxide; Data Center; Reliability block diagrams; Dependability; Electrical architecture; Energy Flow Model; Parametric sensitivity analysis; Power infrastructures; Production and consumption; Sensitivity Analysis; Sustainability evaluations; Telecommunication industry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","15th Annual IEEE International Systems Conference, SysCon 2021 - Proceedings","","","","","","","","","","","","","","",""
"7PR5XYCT","conferencePaper","2019","De Alwis, A.A.C.; Barros, A.; Fidge, C.; Polyvyanyy, A.","Availability and scalability optimized microservice discovery from enterprise systems","","","","10.1007/978-3-030-33246-4_31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077848871&doi=10.1007%2f978-3-030-33246-4_31&partnerID=40&md5=d216f80f69e6a052e795a7c25c3d7174","Microservices have been introduced to industry as a novel architectural design for software development in cloud-based applications. This development has increased interest in finding new methodologies to migrate existing enterprise systems into microservices to achieve desirable performance characteristics such as high scalability, high availability, high cohesion and low coupling. A key challenge in this context is discovering microserviceable components with promising characteristics from a complex monolithic code base while predicting their resulting characteristics. This paper presents a technique to support such re-engineering of an enterprise system based on the fundamental mechanisms for structuring its architecture, i.e., business objects managed by software functions and their interactions. The technique relies on queuing theory and business object relationship analysis. A prototype for microservice discovery and characteristic analysis was developed using the NSGA II software clustering and optimization technique and has been validated against two open-source enterprise systems, SugarCRM and ChurchCRM. Our experiments demonstrate that the proposed approach can recommend microservice design which improves scalability, availability and execution efficiency of the system while achieving high cohesion and low coupling in software modules. © Springer Nature Switzerland AG 2019.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","496-514","","","11877 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Open systems; Software design; Computation theory; Cloud-based applications; Optimization techniques; Scalability; Software prototyping; Multi agent systems; Semantics; Reengineering; Queueing theory; Performance characteristics; Characteristic analysis; Enterprise resource planning; Enterprise software; Microservice discovery; Open source enterprise systems; System optimization; System optimizations; System re-engineering; System reengineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"7ET56N9L","conferencePaper","2020","Jagadeesan, L.J.; Mendiratta, V.B.","When Failure is (Not) an Option: Reliability Models for Microservices Architectures","","","","10.1109/ISSREW51248.2020.00031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099866678&doi=10.1109%2fISSREW51248.2020.00031&partnerID=40&md5=02036281c8d341d90b2350c3db5cf12e","Modern application development and deployment is rapidly evolving to microservices based architectures, in which thousands of microservices communicate with one another and can be independently scaled and updated. While these architectures enable flexibility of deployment and frequency of upgrades, the naive use of thousands of communicating and frequently updated microservices can significantly impact the reliability of applications. To address these challenges, service meshes are used to rapidly detect and respond to microservices failures without necessitating changes to the microservices themselves. However, there are inherent tradeoffs that service meshes must make with regards to how quickly they assume a microservice has failed and the subsequent impact on overall application reliability. We present in this paper a modeling framework for microservices and service mesh reliability that takes these tradeoffs into account. Index Terms-microservices, service mesh, sidecars, circuit breakers, reliability, availability, resilience, reliability models, probabilistic model checking, PRISM.  © 2020 IEEE.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","19-24","","","","","","","","","","","","","","","","Scopus","","","","","","","","Commerce; Timing circuits; Mesh generation; Application deployment; Circuit-breakers; Electric circuit breakers; Availability; Reliability; Reliability modelling; Application reliabilities; Model checking; Probabilistic model checking; Probabilistic model-checking; Application development; Microservice, service mesh, sidecar, circuit breaker, reliability, availability, resilience, reliability model, probabilistic model checking, PRISM; microservices, service mesh, sidecars, circuit breakers, reliability, availability, resilience, reliability models, probabilistic model checking, PRISM; Modelling framework; Modern applications; Prisms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE 31st International Symposium on Software Reliability Engineering Workshops, ISSREW 2020","","","","","","","","","","","","","","",""
"UMHKSF2Q","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180880814&partnerID=40&md5=00baa7e11f40f064630cf3275b10f435","","","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4MSW4CV","journalArticle","","","","KubeEdge Kubeedge Kubernetes Native Edge Computing Framework","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180828009&partnerID=40&md5=1c81b4be81af0c90297ebe9d6f3257e9","","","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93VKGDS7","conferencePaper","2020","Hou, X.; Li, C.; Liu, J.; Zhang, L.; Hu, Y.; Guo, M.","Ant-man: Towards agile power management in the microservice era","","","","10.1109/SC41405.2020.00082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102333512&doi=10.1109%2fSC41405.2020.00082&partnerID=40&md5=a75251d6768fbf25060880aa4c61abda","The emerging trend of decomposing cloud applications into microservices has raised new questions about managing the performance/power trade-off of a datacenter at microsecondscale. We introduce ANT-Man, an Auto, Native and Transparent power Management framework that can exploit fine-grained microservice variability for system efficiency. To achieve this, ANT-Man abstracts away two major sources of latency overhead in traditional hierarchical power management frameworks. First, ANT-Man proposes an auto power budgeting scheme for reducing the power coordination latency at the datacenter level. It can proactively determine the power budget tailored to each individual microservice. Second, ANT-Man proposes a native and transparent power control scheme to overcome the power configuration latency for each microservice. It enables super-fast power budget enforcement with nanosecond-scale performance scaling. Extensive experiments on our prototyped system show that ANT-Man could slash power consumption by ; 7.8∼ 43.5\%; and in the meantime reduce the ;95th; tail latency by ; 9.7∼ 12.5\%; compared to existing techniques. © 2020 IEEE.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","2020-November","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Cloud applications; Economic and social effects; Budget control; power management; microservice; Management frameworks; variability; Emerging trends; Hierarchical power management; Power budgeting; Power configuration; Power control; Power control schemes; System efficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference for High Performance Computing, Networking, Storage and Analysis, SC","","","","","","","","","","","","","","",""
"KVN7T7B3","bookSection","2021","Pinheiro, T.; Oliveira, D.; Matos, R.; Silva, B.; Pereira, P.; Melo, C.; Oliveira, F.; Tavares, E.; Dantas, J.; Maciel, P.","The mercury environment: A modeling tool for performance and dependability evaluation","Intelligent Environments 2021: Workshop Proceedings of the 17th International Conference on Intelligent Environments","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114148193&doi=10.3233%2fAISE210075&partnerID=40&md5=8e1be42c2a2e44e835866092d5b93d8d","It is important to be able to judge the performance or dependability metrics of a system and often we do so by using abstract models even when the system is in the conceptual phase. Evaluating a system by performing measurements can have a high temporal and/or financial cost, which may not be feasible. Mathematical models can provide estimates about system behavior and we need tools supporting different types of formalisms in order to compute desired metrics. The Mercury tool enables a range of models to be created and evaluated for supporting performance and dependability evaluations, such as reliability block diagrams (RBDs), dynamic RBDs (DRBDs), fault trees (FTs), stochastic Petri nets (SPNs), continuous and discrete-time Markov chains (CTMCs and DTMCs), as well as energy flow models (EFMs). In this paper, we introduce recent enhancements to Mercury, namely new SPN simulators, support to prioritized timed transitions, sensitivity analysis evaluation, several improvements to the usability of the tool, and support to DTMC and FT formalisms. © 2021 The authors and IOS Press.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","16-25","","","29","","","","","","","","","","","","","Scopus","","","","","","","","Simulation; Models; DTMC; Fault tree; Mercury","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K7QYST6Z","conferencePaper","2019","Bakhshi, Z.; Rodriguez-Navas, G.; Hansson, H.","Dependable Fog Computing: A Systematic Literature Review","","","","10.1109/SEAA.2019.00066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075999858&doi=10.1109%2fSEAA.2019.00066&partnerID=40&md5=06d0a2fe943726d74d351081504b333e","Fog computing has been recently introduced to bridge the gap between cloud resources and the network edge. Fog enables low latency and location awareness, which is considered instrumental for the realization of IoT, but also faces reliability and dependability issues due to node mobility and resource constraints. This paper focuses on the latter, and surveys the state of the art concerning dependability and fog computing, by means of a systematic literature review. Our findings show the growing interest in the topic but the relative immaturity of the technology, without any leading research group. Two problems have attracted special interest: Guaranteeing reliable data storage/collection in systems with unreliable and untrusted nodes, and guaranteeing efficient task allocation in the presence of varying computing load. Redundancy-based techniques, both static and dynamic, dominate the architectures of such systems. Reliability, availability and QoS are the most important dependability requirements for fog, whereas aspects such as safety and security, and their important interplay, have not been investigated in depth. © 2019 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","395-403","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Systematic literature review; Digital storage; Fog computing; Fog Computing; Fault tolerance; Fog; Dependability; Dependability means; Dependability Requirements; Dependability threats; Dependable Fog; Systematic Literature Review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 45th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2019","","","","","","","","","","","","","","",""
"SXVFNHKC","journalArticle","2018","Peng, L.; Dhaini, A.R.; Ho, P.-H.","Toward integrated Cloud–Fog networks for efficient IoT provisioning: Key challenges and solutions","Future Generation Computer Systems","","","10.1016/j.future.2018.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048705614&doi=10.1016%2fj.future.2018.05.015&partnerID=40&md5=f5271da5e66941c979b89df122a3de50","Fog computing has been proposed as one of the promising technologies for the construction of a scalable network infrastructure in the user's vicinity, with the purpose of serving the tremendous amount of daily generated latency-sensitive Internet-of-Things (IoT) data. In provisioning the emerging IoT data in addition to the legacy Cloud services, the Cloud and Fog form a natural continuum of one another and the integration of these two key technologies would offer a promising infrastructure full with IoT resources for IoT data provisioning. In this article, we present iCloudFog, a reconfigurable architecture that enables an agile integration of Fog and Cloud networks. iCloudFog allows to construct different Fog types (i.e., wireless, wired, or hybrid) to fit the different characteristics of IoT devices and data, and Fog nodes. Due to its nature, iCloudFog presents several unique key research challenges that have not yet been addressed in existing literatures, such as network dimensioning and configuration, resource management/QoS, security/privacy, and positioning/localization. We discuss these challenges and suggest promising approaches to resolve them. Effective design and implementation of solutions based on the suggested approaches would allow iCloudFog to play a salient role towards the successful provisioning of future IoT applications and services. © 2018","2018","2025-10-22 19:07:32","2025-10-22 19:07:32","","606-613","","","88","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Resource management; Internet of things; Edge computing; Internet of Things (IOT); Fog computing; Research challenges; Fog; Agile integration; Data provisioning; Effective designs; Network dimensioning; Reconfigurable architectures; Scalable networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJ66N78C","journalArticle","2019","Kumar, M.; Sharma, S.C.; Goel, A.; Singh, S.P.","A comprehensive survey for scheduling techniques in cloud computing","Journal of Network and Computer Applications","","","10.1016/j.jnca.2019.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067581485&doi=10.1016%2fj.jnca.2019.06.006&partnerID=40&md5=3cdd56761e3ab596c9f85d070f7fad2f","Resource scheduling becomes the prominent issue in cloud computing due to rapid growth of on demand request and heterogeneous nature of cloud resources. Cloud provides dynamism, uncertainty and elasticity based services to users in pay-as-you-go fashion over the internet. In recent decade, increase in requests (diverse and complex applications) for cloud services is raising the workload in cloud environment. Inefficient scheduling techniques face the challenges of resources being over utilized and underutilized (imbalanced) which leads to either degradation in service performance (in case of over utilized) or wastage of cloud resources (in case of underutilized). The basic idea behind the scheduling is to distribute tasks (diverse and complex nature) among the cloud resources in such a manner that scheduling algorithm avoids the problem of imbalance. Scheduling algorithm should also optimize the key performance indicator parameters like response time, makespan time, reliability, availability, energy consumption, cost, resource utilization etc. To fulfill the above-mentioned objective, many state of art scheduling algorithms have been proposed based upon heuristic, meta-heuristic and hybrid, reported in the literature. This paper provides the systematic review as well as classification of proposed scheduling techniques along with their advantages and limitations. We hope that our systematic and comprehensive survey work as a stepping stone for new researchers in the field of cloud computing and will be helpful for further development of scheduling technique. © 2019","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","1-33","","","143","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Cloud computing; Energy utilization; Surveys; Benchmarking; Complex applications; Virtual machines; Heuristic algorithms; Virtual machine; Scheduling algorithms; Resource utilizations; Scheduling techniques; Resource provisioning; Resource scheduling; Resource-scheduling; Metaheuristic; Heuristic; Key performance indicators; meta-Heuristic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSLYAUY4","conferencePaper","2021","Jeffery, A.; Howard, H.; Mortier, R.","Rearchitecting Kubernetes for the Edge","","","","10.1145/3434770.3459730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104662456&doi=10.1145%2f3434770.3459730&partnerID=40&md5=5affbaa5a658a55090c90324acaa80f5","Recent years have seen Kubernetes emerge as a primary choice for container orchestration. Kubernetes largely targets the cloud environment but new use cases require performant, available and scalable orchestration at the edge. Kubernetes stores all cluster state in etcd, a strongly consistent key-value store. We find that at larger etcd cluster sizes, offering higher availability, write request latency significantly increases and throughput decreases similarly. Coupled with approximately 30% of Kubernetes requests being writes, this directly impacts the request latency and availability of Kubernetes, reducing its suitability for the edge. We revisit the requirement of strong consistency and propose an eventually consistent approach instead. This enables higher performance, availability and scalability whilst still supporting the broad needs of Kubernetes. This aims to make Kubernetes much more suitable for performance-critical, dynamically-scaled edge solutions.  © 2021 Owner/Author.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","7-12","","","","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; Cloud environments; Cluster sizes; Cluster state; CRDTs; edge; eventual consistency; Key-value stores; orchestration; Strong consistency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EdgeSys 2021 - Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking, Part of EuroSys 2021","","","","","","","","","","","","","","",""
"GMK22HBD","journalArticle","2023","Charfeddine, L.; Umlai, M.","ICT sector, digitization and environmental sustainability: A systematic review of the literature from 2000 to 2022","Renewable and Sustainable Energy Reviews","","","10.1016/j.rser.2023.113482","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165004761&doi=10.1016%2fj.rser.2023.113482&partnerID=40&md5=b031435af62f65deca19305518513d70","In line with an intensified call for reducing greenhouse emissions and curbing the effects of climate change, scientists and experts have looked to information communication technology (ICT) and digitization as critical tools for the more efficient use and production of energy. Consequently, research on ICT/digitization and their impact on environmental sustainability has witnessed exponential growth in the last few decades. This study provides a systematic review of the relationship between ICT/digitization and environmental sustainability over the period from January 2000 to April 2022. It aimed to improve our understanding of the different theories and channels governing the ICT/digitization–environmental sustainability nexus, to provide an in-depth analysis and discussion of the trends and main empirical findings of the reviewed articles, and to highlight key avenues for future research. In total, 166 scientific articles examining 297 associations between ICT/digitization and environmental sustainability were selected for this review. The results revealed that most of the studies have used measures based on climate change and air pollution for environmental sustainability, and traditional ICT/digitization measures, e.g., mobile phone subscriptions and internet users. The results also showed that although most studies found evidence for ICT/digitization improving environmental sustainability, evidence for a negative association is concentrated in studies on the ’Group of’ countries. The results also revealed a scarcity of studies investigating nonlinear relationships between ICT/digitization and environmental sustainability. © 2023 The Author(s)","2023","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","184","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy; Climate change; Systematic Review; ICT; Environmental sustainability; Sustainable development; In-depth analysis; Digitisation; Digitization; Empirical findings; Exponential growth; Greenhouse emissions; Information communication technology; Systematic review; Technology sectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7UML943","journalArticle","2020","Alli, A.A.; Alam, M.M.","The fog cloud of things: A survey on concepts, architecture, standards, tools, and applications","Internet of Things (Netherlands)","","","10.1016/j.iot.2020.100177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092163275&doi=10.1016%2fj.iot.2020.100177&partnerID=40&md5=c4fc4f8284cdc678e7dc414a3f88f461","The Fog computing paradigms are becoming popular means of utilizing resources optimally by the IoT devices, extending quality of service to the vicinity of the user, and achieve fast processing in the IoT-cloud ecosystems. Fog models allow fast processing of data, easy to reach storage, and reduce bulky network transition. The inefficiencies of the cloud inspire unnecessarily big data to be sent to the backhaul of the network, which incapacitates the cloud infrastructure. Fog computing addresses the limitation of the cloud systems by improving robustness, efficiency, and performance of cloud infrastructure. The need to process some of the big data produced at the peripheral of the network using keen techniques in the fog—cloud ecosystems is a key to new interesting architectures filed in the recent literature. These architectures provide new business opportunities that drive the Internet of things devices to function according to users’ demands. In this paper, we provide an extensive survey on Fog—Edge computing to give a foundation to solutions proposed in studies that involve IoT—Fog—Cloud ecosystems. This is done by providing insights of new research aspects filed, the state—of—art in fog computing architectures, standards, tools and applications. We project the future development trends and provide open issues in fog cloud of things. This will focus developers to develop applications that work well in a cloud-based controlled ecosystem across a range of network terminals. © 2020 Elsevier B.V.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","9","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Content delivery network; Big data analytics; Computational offloading; Fogging; IoT—Fog—Cloud ecosystems; Simulation tools; Smart city applications; Smart farm applications; Web performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WIRB3K8X","journalArticle","2023","Carrión, C.","Kubernetes Scheduling: Taxonomy, Ongoing Issues and Challenges","ACM Computing Surveys","","","10.1145/3539606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134495149&doi=10.1145%2f3539606&partnerID=40&md5=c5f0f6ee1f5012fc705831648624a532","Continuous integration enables the development of microservices-based applications using container virtualization technology. Container orchestration systems such as Kubernetes, which has become the de facto standard, simplify the deployment of container-based applications. However, developing efficient and well-defined orchestration systems is a challenge. This article focuses specifically on the scheduler, a key orchestrator task that assigns physical resources to containers. Scheduling approaches are designed based on different Quality of Service (QoS) parameters to provide limited response time, efficient energy consumption, better resource utilization, and other things. This article aims to establish insight knowledge into Kubernetes scheduling, find the main gaps, and thus guide future research in the area. Therefore, we conduct a study of empirical research on Kubernetes scheduling techniques and present a new taxonomy for Kubernetes scheduling. The challenges, future direction, and research opportunities are also discussed.  © 2022 Association for Computing Machinery.","2023","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","7","55","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Containers; Kubernetes; Energy utilization; containers; Taxonomies; Energy-consumption; Continuous integrations; scheduling; Virtualization technologies; Orchestration; orchestration; Physical resources; survey; De facto standard; Issues and challenges; Quality of Service parameters; Time-efficient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6K26L4TJ","journalArticle","2022","Tran, M.-N.; Vu, X.T.; Kim, Y.","Proactive Stateful Fault-Tolerant System for Kubernetes Containerized Services","IEEE Access","","","10.1109/ACCESS.2022.3209257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139440476&doi=10.1109%2fACCESS.2022.3209257&partnerID=40&md5=c2db74083042f447eb46fb512b14385f","Recently, the development of Kubernetes (K8s) containerization platform has enabled cloud-based, lightweight, highly scalable, and agile services in both general and telco use-cases. Ensuring high availability, reliable and continuous containerized services is a major requirement of service providers to provide fault-tolerance, transparent service experiences to end-users. To satisfy this requirement, fault prediction and proactive stateful service recovery features must be applied in cloud systems. Prior proactive failure recovery approaches mostly focused on either improving fault prediction performance based on different machine learning time series forecasting techniques or optimizing recovery service placement after fault prediction. However, a mechanism that enables stateful containerized service migration from the predicted faulty node to the healthy destination node has not been studied. Service migration in previous proactive works is only simulated or performed by virtual machine (VM) migration techniques. In this paper, we propose a proactive stateful fault-tolerant system for K8s containerized services that pipelines a Bidirectional Long Short-Term Memory (Bi-LSTM) fault prediction framework and a novel K8s stateful service migration mechanism for service recovery. Experimental results show how the Bi-LSTM model improved prediction performance against other time-series forecasting models used prior proactive works. We then combined the Bi-LSTM fault prediction framework with both the default K8s and our stateful migration mechanisms. The comparison between these two proactive systems proves our system efficiency in terms of reducing Quality of Service (QoS) violation percentage and service recovery time.  © 2013 IEEE.","2022","2025-10-22 19:07:32","2025-10-22 19:07:32","","102181-102194","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Containers; Forecasting; Kubernetes; Quality-of-service; Containerization; Predictive models; Learning systems; Long short-term memory; Time series; Fault tolerance; Fault-tolerant; Recovery; Prediction algorithms; Fault prediction; Fault- tolerant systems; Proactive fault; proactive fault-tolerant; Proactive fault-tolerant","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XC7LW98Q","journalArticle","2020","Lyu, Z.; Wei, H.; Bai, X.; Lian, C.","Microservice-Based Architecture for an Energy Management System","IEEE Systems Journal","","","10.1109/JSYST.2020.2981095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097045354&doi=10.1109%2fJSYST.2020.2981095&partnerID=40&md5=2221cf4b263ef6a0faf73588773ca706","This article proposes a microservice-based architecture for an energy management system (MS-EMS) to address the fragility, poor flexibility, and hardware dependence of EMSs. Compared with the service-oriented architecture (SOA), the proposed architecture can significantly improve the load performance and scalability of an EMS through fine-grained decomposition of the system and decentralized data management. Container and cluster technologies are used to manage the microservices. A $k$-fault $(k\geq 2)$-tolerant model is proposed to improve the reliability of the MS-EMS. The model employs containerized microservices as essential components to achieve a parallel connection of the essential components using the horizontal-scale technology of the containers. On the other hand, a MILP model-based algorithm for managing computing resources is also suggested. By minimizing the number of worker nodes of the cluster, where the MS-EMS is deployed, we can improve the utilization of the computing resources and avoid unnecessary costs. The result of the performance analysis showed that the reliability of the MS-EMS is $99.99965625{\%}$, which is two orders and one order of magnitude higher than those of the existing EMSs and the SOA-based EMS (S-EMS), respectively. Moreover, the cost of the MS-EMS is also lower than those of the existing EMSs and S-EMSs. The proposed architecture is implemented in a real-power system and has shown favorable operation performances, indicating a promising prospect for future applications.  © 2007-2012 IEEE.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","5061-5072","","4","14","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Containers; Information management; resource management; Container; Cluster computing; Computer architecture; Future applications; Energy management; Integer programming; Proposed architectures; Information services; Service oriented architecture (SOA); microservice; Minimizing the number of; reliability; Energy management systems; Reliability analysis; Cluster technology; Electric connectors; energy management system (EMS); Operation performance; Parallel connections; Real power systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92V83DEN","journalArticle","2021","Liu, Z.; Fan, G.; Yu, H.; Chen, L.","An Approach to Modeling and Analyzing Reliability for Microservice-Oriented Cloud Applications","Wireless Communications and Mobile Computing","","","10.1155/2021/5750646","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114641496&doi=10.1155%2f2021%2f5750646&partnerID=40&md5=df54c466196e8f328d00ace86756fe8d","Microservice architecture is a cloud-native architectural style, which has attracted extensive attention from the scientific research and industry communities to benefit independent development and deployment. However, due to the complexity of cloud-based platforms, the design of fault-tolerant strategies for microservice-oriented cloud applications becomes challenging. In order to improve the quality of service, it is essential to focus on the microservice with more criticality and maximize the reliability of the entire cloud application. This paper studies the modeling and analysis of service reliability in the cloud environment. Firstly, a formal description language is defined to model microservice, user request, and container accurately. Secondly, the reliability analysis is conducted to measure a critical microservice's fluctuation and vibration attributes within a period, and the related properties of the constructed model are analyzed. Thirdly, a fault-tolerant strategy with redundancy operation has been proposed to optimize cloud application reliability. Finally, the effectiveness of the method is verified by experiments. The simulation results show that the algorithm obtains the maximum benefits and has high performance through several experiments. © 2021 Zheng Liu et al.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","2021","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud environments; Industrial research; Architectural style; Fault tolerance; Redundancy; Cloud based platforms; Fault-tolerant strategy; Formal description language; Model and analysis; Reliability analysis; Scientific researches; Service reliability; Vibration analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TS49FYFW","journalArticle","2021","Menouer, T.","KCSS: Kubernetes container scheduling strategy","Journal of Supercomputing","","","10.1007/s11227-020-03427-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091507109&doi=10.1007%2fs11227-020-03427-3&partnerID=40&md5=018c2cbd20c3c39c7937e54bab2e926f","The Kubernetes framework is a well-known open-source container-orchestration system widely used in industrial and academic fields. In this paper, we introduce a new Kubernetes Container Scheduling Strategy called KCSS. The goal of the KCSS is to optimize the scheduling of several containers submitted online by users to improve the performance concerning the user need in terms of makespan and the cloud provider need in terms of power consumption. In the literature, several container scheduling strategies are proposed. Each one uses a dedicated approach to select one node from the node set supplied by the cloud infrastructure. Then, this node welcomes the newly submitted container. The majority of the proposed container scheduling strategies select for each newly submitted container a node based on a single criteria, such as the number of running containers or the amount of available resources in each node. However, the scheduling based on a single criterion downgrades the performance because the scheduler has a limited vision of the state of the cloud infrastructure and the user need. The contribution of our KCSS is to introduce a multi-criteria selection of the node. This approach provides the scheduler with a global vision about the state of the cloud and the user’s need. The idea is to select from each newly submitted container the best node, with a good compromise between hybrid criteria related to the cloud infrastructure and the user need. In the KCSS, we consider six key criteria: (1) the CPUs utilization rate in each node; (2) the memory utilization rate in each node; (3) the disk utilization rate in each node; (4) the power consumption of each node; (5) the number of running containers in each node; and (6) the time of transmitting the image selected by the user for its container. In our context, the KCSS is based on a multi-criteria decision analysis algorithm to aggregate all criteria in a single rank. Then, select the node which has the highest rank to execute the new submitted container. The multi-criteria algorithm used by KCSS is the Technique for the Order of Prioritisation by Similarity to Ideal Solution (TOPSIS) algorithm. The KCSS is implemented in Go language inside the Kubernetes framework with minimal changes to be used easily with the next Kubernetes versions. The experimental results show that the KCSS improves the performance under different scenarios compared to other container scheduling strategies. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","4267-4293","","5","77","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Electric power utilization; Containers; Cloud computing; Program processors; Open systems; Green computing; Cloud infrastructures; Cloud providers; Memory utilization; Container scheduling; Utilization rates; Container technology; Disk utilization; Ideal solutions; Multi-criteria decision analysis; Multi-criteria scheduling; On-line scheduling; Power consumption in scheduling; Scheduling strategy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32E6K63K","journalArticle","2021","Jazayeri, F.; Shahidinejad, A.; Ghobaei-Arani, M.","A latency-aware and energy-efficient computation offloading in mobile fog computing: a hidden Markov model-based approach","Journal of Supercomputing","","","10.1007/s11227-020-03476-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094629653&doi=10.1007%2fs11227-020-03476-8&partnerID=40&md5=b520d2cbc86993ccecc191c09761cc55","In recent years, Fog Computing (FC) is known as a good infrastructure for the Internet of Things (IoT). Using this architecture for the mobile applications in the IoT is named the Mobile Fog Computing (MFC). If we assume that an application includes some modules, thus, these modules can be sent to the Fog or Cloud layer because of the resource limitation or increased runtime at the mobile. This increases the efficiency of the whole system. As data is entered sequentially, and the input is given to the modules, the number of executable modules increases. So, this research is conducted to find the best place in order to run the modules that can be on the mobile, Fog, or Cloud. According to the proposed method, when the modules arrive at gateway, then, a Hidden Markov model Auto-scaling Offloading (HMAO) finds the best destination to execute the module to create a compromise between the energy consumption and execution time of the modules. The evaluation results obtained regarding the parameters of the energy consumption, execution cost, delay, and network resource usage shows that the proposed method on average is better than the local execution, First-Fit (FF), and Q-learning based method. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","4887-4916","","5","77","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Evaluation results; Energy efficient; Energy utilization; Internet of things; Gateways (computer networks); Mobile applications; Offloading; Fog computing; Reinforcement learning; Network resource; Fog; Execution costs; Hidden Markov model; Hidden Markov models; Internet of thing (IOT); Latency-aware; Mobile fog computing; Resource limitations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R9GTL649","conferencePaper","2020","Luntovskyy, A.; Shubyn, B.","Highly-Distributed Systems Based on Micro-Services and their Construction Paradigms","","","","10.1109/TCSET49122.2020.235378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086306642&doi=10.1109%2fTCSET49122.2020.235378&partnerID=40&md5=c71f3b2ed287cad4bd9b4425fa7ab366","A definition for the HDS, as well as the demarcation to conventional distributed systems, were given. Typical architectures for HDS were discussed which affect increasing of QoS and of so-called QoE (Quality of Experience). The distinguishing features for HDS are clearly formulated. The advanced SWT (Software Technologies) approaches lead to use of young flexible service-oriented architectures like Micro-Services, which provide higher performance and small latencies, as well as better scalability, energy-efficiency and autarky.One possible option in the frame of HDS regarding security, privacy, authentication and compulsoriness of workflow steps, modules and service execution for such apps Blockchain and Smart Contracting are. The theoretical issues are proven via the represented examples and case studies. © 2020 IEEE.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","7-14","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Distributed systems; DevOps; Network security; Information services; Micro services; Distributed database systems; Blockchain; Service oriented architecture (SOA); Quality of experience (QoE); Micro-Services; Agile Process Models; Highly-Distributed Systems; Quality of Experience; Scrum; Service-Oriented Architectures; Case-studies; Conway's Law; Flexible service; Service execution; Software technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 15th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering, TCSET 2020","","","","","","","","","","","","","","",""
"R4MQKMIR","journalArticle","2020","Murtaza, F.; Akhunzada, A.; Islam, S.U.; Boudjadar, J.; Buyya, R.","QoS-aware service provisioning in fog computing","Journal of Network and Computer Applications","","","10.1016/j.jnca.2020.102674","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084937424&doi=10.1016%2fj.jnca.2020.102674&partnerID=40&md5=eb3d7970ee7080e7d501c4f766f6c106","Fog computing has emerged as a complementary solution to address the issues faced in cloud computing. While fog computing allows us to better handle time/delay-sensitive Internet of Everything (IoE) applications (e.g. smart grids and adversarial environment), there are a number of operational challenges. For example, the resource-constrained nature of fog-nodes and heterogeneity of IoE jobs complicate efforts to schedule tasks efficiently. Thus, to better streamline time/delay-sensitive varied IoE requests, the authors contributes by introducing a smart layer between IoE devices and fog nodes to incorporate an intelligent and adaptive learning based task scheduling technique. Specifically, our approach analyzes the various service type of IoE requests and presents an optimal strategy to allocate the most suitable available fog resource accordingly. We rigorously evaluate the performance of the proposed approach using simulation, as well as its correctness using formal verification. The evaluation findings are promising, both in terms of energy consumption and Quality of Service (QoS). © 2020","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","165","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Energy utilization; Fog computing; Quality control; Task-scheduling; Fog; Smart grid; Adaptive learning; Adversarial environments; Internet of everything; LRFC; Operational challenges; Optimal strategies; Quality of experience; Service provisioning; Smart layers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J79HEDPP","journalArticle","2022","Liu, Z.; Yu, H.; Fan, G.; Chen, L.","Reliability modelling and optimization for microservice-based cloud application using multi-agent system","IET Communications","","","10.1049/cmu2.12371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126098914&doi=10.1049%2fcmu2.12371&partnerID=40&md5=9cb89b082c15ae31fc8cc04ba64c8d4b","In the process of the continuous development of the Internet of Things, cloud computing has been applied in many fields, how to guarantee the quality of service, such as low latency, high bandwidth, high reliability etc., has become a challenging problem. This paper proposes a method to model and optimize reliability for microservice-based cloud applications using multi-agent system (MAS), thus maximizing the reliability of cloud computing and dynamically scheduling microservices to minimize the delay within the budget. Firstly, a dynamic microservice scheduling scheme is proposed to provide efficient computing services by using MAS. A hierarchical cloud computing model is formed by predicated Petri net (PrT net) and the properties of constructed model are analysed. Secondly, agents have been utilized to describe the essential characteristics of microservice scheduling process in the cloud applications. The partial critical path (PCP) aims to maximize the reliability of cloud applications under the limitation of budget and meet the user-defined deadline. Finally, the proposed PCPRO algorithm has been applied to cloud environment, which is suitable for different scientific workflows in the cloud computing environment. The effectiveness of this method is verified by simulation, the experiment results show the effectiveness of the proposed method. © 2022 The Authors. IET Communications published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","2022","2025-10-22 19:07:32","2025-10-22 19:07:32","","1182-1199","","10","16","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Cloud computing; Cloud-computing; Cloud applications; Quality-of-service; Budget control; Low latency; Multi agent systems; Continuous development; High bandwidth; High reliability; Modeling and optimization; Petri nets; Reliability; Reliability modelling; Reliability optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Z62LRFD","journalArticle","2022","Khazaei, H.; Mahmoudi, N.; Barna, C.; Litoiu, M.","Performance Modeling of Microservice Platforms","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2020.3029092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145020201&doi=10.1109%2fTCC.2020.3029092&partnerID=40&md5=c18980f71961664bdc764335b2a1de87","Microservice architecture has transformed the way developers are building and deploying applications in the nowadays cloud computing centers. This new approach provides increased scalability, flexibility, manageability, and performance while reducing the complexity of the whole software development life cycle. The increase in cloud resource utilization also benefits microservice providers. Various microservice platforms have emerged to facilitate the DevOps of containerized services by enabling continuous integration and delivery. Microservice platforms deploy application containers on virtual or physical machines provided by public/private cloud infrastructures in a seamless manner. In this article, we study and evaluate the provisioning performance of microservice platforms by incorporating the details of all layers (i.e., both micro and macro layers) in the modeling process. To this end, we first build a microservice platform on top of Amazon EC2 cloud and then leverage it to develop a comprehensive performance model to perform what-if analysis and capacity planning for microservice platforms at scale. In other words, the proposed performance model provides a systematic approach to measure the elasticity of the microservice platform by analyzing the provisioning performance at both the microservice platform and the back-end macroservice infrastructures.  © 2013 IEEE.","2022","2025-10-22 19:07:32","2025-10-22 19:07:32","","2848-2862","","4","10","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud-computing; Performance; New approaches; containers; Software design; Life cycle; Cloud infrastructures; Resources utilizations; Stochastic systems; Performance Modeling; Random processes; Software development life-cycle; Cloud infrastructure and stochastic process; cloud infrastructure and stochastic processes; Computing center; Microservice platform; microservice platforms; Performance modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5EIYYE7","conferencePaper","2018","Von Kistowski, J.; Eismann, S.; Schmitt, N.; Bauer, A.; Grohmann, J.; Kounev, S.","TeaStore: A micro-service reference application for benchmarking, modeling and resource management research","","","","10.1109/MASCOTS.2018.00030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058299875&doi=10.1109%2fMASCOTS.2018.00030&partnerID=40&md5=b9ee5510d42b5ac1ead035c7c172885c","Modern distributed applications offer complex performance behavior and many degrees of freedom regarding deployment and configuration. Researchers employ various methods of analysis, modeling, and management that leverage these degrees of freedom to predict or improve non-functional properties of the software under consideration. In order to demonstrate and evaluate their applicability in the real world, methods resulting from such research areas require test and reference applications that offer a range of different behaviors, as well as the necessary degrees of freedom. Existing production software is often inaccessible for researchers or closed off to instrumentation. Existing testing and benchmarking frameworks, on the other hand, are either designed for specific testing scenarios, or they do not offer the necessary degrees of freedom. Further, most test applications are difficult to deploy and run, or are outdated. In this paper, we introduce the TeaStore, a state-of-The-Art micro-service-based test and reference application. TeaStore offers services with different performance characteristics and many degrees of freedom regarding deployment and configuration to be used as a benchmarking framework for researchers. The TeaStore allows evaluating performance modeling and resource management techniques; it also offers instrumented variants to enable extensive run-Time analysis. We demonstrate TeaStore's use in three contexts: performance modeling, cloud resource management, and energy efficiency analysis. Our experiments show that TeaStore can be used for evaluating novel approaches in these contexts and also motivates further research in the areas of performance modeling and resource management. © 2018 IEEE.","2018","2025-10-22 19:07:32","2025-10-22 19:07:32","","223-236","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Power; Microservice; Performance; Container; Energy Efficiency; Clouds; Benchmarking; Green computing; Natural resources management; Resource allocation; Cloud; Deployment and configuration; Auto Scaler; Models; Degrees of freedom (mechanics); Energy efficiency analysis; Performance characteristics; Resource management techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 26th IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems, MASCOTS 2018","","","","","","","","","","","","","","",""
"2WMQ6M3C","conferencePaper","2018","Melo, C.; Dantas, J.; Oliveira, D.; Fe, I.; Matos, R.; Dantas, R.; MacIel, R.; MacIel, P.","Dependability Evaluation of a Blockchain-as-a-Service Environment","","","","10.1109/ISCC.2018.8538752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059220101&doi=10.1109%2fISCC.2018.8538752&partnerID=40&md5=23ed71d0d35ea06bd6506c1d4e9f7e50","The blockchain shared ledger emerged as an alternative to the bureaucratic banking system that may take days to confirm a payment or a transfer between clients. The blockchain concept evolved and became viable for various applications beyond the domain of financial transactions. Blockchains become a way to reach better relationships through contract validation, documents transfer, and personal and business data security. Recently, the blockchain-as-a-service has debuted on Microsoft Data Centers, and now many share an infrastructure that can change and improve their security routines. This paper evaluates the feasibility of a blockchain-as-a-service infrastructure and helps those who plan to deploy or sell blockchains. A modeling methodology based on Dynamical Reliability Block Diagrams (DRBD) is adopted to evaluate two dependability attributes: system's reliability and availability. The proposed infrastructure contains the minimum requirements to deploy the Hyperledger Cello, a platform to create and manage blockchains. The availability results pointed out a system downtime of 121 hours per year and reliability issues that must be addressed when building blockchain-as-a-service infrastructures. © 2018 IEEE.","2018","2025-10-22 19:07:32","2025-10-22 19:07:32","","909-914","","","2018-June","","","","","","","","","","","","","Scopus","","","","","","","","Blockchain; Reliability; Reliability block diagrams; Contract validations; Dependability evaluation; Financial transactions; Minimum requirements; Modeling methodology; Reliability and availability; Service infrastructure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Symposium on Computers and Communications","","","","","","","","","","","","","","",""
"QY7YXWNQ","journalArticle","2020","Lima, P.A.; Neto, A.S.B.; Maciel, P.","Data centers’ services restoration based on the decision-making of distributed agents","Telecommunication Systems","","","10.1007/s11235-020-00660-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082754227&doi=10.1007%2fs11235-020-00660-2&partnerID=40&md5=50196d18b0a5c87fa94cb043b2e9f1fe","The increasing number of companies that are migrating their IT infrastructure to cloud environments has been motivated many studies on distributed backup strategies to improve the availability of these companies’ systems. In this scenario, it is essential to study mechanisms to evaluate the network conditions to minimize the transmission time to improve the availability of the system. The goal of this study is to build models to evaluate the availability of services running in cloud data center infrastructure, emphasizing the impact of the variation of throughput on the data redundancy, and consequently, on the availability of the service. Based on it, this research purposes some smart models which can be deployed in each data center of a distributed arrange of data centers and help the system administrator to choose the best data center to restore the services of a faulty one. To analyze the impact of the network throughput over the service’s availability, we gathered the MTTF and MTTR metrics of data center’s components and services, generated a reliability block diagram to get the MTTF of the system as a whole, and developed a formalism to model the network component. Based on the results, we built an SPN model to represent the system and get the availability of it in many network conditions. After that, we analyze the availability of the system to discuss the impact of the network conditions over the system’s availability. After building the models and get the system’s availability in many network conditions, we can perceive the enormous impact of the network conditions over the system’s availability through a plot that exhibits the annual downtime along of a year. Using the models developed to study the system availability, we developed smart agents capable of predicting the transfer time of a bulk of data and, with it, choose the data center with the best network conditions to restore the services of a faulty one. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","367-378","","3","74","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Decision making; Data center; Data centers; Learning systems; Machine learning; Restoration; Availability; Network throughput; Vm migrations; Agent; Agents; Distributed agents; IT infrastructures; Reliability block diagrams; System administrators; System availability; VM migration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E63LVS2I","journalArticle","2021","Araujo, E.; Pereira, P.; Dantas, J.; Maciel, P.","Dependability impact in the smart solar power systems: An analysis of smart buildings","Energies","","","10.3390/en14010124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106171493&doi=10.3390%2fen14010124&partnerID=40&md5=de0b49ee88e7621807e8e139e691aeff","The Internet has been going through significant transformations and changing the world around us. We can also see the Internet to be used in many areas, for innumerable purposes, and, currently, it is even used by objects. This evolution leads to the Internet of Things (IoT) paradigm. This new concept can be defined as a system composed of storage resources, sensor devices, con-trollers, applications, and network infrastructure, in order to provide specific services to its users. Since IoT comprises heterogeneous components, the creation of these systems, the communication, and maintenance of their components became a complex task. In this paper, we present a dependability model to evaluate an IoT system. Amid different systems, we chose to assess availability in a smart building. The proposed models allow us to calculate estimations of other measures besides steady-state availability, such as reliability. Thus, it was possible to notice that there was no considerable gain of availability in the system when applying grid-tie solar power or off-grid solar power. The grid-tie solar power system is cheaper than the off-grid solar power system, even though it produces more energy. However, in our research, we were able to observe that the off-grid solar power system recovers the applied financial investment in smaller interval of time. © 2020 by the authors. Li-censee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","1","14","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Storage resources; Electric power transmission networks; Intelligent buildings; Network infrastructure; Complex task; Dependability model; Dependability modeling; Heterogeneous component; Investments; Off-grid solar; Power grids; Sensor device; Smart building; Smart power grids; Solar energy; Solar power; Solar Power Systems; Steady-state availability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4FK4JV4","journalArticle","2021","Vayghan, L.A.; Saied, M.A.; Toeroe, M.; Khendek, F.","A Kubernetes controller for managing the availability of elastic microservice based stateful applications","Journal of Systems and Software","","","10.1016/j.jss.2021.110924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100910850&doi=10.1016%2fj.jss.2021.110924&partnerID=40&md5=b01d6d2e3e057f7b774c14580fc176f6","The architectural style of microservices has been gaining popularity in recent years. In this architectural style, small and loosely coupled modules are deployed and scaled independently to compose cloud-native applications. Carrier-grade service providers are migrating their legacy applications to a microservice based architecture running on Kubernetes which is an open source platform for orchestrating containerized microservice based applications. However, in this migration, service availability remains a concern. Service availability is measured as the percentage of time the service is provisioned. High Availability (HA) is achieved when the service is available at least 99.999% of the time. In this paper, we identify possible architectures for deploying stateful microservice based applications with Kubernetes and evaluate Kubernetes from the perspective of availability it provides for its managed applications. The results of our experiments show that the repair actions of Kubernetes cannot satisfy HA requirements, and in some cases cannot guarantee service recovery. Therefore, we propose an HA State Controller which integrates with Kubernetes and allows for application state replication and automatic service redirection to the healthy microservice instances by enabling service recovery in addition to the repair actions of Kubernetes. Based on experiments we evaluate our solution and compare the different architectures from the perspective of availability and scaling overhead. The results of our investigations show that our solution can improve the recovery time of stateful microservice based applications by 50%. © 2021 Elsevier Inc.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","175","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Kubernetes; Microservices; Architecture; Elasticity; Architectural style; High availability; Availability; Recovery; Carrier grade services; Failure; Legacy applications; Open source platforms; Service availability; Service recoveries; State replications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ASZZFRK","journalArticle","2020","Pietrantuono, R.; Russo, S.; Guerriero, A.","Testing microservice architectures for operational reliability","Software Testing Verification and Reliability","","","10.1002/stvr.1725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076794331&doi=10.1002%2fstvr.1725&partnerID=40&md5=6e46f8f124833347e7c779a0f125cdaa","Microservice architectures (MSA) is an emerging software architectural paradigm for service-oriented applications, well-suited for dynamic contexts requiring loosely coupled independent services, frequent software releases and decentralized governance. A key problem in the engineering of MSA applications is the estimate of their reliability, which is difficult to perform prior to release due frequent releases/service upgrades, dynamic service interactions, and changes in the way customers use the applications. This paper presents an in vivo testing method, named EMART, to faithfully assess the reliability of an MSA application in operation. EMART is based on an adaptive sampling strategy, leveraging monitoring data about microservices usage and failure/success of user demands. We present results of evaluation of estimation accuracy, confidence and efficiency, through a set of controlled experiments with publicly available subjects. © 2019 John Wiley & Sons, Ltd. Copyright © 2019 John Wiley & Sons, Ltd.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","2","30","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Memory architecture; Software testing; Microservice architecture; Loosely coupled; Service oriented architecture (SOA); microservice architecture; Dynamic contexts; in vivo testing; In vivo testing; In-vivo; Operational reliability; Service-oriented applications; Software architectural; software reliability; Software reliability; Software-Reliability; Testing; Vivo testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKWK9CRR","journalArticle","","","","K3s: Lightweight Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084831492&partnerID=40&md5=b56aade0f7f680e0fe756089fce4b226","","","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MHHID7V","journalArticle","2018","Belkhir, L.; Elmeligi, A.","Assessing ICT global emissions footprint: Trends to 2040 & recommendations","Journal of Cleaner Production","","","10.1016/j.jclepro.2017.12.239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041215618&doi=10.1016%2fj.jclepro.2017.12.239&partnerID=40&md5=c91dee0ffd32a303af9af58776c4c37e","In light of the concerted efforts to reduce global greenhouse gas emissions (GHGE) per the so-called Paris Agreement, the Information and Communication Industry (ICT) has received little attention as a significant contributor to GHGE and if anything is often highly praised for enabling efficiencies that help reduce other industry sectors footprint. In this paper, we aim at assessing the global carbon footprint of the overall ICT industry, including the contribution from the main consumer devices, the data centers and communication networks, and compare it with the to the total worldwide GHGE. We conduct a detailed and rigorous analysis of the ICT global carbon footprint, including both the production and the operational energy of ICT devices, as well as the operational energy for the supporting ICT infrastructure. We then compare this contribution to the global 2016-level GHGE. We have found that, if unchecked, ICT GHGE relative contribution could grow from roughly 1–1.6% in 2007 to exceed 14% of the 2016-level worldwide GHGE by 2040, accounting for more than half of the current relative contribution of the whole transportation sector. Our study also highlights the contribution of smart phones and shows that by 2020, the footprint of smart phones alone would surpass the individual contribution of desktops, laptops and displays. Finally, we offer some actionable recommendations on how to mitigate and curb the ICT explosive GHGE footprint, through a combination of renewable energy use, tax policies, managerial actions and alternative business models. © 2018 Elsevier Ltd","2018","2025-10-22 19:07:32","2025-10-22 19:07:32","","448-463","","","177","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Smartphones; Carbon footprint; Gas emissions; Greenhouse gases; ICT infrastructures; Information and communication; Managerial actions; Operational energy; Relative contribution; Renewable energy use; Rigorous analysis; Telephone sets; Transportation sector","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNW7P7UB","journalArticle","2020","Rosendo, D.; Gomes, D.; Leoni Santos, G.; Silva, L.; Moreira, A.; Kelner, J.; Sadok, D.; Gonçalves, G.; Mehta, A.; Wildeman, M.; Takako Endo, P.","Availability analysis of design configurations to compose virtual performance-optimized data center systems in next-generation cloud data centers","Software - Practice and Experience","","","10.1002/spe.2833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084033362&doi=10.1002%2fspe.2833&partnerID=40&md5=a4d25b77122456edcc283b62f8c17e14","Next-generation cloud data centers are based on software-defined data center infrastructures that promote flexibility, automation, optimization, and scalability. The Redfish standard and the Intel Rack Scale Design technology enable software-defined infrastructure and disaggregate bare-metal compute, storage, and networking resources into virtual pools to dynamically compose resources and create virtual performance-optimized data centers (vPODs) tailored to workload-specific demands. This article proposes four chassis design configurations based on Distributed Management Task Force's Redfish industry standard applied to compose vPOD systems, namely, a fully shared design, partially shared homogeneous design, partially shared heterogeneous design, and not shared design; their main difference is based on the used hardware disaggregation level. Furthermore, we propose models that combine reliability block diagram and stochastic Petri net modeling approaches to represent the complexity of the relationship between the pool of disaggregated hardware resources and their power and cooling sources in a vPOD. These four proposed design configurations were analyzed and compared in terms of availability and component's sensitivity indexes by scaling their configurations considering different data center infrastructure. From the obtained results, we can state that, in general, when one increases the hardware disaggregation, availability is improved. However, after a given point, the availability level of the fully shared, partially shared homogeneous, and partially shared heterogeneous configurations remain almost equal, while the not shared configuration is still able to improve its availability. © 2020 John Wiley & Sons, Ltd.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","805-826","","6","50","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Cloud data centers; Stochastic systems; Stochastic models; availability; Availability; Petri nets; Composable; Composable system; composable systems; Data center systems; Design configurations; next-generation cloud data center; Next-generation cloud data center; Random access storage; Redfish standard; stochastic models; Stochastic-modeling; Virtual performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWULWTRE","journalArticle","2017","Yi, X.; Liu, F.; Niu, D.; Jin, H.; Lui, J.C.S.","Cocoa: Dynamic Container-Based Group Buying Strategies for Cloud Computing","ACM Transactions on Modeling and Performance Evaluation of Computing Systems","","","10.1145/3022876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043693914&doi=10.1145%2f3022876&partnerID=40&md5=69808f781d2dc7172257db8695f570c8","Although the Infrastructure-as-a-Service (IaaS) cloud offers diverse instance types to users, a significant portion of cloud users, especially those with small and short demands, cannot find an instance type that exactly fits their needs or fully utilize purchased instance-hours. In the meantime, cloud service providers are also faced with the challenge to consolidate small, short jobs, which exhibit strong dynamics, to effectively improve resource utilization. To handle such inefficiencies and improve cloud resource utilization, we propose Cocoa (COmputing in COntAiners), a novel group buying mechanism that organizes jobs with complementary resource demands into groups and allocates them to group buying deals predefined by cloud providers. Each group buying deal offers a resource pool for all the jobs in the deal, which can be implemented as either a virtual machine or a physical server. By running each user job on a virtualized container, our mechanism allows flexible resource sharing among different users in the same group buying deal, while improving resource utilization for cloud providers. To organize jobs with varied resource demands and durations into groups, we model the initial static group organization as a variable-sized vector bin packing problem, and the subsequent dynamic group organization problem as an online multidimensional knapsack problem. Through extensive simulations driven by a large amount of real usage traces from a Google cluster, we evaluate the potential cost reduction achieved by Cocoa. We show that through the effective combination and interaction of the proposed static and dynamic group organization strategies, Cocoa greatly outperforms the existing cloud workload consolidation mechanism, substantiating the feasibility of group buying in cloud computing. © 2017 ACM.","2017","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","2","2","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Infrastructure as a service (IaaS); Dynamics; Extensive simulations; Resource utilizations; Resource demands; Cloud service providers; Cost reduction; Bin packing problem; Cocoa; Combinatorial optimization; container; cost saving; Flexible resources; Group buying; Multidimensional knapsack problems; Workload consolidation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ9YEXTT","journalArticle","2019","Kiss, T.; DesLauriers, J.; Gesmier, G.; Terstyanszky, G.; Pierantoni, G.; Oun, O.A.; Taylor, S.J.E.; Anagnostou, A.; Kovacs, J.","A cloud-agnostic queuing system to support the implementation of deadline-based application execution policies","Future Generation Computer Systems","","","10.1016/j.future.2019.05.062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067198184&doi=10.1016%2fj.future.2019.05.062&partnerID=40&md5=19f2026013d0f9631667f7bbf2eac555","There are many scientific and commercial applications that require the execution of a large number of independent jobs resulting in significant overall execution time. Therefore, such applications typically require distributed computing infrastructures and science gateways to run efficiently and to be easily accessible for end-users. Optimising the execution of such applications in a cloud computing environment by keeping resource utilisation at minimum but still completing the experiment by a set deadline has paramount importance. As container-based technologies are becoming more widespread, support for job-queuing and auto-scaling in such environments is becoming important. Current container management technologies, such as Docker Swarm or Kubernetes, while provide auto-scaling based on resource consumption, do not support job queuing and deadline-based execution policies directly. This paper presents JQueuer, a cloud-agnostic queuing system that supports the scheduling of a large number of jobs in containerised cloud environments. The paper also demonstrates how JQueuer, when integrated with a cloud application-level orchestrator and auto-scaling framework, called MiCADO, can be used to implement deadline-based execution policies. This novel technical solution provides an important step towards the cost-optimisation of batch processing and job submission applications. In order to test and prove the effectiveness of the solution, the paper presents experimental results when executing an agent-based simulation application using the open source REPAST simulation framework. © 2019 The Authors","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","99-111","","","101","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud computing; Cloud computing environments; Batch data processing; Queueing networks; Commercial applications; Container technologies; Agent based simulation; Agent-based simulation; Application execution; Computing infrastructures; Deadline-based auto-scaling; JQueuer; MiCADO; Queueing theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P34JTR35","conferencePaper","2019","Gan, Y.; Zhang, Y.; Cheng, D.; Shetty, A.; Rathi, P.; Katarki, N.; Bruno, A.; Hu, J.; Ritchken, B.; Jackson, B.; Hu, K.; Pancholi, M.; He, Y.; Clancy, B.; Colen, C.; Wen, F.; Leung, C.; Wang, S.; Zaruvinsky, L.; Espinosa, M.; Lin, R.; Liu, Z.; Padilla, J.; Delimitrou, C.","An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems","","","","10.1145/3297858.3304013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064688619&doi=10.1145%2f3297858.3304013&partnerID=40&md5=b9f662fba2a35d83eb40d32009cf7676","Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","3-18","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Open source software; Datacenter; Microservice; cloud computing; Cloud-computing; microservices; QoS; acceleration; Benchmark suites; Cloud systems; Cluster computing; cluster management; Cluster management; datacenters; Economic and social effects; Field programmable gate arrays (FPGA); fpga; Fpgum; Open systems; Open-source; Quality-of-service; serverless; Serverless","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"9G4GBH5W","journalArticle","2010","Armbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz, R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, A.; Stoica, I.; Zaharia, M.","A view of cloud computing","Communications of the ACM","","","10.1145/1721654.1721672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950347409&doi=10.1145%2f1721654.1721672&partnerID=40&md5=6164f58679f057d5164d1f8f31d3f125","CLOUD COMPUTING, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1,000 servers for one hour costs no more than using one server for 1,000. © 2010 ACM.","2010","2025-10-22 19:07:32","2025-10-22 19:07:32","","50-58","","4","53","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Internet; Servers; Capital outlay; Innovative ideas; Internet services; IT industry; Large parts; Potential customers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5AV6CZNY","journalArticle","2019","Lv, L.; Zhang, Y.; Li, Y.; Xu, K.; Wang, D.; Wang, W.; Li, M.; Cao, X.; Liang, Q.","Communication-Aware Container Placement and Reassignment in Large-Scale Internet Data Centers","IEEE Journal on Selected Areas in Communications","","","10.1109/JSAC.2019.2895473","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061303318&doi=10.1109%2fJSAC.2019.2895473&partnerID=40&md5=f1a368136c670b0d0e1dafb1d960a554","Containerization has been used in many applications for isolation purposes due to its lightweight, scalable, and highly portable properties. However, to apply containerization in large-scale Internet data centers faces a big challenge. Services in data centers are always instantiated as a group of containers, which often generate heavy communication workloads and therefore resulting in inefficient communications and downgraded service performance. Although assigning the containers of the same service to the same server can reduce the communication overhead, this may cause heavily imbalanced resource utilization since containers of the same service are usually intensive to the same resource. To reduce communication cost as well as balance the resource utilization in large-scale data centers, we further explore the container distribution issues in a real industrial environment and find that such conflict lies in two phases-container placement and container reassignment. The objective of this paper is to address the container distribution problem in these two phases. For the container placement problem, we propose an efficient communication aware worst fit decreasing algorithm to place a set of new containers into data centers. For the container reassignment problem, we propose a two-stage algorithm called SweepSearch to optimize a given initial distribution of containers by migrating containers among servers. We implement the proposed algorithms in Baidu's data centers and conduct extensive evaluations. Compared with the state-of-The-Art strategies, the evaluation results show that our algorithms perform better up to 70% and increase the overall service throughput up to 90% simultaneously. © 1983-2012 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","540-555","","3","37","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Information management; Resource management; Distributed computer systems; Internet; Servers; Data centers; Throughput; Large scale data; Cost reduction; Packaging; Load balance; container placement; Container communication; container reassignment; large-scale data centers; multi-resource load balance; Time factors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NPT2C2GL","journalArticle","2014","Toosi, A.N.; Calheiros, R.N.; Buyya, R.","Interconnected cloud computing environments: Challenges, taxonomy, and survey","ACM Computing Surveys","","","10.1145/2593512","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905817532&doi=10.1145%2f2593512&partnerID=40&md5=697eb8026fa5a768ebc718a86bee7597","A brief review of the Internet history reveals the fact that the Internet evolved after the formation of primarily independent networks. Similarly, interconnected clouds, also called Inter-cloud, can be viewed as a natural evolution of cloud computing. Recent studies show the benefits in utilizing multiple clouds and present attempts for the realization of an Inter-cloud or federated cloud environment. However, cloud vendors have not taken into account cloud interoperability issues, and each cloud comes with its own solution and interfaces for services. This survey initially discusses all the relevant aspects motivating cloud interoperability. Furthermore, it categorizes and identifies possible cloud interoperability scenarios and architectures. The spectrum of challenges and obstacles that the Inter-cloud realization is faced with are covered, a taxonomy of them is provided, and fitting enablers that tackle each challenge are identified. All these aspects require a comprehensive review of the state of the art, including ongoing projects and studies in the area. We conclude by discussing future directions and trends toward the holistic approach in this regard. © 2014 ACM.","2014","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","1","47","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud-computing; Multi-clouds; Cloud environments; Surveys; Taxonomies; Interoperability; Cloud computing environments; Multi-cloud; Federated clouds; Cloud federation; Cloud federations; Cross-cloud; Cross-clouds; Inter clouds; Inter-cloud; Natural evolution; Utility computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLZ6S26S","journalArticle","2019","Kiss, T.; Kacsuk, P.; Kovacs, J.; Rakoczi, B.; Hajnal, A.; Farkas, A.; Gesmier, G.; Terstyanszky, G.","MiCADO—Microservice-based Cloud Application-level Dynamic Orchestrator","Future Generation Computer Systems","","","10.1016/j.future.2017.09.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030791545&doi=10.1016%2fj.future.2017.09.050&partnerID=40&md5=9c76c61725df8d55d77b845b82b28205","Various scientific and commercial applications require automated scalability and orchestration on cloud computing resources. However, extending applications with such automated scalability on an individual basis is not feasible. This paper investigates how such automated orchestration can be added to cloud applications without major reengineering of the application code. We suggest a generic architecture for an application level cloud orchestration framework, called MiCADO that supports various application scenarios on multiple heterogeneous federated clouds. Besides the generic architecture description, the paper also presents the first MiCADO reference implementation, and explains how the scalability of the Data Avenue service that is applied for data transfer in WS-PGRADE/gUSE based science gateways, can be improved. Performance evaluation of the implemented scalability based on up and downscaling experiments is presented. © 2017 Elsevier B.V.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","937-946","","","94","","","","","","","","","","","","","Scopus","","","","","","","","Automation; Cloud applications; Application scenario; Scalability; Commercial applications; Automated scalability; Cloud orchestration; Data Avenue; Data transfer; Generic architecture; Performance evaluations; Reference implementation; Science gateway","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38G6UA97","conferencePaper","2008","Buyya, R.; Yeo, C.S.; Venugopal, S.","Market-oriented cloud computing: Vision, hype, and reality for delivering IT services as computing utilities","","","","10.1109/HPCC.2008.172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-56349150824&doi=10.1109%2fHPCC.2008.172&partnerID=40&md5=6c72d9bf489047e57ce934a25be09075","This keynote paper: presents a 21st century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3 rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision. © 2008 IEEE.","2008","2025-10-22 19:07:32","2025-10-22 19:07:32","","5-13","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Grid computing; Clouds; Resource allocation; Computing environments; Computer systems; Risk analysis; Computational risk managements; Computing paradigms; GRID technologies; High performance liquid chromatography; It services; Management; Marketing; Planning; Resource Management strategies; Risk management; Service managements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 10th IEEE International Conference on High Performance Computing and Communications, HPCC 2008","","","","","","","","","","","","","","",""
"BIB9AQKS","journalArticle","2019","Zhang, R.; Chen, Y.; Dong, B.; Tian, F.; Zheng, Q.","A Genetic Algorithm-Based Energy-Efficient Container Placement Strategy in CaaS","IEEE Access","","","10.1109/ACCESS.2019.2937553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090845423&doi=10.1109%2fACCESS.2019.2937553&partnerID=40&md5=25bbbc9a62d74b7a5a06cb7c854d05f0","Container placement (CP) is a nontrivial problem in Container as a Service (CaaS). Many works in the literature solve it by using linear server energy-consumption models. However, the solutions of using a linear model makes different CPs indistinguishable with regard to energy consumption in a homogeneous host environment that has a same amount of active hosts. As such, these solutions are energy inefficient. In this paper, we demonstrate that an energy-saving gain can be achieved by optimizing the placement of containers under a nonlinear energy consumption model. Specifically, we leverage a strategy based on genetic algorithm (GA) to search the optimal solution. Unfortunately, the conventional GA incurs performance degradation when the virtual machine (VM) resource utilization is high. In order to solve this problem, we propose an improved genetic algorithm called IGA for efficiently searching the optimal CP solution by introducing two different exchange mutation operations and constructing a function as the control parameter to selectively control the usage of the two operations. Extensive experiments are carried out under different settings, and their results show that our strategy is better than the existing CP strategies, i.e., spread and binpack, on energy efficiency target. In addition, the introduced IGA is experimentally proved to be more effective compared with the First Fit, Particle Swarm Optimization (PSO) algorithm and conventional GA. Moreover, the results validate that our proposed strategy can search new CP solutions with better fitness and alleviate the performance degradation caused by the conventional GA when the VM resource utilization is high.  © 2013 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","121360-121373","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Performance degradation; Energy utilization; Green computing; Virtual machine; Resource utilizations; Genetic algorithms; Placement strategy; Energy consumption model; CaaS; container placement; Control parameters; exchange mutation operation; genetic algorithm; Mutation operations; Optimal solutions; Particle swarm optimization (PSO); Particle swarm optimization algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIZM89J5","journalArticle","2021","Gorski, T.; Wozniak, A.P.","Optimization of Business Process Execution in Services Architecture: A Systematic Literature Review","IEEE Access","","","10.1109/ACCESS.2021.3102668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112200345&doi=10.1109%2fACCESS.2021.3102668&partnerID=40&md5=4508370dfbbae73b1b4330dcc8a52caf","Web services have become a standard way to provide functions of information systems. The number of web services grows rapidly with the increasing popularity of microservices architecture. In consequence, many business processes are executed entirely through web services. Therefore, optimizing the performance of business process execution may bring many benefits. There are many optimization methods in this area. Our systematic literature review aims to introduce available methods to researchers interested in the optimization of business process execution. We queried four databases: ACM, IEEE Xplore, Science Direct, and Springer. Out of 12150 initially found papers, we have selected 128 for the review. We have grouped methods presented in those papers into three stages of business process optimization: Resource Allocation, Service Composition, and Service Scheduling. Service Composition attracts the largest group of researchers with a vast majority of 119 articles in it. Moreover, the most popular are genetic algorithms. In general, researchers mainly propose heuristic methods that optimize business processes during run-time. We see the potential for further exploration at both Resource Allocation and Service Scheduling stages.  © 2013 IEEE.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","111833-111852","","","9","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Systematic literature review; Web services; Resource allocation; Service compositions; Websites; optimization; Heuristic methods; Genetic algorithms; business process; Business Process; Business process execution; Business process optimization; micro-services; Optimization method; reliability; Service-oriented architecture; Service-scheduling; Services Architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ANIRWP8","journalArticle","2015","Esfandiarpoor, S.; Pahlavan, A.; Goudarzi, M.","Structure-aware online virtual machine consolidation for datacenter energy improvement in cloud computing","Computers and Electrical Engineering","","","10.1016/j.compeleceng.2014.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961340594&doi=10.1016%2fj.compeleceng.2014.09.005&partnerID=40&md5=8d4fdd17fab9ba30c33ea94b18c70752","The necessity and significance of improving the energy efficiency of cloud implementations have increased due to the rapid growth and proliferation of cloud computing services around the world. Virtual machines (VMs) comprise the backend of most, if not all, cloud computing services. Several VMs are often consolidated on a physical machine to efficiently utilize its resources. In this paper, we take into account the cooling and network structure of the datacenter host ing the physical machines when consolidating the VMs so that fewer racks and routers are employed, without compromising the service-level agreements; consequently, idle routing and cooling equipment can be turned off in order to reduce the energy consumption. Our experimental results on four benchmarks show that the proposed techniques improve energy consumption of servers, network equipment, and cooling systems by 2.5%, 18.8%, and 28.2% respectively compared to state of the art, resulting in a total of 14.7% energy improvement on average in the entire datacenter. © 2014 Elsevier Ltd. All rights reserved.","2015","2025-10-22 19:07:32","2025-10-22 19:07:32","","74-89","","","42","","","","","","","","","","","","","Scopus","","","","","","","","Cooling systems; Energy efficiency; Datacenter; Cloud computing; Energy utilization; Java programming language; Service Level Agreements; Virtual machine consolidations; Virtual machines; Virtual machine; Computer simulation; Cooling; Cloud computing services; Consolidation; Cooling equipment; Network equipment; Network structures; Service-level agreements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NWQFE538","journalArticle","2020","Hu, Y.; Zhou, H.; de Laat, C.; Zhao, Z.","Concurrent container scheduling on heterogeneous clusters with multi-resource constraints","Future Generation Computer Systems","","","10.1016/j.future.2019.08.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072185441&doi=10.1016%2fj.future.2019.08.025&partnerID=40&md5=d478ea29948a8e62e10945cbf4ffaae5","By effectively virtualizing operating systems and encapsulating necessary runtime contexts of software components and services, container technologies can significantly improve portability and efficiency for distributed application deployment. It flexibly extends virtual machine based cloud (Infrastructure-as-a-Service) as a much lighter virtual environment (container cluster) for agile application management. However, existing container management systems are not capable of handling concurrent requests efficiently, particularly for the underlying clusters with heterogeneous machines and the requested containers with multi-resource demands. In this paper, we propose an Enhanced Container Scheduler (ECSched) for efficiently scheduling concurrent container requests on heterogeneous clusters with multi-resource constraints. We formulate the container scheduling problem as a minimum cost flow problem (MCFP), and represent the container requirements using a specific graph data structure (flow network). ECSched affords flexibility in constructing the flow network based on a batch of concurrent requests, and performs the MCFP algorithm to schedule the concurrent requests in an online manner. We evaluate ECSched in different testbed clusters, and measure the scheduling overhead with large-scale simulations. The experimental results show that ECSched outperforms state-of-the-art container schedulers in container performance and resource efficiency, and only introduces a small and acceptable scheduling overhead in large-scale clusters. © 2019","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","562-573","","","102","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Application programs; Containers; Container; Virtual reality; Infrastructure as a service (IaaS); Efficiency; Distributed applications; Resource efficiencies; Scheduling algorithms; Container management; Computer software portability; Application management; Concurrent scheduling; Cost accounting; Flow graphs; Flow measurement; Heterogeneous cluster; Heterogeneous clusters; Large scale simulations; Minimum cost flow problem; Multi-resource constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQKJQ8P4","journalArticle","2018","Juarez, F.; Ejarque, J.; Badia, R.M.","Dynamic energy-aware scheduling for parallel task-based application in cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2016.06.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003666406&doi=10.1016%2fj.future.2016.06.029&partnerID=40&md5=a674981d2df0280fb716d55d5ac0ec41","Green Computing is a recent trend in computer science, which tries to reduce the energy consumption and carbon footprint produced by computers on distributed platforms such as clusters, grids, and clouds. Traditional scheduling solutions attempt to minimize processing times without taking into account the energetic cost. One of the methods for reducing energy consumption is providing scheduling policies in order to allocate tasks on specific resources that impact over the processing times and energy consumption. In this paper, we propose a real-time dynamic scheduling system to execute efficiently task-based applications on distributed computing platforms in order to minimize the energy consumption. Scheduling tasks on multiprocessors is a well known NP-hard problem and optimal solution of these problems is not feasible, we present a polynomial-time algorithm that combines a set of heuristic rules and a resource allocation technique in order to get good solutions on an affordable time scale. The proposed algorithm minimizes a multi-objective function which combines the energy-consumption and execution time according to the energy-performance importance factor provided by the resource provider or user, also taking into account sequence-dependent setup times between tasks, setup times and down times for virtual machines (VM) and energy profiles for different architectures. A prototype implementation of the scheduler has been tested with different kinds of DAG generated at random as well as on real task-based COMPSs applications. We have tested the system with different size instances and importance factors, and we have evaluated which combination provides a better solution and energy savings. Moreover, we have also evaluated the introduced overhead by measuring the time for getting the scheduling solutions for a different number of tasks, kinds of DAG, and resources, concluding that our method is suitable for run-time scheduling. © 2016 Elsevier B.V.","2018","2025-10-22 19:07:32","2025-10-22 19:07:32","","257-271","","","78","","","","","","","","","","","","","Scopus","","","","","","","","Energy-aware scheduling; Power management; Scheduling; Optimization; Cloud computing; Distributed computer systems; Energy utilization; Computer resource management; Green computing; Resource allocation; Computational complexity; Energy conservation; Carbon footprint; Reducing energy consumption; Carbon; Distributed computing; Distributed computing platform; Energy policy; Multi-heuristic resource allocation; Polynomial approximation; Polynomial-time algorithms; Polynomials; Resource allocation techniques; Sequence-dependent setup time; Task-based; Task-based applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ZFWGTEW","journalArticle","2019","Qureshi, B.","Profile-based power-aware workflow scheduling framework for energy-efficient data centers","Future Generation Computer Systems","","","10.1016/j.future.2018.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058448825&doi=10.1016%2fj.future.2018.11.010&partnerID=40&md5=dde9da3a5ed903e8ba5fc78a376476be","In the age of big data, software-as-a-service (SaaS) clouds provide heterogeneous and multitenant utilization of underlying virtual environments in data centers. Real-time and parallel deployment of applications with data-intensive workloads of various sizes pose challenges in optimal resource scheduling, power utilization, task completion time, network latency, and so on, causing degradation in the quality of service and affecting the user experience. In this paper, we investigate the role of application profiles in addressing the tradeoff between performance and energy efficiency of small- to medium-scale data centers. A power-aware framework for efficient placement of application workloads in the data center is proposed. The framework considers various application workflow constraints, such as CPU, memory, network I/O, and power consumption requirements to develop realistic profiles of application workloads. A system model for the efficient workflow assignment in the data center using a novel scheduler algorithm is presented. The performance of the proposed scheduler is validated through simulation studies. We compare the proposed scheduler with two scheduling algorithms: robust time cost (RTC) and heterogeneous earliest finish time (HEFT). Results show that the proposed scheduler is 19% and 38% more energy efficient than RTC and HEFT, respectively for medium–large sized workloads. © 2018 Elsevier B.V.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","453-467","","","94","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Quality of service; Scheduling; Electric power utilization; Energy efficiency; Big data; Cloud computing; Virtual reality; Green computing; Data center; Data centers; Scheduling algorithms; Workflow scheduling; Resource-scheduling; Software as a service (SaaS); Application-based profiles; Data-intensive workloads; Hadoop; Network latencies; Simulation studies; Task completion time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69ZS9R67","journalArticle","2021","Malik, N.; Sardaraz, M.; Tahir, M.; Shah, B.; Ali, G.; Moreira, F.","Energy-efficient load balancing algorithm for workflow scheduling in cloud data centers using queuing and thresholds","Applied Sciences (Switzerland)","","","10.3390/app11135849","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109127901&doi=10.3390%2fapp11135849&partnerID=40&md5=5624f4ac5b1050a253be087f8092f18b","Cloud computing is a rapidly growing technology that has been implemented in various fields in recent years, such as business, research, industry, and computing. Cloud computing provides different services over the internet, thus eliminating the need for personalized hardware and other resources. Cloud computing environments face some challenges in terms of resource utilization, energy efficiency, heterogeneous resources, etc. Tasks scheduling and virtual machines (VMs) are used as consolidation techniques in order to tackle these issues. Tasks scheduling has been extensively studied in the literature. The problem has been studied with different parameters and objectives. In this article, we address the problem of energy consumption and efficient resource utilization in virtualized cloud data centers. The proposed algorithm is based on task classification and thresholds for efficient scheduling and better resource utilization. In the first phase, workflow tasks are pre-processed to avoid bottlenecks by placing tasks with more dependencies and long execution times in separate queues. In the next step, tasks are classified based on the intensities of the required resources. Finally, Particle Swarm Optimization (PSO) is used to select the best schedules. Experiments were performed to validate the proposed technique. Comparative results obtained on benchmark datasets are presented. The results show the effectiveness of the proposed algorithm over that of the other algorithms to which it was compared in terms of energy consumption, makespan, and load balancing. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","13","11","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Energy consumption; Load balancing; PSO; Makespan; Task scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YNMFJQY5","journalArticle","2019","Mekala, M.S.; Viswanathan, P.","Energy-Efficient virtual machine selection based on resource ranking and utilization factor approach in cloud computing for IoT","Computers and Electrical Engineering","","","10.1016/j.compeleceng.2018.11.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057774182&doi=10.1016%2fj.compeleceng.2018.11.021&partnerID=40&md5=0ab7ebaaa39b38c97a6c989622e8e443","IoT leads to abrupt variations producing an immense number of data streams for storage, which is a considerable task in the heterogeneous cloud computing environment. Extant techniques consider task deadlines for virtual machine (VM) allocation and migration. This creates a resource famine leading to haphazard and numerous VM migrations, high energy consumption and unbalanced resource utilization. To solve this issue, an energy-efficient resource ranking and utilization factor-based virtual machine selection (ERVS) approach is proposed. ERVS encompasses the resource requirement rate for task classification, comprehensive resource balance ranking, processing element cost and the resource utilization square model for migration. It evaluates overloaded and underloaded hosts and types of VM by predicting CPU utilization rate and energy consumption. Based on this, tasks are sorted and VMs are optimally assigned, which enhances the resource utilization rate, reducing the number of live VM migrations. The experiments evaluate the ability of the proposed approach to diminish energy consumption without violation of service level agreements. © 2018 Elsevier Ltd","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","227-244","","","73","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Energy utilization; Internet of things; Digital storage; Virtual machine; Network security; CRB Ranking; Food supply; Processing element cost; Processing elements; Resource requirement rate; Resource requirements; Task categorization; VM Migration; Vm migrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JB76254R","conferencePaper","2019","Rossi, F.; Nardelli, M.; Cardellini, V.","Horizontal and vertical scaling of container-based applications using reinforcement learning","","","","10.1109/CLOUD.2019.00061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072308220&doi=10.1109%2fCLOUD.2019.00061&partnerID=40&md5=a79b3944fa91c9bd5f10915a4892e490","Software containers are changing the way distributed applications are executed and managed on cloud computing resources. Interestingly, containers offer the possibility of handling workload fluctuations by exploiting both horizontal and vertical elasticity 'on the fly'. However, most of the existing control policies consider horizontal and vertical scaling as two disjointed control knobs. In this paper, we propose Reinforcement Learning (RL) solutions for controlling the horizontal and vertical elasticity of container-based applications with the goal to increase the flexibility to cope with varying workloads. Although RL represents an interesting approach, it may suffer from a possible long learning phase, especially when nothing about the system is known a-priori. To speed up the learning process and identify better adaptation policies, we propose RL solutions that exploit different degrees of knowledge about the system dynamics (i.e., Q-learning, Dyna-Q, and Model-based). We integrate the proposed policies in Elastic Docker Swarm, our extension that introduces self-adaptation capabilities in the container orchestration tool Docker Swarm. We demonstrate the effectiveness and flexibility of model-based RL policies through simulations and prototype-based experiments. © 2019 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","329-338","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Docker; Cloud computing; Container; Elasticity; Machine learning; Distributed applications; Reinforcement learning; Adaptation policies; Learning process; Model-based OPC; Reinforcement Learning; Self adaptation; System Dynamics; Vertical scaling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"5IBQNE82","journalArticle","2019","Xu, M.; Buyya, R.","BrownoutCon: A software system based on brownout and containers for energy-efficient cloud computing","Journal of Systems and Software","","","10.1016/j.jss.2019.05.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065894559&doi=10.1016%2fj.jss.2019.05.031&partnerID=40&md5=c35adecba4fa8eadc6b68d173fb3f2ef","VM consolidation and Dynamic Voltage Frequency Scaling approaches have been proved to be efficient to reduce energy consumption in cloud data centers. However, the existing approaches cannot function efficiently when the whole data center is overloaded. An approach called brownout has been proposed to solve the limitation, which dynamically deactivates or activates optional microservices or containers. In this paper, we propose a brownout-based software system for container-based clouds to handle overloads and reduce power consumption. We present its design and implementation based on Docker Swarm containers. The proposed system is integrated with existing Docker Swarm without the modification of their configurations. To demonstrate the potential of BrownoutCon software in offering energy-efficient services in brownout situation, we implemented several policies to manage containers and conducted experiments on French Grid’5000 cloud infrastructure. The results show the currently implemented policies in our software system can save about 10%–40% energy than the existing baselines while ensuring quality of services. © 2019 Elsevier Inc.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","91-103","","","155","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Voltage scaling; Design and implementations; Containers; Energy efficiency; Microservices; Distributed computer systems; Cloud data centers; Energy utilization; Software systems; Green computing; Computer software; Dynamic frequency scaling; Cloud infrastructures; Reduce energy consumption; Dynamic voltage frequency scaling; Brownout","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FF6B7R65","journalArticle","2021","Calderón-Gómez, H.; Mendoza-Pittí, L.; Vargas-Lombardo, M.; Gómez-Pulido, J.M.; Rodríguez-Puyol, D.; Sención, G.; Polo-Luque, M.-L.","Evaluating service-oriented and microservice architecture patterns to deploy ehealth applications in cloud computing environment","Applied Sciences (Switzerland)","","","10.3390/app11104350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106660998&doi=10.3390%2fapp11104350&partnerID=40&md5=5fb71f9aed43e333ebe2945833fcec73","This article proposes a new framework for a Cloud-based eHealth platform concept focused on Cloud computing environments, since current and emerging approaches using digital clinical history increasingly demonstrate their potential in maintaining the quality of the benefits in medical care services, especially in computer-assisted clinical diagnosis within the field of infectious diseases and due to the worsening of chronic pathologies. Our objective is to evaluate and contrast the performance of the architectural patterns most commonly used for developing eHealth applications (i.e., service-oriented architecture (SOA) and microservices architecture (MSA)), using as reference the quantitative values obtained from the various performance tests and their ability to adapt to the required software attribute (i.e., versatile high-performance). Therefore, it was necessary to modify our platform to fit two architectural variants. As a follow-up to this activity, corresponding tests were performed that showed that the MSA variant functions better in terms of performance and response time compared to the SOA variant; however, it consumed significantly more bandwidth than SOA, and scalability in SOA is generally not possible or requires significant effort to be achieved. We conclude that the implementation of SOA and MSA depends on the nature and needs of organizations (e.g., performance or interoperability). © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","10","11","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; MSA; EHealth; Elderly people; Infectious diseases; SOA; Telemonitoring; Versatile high-performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJZRRBQT","journalArticle","2020","Rossi, F.; Cardellini, V.; Lo Presti, F.; Nardelli, M.","Geo-distributed efficient deployment of containers with Kubernetes","Computer Communications","","","10.1016/j.comcom.2020.04.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084943561&doi=10.1016%2fj.comcom.2020.04.061&partnerID=40&md5=92df7a3da86927a4a6bae90fbdbb6076","Software containers are changing the way applications are designed and executed. Moreover, in the last few years, we see the increasing adoption of container orchestration tools, such as Kubernetes, to simplify the management of multi-container applications. Kubernetes includes simple deployment policies that spread containers on computing resources located in the cluster and automatically scale them out or in based on some cluster-level metrics. As such, Kubernetes is not well-suited for deploying containers in a geo-distributed computing environment and dealing with the dynamism of application workload and computing resources. To tackle the problem, in this paper we present ge-kube (Geo-distributed and Elastic deployment of containers in Kubernetes), an orchestration tool that relies on Kubernetes and extends it with self-adaptation and network-aware placement capabilities. Ge-kube introduces flexible and decentralized control loops that can be easily equipped with different deployment policies. Specifically, we propose a two-step control loop, in which a model-based reinforcement learning approach dynamically controls the number of replicas of individual containers on the basis of the application response time, and a network-aware placement policy allocates containers on geo-distributed computing resources. To address the placement issue, we propose an optimization problem formulation and a network-aware heuristic, which explicitly take into account the non-negligible network delays among computing resources so to satisfy Quality of Service requirements of latency-sensitive applications. Using a surrogate CPU-intensive application and a real application (i.e., Redis), we conducted an extensive set of experiments, which show the benefits arising from the combination of elasticity and placement policies, as well as the advantages of using network-aware placement solutions. © 2020 Elsevier B.V.","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","161-174","","","159","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Application programs; Containers; Kubernetes; Cluster computing; Elasticity; Sensitive application; Reinforcement learning; Optimization problems; Computing resource; Decentralized control; Decentralized control loops; Distributed computing environment; Distributed computing resources; Elastic deployment; Geographically distributed resources; Model-based reinforcement learning; Placement; Self-management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMCDV6HY","journalArticle","2014","Horri, A.; Mozafari, M.S.; Dastghaibyfard, G.","Novel resource allocation algorithms to performance and energy efficiency in cloud computing","Journal of Supercomputing","","","10.1007/s11227-014-1224-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919877932&doi=10.1007%2fs11227-014-1224-8&partnerID=40&md5=93d310b40534cbb7a80b57193481804a","The rapid growth in demand for computational power has led to a shift to the cloud computing model established by large-scale virtualized data centers. Such data centers consume enormous amounts of electrical energy. Cloud providers must ensure that their service delivery is flexible to meet various consumer requirements. However, to support green computing, cloud providers also need to minimize the cloud infrastructure energy consumption while conducting the service delivery. In this paper, for cloud environments, a novel QoS-aware VMs consolidation approach is proposed that adopts a method based on resource utilization history of virtual machines. Proposed algorithms have been implemented and evaluated using CloudSim simulator. Simulation results show improvement in QoS metrics and energy consumption as well as demonstrate that there is a trade-off between energy consumption and quality of service in the cloud environment. © 2014, Springer Science+Business Media New York.","2014","2025-10-22 19:07:32","2025-10-22 19:07:32","","1445-1461","","3","69","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Cloud environments; Energy utilization; Economic and social effects; Computational power; Green computing; Resource allocation; Cloud infrastructures; Resource utilizations; Dynamic consolidation; Virtualized data centers; Energy-efficient resource management; Resource allocation algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PX97ZUNJ","journalArticle","2021","Cambronero, M.E.; Bernal, A.; Valero, V.; Cañizares, P.C.; Núñez, A.","Profiling SLAs for Cloud System Infrastructures and User Interactions","PeerJ Computer Science","","","10.7717/PEERJ-CS.513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107721190&doi=10.7717%2fPEERJ-CS.513&partnerID=40&md5=ab1fb2f0cf1b804eeddd22b46f6e74f6","Cloud computing has emerged as a cutting-edge technology which is widely used by both private and public institutions, since it eliminates the capital expense of buying, maintaining, and setting up both hardware and software. Clients pay for the services they use, under the so-called Service Level Agreements (SLAs), which are the contracts that establish the terms and costs of the services. In this paper, we propose the CloudCost UML profile, which allows the modeling of cloud architectures and the users’ behavior when they interact with the cloud to request resources. We then investigate how to increase the profits of cloud infrastructures by using price schemes. For this purpose, we distinguish between two types of users in the SLAs: regular and high-priority users. Regular users do not require a continuous service, so they can wait to be attended to. In contrast, high-priority users require a constant and immediate service, so they pay a greater price for their services. In addition, a computer-aided design tool, called MSCC (Modeling SLAs Cost Cloud), has been implemented to support the CloudCost profile, which enables the creation of specific cloud scenarios, as well as their edition and validation. Finally, we present a complete case study to illustrate the applicability of the CloudCost profile, thus making it possible to draw conclusions about how to increase the profits of the cloud infrastructures studied by adjusting the different cloud parameters and the resource configuration. Copyright 2021 Cambronero et al.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","1-37","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Platform as a Service (PaaS); Cloud infrastructures; Resource configurations; Hardware and software; Cloud; Model development; Computer aided design; Cloud architectures; Profitability; Service level agreement (SLAs); Computer aided design tools; Continuous services; Cutting edge technology; Design and simulation tools; Profit improvement; SLAs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SSKEILI","journalArticle","2019","Hussein, M.K.; Mousa, M.H.; Alqarni, M.A.","A placement architecture for a container as a service (CaaS) in a cloud environment","Journal of Cloud Computing","","","10.1186/s13677-019-0131-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066495867&doi=10.1186%2fs13677-019-0131-1&partnerID=40&md5=619dcedbedfe2f6ee01328ad9ee79dd5","Unlike a traditional virtual machine (VM), a container is an emerging lightweight virtualization technology that operates at the operating system level to encapsulate a task and its library dependencies for execution. The Container as a Service (CaaS) strategy is gaining in popularity and is likely to become a prominent type of cloud service model. Placing container instances on virtual machine instances is a classical scheduling problem. Previous research has focused separately on either virtual machine placement on physical machines (PMs) or container, or only tasks without containerization, placement on virtual machines. However, this approach leads to underutilized or overutilized PMs as well as underutilized or overutilized VMs. Thus, there is a growing research interest in developing a container placement algorithm that considers the utilization of both instantiated VMs and used PMs simultaneously. The goal of this study is to improve resource utilization, in terms of number of CPU cores and memory size for both VMs and PMs, and to minimize the number of instantiated VMs and active PMs in a cloud environment. The proposed placement architecture employs scheduling heuristics, namely, Best Fit (BF) and Max Fit (MF), based on a fitness function that simultaneously evaluates the remaining resource waste of both PMs and VMs. In addition, another meta-heuristic placement algorithm is proposed that uses Ant Colony Optimization based on Best Fit (ACO-BF) with the proposed fitness function. Experimental results show that the proposed ACO-BF placement algorithm outperforms the BF and MF heuristics and maintains significant improvement of the resource utilization of both VMs and PMs. © 2019, The Author(s).","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","1","8","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Containers; Cloud computing; Virtual machine; Artificial intelligence; Network security; Virtual machine placements; Placement algorithm; Ant colony optimization; Ant colonies; Ant colony; Best fit; Cloud container; Container placement; Digital libraries; Max fit; Two-tier placement algorithm; Virtual machine placement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Q7M7R6H","conferencePaper","2017","Tan, B.; Ma, H.; Mei, Y.","A NSGA-II-based approach for service resource allocation in Cloud","","","","10.1109/CEC.2017.7969618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027868076&doi=10.1109%2fCEC.2017.7969618&partnerID=40&md5=558f17ce73278ad06c2bc0bdf8d7fa19","Web service and Cloud computing have significantly reformed the software industry. The need for web service allocation in the cloud environment is increasing dramatically. In order to reduce the cost for service providers as well as improve the utilization of cloud resource for cloud providers, this paper formulates the web service resource allocation in cloud environment problem as a two-level multi-objective bin packing problem. It proposes a NSGA-II-based algorithm with specifically designed genetic operators. We are compared with two varieties of the algorithm. The results show that the proposed algorithm can provide reasonably good results with low violation rate. © 2017 IEEE.","2017","2025-10-22 19:07:32","2025-10-22 19:07:32","","2574-2581","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE Congress on Evolutionary Computation, CEC 2017 - Proceedings","","","","","","","","","","","","","","",""
"F2Q5G5PD","journalArticle","2016","Gai, K.; Qiu, M.; Zhao, H.; Tao, L.; Zong, Z.","Dynamic energy-aware cloudlet-based mobile cloud computing model for green computing","Journal of Network and Computer Applications","","","10.1016/j.jnca.2015.05.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949627105&doi=10.1016%2fj.jnca.2015.05.016&partnerID=40&md5=5abb99d76ead892a44038e02e5a26544","Employing mobile cloud computing (MCC) to enable mobile users to acquire benefits of cloud computing by an environmental friendly method is an efficient strategy for meeting current industrial demands. However, the restrictions of wireless bandwidth and device capacity have brought various obstacles, such as extra energy waste and latency delay, when deploying MCC. Addressing this issue, we propose a dynamic energy-aware cloudlet-based mobile cloud computing model (DECM) focusing on solving the additional energy consumptions during the wireless communications by leveraging dynamic cloudlets (DCL)-based model. In this paper, we examine our model by a simulation of practical scenario and provide solid results for the evaluations. The main contributions of this paper are twofold. First, this paper is the first exploration in solving energy waste problems within the dynamic networking environment. Second, the proposed model provides future research with a guideline and theoretical supports. © 2015 Elsevier Ltd. All rights reserved.","2016","2025-10-22 19:07:32","2025-10-22 19:07:32","","46-54","","","59","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Cloud computing; Energy aware; Mobile cloud computing; Green computing; Wireless communications; Wireless telecommunication systems; Power management (telecommunication); Cloudlets; Dynamic models; Dynamic program; Dynamic programs; Efficient strategy; Energy-aware; Environmental friendly methods; Wireless bandwidth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B2MGNUBY","conferencePaper","2019","Tan, B.; Ma, H.; Mei, Y.","Novel genetic algorithm with dual chromosome representation for resource allocation in container-based clouds","","","","10.1109/CLOUD.2019.00078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072335660&doi=10.1109%2fCLOUD.2019.00078&partnerID=40&md5=e2b59ea608fa876acf93eb4087754319","Containerization does not only support fast development and deployment of web applications but also provides the potential to improve the energy efficiency in cloud data centers. In container-based clouds, containers are allocated to virtual machines (VMs) and VMs are allocated to physical machines (PMs). This new architecture requires consolidation algorithms to select heterogeneous VMs to host containers and consolidate VMs to PMs simultaneously. Existing server consolidation techniques in VM-based clouds can hardly be applied because of the two-level architecture of the container-based clouds. This paper proposes a novel genetic algorithm (GA) with dual chromosome representation to solve the problem. The experiments show that the proposed GA achieves significantly higher energy efficiency than the compared state-of-the-art algorithms on a wide range of test problems. © 2019 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","452-456","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Cloud computing; Container; Cloud data centers; Green computing; Resource allocation; Server consolidation; WEB application; Evolutionary algorithms; Genetic algorithms; Genetic algorithm; Chromosomes; Cloud resource allocation; Evolutionary computation; Novel genetic algorithm; State-of-the-art algorithms; Test problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"X4INZGTY","journalArticle","2020","Khan, A.A.; Zakarya, M.; Khan, R.; Rahman, I.U.; Khan, M.; Khan, A.U.R.","An energy, performance efficient resource consolidation scheme for heterogeneous cloud datacenters","Journal of Network and Computer Applications","","","10.1016/j.jnca.2019.102497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075576818&doi=10.1016%2fj.jnca.2019.102497&partnerID=40&md5=14be49026985907961b015fa6fc7e510","Datacenters are the principal electricity consumers for cloud computing that provide an IT backbone for today's business and economy. Numerous studies suggest that most of the servers, in the US datacenters, are idle or less-utilised, making it possible to save energy by using resource consolidation techniques. However, consolidation involves migrations of virtual machines, containers and/or applications, depending on the underlying virtualisation method; that can be expensive in terms of energy consumption and performance loss. In this paper, we: (a) propose a consolidation algorithm which favours the most effective migration among VMs, containers and applications; and (b) investigate how migration decisions should be made to save energy without any negative impact on the service performance. We demonstrate through a number of experiments, using the real workload traces for 800 hosts, approximately 1516 VMs, and more than million containers, how different approaches to migration, will impact on datacenter's energy consumption and performance. We suggest, using reasonable assumptions for datacenter set-up, that there is a trade-off involved between migrating containers and virtual machines. It is more performance efficient to migrate virtual machines; however, migrating containers could be more energy efficient than virtual machines. Moreover, migrating containerised applications, that run inside virtual machines, could lead to energy and performance efficient consolidation technique in large-scale datacenters. Our evaluation suggests that migrating applications could be ~5.5% more energy efficient and ~11.9% more performance efficient than VMs migration. Further, energy and performance efficient consolidation is ~14.6% energy and ~7.9% performance efficient than application migration. Finally, we generalise our results using several repeatable experiments over various workloads, resources and datacenter set-ups. © 2019 Elsevier Ltd","2020","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","150","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Cloud computing; Performance; Energy utilization; Economic and social effects; Clouds; Green computing; Virtual machine; Network security; Application migrations; Consolidation techniques; Electricity consumers; Migrations; Performance loss; Resource consolidation; Service performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJDXSL92","conferencePaper","2013","Chen, F.; Grundy, J.; Yang, Y.; Schneider, J.-G.; He, Q.","Experimental analysis of task-based energy consumption in cloud computing systems","","","","10.1145/2479871.2479911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878194291&doi=10.1145%2f2479871.2479911&partnerID=40&md5=50fc4bb7a4bd5e428794fe725c6d236d","Cloud computing delivers IT solutions as a utility to users. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A common objective of cloud providers is to develop resource provisioning and management solutions that minimise energy consumption while guaranteeing Service Level Agreements (SLAs). In order to achieve this objective, a thorough understanding of energy consumption patterns in complex cloud systems is imperative. We have developed an energy consumption model for cloud computing systems. To operationalise this model, we have conducted extensive experiments to profile the energy consumption in cloud computing systems based on three types of tasks: computation- intensive, data-intensive and communication-intensive tasks. We collected fine-grained energy consumption and performance data with varying system configurations and workloads. Our experimental results show the correlation coefficients of energy consumption, system configuration and workload, as well as system performance in cloud systems. These results can be used for designing energy consumption monitors, and static or dynamic system-level energy consumption optimisation strategies for green cloud computing systems. © 2013 ACM.","2013","2025-10-22 19:07:32","2025-10-22 19:07:32","","295-306","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Energy efficiency; cloud computing; Cloud computing; Energy utilization; Computer systems; Carbon footprint; energy efficiency; Green Clouds; Service level agreement (SLAs); Experimental analysis; Correlation coefficient; energy consumption; Energy consumption model; Energy consumption monitors; green cloud; performance analysis; System configurations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2013 - Proceedings of the 2013 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"VPT3U8FA","conferencePaper","2021","Assunção, W.K.G.; Colanzi, T.E.; Carvalho, L.; Pereira, J.A.; Garcia, A.; De Lima, M.J.; Lucena, C.","A Multi-Criteria Strategy for Redesigning Legacy Features as Microservices: An Industrial Case Study","","","","10.1109/SANER50967.2021.00042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106562484&doi=10.1109%2fSANER50967.2021.00042&partnerID=40&md5=f4878c936ea66a41ca9b8f11ade5728e","Microservices are small and autonomous services that communicate through lightweight protocols. Companies have often been adopting microservices to incrementally redesign legacy systems as part of a modernization process. Microservices promote better reuse and customization of existing features while increasing business capabilities, if appropriate design decisions are made. There are some partially-automated approaches supporting the re-design of legacy features into microservices. However, they fail in covering two key aspects: (i) provide an architectural design of the features being redesigned, and (ii) simultaneously support relevant criteria, e.g., feature modularization and decrease of network communication overhead. Also, these two aspects tend to be poorly discussed along industrial case studies. To fulfill these gaps, we propose a redesign strategy to support the re-engineering of features legacy code as microservices. This strategy covers key possibly-conflicting criteria on microservice-based architectures. We employ search-based optimization to deal with such conflicting criteria. The output of the strategy is a set of redesign candidates of legacy features as microservices. We reflect upon the benefits and drawbacks of the proposed strategy through an industrial case study. In particular, we perform an in-depth analysis of the resulting microservice candidates, and a discussion about their potential for customization and reuse. The reflections/discussions are also supported by observations of developers involved in the process. © 2021 IEEE.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","377-387","","","","","","","","","","","","","","","","Scopus","","","","","","","","Legacy systems; Appropriate designs; Automated approach; In-depth analysis; Industrial case study; legacy systems; Lightweight protocols; microservice architecture; Modular construction; Modularizations; Network communication overhead; Reengineering; Search based optimizations; search-based software engineering; software evolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2021","","","","","","","","","","","","","","",""
"HCLUE63R","conferencePaper","2018","Zhang, R.; Zhong, A.-M.; Dong, B.; Tian, F.; Li, R.","Container-VM-PM Architecture: A Novel Architecture for Docker Container Placement","","","","10.1007/978-3-319-94295-7_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049337921&doi=10.1007%2f978-3-319-94295-7_9&partnerID=40&md5=8448a5e06864d8939a95f882211f5b79","Docker is a mature containerization technique used to perform operating system level virtualization. One open issue in the cloud environment is how to properly choose a virtual machine (VM) to initialize its instance, i.e., container, which is similar to the conventional problem of VM placement towards physical machines (PMs). Current studies mainly focus on container placement and VM placement independently, but rarely take into consideration of the two placements’ systematic collaboration. However, we view it as a main reason for scattered distribution of containers in a data center, which finally results in worse physical resource utilization. In this paper, we propose a definition named “Container-VM-PM” architecture and propose a novel container placement strategy by simultaneously taking into account the three involved entities. Furthermore, we model a fitness function for the selection of VM and PM. Simulation experiments show that our method is superior to the existing strategy with regarding to the physical resource utilization. © 2018, Springer International Publishing AG, part of Springer Nature.","2018","2025-10-22 19:07:32","2025-10-22 19:07:32","","128-140","","","10967 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud computing; Cloud environments; Architecture; Docker containers; Virtual machine; Network security; Client server computer systems; Docker container; Fitness functions; Novel architecture; Physical resources; Placement strategy; Resource fragment; Three-tier architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"74EKWHLL","journalArticle","2022","Malik, S.; Tahir, M.; Sardaraz, M.; Alourani, A.","A Resource Utilization Prediction Model for Cloud Data Centers Using Evolutionary Algorithms and Machine Learning Techniques","Applied Sciences (Switzerland)","","","10.3390/app12042160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124946319&doi=10.3390%2fapp12042160&partnerID=40&md5=9e461e050680597e2e8bdfdf8cb1d739","Cloud computing has revolutionized the modes of computing. With huge success and diverse benefits, the paradigm faces several challenges as well. Power consumption, dynamic resource scaling, and over-and under-provisioning issues are challenges for the cloud computing paradigm. The research has been carried out in cloud computing for resource utilization prediction to overcome over-and under-provisioning issues. Over-provisioning of resources consumes more energy and leads to high costs. However, under-provisioning induces Service Level Agreement (SLA) violation and Quality of Service (QoS) degradation. Most of the existing mechanisms focus on single resource utilization prediction, such as memory, CPU, storage, network, or servers allocated to cloud applications but overlook the correlation among resources. This research focuses on multi-resource utilization prediction using Functional Link Neural Network (FLNN) with hybrid Genetic Algorithm (GA) and Particle Swarm Optimization (PSO). The proposed technique is evaluated on Google cluster traces data. Experimental results show that the proposed model yields better accuracy as compared to traditional techniques. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2022","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","4","12","","","","","","","","","","","","","Scopus","","","","","","","","Forecasting; Cloud computing; Neural networks; GA; PSO; Resource utilization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGHQ48GA","journalArticle","","","","Microservices Divvy up Tasks to Improve Cloud Apps | Cornell Chronicle","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132281015&partnerID=40&md5=000085d6ccb910c48f449fedf1a27c9c","","","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MAJ8KVSZ","conferencePaper","2019","Liu, H.; Zhang, J.; Shan, H.; Li, M.; Chen, Y.; He, X.; Li, X.","JCallGraph: Tracing microservices in very large scale container cloud platforms","","","","10.1007/978-3-030-23502-4_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068217062&doi=10.1007%2f978-3-030-23502-4_20&partnerID=40&md5=78356a6c290932cd264c50d472a6d612","Microservice architecture splits giant and complex enterprise applications into fine-grained microservices, promoting agile development, integration, delivery and deployment. However, monitoring tens of thousands of microservices is extremely challenging, and debugging problems among massive microservices is like looking for a needle in a haystack. We present JCallGraph, a tracing and analytics tool to capture and visualize the microservice invocation relationship of tens of thousands of microservices with millions of containers at JD.com. JCallGraph achieves three main goals for distributed tracing and debugging: online microservices invocation construction within milliseconds, minimal overhead without any significant performance impact on real-production applications, and application-agnostic with zero-intrusion to application. Our evaluation shows that JCallGraph can accurately capture the real-time invocation relationship at massive scale and help developers to efficiently understand interactions among microservices, pinpoint root-cause of problems. © Springer Nature Switzerland AG 2019.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","287-302","","","11513 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Containers; Cloud computing; Program debugging; Performance impact; Cloud platforms; Distributed tracing; Agile development; Analytics tools; Distributed tracing system; Enterprise applications; Invocation graph; Microservice invocation graph; Performance analysis and measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"MVUFU83P","journalArticle","2017","Piraghaj, S.F.; Dastjerdi, A.V.; Calheiros, R.N.; Buyya, R.","ContainerCloudSim: An environment for modeling and simulation of containers in cloud data centers","Software - Practice and Experience","","","10.1002/spe.2422","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977508166&doi=10.1002%2fspe.2422&partnerID=40&md5=c5f51b9c0d8e162bb0c22f052c69f901","Containers are increasingly gaining popularity and becoming one of the major deployment models in cloud environments. To evaluate the performance of scheduling and allocation policies in containerized cloud data centers, there is a need for evaluation environments that support scalable and repeatable experiments. Simulation techniques provide repeatable and controllable environments, and hence, they serve as a powerful tool for such purpose. This paper introduces ContainerCloudSim, which provides support for modeling and simulation of containerized cloud computing environments. We developed a simulation architecture for containerized clouds and implemented it as an extension of CloudSim. We described a number of use cases to demonstrate how one can plug in and compare their container scheduling and provisioning policies in terms of energy efficiency and SLA compliance. Our system is highly scalable as it supports simulation of large number of containers, given that there are more containers than virtual machines in a data center. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","2017","2025-10-22 19:07:32","2025-10-22 19:07:32","","505-521","","4","47","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Containers; Energy efficiency; cloud computing; Cloud computing; Cloud computing environments; Allocation policies; simulation; Model and simulation; Container scheduling; container as a service (CaaS); containerized clouds; Provisioning policies; Simulation; Simulation architecture; Simulation technique","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6H83XH39","journalArticle","2013","Tchana, A.; Son Tran, G.; Broto, L.; Depalma, N.; Hagimont, D.","Two levels autonomic resource management in virtualized IaaS","Future Generation Computer Systems","","","10.1016/j.future.2013.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875197085&doi=10.1016%2fj.future.2013.02.002&partnerID=40&md5=5b5c3ac6977d47303553edcbbd7b538f","Virtualized cloud infrastructures are very popular as they allow resource mutualization and therefore cost reduction. For cloud providers, minimizing the number of used resources is one of the main services that such environments must ensure. Cloud customers are also concerned with the minimization of used resources in the cloud since they want to reduce their invoice. Thus, resource management in the cloud should be considered by the cloud provider at the virtualization level and by the cloud customers at the application level. Many research works investigate resource management strategies in these two levels. Most of them study virtual machine consolidation (according to the virtualized infrastructure utilization rate) at the virtualized level and dynamic application sizing (according to its workload) at the application level. However, these strategies are studied separately. In this article, we show that virtual machine consolidation and dynamic application sizing are complementary. We show the efficiency of the combination of these two strategies, in reducing resource usage and keeping an application's Quality of Service. Our demonstration is done by comparing the evaluation of three resource management strategies (implemented at the virtualization level only, at the application level only, or complementary at both levels) in a private cloud infrastructure, hosting typical JEE web applications (evaluated with the RUBiS benchmark). © 2013 Elsevier B.V. All rights reserved.","2013","2025-10-22 19:07:32","2025-10-22 19:07:32","","1319-1332","","6","29","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Resource management; Virtual reality; Virtual machine consolidations; Benchmarking; Natural resources management; Resource allocation; Cloud infrastructures; Application level; WEB application; Autonomic administration; Dynamic applications; Minimizing the number of; Utilization rates","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSZB6GAC","journalArticle","2019","Kovács, J.","Supporting Programmable Autoscaling Rules for Containers and Virtual Machines on Clouds","Journal of Grid Computing","","","10.1007/s10723-019-09488-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072128121&doi=10.1007%2fs10723-019-09488-w&partnerID=40&md5=c046b5407e3d615944790d1cff07dabc","With the increasing utilization of cloud computing and container technologies, orchestration is becoming an important area on both cloud and container levels. Beyond resource allocation, deployment and configuration, scaling is a key functionality in orchestration in terms of policy, description and flexibility. This paper presents an approach where the aim is to provide a high degree of flexibility in terms of available monitoring metrics and in terms of the definition of elasticity rules to implement practically any possible business logic for a given application. The aim is to provide a general interface for supporting programmable scaling policies utilizing monitoring metrics originating from infrastructure, application or any external components. The paper introduces a component, called Policy Keeper performing the auto-scaling based on user-defined rules, details how this component is operating in the auto-scaling framework, called MiCADO and demonstrates a deadline-based scaling use case. © 2019, The Author(s).","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","813-829","","4","17","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Docker; Cloud computing; Container; Clouds; Computation theory; Virtual machine; Autoscaling; Cloud; Network security; Business logic; Degree of flexibility; Deployment and configuration; Distributed monitoring; External components; Monitoring metrics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2G4UDAVG","conferencePaper","2017","Kaewkasi, C.; Chuenmuneewong, K.","Improvement of container scheduling for Docker using Ant Colony Optimization","","","","10.1109/KST.2017.7886112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017513531&doi=10.1109%2fKST.2017.7886112&partnerID=40&md5=c25c6c7e8c1f8110164504b541ccb644","Docker, a software container implementation, has emerged not only as an operating-system level virtualization but also an application delivery platform for today Internet. However, the scheduling algorithm shipped with SwarmKit, the orchestration engine behind Docker, is suboptimal when resources are nonuniform. The use of meta-heuristic, like Ant Colony Optimization (ACO), is feasible to improve the scheduler's optimality. This paper presents a study of ACO to implement a new scheduler for Docker. The main contribution of this paper is an ACO-based algorithm, which distributes application containers over Docker hosts. It is to balance the resource usages and finally l eads to the better performance of applications. The experimental results showed that workloads placed by ACO performed better than those of the greedy algorithm by approximately 15% on the same host configuration. © 2017 IEEE.","2017","2025-10-22 19:07:32","2025-10-22 19:07:32","","254-259","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Application programs; Containers; Optimization; Resource usage; Artificial intelligence; Scheduling algorithms; Container scheduling; Aco-based algorithms; Ant colony optimization; Ant Colony Optimization (ACO); Application delivery; Greedy algorithms; Metaheuristic; System levels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 9th International Conference on Knowledge and Smart Technology: Crunching Information of Everything, KST 2017","","","","","","","","","","","","","","",""
"CEKQWC8B","conferencePaper","2019","Morikawa, T.; Kourai, K.","Low-cost and fast failure recovery using In-VM containers in clouds","","","","10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075150152&doi=10.1109%2fDASC%2fPiCom%2fCBDCom%2fCyberSciTech.2019.00112&partnerID=40&md5=719e7783c3442eaf54392734ba796321","Recently, various services are provided using virtual machines (VMs) in clouds. Therefore, it is necessary to prepare for system failures of VMs, hosts running VMs, and even data centers, e.g., using active/standby clustering. However, a trade-off exists between the maintenance cost for additional VMs and the recovery time in traditional techniques. For example, hot standby can rapidly fail over to the secondary system on a system failure, but the secondary system has to always run the same number of VMs as the primary system. In contrast, cold standby does not need to run VMs until a system failure, but it has to boot VMs on failure recovery. In this paper, we propose VCRecovery, which is the system for achieving both low-cost and fast failure recovery. VCRecovery consolidates services using containers inside VMs (in-VM containers) in the secondary system. For hot standby, it can reduce the maintenance cost by using only a smaller number of VMs in the secondary system. For cold standby, it can reduce the recovery time by quickly booting in-VM containers. If a VM is overloaded after the recovery, VCRecovery can migrate several in-VM containers to other VMs. To synchronize storage between VMs in the primary system and in-VM containers in the secondary system, it efficiently performs minimum file-based synchronization based on software packages. We have implemented VCRecovery using LXD and Zabbix and examined the performance. © 2019 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","572-579","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Big data; Economic and social effects; Failure detection; Virtual machines; Digital storage; Virtual machine; Costs; Network security; Systems engineering; Failure recovery; Availability; Active/standby; Fast failure recovery; Maintenance; Maintenance cost; Primary systems; Recovery; Secondary system; Traditional techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE 17th International Conference on Dependable, Autonomic and Secure Computing, IEEE 17th International Conference on Pervasive Intelligence and Computing, IEEE 5th International Conference on Cloud and Big Data Computing, 4th Cyber Science and Technology Congress, DASC-PiCom-CBDCom-CyberSciTech 2019","","","","","","","","","","","","","","",""
"PSIBJJBX","conferencePaper","2021","Saboor, A.; Mahmood, A.K.; Hassan, M.F.; Shah, S.N.M.; Hassan, F.; Siddiqui, M.A.","Design Pattern Based Distribution of Microservices in Cloud Computing Environment","","","","10.1109/ICCOINS49721.2021.9497188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112426648&doi=10.1109%2fICCOINS49721.2021.9497188&partnerID=40&md5=616aca5df05d88fa2b5a06b1446cf9a2","Cloud computing is a paradigm that has already evolved. Cloud computing moved widely to microservices from monoliths. The modular cloud application has gained attention for Microservices. Intensive network communication is required to call the interdependent microservices operating inside the cloud nodes. This research focuses on container-based microservices pre-distribution techniques and proposes two distribution strategies i.e. design pattern distribution and random distribution. The microservices are arbitrarily distributed to the available data centers in the random allocation method. While the microservices are clustered in the pattern distribution based on behavioral design patterns, which identify common contact patterns between entities. A custom-built modeling environment has been used to evaluate the proposed method. The findings revealed that the pre-distribution of microservices in accordance with the application architecture trend led to substantial less response time for the calls made to services hosted at geographically dispersed data centers. © 2021 IEEE.","2021","2025-10-22 19:07:32","2025-10-22 19:07:32","","396-400","","","","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Microservices; Cloud computing; Cloud applications; Cloud Computing; Software engineering; Computer science; Computers; Artificial intelligence; Cloud computing environments; Network communications; Application architecture; Cloud Containers; Distribution strategies; Modeling environments; Random allocation; Random distribution; Virtual Machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Computer and Information Sciences: Sustaining Tomorrow with Digital Innovation, ICCOINS 2021","","","","","","","","","","","","","","",""
"6VCT5B9M","journalArticle","2016","Wolke, A.; Bichler, M.; Setzer, T.","Planning vs. Dynamic Control: Resource Allocation in Corporate Clouds","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2014.2360399","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986571155&doi=10.1109%2fTCC.2014.2360399&partnerID=40&md5=defc85bcc612d4727bbb1df287687d8f","Nowadays corporate data centers leverage virtualization technology to cut operational and management costs. Virtualization allows splitting and assigning physical servers to virtual machines (VM) that run particular business applications. This has led to a new stream in the capacity planning literature dealing with the problem of assigning VMs with volatile demands to physical servers in a static way such that energy costs are minimized. Live migration technology allows for dynamic resource allocation, where a controller responds to overload or underload on a server during runtime and reallocates VMs in order to maximize energy efficiency. Dynamic resource allocation is often seen as the most efficient means to allocate hardware resources in a data center. Unfortunately, there is hardly any experimental evidence for this claim. In this paper, we provide the results of an extensive experimental analysis of both capacity management approaches on a data center infrastructure. We show that with typical workloads of transactional business applications dynamic resource allocation does not increase energy efficiency over the static allocation of VMs to servers and can even come at a cost, because migrations lead to overheads and service disruptions. © 2013 IEEE.","2016","2025-10-22 19:07:32","2025-10-22 19:07:32","","322-335","","3","4","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Virtual reality; Dynamics; Dynamic resource allocations; Resource allocation; Costs; Virtualization technologies; Business applications; resource allocation; Capacity management; Capacity planning; Experimental analysis; Experimental evidence; IT service management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X6932KT3","conferencePaper","2008","Srikantaiah, S.; Kansal, A.; Zhao, F.","Energy aware consolidation for cloud computing","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021450123&partnerID=40&md5=8516c07058681fe98cfd3b25d0bd6240","Consolidation of applications in cloud computing environments presents a significant opportunity for energy optimization. As a first step toward enabling energy efficient consolidation, we study the inter-relationships between energy consumption, resource utilization, and performance of consolidated workloads. The study reveals the energy performance trade-offs for consolidation and shows that optimal operating points exist. We model the consolidation problem as a modified bin packing problem and illustrate it with an example. Finally, we outline the challenges in finding effective solutions to the consolidation problem. © Workshop on Power Aware Computing and Systems, HotPower 2008. All rights reserved.","2008","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Optimization; Cloud computing; Energy utilization; Economic and social effects; Cloud computing environments; Resource utilizations; Energy optimization; Bin packing problem; Effective solution; Energy performance; Inter-relationships; Optimal operating point","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Workshop on Power Aware Computing and Systems, HotPower 2008","","","","","","","","","","","","","","",""
"8SRWLX6H","conferencePaper","2016","Visti, H.; Kiss, T.; Terstyanszky, G.; Gesmier, G.; Winter, S.","MiCADO - Towards a microservice-based cloud application-level dynamic orchestrator","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025151047&partnerID=40&md5=6ecc4923cc7d043e3aacfa7df11e8950","In order to satisfy end-user requirements, many scientific and commercial applications require access to dynamically adjustable infrastructure resources. Cloud computing has the potential to provide these dynamic capabilities. However, utilising these capabilities from application code is not trivial and requires application developers to understand low-level technical details of clouds. This paper investigates how a generic framework can be developed that supports the dynamic orchestration of cloud applications both at deployment and at run-time. The advantages and challenges of designing such framework based on microservices is analysed, and a generic framework, called MiCADO - (Microservices-based Cloud Application-level Dynamic Orchestrator) is proposed. A first prototype implementation of MiCADO to support data intensive commercial web applications is also presented.","2016","2025-10-22 19:07:32","2025-10-22 19:07:32","","","","","1871","","","","","","","","","","","","","Scopus","","","","","","","","Cloud applications; Application developers; Prototype implementations; Application level; Infrastructure resources; Application-level orchestration; Commercial applications; Container technologies; Dynamic capabilities; End user requirements; Microservices-based architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CEUR Workshop Proceedings","","","","","","","","","","","","","","",""
"VQA2NFDF","journalArticle","2017","Khan, A.","Key Characteristics of a Container Orchestration Platform to Enable a Modern Application","IEEE Cloud Computing","","","10.1109/MCC.2017.4250933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038634613&doi=10.1109%2fMCC.2017.4250933&partnerID=40&md5=2dcb5fc2b388db00d5bc60ece6aedf0c","As compute evolves from bare metal to virtualized environments to containers towards serverless, the efficiency gains have enabled a wide variety of use cases. Organizations have used containers to run long running services, batch processing at scale, control planes, Internet of Things, and Artificial Intelligence workloads. Further, methodologies for software as a service, such as twelve-factor app, emphasize a clean contract with the underlying operating system and maximum portability between execution environments.1 In this paper, we address a set of capabilities required of a container orchestration platform to embody the design principles as illustrated by twelve factor app design. This paper also provides a non-exhaustive and prescriptive guide to identifying and implementing key mechanisms required in a container orchestration platform. We will cover capabilities such as cluster state management and scheduling, high availability and fault tolerance, security, networking, service discovery, continuous deployment, monitoring, and governance. © 2017 IEEE.","2017","2025-10-22 19:07:32","2025-10-22 19:07:32","","42-48","","5","4","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Application programs; Monitoring; Containers; Docker; microservices; monitoring; tracing; Virtual reality; cluster management; Cluster management; containers; High availability; scheduling; Service discovery; Fault tolerance; Batch data processing; Fault tolerant computer systems; application load balancing; code review; Code review; Computer software portability; container orchestration; container security; continuous delivery and deployment; cyclomatic complexity; Cyclomatic complexity; dynamic port mapping; fault tolerant; Fault-tolerant; high availability; Port mapping; service discovery; Software as a service (SaaS); twelve-factor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFEEGEJ8","journalArticle","2022","Saboor, A.; Mahmood, A.K.; Omar, A.H.; Hassan, M.F.; Shah, S.N.M.; Ahmadian, A.","Enabling rank-based distribution of microservices among containers for green cloud computing environment","Peer-to-Peer Networking and Applications","","","10.1007/s12083-021-01218-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112841408&doi=10.1007%2fs12083-021-01218-y&partnerID=40&md5=ee57caac17e75a71c6e3bdd06f31114e","Microservices architecture is a functional software design methodology that promises the redefinition of the architectural style that aims to create a single application as a suite of tiny, loosely coupled services or components, each performing its own tasks and interacting with each other. The cloud services widely shifted from monoliths to microservices and gained the popularity for use in scalable cloud application. The usage of microservices involved intensive network communication to call number of interdependent microservices running inside the cloud nodes. It provides flexibility in the delivery of service but also increases energy usage and poor service efficiency which results in increased carbon emissions. To solve these issues, the prevailing technologies were designed for single unit monolithic cloud applications, and not tailored for the chain oriented service delivery. This study addresses the dynamic provisioning of containers and respective microservices in cloud computing environment by building rank-based profiles and using those profiles for allocation of web application’s microservices along with containers to the cloud data centers. The MicroRanker service is proposed to rank all of the participating microservices and distribute them across different nodes even before the execution of the cloud services. Further, the MicroRanker service is utilized to dynamically update the container placement due to continuous DevOps actions. The proposed solution was tested using custom built simulation environment. The achieved results showed that the distribution of containers along with respective microservices in accordance with MicroRanker service resulted in less energy consumption (i.e. between 81.6 kWh-87.7 kWh compared to 88.9 kWh-95.7 kWh) and significantly lowered the emission of carbon (i.e. between 5.92 kg-33.31 kg compared to 17.2 kg-47.35 kg) due to higher utilization of renewable energy. The use of rank-based microservices distribution also decreased response time (i.e. between 29 ms-142 ms compared to 106 ms-217 ms) due to the availability of the container along with microservice within the same data center region. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2022","2025-10-22 19:07:32","2025-10-22 19:07:32","","77-91","","1","15","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Optimization; Microservices; Cloud computing; Cloud data centers; Energy utilization; Software design; Green computing; Web services; Architectural style; Cloud computing environments; Simulation environment; High performance computing; Carbon; Dynamic provisioning; Network communications; Ranking; Renewable energies; Software design methodologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HJTBLAW","journalArticle","2019","Zhou, R.; Li, Z.; Wu, C.","An Efficient Online Placement Scheme for Cloud Container Clusters","IEEE Journal on Selected Areas in Communications","","","10.1109/JSAC.2019.2906745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064688806&doi=10.1109%2fJSAC.2019.2906745&partnerID=40&md5=74d4c34ac5f4f6c647eff4c6890c8ac5","Containers represent an agile alternative to virtual machines (VMs), for providing cloud computing services. Containers are more flexible and lightweight, and can be easily instrumented. Enterprise users often create clusters of inter-connected containers to provision complex services. Compared to traditional cloud services, key challenges in container cluster (CC) provisioning lie in the optimal placement of containers while considering inter-container traffic in a CC. The challenge further escalates, when CCs are provisioned in an online fashion. We propose an online algorithm to address the above challenges, aiming to maximize the aggregate value of all served clusters. We first study a one-shot CC placement problem. Leveraging techniques of exhaustive sampling and ST rounding, we design an efficient one-shot algorithm to determine the placement scheme of a given CC. We then propose a primal-dual online placement scheme that employs the one-shot algorithm as a building block to make decisions upon the arrival of each CC request. Through both theoretical analysis and trace-driven simulations, we verify that the online placement algorithm is computationally efficient and achieves a good competitive ratio. © 1983-2012 IEEE.","2019","2025-10-22 19:07:32","2025-10-22 19:07:32","","1046-1058","","5","37","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Clustering algorithms; Trace driven simulation; Cloud computing services; Cloud container clusters; compact exponential optimization; Computationally efficient; Container traffic; On-line algorithms; online algorithms; Optimal placements; Placement algorithm; Placement problems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PFH28Y2X","conferencePaper","2014","Chen, F.; Grundy, J.; Schneider, J.-G.; Yang, Y.; He, Q.","Automated analysis of performance and energy consumption for cloud applications","","","","10.1145/2568088.2568093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899684460&doi=10.1145%2f2568088.2568093&partnerID=40&md5=622fb7a332b7288418657e57354f2225","In cloud environments, IT solutions are delivered to users via shared infrastructure. One consequence of this model is that large cloud data centres consume large amounts of energy and produce significant carbon footprints. A key objective of cloud providers is thus to develop resource provisioning and management solutions at minimum energy consumption while still guaranteeing Service Level Agreements (SLAs). However, a thorough understanding of both system performance and energy consumption patterns in complex cloud systems is imperative to achieve a balance of energy efficiency and acceptable performance. In this paper, we present StressCloud, a performance and energy consumption analysis tool for cloud systems. StressCloud can automatically generate load tests and profile system performance and energy consumption data. Using StressCloud, we have conducted extensive experiments to profile and analyse system performance and energy consumption with different types and mixes of runtime tasks. We collected finegrained energy consumption and performance data with different resource allocation strategies, system configurations and workloads. The experimental results show the correlation coefficients of energy consumption, system resource allocation strategies and workload, as well as the performance of the cloud applications. Our results can be used to guide the design and deployment of cloud applications to balance energy and performance requirements. Copyright is held by the owner/author(s). Publication rights licensed to ACM.","2014","2025-10-22 19:07:33","2025-10-22 19:07:33","","39-50","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Energy efficiency; Cloud computing; Automation; Energy utilization; Energy consumption; Resource allocation; Performance requirements; Carbon footprint; Green Clouds; Resource allocation strategies; Energy consumption analysis; Energy consumption datum; Green cloud; Minimum energy consumption; Service level agreement (SLAs)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2014 - Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"5ITLBJC2","conferencePaper","2017","Nadgowda, S.; Suneja, S.; Bila, N.; Isci, C.","Voyager: Complete Container State Migration","","","","10.1109/ICDCS.2017.91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027285087&doi=10.1109%2fICDCS.2017.91&partnerID=40&md5=ce48676f7441bf8002bc8cf0827f12ea","Due to the small memory footprint and fast startup times offerred by container virtualization, made ever more popular by the Docker platform, containers are seeing rapid adoption as a foundational capability to build PaaS and SaaS clouds. For such container clouds, which are fundamentally different from VM clouds, various cloud management services need to be revisited. In this paper, we present our Voyager-just-in-time live container migration service, designed in accordance with the Open Container Initiative (OCI) principles. Voyager is a novel filesystem-agnostic and vendor-agnostic migration service that provides consistent full-system migration. Voyager combines CRIU-based memory migration together with the data federation capabilities of union mounts to minimize migration downtime. With a union view of data between the source and target hosts, Voyager containers can resume operation instantly on the target host, while performing disk state transfer lazily in the background. © 2017 IEEE.","2017","2025-10-22 19:07:33","2025-10-22 19:07:33","","2137-2142","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Distributed computer systems; Clouds; Just in time; Cloud; Cloud managements; Container Migration; Data federation; Fast start-up; Lazy replication; Lazy Replication; Small memory footprint; State migrations; System migration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Distributed Computing Systems","","","","","","","","","","","","","","",""
"VC5S4LGZ","conferencePaper","2013","Yang, H.; Breslow, A.; Mars, J.; Tang, L.","Bubble-flux: Precise online QoS management for increased utilization in warehouse scale computers","","","","10.1145/2485922.2485974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881190996&doi=10.1145%2f2485922.2485974&partnerID=40&md5=bf2c0ba94cd80ac95309a58a0f29e770","Ensuring the quality of service (QoS) for latency-sensitive applications while allowing co-locations of multiple applications on servers is critical for improving server utilization and reducing cost in modern warehouse-scale computers (WSCs). Recent work relies on static profiling to precisely predict the QoS degradation that results from performance interference among co-running applications to increase the number of ""safe"" co-locations. However, these static profiling techniques have several critical limitations: 1) a priori knowledge of all workloads is required for profiling, 2) it is difficult for the prediction to capture or adapt to phase or load changes of applications, and 3) the prediction technique is limited to only two co-running applications. To address all of these limitations, we present Bubble-Flux, an integrated dynamic interference measurement and online QoS management mechanism to provide accurate QoS control and maximize server utilization. Bubble-Flux uses a Dynamic Bubble to probe servers in real time to measure the instantaneous pressure on the shared hardware resources and precisely predict how the QoS of a latency-sensitive job will be affected by potential co-runners. Once ""safe"" batch jobs are selected and mapped to a server, Bubble-Flux uses an Online Flux Engine to continuously monitor the QoS of the latency-sensitive application and control the execution of batch jobs to adapt to dynamic input, phase, and load changes to deliver satisfactory QoS. Batch applications remain in a state of flux throughout execution. Our results show that the utilization improvement achieved by Bubble-Flux is up to 2.2x better than the prior static approach. Copyright 2013 ACM.","2013","2025-10-22 19:07:33","2025-10-22 19:07:33","","607-618","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Forecasting; Computer architecture; Warehouses; Hardware resources; Instantaneous pressures; Interference measurements; Multiple applications; Prediction techniques; Priori knowledge; Static approach; Utilization improvement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"ENFE4ELY","journalArticle","2019","Yu, Y.; Yang, J.; Guo, C.; Zheng, H.; He, J.","Joint optimization of service request routing and instance placement in the microservice system","Journal of Network and Computer Applications","","","10.1016/j.jnca.2019.102441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072519087&doi=10.1016%2fj.jnca.2019.102441&partnerID=40&md5=12d28f55304bc761583ba7edea990eb5","Microservice architecture is a promising architectural style. It decomposes monolithic software into a set of loosely coupled containerized microservices and associates them into multiple microservice chains to serve service requests. The new architecture creates flexibility for service provisioning but also introduces increased energy consumption and low service performance. Efficient resource allocation is critical. Unfortunately, existing solutions are designed at a coarse level for virtual machine (VM)-based clouds and not optimized for such chain-oriented service provisioning. In this paper, we study the resource allocation optimization problem for service request routing and microservice instance placement, so as to jointly reduce both resource usage and chains’ end-to-end response time for saving energy and guaranteeing Quality of Service (QoS). We design detailed workload models for microservices and chains and formulate the optimization problem as a bi-criteria optimization problem. To address it, a three-stage scheme is proposed to search and optimize the trade-off decisions, route service requests into instances and deploy instances to servers in a balanced manner. Through numerical evaluations, we show that while assuring the same QoS, our scheme performs significantly better than and faster than benchmarking algorithms on reducing energy consumption and balancing load. © 2019","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","147","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; Microservice; QoS; Energy utilization; Economic and social effects; Energy consumption; Resource allocation; Balancing; Reducing energy consumption; Benchmarking algorithm; Bi-criteria optimization; Bicriteria optimization; Efficient resource allocation; End-to-end response time; Load balance; Microservice chain; Resource allocation optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QP4IHVQL","journalArticle","2016","Tumanov, A.; Jiang, A.; Park, J.W.; Kozuch, M.A.; Ganger, G.R.","Jamaisvu: Robust Scheduling with Auto-Estimated Job Runtimes","JamaisVu: Robust Scheduling with Auto-Estimated Job Runtimes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050887060&partnerID=40&md5=2fa5b49d2ba113886b70582cdf0e6b3d","","2016","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N9ZJG8K6","journalArticle","2020","Ding, Z.; Tian, Y.-C.; Tang, M.; Li, Y.; Wang, Y.-G.; Zhou, C.","Profile-Guided Three-Phase Virtual Resource Management for Energy Efficiency of Data Centers","IEEE Transactions on Industrial Electronics","","","10.1109/TIE.2019.2902786","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074686925&doi=10.1109%2fTIE.2019.2902786&partnerID=40&md5=100e3d1868bf115799f4e4a1b0b17050","Energy efficiency is a critical issue in the management of data centers, which form the backbone of cloud computing. Virtual resource management has a significant impact on improving the energy efficiency of data centers. Despite the progress in this area, virtual resource management has been considered mainly at two separate levels: application assignment and virtual machine placement. It has not been well-investigated in a unified framework for both levels, limiting further improvement in the energy efficiency of data centers. To address this issue, this paper proposes the virtual resource management problem for energy efficiency as a constrained optimization problem. Then, this paper simplifies the problem through profile-guided task classification and problem decomposition for complexity reduction and improved energy efficiency. After that, a three-phase framework and algorithms are presented for profiling and profile updating, task classification and application assignment, and successive virtual machine placement. Experimental studies show energy savings of 8-12% by the three-phase framework compared to the existing technique. © 1982-2012 IEEE.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","2460-2468","","3","67","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Information management; Framework and algorithms; Green computing; Natural resources management; Resource allocation; Virtual machine; Data center; Data centers; Network security; energy efficiency; Constrained optimization; Virtual addresses; Virtual resource management; Constrained optimi-zation problems; Problem decomposition; profile; task classification; Task classification; Virtual machine placements; virtual resource management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IF7MR5V7","journalArticle","2019","Watada, J.; Roy, A.; Kadikar, R.; Pham, H.; Xu, B.","Emerging Trends, Techniques and Open Issues of Containerization: A Review","IEEE Access","","","10.1109/ACCESS.2019.2945930","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078452782&doi=10.1109%2fACCESS.2019.2945930&partnerID=40&md5=8cee3372ef3ca737a11b1b4b3bd4438d","Containerization is revolutionizing the way that many industries operate, provisioning major impact to modern computing technologies because it is extra lightweight, highly portable, energy, resource and storage efficient, cost-effective, performance efficient, and extremely quick during boot up. These often facilitate efficient load balancing, low-level system maintenance, server consolidation (for efficient energy and resource utilization) and replication of instances over geographical locations for better fault tolerance to escalate application reliability. However, some recent literature have addressed various challenges (such as complex networking, persistent~storage facilities, cross~data centers and multicloud supports, security issues, and lack of available, capable container management APIs, etc.) regarding successful container adoption in industries, which might have resulted in a seemingly meager increase in industrial deployments of containerization over the past few years despite bestowing efficient lightweight virtualization. Moreover, a comprehensive overview of containerizations along with their popularity dynamics has still not been found in contemporary literature, which further extends knowledge gap between developers and available technologies. Hence, current study touches upon different technicalities involved in containerization with potential problems and possible solutions along with various important industrial applications to manifest its existing supports and technical hardships. Finally, we have conducted a comprehensive experimental study to compare the performance of VMs, containers and unikernels in terms of CPU utilization, memory footprints, network bandwidth, execution time and technological maturity using standard benchmarks and observed containers to deliver satisfactory performance in almost all aspects, however, are still not free from issues regarding isolation security, performance stability, lack of available efficient tools for cross-platform support and persistent storage. Unikernels deliver good performance with VM-like isolation but still need to achieve desired technical maturity (in terms of microprocessor stability, process containment, persistent storage, etc.). VMs, on the other hand, are found to provide stable performance throughout, though bigger memory footprints and slower spin up/down remain their biggest weaknesses. © 2013 IEEE.","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","152443-152472","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Information management; Virtual reality; Virtualization; Benchmarking; Digital storage; Cost effectiveness; Resource utilizations; Fault tolerance; Application reliabilities; Computing technology; containerization; Geographical locations; Industrial deployment; isolation and security; management and orchestration; Packaging; Performance stability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQ2SDIJN","journalArticle","2009","Mell, P.; Grance, T.","The NIST definition of cloud computing","The NIST Definition of Cloud Computing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954051808&partnerID=40&md5=f6091a4b8da174c1360c9fe07e10e513","","2009","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HFX4W33P","journalArticle","2016","Hemmat, R.A.; Hafid, A.","","SLA Violation Prediction in Cloud Computing: A Machine Learning Perspective","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029500612&partnerID=40&md5=84717489e78e87853ff40db2f8f7a964","","2016","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHTUEXHC","journalArticle","2022","Dang-Quang, N.-M.; Yoo, M.","An Efficient Multivariate Autoscaling Framework Using Bi-LSTM for Cloud Computing","Applied Sciences (Switzerland)","","","10.3390/app12073523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128185483&doi=10.3390%2fapp12073523&partnerID=40&md5=27d52741a0a8dc2accedaed973beaa9e","With the rapid development of 5G technology, the need for a flexible and scalable realtime system for data processing has become increasingly important. By predicting future resource workloads, cloud service providers can automatically provision and deprovision user resources for the system beforehand, to meet service level agreements. However, workload demands fluctuate continuously over time, which makes their prediction difficult. Hence, several studies have proposed a technique called time series forecasting to accurately predict the resource workload. However, most of these studies focused solely on univariate time series forecasting; in other words, they only analyzed the measurement of a single feature. This study proposes an efficient multivariate autoscaling framework using bidirectional long short-term memory (Bi-LSTM) for cloud computing. The system framework was designed based on the monitor–analyze–plan–execute loop. The results obtained from our experiments on different actual workload datasets indicated that the proposed multivariate Bi-LSTM exhibited a root-mean-squared error (RMSE) prediction error 1.84-times smaller than that of the univariate one. Furthermore, it reduced the RMSE prediction error by 6.7% and 5.4% when compared with the multivariate LSTM and convolutional neural network-long shortterm memory (CNN-LSTM) models, respectively. Finally, in terms of resource provisioning, the multivariate Bi-LSTM autoscaler was 47.2% and 14.7% more efficient than the multivariate LSTM and CNN-LSTM autoscalers, respectively. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","7","12","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; autoscaling; multivariate variables; resource estimation; time series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I374N2DU","journalArticle","2022","Liu, Z.; Yu, H.; Fan, G.; Chen, L.","Reliability modelling and optimization for microservice-based cloud application using multi-agent system","IET Communications","","","10.1049/cmu2.12371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126098914&doi=10.1049%2fcmu2.12371&partnerID=40&md5=9cb89b082c15ae31fc8cc04ba64c8d4b","In the process of the continuous development of the Internet of Things, cloud computing has been applied in many fields, how to guarantee the quality of service, such as low latency, high bandwidth, high reliability etc., has become a challenging problem. This paper proposes a method to model and optimize reliability for microservice-based cloud applications using multi-agent system (MAS), thus maximizing the reliability of cloud computing and dynamically scheduling microservices to minimize the delay within the budget. Firstly, a dynamic microservice scheduling scheme is proposed to provide efficient computing services by using MAS. A hierarchical cloud computing model is formed by predicated Petri net (PrT net) and the properties of constructed model are analysed. Secondly, agents have been utilized to describe the essential characteristics of microservice scheduling process in the cloud applications. The partial critical path (PCP) aims to maximize the reliability of cloud applications under the limitation of budget and meet the user-defined deadline. Finally, the proposed PCPRO algorithm has been applied to cloud environment, which is suitable for different scientific workflows in the cloud computing environment. The effectiveness of this method is verified by simulation, the experiment results show the effectiveness of the proposed method. © 2022 The Authors. IET Communications published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","1182-1199","","10","16","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Cloud computing; Cloud-computing; Cloud applications; Quality-of-service; Budget control; Low latency; Multi agent systems; Continuous development; High bandwidth; High reliability; Modeling and optimization; Petri nets; Reliability; Reliability modelling; Reliability optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ8X3ICQ","journalArticle","","","","SaaS vs. PaaS vs. IaaS: What’s The Difference & How To Choose—BMC Software|Blogs","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132272208&partnerID=40&md5=f71cb3f5fe8111b9056b65038283cfb4","","","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8TRAHTTK","journalArticle","2018","Vasudevan, M.; Tian, Y.-C.; Tang, M.; Kozan, E.; Zhang, X.","Energy-efficient application assignment in profile-based data center management through a Repairing Genetic Algorithm","Applied Soft Computing Journal","","","10.1016/j.asoc.2018.03.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044168150&doi=10.1016%2fj.asoc.2018.03.016&partnerID=40&md5=0c3c4578b839a55ffeb6f26a238862d0","The massive deployment of data center services and cloud computing comes with exorbitant energy costs and excessive carbon footprint. This demands green initiatives and energy-efficient strategies for greener data centers. Assignment of an application to different virtual machines has a significant impact on both energy consumption and resource utilization in virtual resource management of a data centre. However, energy efficiency and resource utilization are conflicting in general. Thus, it is imperative to develop a scalable application assignment strategy that maintains a trade-off between energy efficiency and resource utilization. To address this problem, this paper formulates application assignment to virtual machines as a profile-driven optimization problem under constraints. Then, a Repairing Genetic Algorithm (RGA) is presented to solve the large-scale optimization problem. It enhances penalty-based genetic algorithm by incorporating the Longest Cloudlet Fastest Processor (LCFP), from which an initial population is generated, and an infeasible-solution repairing procedure (ISRP). The application assignment with RGA is integrated into a three-layer energy management framework for data centres. Experiments are conducted to demonstrate the effectiveness of the presented approach, e.g., 23% less energy consumption and 43% more resource utilization in comparison with the steady-state Genetic Algorithm (GA) under investigated scenarios. © 2018 Elsevier B.V.","2018","2025-10-22 19:07:33","2025-10-22 19:07:33","","399-408","","","67","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Cloud computing; Information management; Energy utilization; Economic and social effects; Energy management; Green computing; Virtual machine; Data center; Data centers; Scheduling algorithms; Network security; Carbon footprint; Carbon; Genetic algorithms; Application assignment; Data center management; Energy efficient strategies; Genetic algorithm; Large-scale optimization; Profile-driven optimizations; Repair; Resource scheduling; Resource-scheduling; Steady-state genetic algorithms; Virtual addresses; Virtual resource management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ABZX6KD4","journalArticle","2019","Qiu, C.; Shen, H.; Chen, L.","Towards green cloud computing: Demand allocation and pricing policies for cloud service brokerage","IEEE Transactions on Big Data","","","10.1109/TBDATA.2018.2823330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140807374&doi=10.1109%2fTBDATA.2018.2823330&partnerID=40&md5=b400573b46ab15d79e7d0c02672746ba","Functioning as an intermediary between tenants and cloud providers, cloud service brokerages (CSBs) can bring about great benefits to the cloud market. As energy costs of cloud computing have been increasing rapidly, there is a need for cloud providers to optimize energy efficiency while maintain high service level performance to tenants, not only for their own benefit but also for social welfares. Thus, for green cloud companies, two questions have arisen: 1) under what pricing policies from the cloud providers to the CSB, a profit-driven CSB is willing to minimize the total energy cost while satisfy tenant demands and 2) how should a CSB distribute tenants demands to achieve this objective? To address question 1), we find a pricing policy for cloud providers such that maximizing CSBs profit is equivalent to minimizing cloud providers energy cost. To address question 2), we first devise a greedy solution, and then propose an approximation algorithm and a decomposition-based solution with a constant approximation ratio. Both simulation and real-world Amazon EC2 experimental results demonstrate the effectiveness of our pricing policy to incentivize CSBs to save energy and the superior performance of our algorithms in energy efficiency and resource utilization over the previous algorithms. © 2015 IEEE.","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","238-251","","2","5","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Cloud-computing; Performance; Cloud services; Green computing; Costs; Cloud providers; Approximation algorithms; Distributed database systems; Green Clouds; cloud service brokerage; Cloud service brokerage; Computing demands; demand allocation; Demand allocation; Energy cost; pricing policy; Pricing policy; Profitability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98BQSYFV","conferencePaper","2018","Chung, A.; Park, J.W.; Ganger, G.R.","Stratus: Cost-aware container scheduling in the public cloud","","","","10.1145/3267809.3267819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058982961&doi=10.1145%2f3267809.3267819&partnerID=40&md5=92b2e003340b423f8524c57fc0a3dace","Stratus is a new cluster scheduler specialized for orchestrating batch job execution on virtual clusters, dynamically allocated collections of virtual machine instances on public IaaS platforms. Unlike schedulers for conventional clusters, Stratus focuses primarily on dollar cost considerations, since public clouds provide effectively unlimited, highly heterogeneous resources allocated on demand. But, since resources are charged-for while allocated, Stratus aggressively packs tasks onto machines, guided by job runtime estimates, trying to make allocated resources be either mostly full (highly utilized) or empty (so they can be released to save money). Simulation experiments based on cluster workload traces from Google and TwoSigma show that Stratus reduces cost by 17–44% compared to state-of-the-art approaches to virtual cluster scheduling. © 2018 Association for Computing Machinery.","2018","2025-10-22 19:07:33","2025-10-22 19:07:33","","121-134","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Cloud computing; Cluster computing; Cost-aware; State-of-the-art approach; Cluster scheduling; Container scheduling; Heterogeneous resources; Public clouds; Runtime estimates; Transient server; Virtual clusters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2018 - Proceedings of the 2018 ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"MFB6UNIA","journalArticle","2021","","","KubeEdge: Kubernetes Native Edge Computing Framework.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119094775&partnerID=40&md5=cdb349b672f62bdfb7b9d2659dace76d","","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQZT8Y58","conferencePaper","2018","Wang, Y.; Zhang, J.; Zhang, X.; Wang, P.; Liu, L.","A Computation Offloading Strategy in Satellite Terrestrial Networks with Double Edge Computing","","","","10.1109/ICCS.2018.8689224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065047384&doi=10.1109%2fICCS.2018.8689224&partnerID=40&md5=24513282b98a1e188b72d85e7731281b","Mobile edge computing (MEC) can efficiently minimize computational latency, reduce response time, and improve quality-of-service (QoS) by offloading tasks in the access network. Although lots of edge computation offloading schemes have been proposed in terrestrial networks, the hybrid satellite terrestrial communication, as an emerging trend for the next generation communication, has not taken edge computing into consideration. In this paper, a novel satellite terrestrial network with double edge computing is introduced to reap the benefits of providing computing service for remote areas. A strategy is designed to solve the problem of efficiently scheduling the edge servers distributed in the satellite terrestrial networks to provide more powerful edge computing services. For the purpose of allocating satellite edge computing resource efficiently in the strategy, a double edge computation offloading algorithm is proposed to optimize energy consumption and reduce latency by assigning tasks to edge servers with minimal cost. Numerical results verify that the proposed algorithm can reduce the average latency and the energy consumption by approximately 45% and 49% respectively. The study on the number selection of utilized satellite edge servers provides an insight for following studies of edge servers scheduling in satellite terrestrial networks. © 2018 IEEE.","2018","2025-10-22 19:07:33","2025-10-22 19:07:33","","450-455","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Energy utilization; Edge computing; Computation offloading; Computational efficiency; Green computing; computation offloading; Computing resource; Satellites; Satellite-terrestrial network; Terrestrial networks; Computing services; double edge computing; Hybrid satellites; Numerical results; satellite terrestrial networks; Terrestrial communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE International Conference on Communication Systems, ICCS 2018","","","","","","","","","","","","","","",""
"FLYTBCAL","journalArticle","2020","Samanta, A.; Tang, J.","Dyme: Dynamic Microservice Scheduling in Edge Computing Enabled IoT","IEEE Internet of Things Journal","","","10.1109/JIOT.2020.2981958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089309950&doi=10.1109%2fJIOT.2020.2981958&partnerID=40&md5=38b71fcbb6b26d203c0c225cde1c059e","In recent years, the rapid development of mobile edge computing (MEC) provides an efficient execution platform at the edge for Internet-of-Things (IoT) applications. Nevertheless, the MEC also provides optimal resources to different microservices, however, underlying network conditions and infrastructures inherently affect the execution process in MEC. Therefore, in the presence of varying network conditions, it is necessary to optimally execute the available task of end users while maximizing the energy efficiency in edge platform and we also need to provide fair Quality-of-Service (QoS). On the other hand, it is necessary to schedule the microservices dynamically to minimize the total network delay and network price. Thus, in this article, unlike most of the existing works, we propose a dynamic microservice scheduling scheme for MEC. We design the microservice scheduling framework mathematically and also discuss the computational complexity of the scheduling algorithm. Extensive simulation results show that the microservice scheduling framework significantly improves the performance metrics in terms of total network delay, average price, satisfaction level, energy consumption rate (ECR), failure rate, and network throughput over other existing baselines. © 2014 IEEE.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","6164-6174","","7","7","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Energy efficiency; Performance metrics; Execution platforms; Energy utilization; Internet of things; Failure analysis; Edge computing; Internet of Things (IOT); edge computing; Extensive simulations; Internet of Things (IoT); microservice; Dynamic microservice scheduling; Energy consumption rates; Network throughput; Quality-of-Service (QoS); Scheduling frameworks; Underlying networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VLCVP29J","conferencePaper","2019","Liang, J.; Liu, F.; Li, S.; Cai, Z.","A Comparative Research on Open Source Edge Computing Systems","","","","10.1007/978-3-030-24265-7_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070225902&doi=10.1007%2f978-3-030-24265-7_14&partnerID=40&md5=871cff564de3a48b4b9c9f2f527b62d4","With the development of edge computing, open source communities have put forward several edge computing systems. This paper discussed about edge computing and its current situation, then presented typical open source edge computing systems such as EdgeX Foundry, Azure IoT Edge, CORD, Apache Edgent and Akraino Edge Stack, and gave a comparison about them on their characteristics. A comparison study on their characteristics were given to help users to understand these open source edge computing systems and make choices. © 2019, Springer Nature Switzerland AG.","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","157-170","","","11633 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Open systems; Edge computing; Current situation; Artificial intelligence; Open sources; Computing system; Comparative research; Comparison study; Edge computing systems; Open source; Open source communities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"2B4KSMFS","conferencePaper","2021","Cao, L.; Merican, A.; Tootaghaj, D.Z.; Ahmed, F.; Sharma, P.; Saxena, V.","CaaS: A Management Framework of Edge Container as a Service for Business Workload","","","","10.1145/3434770.3459741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104683347&doi=10.1145%2f3434770.3459741&partnerID=40&md5=c611321688b3f8a02de87b8dd36cb37d","Enterprises are containerizing their business applications and extending those applications from cloud to edge to achieve better flexibility, agility, and performance for their business workload. Unlike data centers, edge sites including infrastructure and orchestration systems are often heterogeneous and highly customized depending on the resource availability, business requirements of the use case, and technical requirements of the application. However, in many business use cases, the lack of IT professionals with proper domain expertise makes it very challenging to create, manage, and support heterogeneous containerized edge sites at a large scale. In this work, we present the eCaaS framework that provides automated lifecycle management of containerized edge sites and applications. With eCaaS, users can create customized edge sites with only high-level business intents which are analyzed and translated to deployment templates with low-level specifications. The edge site deployment templates are then automatically executed to build, deploy, and configure the containerized edge sites and applications. To support more customization options in the future, eCaaS decouples user intents, deployment rules, and deployment specifications and formulates deployment template generation as an SMT problem to achieve better scalability and extensibility. For creating an edge site with five nodes, eCaaS takes less than one second to generate the deployment template and less than ten minutes to complete the entire deployment.  © 2021 ACM.","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","73-78","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Resource availability; Life cycle; Business applications; Business requirement; Domain expertise; Life-cycle management; Management frameworks; Specifications; Technical requirement; Template generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EdgeSys 2021 - Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking, Part of EuroSys 2021","","","","","","","","","","","","","","",""
"5MNG3IAX","journalArticle","2021","","","K3s: Lightweight Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107067452&partnerID=40&md5=e81cca55863540110c756df6d8b91e2a","","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64K5TZ7G","journalArticle","2020","Chen, S.; Sun, S.; Kang, S.","System integration of terrestrial mobile communication and satellite communication-The trends, challenges and key technologies in B5G and 6G","China Communications","","","10.23919/JCC.2020.12.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099147415&doi=10.23919%2fJCC.2020.12.011&partnerID=40&md5=5e12dd7a62a1f2eda6afe0b870f6d72f","Mobile communication standards have been developed into a new era of B5G and 6G. In recent years, low earth orbit (LEO) satellites and space Internet have become hot topics. The integrated satellite and terrestrial systems have been widely discussed by industries and academics, and even are expected to be applied in those huge constellations in construction. This paper points out the trends of two stages towards system integration of the terrestrial mobile communication and the satellite communications: to be compatible with 5G, and to be integrated within 6G. Based on analysis of the challenges of both stages, key technologies are thereafter analyzed in detail, covering both air interface currently discussed in 3GPP for B5G and also novel network architecture and related transmission technologies toward future 6G. © 2013 China Institute of Communications.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","156-171","","12","17","","","","","","","","","","","","","Scopus","","","","","","","","6G; B5G; satellite communication; space internet; system integration; terrestrial mobile communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IHYUWEZ","conferencePaper","2020","Jia, Y.; Zhang, J.; Wang, P.; Liu, L.; Zhang, X.; Wang, W.","Collaborative Transmission in Hybrid Satellite-Terrestrial Networks: Design and Implementation","","","","10.1109/WCNC45663.2020.9120560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087274899&doi=10.1109%2fWCNC45663.2020.9120560&partnerID=40&md5=71f5fd33a760795c7f04cf1598db8674","With the rapid development of 5G technology, there is an increasing demand of high-definition (HD) video service, so that efficient content transmission is expected to guaranteed the quality of experience of users. However, traditional terrestrial networks can hardly support this kind of service due to the limited coverage and capability especially in scene of remote area or peak hours of hotspots. Under the support of High Throughput Satellite, satellite can serve as a supplement in hybrid satellite-terrestrial networks (HSTN) to provide various of services. Specifically, aggregation in packet level for collaborative transmission between satellite and terrestrial networks is in direction of development which should be reconsidered. In this paper, a classic SDN-aware HSTN architecture is adopted to capture content information of the system and make strategy dynamically for efficient distribution of content in finer scale. Key technologies, including tag method, path selection strategy and reordering scheme, are proposed to achieve collaborative transmission of HD videos. Finally, complete implementation of a prototype, a Hardware In the Loop (HIL) platform with the SITL module of OPNET, is built to illustrate the feasibility and effectiveness of the proposed solutions. Numerical results show that collaborative transmission in HSTN can effectively realize link aggregation, which has great significance for complex conditions in future networks. © 2020 IEEE.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","2020-May","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Design and implementations; User experience; 5G mobile communication systems; Satellites; Terrestrial networks; collaborative transmission; Content information; Content transmission; Digital television; Hardware In the Loop; Hardware in the loops; High-definition videos; hybrid satellite-terrestrial networks; OPNET.; Path selection strategies; Quality of experience (QoE); software defined networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE Wireless Communications and Networking Conference, WCNC","","","","","","","","","","","","","","",""
"I7DQ7EFB","journalArticle","2017","Wang, S.; Zhang, X.; Zhang, Y.; Wang, L.; Yang, J.; Wang, W.","A Survey on Mobile Edge Networks: Convergence of Computing, Caching and Communications","IEEE Access","","","10.1109/ACCESS.2017.2685434","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026285613&doi=10.1109%2fACCESS.2017.2685434&partnerID=40&md5=15df1f231649db466b92db53c693a85d","As the explosive growth of smart devices and the advent of many new applications, traffic volume has been growing exponentially. The traditional centralized network architecture cannot accommodate such user demands due to heavy burden on the backhaul links and long latency. Therefore, new architectures, which bring network functions and contents to the network edge, are proposed, i.e., mobile edge computing and caching. Mobile edge networks provide cloud computing and caching capabilities at the edge of cellular networks. In this survey, we make an exhaustive review on the state-of-the-art research efforts on mobile edge networks. We first give an overview of mobile edge networks, including definition, architecture, and advantages. Next, a comprehensive survey of issues on computing, caching, and communication techniques at the network edge is presented. The applications and use cases of mobile edge networks are discussed. Subsequently, the key enablers of mobile edge networks, such as cloud technology, SDN/NFV, and smart devices are discussed. Finally, open research challenges and future directions are presented as well. © 2013 IEEE.","2017","2025-10-22 19:07:33","2025-10-22 19:07:33","","6757-6779","","","5","","","","","","","","","","","","","Scopus","","","","","","","","Distributed computer systems; Network architecture; Edge computing; Surveys; Mobile edge computing; Network functions; Research challenges; NFV; Cloud technologies; Communication techniques; computational offloading; content delivery; Content delivery; D2D; Edge caching; mobile edge caching; SDN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PDFKDH82","journalArticle","2020","Guo, K.; An, K.; Zhang, B.; Huang, Y.; Tang, X.; Zheng, G.; Tsiftsis, T.A.","Physical Layer Security for Multiuser Satellite Communication Systems with Threshold-Based Scheduling Scheme","IEEE Transactions on Vehicular Technology","","","10.1109/TVT.2020.2979496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085063068&doi=10.1109%2fTVT.2020.2979496&partnerID=40&md5=4b5185b04585a3ef4a02343a2ac11def","Satellite communication (SatCom) has attracted much attention due to its inherent characteristics. Security issues have gained severe concerns in SatCom since it is susceptible to be illegally eavesdropped by malicious ground stations within large-scale wireless coverage. In this paper, we investigate the physical layer security of a multiuser SatCom system in the presence of multiple eavesdroppers. Particularly, we propose a threshold-based scheduling scheme, where the geographically clustered eavesdroppers with both the colluded and collaborated eavesdropping scenarios are assumed. Specifically, closed-form expression for the secrecy outage probability (SOP) is derived for the passive eavesdropping scenario when the channel state information (CSI) of the eavesdroppers is unavailable. Moreover, we obtain a closed-form expression for the average secrecy capacity (ASC) of the considered system under the proposed user scheduling scheme. In order to get further insights of the proposed scheduling scheme at high signal-to-noise ratios (SNRs), the asymptotic analysis for the SOP and ASC is also demonstrated. Moreover, the reduced percentage with respect to number of user examination is also given, which validates the simplicity and efficiency of our proposed scheme compared to the traditional approaches. Numerical results deduce that with the proposed scheme, a comparable system performance with regard to the maximal selection (MS) scheme can be achieved. © 1967-2012 IEEE.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","5129-5141","","5","69","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Security systems; Satellite communication systems; Asymptotic analysis; average secrecy capacity (ASC); Channel state information; Closed-form expression; High signal-to-noise ratio; Inherent characteristics; Physical layer; Physical layer security; Satellite communication (SatCom); Satellite communications; Scheduling schemes; Secrecy outage probabilities; secrecy outage probability (SOP); Signal to noise ratio; threshold-based scheduling; Traditional approaches","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJ9H2XPR","journalArticle","2020","Zhang, J.; Zhang, X.; Wang, P.; Liu, L.; Wang, Y.","Double-edge intelligent integrated satellite terrestrial networks","China Communications","","","10.23919/JCC.2020.09.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094903592&doi=10.23919%2fJCC.2020.09.011&partnerID=40&md5=7743d87d67b2e6206aa466ac32511a45","The efficient integration of satellite and terrestrial networks has become an important component for 6G wireless architectures to provide highly reliable and secure connectivity over a wide geographical area. As the satellite and cellular networks are developed separately these years, the integrated network should synergize the communication, storage, computation capabilities of both sides towards an intelligent system more than mere consideration of coexistence. This has motivated us to develop double-edge intelligent integrated satellite and terrestrial networks (DILIGENT). Leveraging the boost development of multi-access edge computing (MEC) technology and artificial intelligence (AI), the framework is entitled with the systematic learning and adaptive network management of satellite and cellular networks. In this article, we provide a brief review of the state-of-art contributions from the perspective of academic research and standardization. Then we present the overall design of the proposed DILIGENT architecture, where the advantages are discussed and summarized. Strategies of task offloading, content caching and distribution are presented. Numerical results show that the proposed network architecture outperforms the existing integrated networks.  © 2013 China Institute of Communications.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","128-146","","9","17","","","","","","","","","","","","","Scopus","","","","","","","","6G Networks; content caching and distribution; edge intelligence; integrated satellite and terrestrial networks; non-terrestrial networks; task offloading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYD65DC4","conferencePaper","2008","Wu, Q.; Gu, Y.; Zhu, M.; Rao, N.S.V.","Optimizing network performance of computing pipelines in distributed environments","","","","10.1109/IPDPS.2008.4536465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-51049114925&doi=10.1109%2fIPDPS.2008.4536465&partnerID=40&md5=77a71149440384046a16a3dd2ae0bf14","Supporting high performance computing pipelines over wide-area networks is critical to enabling large-scale distributed scientific applications that require fast responses for interactive operations or smooth flows for data streaming. We construct analytical cost models for computing modules, network nodes, and communication links to estimate the computing times on nodes and the data transport times over connections. Based on these time estimates, we present the Efficient Linear Pipeline Configuration method based on dynamic programming that partitions the pipeline modules into groups and strategically maps them onto a set of selected computing nodes in a network to achieve minimum end-to-end delay or maximum frame rate. We implemented this method and evaluated its effectiveness with experiments on a large set of simulated application pipelines and computing networks. The experimental results show that the proposed method outperforms the Streamline and Greedy algorithms. These results, together with polynomial computational complexity, make our method a potential scalable solution for large practical deployments. ©2008 IEEE.","2008","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Java programming language; Data reduction; Computational complexity; Computer networks; Systems engineering; Wide area networks; High performance computing; Chlorine compounds; Distributed parameter networks; Interactive operations; Mathematical programming; Parallel and distributed processing; Pipelines; Scientific applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IPDPS Miami 2008 - Proceedings of the 22nd IEEE International Parallel and Distributed Processing Symposium, Program and CD-ROM","","","","","","","","","","","","","","",""
"5AI3DT67","journalArticle","2023","Liu, R.; Guo, K.; An, K.; Huang, Y.; Zhou, F.; Zhu, S.","Resource Allocation for Cognitive Satellite-HAP-Terrestrial Networks With Non-Orthogonal Multiple Access","IEEE Transactions on Vehicular Technology","","","10.1109/TVT.2023.3252642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151533759&doi=10.1109%2fTVT.2023.3252642&partnerID=40&md5=48720bc968bcb6213cb7cf2365407fe9","Cognitive radio and non-orthogonal multiple access are promising to improve the spectrum efficiency for the satellite-high altitude platform (HAP)-terrestrial networks. To achieve the optimal system performance and guarantee the quality of service, we formulate a constrained mixed integer nonlinear programming problem to maximize the sum rate of secondary network for the considered NOMA-enabled cognitive satellite-HAP-terrestrial network, while considering the constraints of the quality of service of primary users, the maximum power of HAP, and the number of secondary users in a NOMA group. To tackle the non-convex optimization problem, we decouple it into subchannel assignment and power assignment subproblems. Then, a greedy heuristic algorithm is proposed to assign subchannels to secondary users. Moreover, to solve the power allocation subproblem, we further design a power allocation algorithm by utilizing successive convex approximation, dual decomposition, and subgradient methods. On this basis, an iterative joint resource allocation algorithm is designed. Numerical simulations and comparisons with the orthogonal multiple access scheme are provided to verify the effectiveness of the proposed scheme. © 1967-2012 IEEE.","2023","2025-10-22 19:07:33","2025-10-22 19:07:33","","9659-9663","","7","72","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Resource management; Quality-of-service; Resource allocation; Integer programming; Iterative methods; Heuristic algorithms; Convex optimization; Approximation algorithms; Satellite communication systems; Satellites; Array processing; Array signal processing; cognitive radio; Cognitive radio; Heuristics algorithm; Interference; Multiple access; NOMA; Non-orthogonal; non-orthogonal multiple access; Non-orthogonal multiple access; Nonlinear programming; Radio interference; resource allocation; Resources allocation; Satellite-HAP-terrestrial networks; Satellite-high altitude platform-terrestrial network; Spectrum efficiency; Terrestrial networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2YNGYS99","journalArticle","2019","Bao, L.; Wu, C.; Bu, X.; Ren, N.; Shen, M.","Performance modeling and workflow scheduling of microservice-based applications in clouds","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2019.2901467","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070656668&doi=10.1109%2fTPDS.2019.2901467&partnerID=40&md5=d75e7f1cff1ad9a14d73bf84e309b633","Microservice has been increasingly recognized as a promising architectural style for constructing large-scale cloud-based applications within and across organizational boundaries. This microservice-based architecture greatly increases application scalability, but meanwhile incurs an expensive performance overhead, which calls for a careful design of performance modeling and task scheduling. However, these problems have thus far remained largely unexplored. In this paper, we develop a performance modeling and prediction method for independent microservices, design a three-layer performance model for microservice-based applications, formulate a Microservice-based Application Workflow Scheduling problem for minimum end-to-end delay under a user-specified Budget Constraint (MAWS-BC), and propose a heuristic microservice scheduling algorithm. The performance modeling and prediction method are validated and justified by experimental results generated through a well-known microservice benchmark on disparate computing nodes, and the performance superiority of the proposed scheduling solution is illustrated by extensive simulation results in comparison with existing algorithms. © 1990-2012 IEEE.","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","2101-2116","","9","30","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Forecasting; Multitasking; Microservice; cloud computing; Cloud computing; Benchmarking; Cloud-based applications; Extensive simulations; Budget control; Scheduling algorithms; Workflow scheduling; Heuristic methods; Application scalability; Organizational boundaries; performance modeling and prediction; Performance modeling and prediction; task scheduling; Task-scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTVTV3V6","journalArticle","2020","Xie, R.; Tang, Q.; Wang, Q.; Liu, X.; Yu, F.R.; Huang, T.","Satellite-Terrestrial Integrated Edge Computing Networks: Architecture, Challenges, and Open Issues","IEEE Network","","","10.1109/MNET.011.1900369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082557931&doi=10.1109%2fMNET.011.1900369&partnerID=40&md5=5b74c6ef5dca3c190835e7a8488a52c4","STN has been considered a novel network architecture to accommodate a variety of services and applications in future networks. Being a promising paradigm, MEC has been regarded as a key technology-enabler to offer further service innovation and business agility in STN. However, most of the existing research in MEC enabled STN regards a satellite network as a relay network, and the feasibility of tasks processing directly on the satellites is largely ignored. Moreover, the problem of multi-layer edge computing architecture design and heterogeneous edge computing resource co-scheduling, have not been fully considered. Therefore, different from previous works, in this article, we propose a novel architecture named STECN, in which computing resources exist in multi-layer heterogeneous edge computing clusters. The detailed functional components of the proposed STECN are discussed, and we present the promising technical challenges, including meeting QoE requirements, cooperative computation offloading, multi-node task scheduling, mobility management and fault/failure recovery. Finally, some potential research issues for future research are highlighted. © 1986-2012 IEEE.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","224-231","","3","34","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Computer architecture; Network architecture; Edge computing; Mobility management; Computing resource; Technical challenges; Satellites; Services and applications; Cooperative computation; Computing architecture; Functional components; Potential researches","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8Y58TQR","conferencePaper","2008","Wu, Q.; Gu, Y.","Supporting distributed application workflows in heterogeneous computing environments","","","","10.1109/ICPADS.2008.40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-60649109658&doi=10.1109%2fICPADS.2008.40&partnerID=40&md5=62379e43a6133fbdb84b0076a589fa9f","Next-generation computation-intensive applications in various fields of science and engineering feature large-scale computing workflows with complex structures that are often modeled as directed acyclic graphs. Supporting such task graphs and optimizing their end-to-end network performances in heterogeneous computing environments are critical to the success of these distributed applications that require fast response. We construct analytical models for computing modules, network nodes, and communication links to estimate data processing and transport overhead, and formulate the task graph mapping with node reuse and resource sharing for minimum end-to-end delay as an NP-complete optimization problem. We propose a heuristic approach to this problem that recursively computes and maps the critical path to the network using a dynamic programming-based procedure. The performance superiority of the proposed approach is justified by an extensive set of experiments on simulated data sets in comparison with existing methods. © 2008 IEEE.","2008","2025-10-22 19:07:33","2025-10-22 19:07:33","","3-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","Wireless local area networks (WLAN); Heterogeneous computing; Heuristic algorithms; Data storage equipment; Distributed applications; Systems engineering; Optimization problems; Heuristic methods; Analytical models; Applications; Communication links; Complex structures; Critical paths; Data processing; Directed acyclic graphs; Existing methods; Fast response; Graph mapping; Heuristic algorithm; Heuristic approaches; Large-scale computing; Minimum end-to-end delay; Network nodes; NP-complete; Portals; Pptimization problem; Resource-sharing; Science and engineerings; Simulated data sets; Task graphs; Work-flows","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS","","","","","","","","","","","","","","",""
"T9UFFBFV","conferencePaper","2021","Jeffery, A.; Howard, H.; Mortier, R.","Rearchitecting Kubernetes for the Edge","","","","10.1145/3434770.3459730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104662456&doi=10.1145%2f3434770.3459730&partnerID=40&md5=5affbaa5a658a55090c90324acaa80f5","Recent years have seen Kubernetes emerge as a primary choice for container orchestration. Kubernetes largely targets the cloud environment but new use cases require performant, available and scalable orchestration at the edge. Kubernetes stores all cluster state in etcd, a strongly consistent key-value store. We find that at larger etcd cluster sizes, offering higher availability, write request latency significantly increases and throughput decreases similarly. Coupled with approximately 30% of Kubernetes requests being writes, this directly impacts the request latency and availability of Kubernetes, reducing its suitability for the edge. We revisit the requirement of strong consistency and propose an eventually consistent approach instead. This enables higher performance, availability and scalability whilst still supporting the broad needs of Kubernetes. This aims to make Kubernetes much more suitable for performance-critical, dynamically-scaled edge solutions.  © 2021 Owner/Author.","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","7-12","","","","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; Cloud environments; Cluster sizes; Cluster state; CRDTs; edge; eventual consistency; Key-value stores; orchestration; Strong consistency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EdgeSys 2021 - Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking, Part of EuroSys 2021","","","","","","","","","","","","","","",""
"7E2ZSGXA","journalArticle","2019","Yan, L.; Cao, S.; Gong, Y.; Han, H.; Wei, J.; Zhao, Y.; Yang, S.","SatEC: A 5G satellite edge computing framework based on microservice architecture","Sensors (Switzerland)","","","10.3390/s19040831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061862436&doi=10.3390%2fs19040831&partnerID=40&md5=26a618b1c3da3d416270a02563a65f3d","As outlined in the 3Gpp Release 16, 5G satellite access is important for 5G network development in the future. A terrestrial-satellite network integrated with 5G has the characteristics of low delay, high bandwidth, and ubiquitous coverage. A few researchers have proposed integrated schemes for such a network; however, these schemes do not consider the possibility of achieving optimization of the delay characteristic by changing the computing mode of the 5G satellite network. We propose a 5G satellite edge computing framework (5GsatEC), which aims to reduce delay and expand network coverage. This framework consists of embedded hardware platforms and edge computing microservices in satellites. To increase the flexibility of the framework in complex scenarios, we unify the resource management of the central processing unit (CPU), graphics processing unit (GPU), and field-programmable gate array (FPGA); we divide the services into three types: system services, basic services, and user services. In order to verify the performance of the framework, we carried out a series of experiments. The results show that 5GsatEC has a broader coverage than the ground 5G network. The results also show that 5GsatEC has lower delay, a lower packet loss rate, and lower bandwidth consumption than the 5G satellite network. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","4","19","","","","","","","","","","","","","Scopus","","","","","","","","Embedded hardware; Microservices; Resource management; Program processors; Field programmable gate arrays (FPGA); Edge computing; Bandwidth; Graphics processing unit; 5G mobile communication systems; Computing frameworks; Data handling; Computer graphics equipment; Satellite network; Satellites; Bandwidth consumption; Computer graphics; Delay characteristics; Integrated Terrestrial-Satellite Networks; On-board data processing; Queueing networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UCHXUB7G","journalArticle","2022","Ahmed, A.; Abdullah, S.; Iftikhar, S.; Ahmad, I.; Ajmal, S.; Hussain, Q.","A Novel Blockchain Based Secured and QoS Aware IoT Vehicular Network in Edge Cloud Computing","IEEE Access","","","10.1109/ACCESS.2022.3192111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135240594&doi=10.1109%2fACCESS.2022.3192111&partnerID=40&md5=5d86ea1b2cf855a0f2a088b17cde327d","A software-defined vehicular network is made up of an IoT (Internet of Things) based vehicular ad-hoc network and a software-defined network. For better communication in IoT based vehicle networks, researchers are now working on the VANET (Vehicular Ad-hoc Network) to increase the overall system performance. To maximize the VANET ad-hoc network's information application performance and reliability, edge computing has gained the attention of researchers. In current research, cloud computing is used for message related task execution, which increases the response time. We propose a Software-defined Fault Tolerance and QoS-Aware (Quality of Service) IoT-Based Vehicular Networks Using Edge Computing Secured by Blockchain to reduce overall communication delay, message failure fault tolerance, and secure service provisioning for VANET ad-hoc networks in this article. We proposed heuristic algorithms to solve the above mentioned problems of response delay, message failure, fault tolerance, and security provided by the Blockchain. The proposed model gets vehicle messages through SDN (Software defined network) nodes, which are placed on nearby edge servers, and the edge servers are validated by the blockchain to provide secure services to vehicles. The SDN controller, which exists on an edge server, which is placed on the road side to overcome communication delays, receives different messages from the vehicles and divides these messages in to two different categories. The message division is performed by the edge server by judging the time line, size, and emergency situation. SDN controller organized these messages and forwarded them to their destination. After the message is delivered to its destination, a fault tolerance mechanism checks their acknowledgements. If the message delivery fails, the fault tolerance algorithm will resend the failure message. The proposed model is implemented using a custom simulator and compared with the latest VANET based QoS and fault tolerance models. The result shows the performance of the proposed model, which decreased the overall message communication delay by 55% of the normal and emergency messages by using the edge server SDN controller. Furthermore, the proposed model reduces the execution time, security risk, and message failure ratio by using the edge server, cloud server and blockchain infrastructure. © 2013 IEEE.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","77707-77722","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud-computing; Internet of things; Quality-of-service; cloud; Edge computing; Heuristic algorithms; edge computing; Network security; Security; Controllers; security; Block-chain; Blockchain; quality of service; Fault tolerance; Internet of thing system; IoT systems; Ad-hoc networks; Delay; fault-tolerance; response time; Response time; Vehicle to vehicle communications; Vehicles; Vehicular ad hoc networks; Vehicular ad-hoc network; Vehicular Adhoc Networks (VANETs)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4B7VHCJ4","journalArticle","2016","Fazio, M.; Celesti, A.; Ranjan, R.; Liu, C.; Chen, L.; Villari, M.","Open Issues in Scheduling Microservices in the Cloud","IEEE Cloud Computing","","","10.1109/MCC.2016.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996569901&doi=10.1109%2fMCC.2016.112&partnerID=40&md5=d52198bb1cc22e10b6f9e5e3d6df7c95","The adoption of container-based microservices architectures is revolutionizing application design. By adopting a microservices architecture, developers can engineer applications that are composed of multiple lightweight, self-contained, and portable runtime components deployed across a large number of geodistributed servers. © 2016 IEEE.","2016","2025-10-22 19:07:33","2025-10-22 19:07:33","","81-88","","5","3","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Cloud computing; microservices; Internet of things; Cloud systems; Runtimes; Software developer; Distributed applications; Application architecture; Application design; Cloud computing architecture; Federated clouds; Independent components; Service deployment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3M4GF8ND","journalArticle","2022","Ahmed, A.; Abdullah, S.; Bukhsh, M.; Ahmad, I.; Mushtaq, Z.","An Energy-Efficient Data Aggregation Mechanism for IoT Secured by Blockchain","IEEE Access","","","10.1109/ACCESS.2022.3146295","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123737399&doi=10.1109%2fACCESS.2022.3146295&partnerID=40&md5=e4a8f008ac1f1b88bb2c81785dc11f1c","The Internet of Things (IoT) is getting important and interconnected technologies of the world, consisting of sensor devices. The internet is smoothly changing from an internet of people towards an Internet of Things, which permits various objects to connect to another wirelessly. The energy consumption of the IoT routing protocol can affect the network life span. In addition, the high volume of data produced by IoT will result in transmission collision, security issues, and energy dissipation due to increased data redundancy because tiny sensors are usually hard to recharge after they are deployed. Generally, to save energy, data aggregation reduces data redundancy at each node by turning some nodes into sleep mode and others into wake mode. Therefore, it is important to group the nodes with high data similarity using the fuzzy matrix. Then, the data received from the member nodes at the Cluster Head (CH) are analyzed using a fuzzy similarity matrix for clustering. In the next step, after clustering, some nodes are chosen from all groups as redundant nodes. The sleep scheduling mechanism is then applied to reduce data redundancy, network traffic jamming, and transmission costs. We have proposed an Energy-Efficient Data Aggregation Mechanism (EEDAM) secured by blockchain, which uses a data aggregation mechanism at the cluster level to save energy. As edge computing is used to provide on-demand trusted services to IoT with minimum delay, blockchain is integrated inside a cloud server, so the edge is validated by the blockchain to provide secure services to IoT. Finally, we performed simulations to calculate the performance of the proposed mechanism and compared it with the conventional energy-efficient algorithms. The simulation results show that the proposed structural design can successfully reduce the amount of data, provide proper security to the IoT, and extend the wireless sensor network (WSN).  © 2013 IEEE.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","11404-11419","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud-computing; Structural design; Energy utilization; Internet of things; Computer architecture; Network architecture; Edge computing; Green computing; Energy dissipation; Data reduction; Power management (telecommunication); Network security; Security; Sensor nodes; security; energy efficiency; Block-chain; blockchain; Blockchain; Aggregation mechanism; availability; Availability; Cloud security; Cost reduction; Data aggregation; Internet of thing system; IoT systems; Matrix algebra; Redundancy; wireless sensor networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MY2T9QAU","journalArticle","2019","Zhang, Z.; Zhang, W.; Tseng, F.-H.","Satellite Mobile Edge Computing: Improving QoS of High-Speed Satellite-Terrestrial Networks Using Edge Computing Techniques","IEEE Network","","","10.1109/MNET.2018.1800172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060086385&doi=10.1109%2fMNET.2018.1800172&partnerID=40&md5=078a78017daf2673969efb35a6b0e797","The high-speed satellite-terrestrial network (STN) is an indispensable alternative in future mobile communication systems. In this article, we first introduce the architecture and application scenarios of STNs, and then investigate possible ways to implement mobile edge computing (MEC) technique for QoS improvement in STNs. We propose satellite MEC (SMEC), in which a user equipment without a proximal MEC server can also enjoy MEC services via satellite links. We propose a dynamic network virtualization technique to integrate the network resources, and furtherly design a cooperative computation offloading (CCO) model to achieve parallel computation in STNs. Task scheduling models in SMEC are discussed in detail, and an elemental simulation is conducted to evaluate the performance of the proposed CCO model in SMEC. © 1986-2012 IEEE.","2019","2025-10-22 19:07:33","2025-10-22 19:07:33","","70-76","","1","33","","","","","","","","","","","","","Scopus","","","","","","","","Application scenario; Edge computing; Computing techniques; Mobile telecommunication systems; Mobile Edge Computing; Satellite communication systems; Satellites; Cooperative computation; Network resource; Parallel Computation; Radio broadcasting; Satellite links; Satellite-terrestrial network; User equipments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6G2BSPWD","journalArticle","2021","","","K8s: An Open-Source System for Automating Deployment, Scaling, and Management of Containerized Application.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177196335&partnerID=40&md5=5fbd26fbdb996aa781c87e4bd11683e6","","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGH3872Y","conferencePaper","2022","Huang, Y.; Zhang, X.","Microservice Scheduling for Satellite-Terrestrial Hybrid Network with Edge Computing","","","","10.1109/ICCCWorkshops55477.2022.9896704","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141205148&doi=10.1109%2fICCCWorkshops55477.2022.9896704&partnerID=40&md5=79779d3dbc3692df1eb90ce6051f23b0","Satellite-Terrestrial Hybrid Network (STHN) has become a focus for future communication architecture to accommodate more services and applications. STHN combined with Edge Computing (EC) could provide lower delay, faster transfer speed, and better information transmission. Meanwhile, microservice-based architecture greatly increases system flexibility, which fits the STHN. In this paper, to verify the efficiency of STHN with EC system, we develop a platform based on an open-source EC architecture called KubeEdge. The platform not only helps terrestrial to deploy and manage microservice on satellites but also increases the flexibility of satellite service provision. Besides, in this platform, we design a microservice scheduling algorithm called Optimal Microservice Scheduling with Adaptive Link Changes (OMS-ALC) to minimize communication delay. The experimental results show that OMS-ALC outperforms other solutions in end-to-end delay performance.  © 2022 IEEE.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","24-29","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Open systems; Computer architecture; Network architecture; Edge computing; Scheduling algorithms; Computing system; Information transmission; Satellites; Communication architectures; Fast transfer; Hybrid network; Low delay; Services and applications; System flexibility; Transfer speed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2022 IEEE/CIC International Conference on Communications in China, ICCC Workshops 2022","","","","","","","","","","","","","","",""
"DIAGF786","journalArticle","2022","","Ericsson mobility report","Ericsson Mobility Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147910500&partnerID=40&md5=8a0b639c4a1a81d48586a1f2f18faa1c","","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXPPV7NK","conferencePaper","2021","Wang, S.; Li, Q.; Xu, M.; Ma, X.; Zhou, A.; Sun, Q.","Tiansuan Constellation: An Open Research Platform","","","","10.1109/EDGE53862.2021.00022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136239745&doi=10.1109%2fEDGE53862.2021.00022&partnerID=40&md5=df3275bc7b78ea0b858d24438ab285fe","Satellite network is the first step towards interstellar voyages. It can provide global Internet connectivity everywhere on the earth, where most areas cannot access the Internet by the terrestrial infrastructure due to the geographic accessibility and high deployment cost. The space industry experiences a rise in large low-earth-orbit satellite constellations to achieve universal connectivity. The research community is also urgent to do some leading research to bridge the connectivity divide. Researchers now conduct their work by simulation, which is far from enough. However, experiments on real satellites are hindered by the exceptionally high bar of space technology, such as deployment cost and unknown risks. To solve the above challenges, we are eager to contribute to the universal connectivity and build an open research platform, Tiansuan constellation, to support experiments on real satellite networks. We discuss the potential research topics that would benefit from Tiansuan. We provide two case studies that have already been deployed in two experimental satellites of Tiansuan. © 2021 IEEE.","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","94-101","","","2021-September","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Satellite Edge Computing; Satellite network; 6g; 6G; Communication satellites; Deployment costs; Earth (planet); Geographics; Global internet connectivity; Orbits; Research platforms; Satellite edge computing; Satellite internet; Satellite Internet; Space industry; Testbed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE International Conference on Edge Computing","","","","","","","","","","","","","","",""
"TZCG5YDY","conferencePaper","2020","Wei, J.; Cao, S.; Pan, S.; Han, J.; Yan, L.; Zhang, L.","SatEdgeSim: A Toolkit for Modeling and Simulation of Performance Evaluation in Satellite Edge Computing Environments","","","","10.1109/ICCSN49894.2020.9139057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088888490&doi=10.1109%2fICCSN49894.2020.9139057&partnerID=40&md5=6af8230a42250dca31d9dd5fae24aa05","Along with the progress of satellite technology, satellites are becoming more and more powerful, making emerging technologies such as mist computing and edge computing considered in the future development of satellite networks. Satellite networks will use mist/edge computing to provide low-latency, highly reliable information transmission capabilities. However, despite much research in the area of satellite edge computing, there is still a lack of simulation tools with satellite edge computing environments. Here, we propose a satellite edge computing simulator-SatEdgeSim, which is an extension of PureEdgeSim and utilizes the effectiveness of it in simulating cloud, mist and edge computing environments to evaluate the satellite edge computing environment. Finally, we use SatEdgeSim to simulate the impact of different task deployment strategies in satellite edge computing scenarios. Simulation results show that SatEdgeSim is effective in satellite edge computing environment. Compared with the traditional task deployment strategy, the proposed deployment strategy designed in this paper can reduce delay and energy consumption, and improve the task success rate. © 2020 IEEE.","2020","2025-10-22 19:07:33","2025-10-22 19:07:33","","307-313","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Edge computing; Emerging technologies; Computing environments; Low latency; Internet of Things; Deployment strategy; Edge Computing; Information transmission; Mist Computing; Model and simulation; Modeling and Simulation; Satellite Edge Computing; Satellite network; Satellite technology; Satellites","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2020 12th International Conference on Communication Software and Networks, ICCSN 2020","","","","","","","","","","","","","","",""
"3IWFELJF","conferencePaper","2015","Pahl, C.; Lee, B.","Containers and clusters for edge cloud architectures-A technology review","","","","10.1109/FiCloud.2015.35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959064257&doi=10.1109%2fFiCloud.2015.35&partnerID=40&md5=62b8b344c5929aa444c08ae98c6abf59","Cloud technology is moving towards more distribution across multi-clouds and the inclusion of various devices, as evident through IoT and network integration in the context of edge cloud and fog computing. Generally, lightweight virtualisation solutions are beneficial for this architectural setting with smaller, but still virtualised devices to host application and platform services, and the logistics required to manage this. Containerisation is currently discussed as a lightweight virtualisation solution. In addition to having benefits over traditional virtual machines in the cloud in terms of size and flexibility, containers are specifically relevant for platform concerns typically dealt with Platform-as-a-Service (PaaS) clouds such as application packaging and orchestration. For the edge cloud environment, application and service orchestration can help to manage and orchestrate applications through containers as an application packaging mechanism. We review edge cloud requirements and discuss the suitability container and cluster technology of that arise from having to facilitate applications through distributed multi-cloud platforms build from a range of networked nodes ranging from data centres to small devices, which we refer to here as edge cloud. © 2015 IEEE.","2015","2025-10-22 19:07:33","2025-10-22 19:07:33","","379-386","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Platform as a Service (PaaS); Big data; Cloud computing; Container; Multi-clouds; Virtual reality; Distributed computer systems; Cloud Computing; Internet; Internet of things; Cluster computing; Edge clouds; Topology; Cluster; Edge Cloud; Multi-cloud; Orchestration; PaaS; Virtualisation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 International Conference on Future Internet of Things and Cloud, FiCloud 2015 and 2015 International Conference on Open and Big Data, OBD 2015","","","","","","","","","","","","","","",""
"MW9DVKFE","conferencePaper","2018","Xiong, Y.; Sun, Y.; Xing, L.; Huang, Y.","Extend cloud to edge with KubeEdge","","","","10.1109/SEC.2018.00048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060224033&doi=10.1109%2fSEC.2018.00048&partnerID=40&md5=54f1ee667ca65b525e64f5b63ed890ee","In this paper, we introduce an infrastructure in edge computing environment, KubeEdge, to extend cloud capabilities to the edge. In the new form of cloud architecture, Cloud consists of computing resources both at centralized data centers and at distributed edges. KubeEdge infrastructure connects and coordinates two computing environments for applications leveraging both computing resources to achieve better performance and user experience. Technically, KubeEdge provides the network protocol infrastructure and the same runtime environment on the edge as in the cloud, which allows the seamless communication of applications with components running on edge nodes as well as cloud servers. It also allows the existing cloud services and cloud development model to be adopted at edge. Based on Kubernetes [1], KubeEdge architecture includes a network protocol stack called KubeBus, a distributed metadata store and synchronization service, and a lightweight agent (EdgeCore) for the edge. KubeBus is designed to have its own implementation of OSI network protocol layers, which connects servers at edge and VMs in the cloud as one virtual network. KubeBus provides a unified multitenant communication infrastructure with fault tolerance and high availability. The distributed metadata store and sync service is designed to support the offline scenario when edge nodes are not connected to the cloud. EdgeController component in KubeEdge architecture is a controller plugin for Kubernetes [1] to manage remote edge nodes and cloud VMs as one logical cluster, which enables KubeEdge to schedule, deploy and manage container applications across edge and cloud with the same API. © 2018 IEEE","2018","2025-10-22 19:07:33","2025-10-22 19:07:33","","373-377","","","","","","","","","","","","","","","","Scopus","","","","","","","","Internet protocols; Cloud computing; Distributed systems; Cluster computing; Computer architecture; Network architecture; Edge computing; Network protocols; Computing environments; Network layers; Information services; Fault tolerance; Communication infrastructure; Data synchronization; Fault tolerance and high availabilities; Fault tolerant computer systems; Metadata; Network protocol; Network protocol stack; Runtime environments; Seamless communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2018 3rd ACM/IEEE Symposium on Edge Computing, SEC 2018","","","","","","","","","","","","","","",""
"IC27SQJA","journalArticle","2021","Patros, P.; Spillner, J.; Papadopoulos, A.V.; Varghese, B.; Rana, O.; Dustdar, S.","Toward Sustainable Serverless Computing","IEEE Internet Computing","","","10.1109/MIC.2021.3093105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121710845&doi=10.1109%2fMIC.2021.3093105&partnerID=40&md5=f28e5566d277c6654ea70fa0605f15d5","Although serverless computing generally involves executing short-lived functions, the increasing migration to this computing paradigm requires careful consideration of energy and power requirements. serverless computing is also viewed as an economically-driven computational approach, often influenced by the cost of computation, as users are charged for per-subsecond use of computational resources rather than the coarse-grained charging that is common with virtual machines and containers. To ensure that the startup times of serverless functions do not discourage their use, resource providers need to keep these functions hot, often by passing in synthetic data. We describe the real power consumption characteristics of serverless, based on execution traces reported in the literature, and describe potential strategies (some adopted from existing VM and container-based approaches) that can be used to reduce the energy overheads of serverless execution. Our analysis is, purposefully, biased toward the use of machine learning workloads because: (1) workloads are increasingly being used widely across different applications; (2) functions that implement machine learning algorithms can range in complexity from long-running (deep learning) versus short-running (inference only), enabling us to consider serverless across a variety of possible execution behaviors. The general findings are easily translatable to other domains.  © 1997-2012 IEEE.","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","42-50","","6","25","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Deep learning; Coarse-grained; Learning algorithms; Startup time; Resource providers; Computing paradigm; Computational approach; Computational resources; Energy requirements; Inference engines; Power requirement; Real power; Synthetic data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X622T32H","journalArticle","2022","Saboor, A.; Mahmood, A.K.; Omar, A.H.; Hassan, M.F.; Shah, S.N.M.; Ahmadian, A.","Enabling rank-based distribution of microservices among containers for green cloud computing environment","Peer-to-Peer Networking and Applications","","","10.1007/s12083-021-01218-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112841408&doi=10.1007%2fs12083-021-01218-y&partnerID=40&md5=ee57caac17e75a71c6e3bdd06f31114e","Microservices architecture is a functional software design methodology that promises the redefinition of the architectural style that aims to create a single application as a suite of tiny, loosely coupled services or components, each performing its own tasks and interacting with each other. The cloud services widely shifted from monoliths to microservices and gained the popularity for use in scalable cloud application. The usage of microservices involved intensive network communication to call number of interdependent microservices running inside the cloud nodes. It provides flexibility in the delivery of service but also increases energy usage and poor service efficiency which results in increased carbon emissions. To solve these issues, the prevailing technologies were designed for single unit monolithic cloud applications, and not tailored for the chain oriented service delivery. This study addresses the dynamic provisioning of containers and respective microservices in cloud computing environment by building rank-based profiles and using those profiles for allocation of web application’s microservices along with containers to the cloud data centers. The MicroRanker service is proposed to rank all of the participating microservices and distribute them across different nodes even before the execution of the cloud services. Further, the MicroRanker service is utilized to dynamically update the container placement due to continuous DevOps actions. The proposed solution was tested using custom built simulation environment. The achieved results showed that the distribution of containers along with respective microservices in accordance with MicroRanker service resulted in less energy consumption (i.e. between 81.6 kWh-87.7 kWh compared to 88.9 kWh-95.7 kWh) and significantly lowered the emission of carbon (i.e. between 5.92 kg-33.31 kg compared to 17.2 kg-47.35 kg) due to higher utilization of renewable energy. The use of rank-based microservices distribution also decreased response time (i.e. between 29 ms-142 ms compared to 106 ms-217 ms) due to the availability of the container along with microservice within the same data center region. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","77-91","","1","15","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Optimization; Microservices; Cloud computing; Cloud data centers; Energy utilization; Software design; Green computing; Web services; Architectural style; Cloud computing environments; Simulation environment; High performance computing; Carbon; Dynamic provisioning; Network communications; Ranking; Renewable energies; Software design methodologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3A5DH7T","journalArticle","2023","Ouyang, R.; Wang, J.; Xu, H.; Chen, S.; Xiong, X.; Tolba, A.; Zhang, X.","A Microservice and Serverless Architecture for Secure IoT System","Sensors","","","10.3390/s23104868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160394089&doi=10.3390%2fs23104868&partnerID=40&md5=0a7d2eb590561230fad53713c8587eff","In cross-border transactions, the transmission and processing of logistics information directly affect the trading experience and efficiency. The use of Internet of Things (IoT) technology can make this process more intelligent, efficient, and secure. However, most traditional IoT logistics systems are provided by a single logistics company. These independent systems need to withstand high computing loads and network bandwidth when processing large-scale data. Additionally, due to the complex network environment of cross-border transactions, the platform’s information security and system security are difficult to guarantee. To address these challenges, this paper designs and implements an intelligent cross-border logistics system platform that combines serverless architecture and microservice technology. This system can uniformly distribute the services of all logistics companies and divide microservices based on actual business needs. It also studies and designs corresponding Application Programming Interface (API) gateways to solve the interface exposure problem of microservices, thereby ensuring the system’s security. Furthermore, asymmetric encryption technology is used in the serverless architecture to ensure the security of cross-border logistics data. The experiments show that this research solution validates the advantages of combining serverless architecture and microservices, which can significantly reduce the operating costs and system complexity of the platform in cross-border logistics scenarios. It allows for resource expansion and billing based on application program requirements at runtime. The platform can effectively improve the security of cross-border logistics service processes and meet cross-border transaction needs in terms of data security, throughput, and latency. © 2023 by the authors.","2023","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","10","23","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Microservice; Internet of things; Computer architecture; Network architecture; Edge computing; Application programming interfaces (API); Cryptography; encryption; edge computing; article; Complex networks; Operating costs; Network security; Internet of thing security; IoT security; Internet of things technologies; internet of things; bandwidth; Cross-border; Independent systems; information security; Logistics company; Logistics information; Logistics system; microservice; serverless architecture; Serverless architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E33V5CHP","journalArticle","2023","Sallo, D.H.; Kecskemeti, G.","Enriching computing simulators by generating realistic serverless traces","Journal of Cloud Computing","","","10.1186/s13677-023-00397-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150208452&doi=10.1186%2fs13677-023-00397-8&partnerID=40&md5=68c93581a3135014027d6b9fa9d8b39f","Serverless computing is stepping forward to provide a cloud environment that mainly focuses on managing infrastructure, resources and configurations on the behalf of a user. Research in this field can’t rely on commercial providers such as AWS and Azure, as their inflexibility and cost often limits the required levels of reproducibility and scalability. Therefore, simulators have been opted as an alternative solution by the research community. They offer a reduced-cost and easy-setup environment. To get respectable precision, simulators use real traces collected and offered by commercial providers. These traces represent comprehensive information of executed tasks that reflect user behaviour. Due to serverless computing’s recency, typical workload traces employed by IaaS simulators are not well adoptable to the new computing model. In this paper, we propose an approach for generating realistic serverless traces. We enhance our previous generator approach that was based on the Azure Functions dataset. Our new, genetic algorithm based approach improves the statistical properties of the generated traces. We also enabled arbitrary scaling of the workload, while maintaining real users’ behaviour. These advances further support reproducibility in the serverless research community. We validated the results of our generator approach using the coefficient of determination (R2), which shows that our generated workload closely matches the original dataset’s characteristics in terms of execution time, memory utilisation as well as user participation percentage. To demonstrate the benefits of the reusability of the generated traces, we applied them with a diverse set of simulators and shown that they offer reproducible results independently of the simulator used. © 2023, The Author(s).","2023","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","1","12","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Cloud environments; FaaS; Faas; Alternative solutions; Genetic Algorithm; Genetic algorithms; Infrastructure resources; Reduced cost; Reproducibilities; Research communities; Reusability; Serverless trace; Serverless workload; User behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QIMCD8Q2","journalArticle","2023","Mahmoudi, N.; Khazaei, H.","Performance Modeling of Metric-Based Serverless Computing Platforms","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2022.3169619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129646106&doi=10.1109%2fTCC.2022.3169619&partnerID=40&md5=03968c7aea5a520e6e7a7b101751e886","Analytical performance models are very effective in ensuring the quality of service and cost of service deployment remain desirable under different conditions and workloads. While various analytical performance models have been proposed for previous paradigms in cloud computing, serverless computing lacks such models that can provide developers with performance guarantees. Besides, most serverless computing platforms still require developers’ input to specify the configuration for their deployment that could affect both the performance and cost of their deployment, without providing them with any direct and immediate feedback. In previous studies, we built such performance models for steady-state and transient analysis of scale-per-request serverless computing platforms (e.g., AWS Lambda, Azure Functions, Google Cloud Functions) that could give developers immediate feedback about the quality of service and cost of their deployments. In this work, we aim to develop analytical performance models for latest trend in serverless computing platforms that use concurrency value and the rate of requests per second for autoscaling decisions. Examples of such serverless computing platforms are Knative and Google Cloud Run (a managed Knative service by Google). The proposed performance model can help developers and providers predict the performance and cost of deployments with different configurations which could help them tune the configuration toward the best outcome. We validate the applicability and accuracy of the proposed performance model by extensive real-world experimentation on Knative and show that our performance model is able to accurately predict the steady-state characteristics of a given workload with minimal amount of data collection. © 2022 IEEE.","2023","2025-10-22 19:07:33","2025-10-22 19:07:33","","1899-1910","","2","11","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Knative; Serverless computing; Autoscaling; Google+; serverless computing; Cost benefit analysis; Computational modelling; Optimisations; Stochastic systems; optimization; Quality control; Analytical models; Concurrent computing; Google cloud run; knative; metric-based autoscaling; Metric-based autoscaling; Performance Modeling; performance modelling; Random processes; Stochastic models; stochastic processes; Transient analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSINFZ6P","journalArticle","2012","Lee, Y.C.; Zomaya, A.Y.","Energy efficient utilization of resources in cloud computing systems","Journal of Supercomputing","","","10.1007/s11227-010-0421-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027919535&doi=10.1007%2fs11227-010-0421-3&partnerID=40&md5=7eb98f2d838791fa4fb7b3edbcb6cd4c","The energy consumption of under-utilized resources, particularly in a cloud environment, accounts for a substantial amount of the actual energy use. Inherently, a resource allocation strategy that takes into account resource utilization would lead to a better energy efficiency; this, in clouds, extends further with virtualization technologies in that tasks can be easily consolidated. Task consolidation is an effective method to increase resource utilization and in turn reduces energy consumption. Recent studies identified that server energy consumption scales linearly with (processor) resource utilization. This encouraging fact further highlights the significant contribution of task consolidation to the reduction in energy consumption. However, task consolidation can also lead to the freeing up of resources that can sit idling yet still drawing power. There have been some notable efforts to reduce idle power draw, typically by putting computer resources into some form of sleep/power-saving mode. In this paper, we present two energy-conscious task consolidation heuristics, which aim to maximize resource utilization and explicitly take into account both active and idle energy consumption. Our heuristics assign each task to the resource on which the energy consumption for executing the task is explicitly or implicitly minimized without the performance degradation of that task. Based on our experimental results, our heuristics demonstrate their promising energy-saving capability. © Springer Science+Business Media, LLC 2010.","2012","2025-10-22 19:07:33","2025-10-22 19:07:33","","268-280","","2","60","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Scheduling; Energy efficiency; Performance degradation; Cloud computing; Distributed computer systems; Energy utilization; Green computing; Resource allocation; Energy conservation; Resource utilizations; Utilization of resources; Energy aware computing; Energy-aware computing; Load balancing; Reduction in energy consumption; Resource allocation strategies; Task consolidation; Virtualization technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FH6TLQN7","journalArticle","2024","Taruna, S.; Singh, P.; Joshi, S.","","Green Computing In Developed And Developing Countries","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207485808&partnerID=40&md5=21a49eee3a5a381287159982ab226b0b","","2024","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","14","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INR4HRS7","journalArticle","2021","Zafar, M.W.; Sinha, A.; Ahmed, Z.; Qin, Q.; Zaidi, S.A.H.","Effects of biomass energy consumption on environmental quality: The role of education and technology in Asia-Pacific Economic Cooperation countries","Renewable and Sustainable Energy Reviews","","","10.1016/j.rser.2021.110868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101769756&doi=10.1016%2fj.rser.2021.110868&partnerID=40&md5=58c4f04ec1dac46f2d3b980922623b18","Rising concern regarding traditional non-renewable energy consumption has led policymakers to explore the potential of economical renewable energy sources. In this regard, biomass energy has received considerable attention because previous studies have found mixed results regarding the effect of biomass energy on environmental quality. Together with modern technology, biomass energy may significantly influence environmental quality. This study investigates the impact of biomass energy consumption, education, and technological innovation on environmental quality by controlling for the role of economic growth and financial development in the function of environmental quality. Second-generation econometric methods were used to solve the issues of heterogeneity and cross-sectional dependence in the study variables. The Westerlund and Edgerton (2008) cointegration technique confirmed the existence of a long-run equilibrium among the variables in the presence of structural breaks. The panel quantile regression results indicate that biomass energy use and technological innovation reduce environmental quality. Similarly, economic growth increases carbon emissions in the environment. Education and financial development contribute to reduce carbon emissions. © 2021 Elsevier Ltd","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","142","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Economic and social effects; Energy-consumption; Education; Carbon emissions; Bio-mass energy; Biomass; Biomass energy consumption; Carbon; Economic analysis; Economic Co-operation; Economic growths; Engineering education; Environmental quality; Environmental technology; Financial development; Non-renewable energy; Technological innovation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3QKY6Q2","journalArticle","2023","Sunardiyo, S.; Purwanto, P.; Hermawan, H.","Sustainable Campus Policy Strategy in Estimating CO2 Emissions at the Universitas Negeri Semarang, Indonesia","Nature Environment and Pollution Technology","","","10.46488/NEPT.2023.V22I01.044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152522220&doi=10.46488%2fNEPT.2023.V22I01.044&partnerID=40&md5=2349c487d342067d2f98f335f2086871","In the fight against global warming, various options for reducing CO2 emissions are being implemented on campus. Furthermore, the management of campus sustainability at the Universitas Negeri Semarang (UNNES), Central Java, Indonesia, should be supported by accurate forecasts of electrical energy consumption. Therefore, this research aims to develop a predictive model to forecast the consumption of electrical energy in reducing CO2 emissions and to determine the factors triggering the increase. The prediction model is developed using Back Propagation Neural Network Artificial (BP-ANN) architecture. Furthermore, the data on the occupancy of lecturers and education staff as well as on students was obtained from the University's staffing and student affairs bureau. Climatic data such as temperature, humidity, wind speed, the duration of irradiation, and the average intensity of solar radiation were obtained per month from the Meteorology, Climatology, and Geophysics Agency of Semarang, Central Java for the 2013-2019 period as input data. The results of the empirical analysis showed an increase in electrical energy consumption from 2020 to 2025. In March, the consumption decreased but increased from April to June and decreased in July. It then increased until November and December, and it decreased every year. The results of CO2 emissions calculated by considering the emission factors from Indonesia's RUPTLPLN in 2020-2025 showed an increase in electrical energy consumption and the ecological consequences affecting the campus area. Furthermore, the main factors causing the high consumption of electrical energy are the occupancy rate, lecturers, students, and campus employees, as well as local climate influences such as temperature, humidity, wind speed, duration of solar radiation, and intensity of solar radiation. Therefore, developing guidelines to reduce power consumption on campus should be a priority. © 2023 Technoscience Publications. All rights reserved.","2023","2025-10-22 19:07:33","2025-10-22 19:07:33","","463-470","","1","22","","","","","","","","","","","","","Scopus","","","","","","","","BP-ANN; Campus management policies; carbon emission; Central Java; CO2 emissions; electrical power; Electricity consumption; environmental factor; forecasting method; Forecasts; Indonesia; policy strategy; Semarang; spatiotemporal analysis; sustainability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J597HCZX","journalArticle","2021","Mazzara, M.; Dragoni, N.; Bucchiarone, A.; Giaretta, A.; Larsen, S.T.; Dustdar, S.","Microservices: Migration of a Mission Critical System","IEEE Transactions on Services Computing","","","10.1109/TSC.2018.2889087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059027049&doi=10.1109%2fTSC.2018.2889087&partnerID=40&md5=5c8e72ef29ee1e2faf74cecae680ec14","An increasing interest is growing around the idea of microservices and the promise of improving scalability when compared to monolithic systems. Several companies are evaluating pros and cons of a complex migration. In particular, financial institutions are positioned in a difficult situation due to the economic climate and the appearance of agile competitors that can navigate in a more flexible legal framework and started their business since day one with more agile architectures and without being bounded to outdated technological standard. In this paper, we present a real world case study in order to demonstrate how scalability is positively affected by re-implementing a monolithic architecture (MA) into a microservices architecture (MSA). The case study is based on the FX Core system, a mission critical system of Danske Bank, the largest bank in Denmark and one of the leading financial institutions in Northern Europe. The technical problem that has been addressed and solved in this paper is the identification of a repeatable migration process that can be used to convert a real world Monolithic architecture into a Microservices architecture in the specific setting of financial domain, typically characterized by legacy systems and batch-based processing on heterogeneous data sources.  © 2008-2012 IEEE.","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","1464-1477","","5","14","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; microservices; Automation; Software architecture; Computer architecture; Data handling; Agile manufacturing systems; Scalability; Legacy systems; Information services; Tools; Monolithic architecture; Agile architectures; Batch data processing; Finance; Financial institution; Heterogeneous data sources; Mission critical systems; scalability; Service computing; Service oriented architecture (SOA); software architecture; Technological standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFSW8WHF","journalArticle","2022","Li, Z.; Guo, L.; Cheng, J.; Chen, Q.; He, B.; Guo, M.","The Serverless Computing Survey: A Technical Primer for Design Architecture","ACM Computing Surveys","","","10.1145/3508360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149425293&doi=10.1145%2f3508360&partnerID=40&md5=fa85ba8ddf2629f7804768d2b9738f39","The development of cloud infrastructures inspires the emergence of cloud-native computing. As the most promising architecture for deploying microservices, serverless computing has recently attracted more and more attention in both industry and academia. Due to its inherent scalability and flexibility, serverless computing becomes attractive and more pervasive for ever-growing Internet services. Despite the momentum in the cloud-native community, the existing challenges and compromises still wait for more advanced research and solutions to further explore the potential of the serverless computing model. As a contribution to this knowledge, this article surveys and elaborates the research domains in the serverless context by decoupling the architecture into four stack layers: Virtualization, Encapsule, System Orchestration, and System Coordination. Inspired by the security model, we highlight the key implications and limitations of these works in each layer, and make suggestions for potential challenges to the field of future serverless computing.  © 2022 Association for Computing Machinery.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","10","54","","","","","","","","","","","","","Scopus","","","","","","","","Computer architecture; Architecture; Design architecture; FaaS; Serverless computing; Cloud infrastructures; Faas; Advanced researches; architecture design; Architecture designs; Computing surveys; Internet-services; Lambda paradigm; Lambda's","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X38M3QET","journalArticle","2022","Sellami, K.; Ouni, A.; Saied, M.A.; Bouktif, S.; Mkaouer, M.W.","Improving microservices extraction using evolutionary search","Information and Software Technology","","","10.1016/j.infsof.2022.106996","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134792906&doi=10.1016%2fj.infsof.2022.106996&partnerID=40&md5=fc5c1a3e4564f414f946f9e2c52f23b0","Context: Microservices constitute a modern style of building software applications as collections of small, cohesive, and loosely coupled services, i.e., modules, that are developed, deployed, and scaled independently. Objective: The migration from legacy systems towards the microservice-based architecture is not a trivial task. It is still manual, time-consuming, error-prone and subsequently costly. The most critical and challenging issue is the cost-effective identification of microservices boundaries that ensure adequate granularity and cohesiveness. Method: To address this problem, we introduce in this paper a novel approach, named MSExtractor, that formulates microservices identification as a multi-objective optimization problem. The proposed solution aims at decomposing a legacy application into a set of cohesive, loosely-coupled and coarse-grained services. We employ the Indicator-Based Evolutionary Algorithm (IBEA) to drive a search process towards optimal microservices identification while considering structural and semantic dependencies in the source code. Results: We conduct an empirical evaluation on a benchmark of seven software systems to assess the efficiency of our approach. Results show that MSExtractor is able to carry out an effective identification of relevant microservice candidates and outperforms three other existing approaches. Conclusion: In this paper, we show that MSExtractor is able to extract cohesive and loosely coupled services with higher performance than three other considered methods. However, we advocate that while automated microservices identification approaches are very helpful, the role of the human experts remains crucial to validate and calibrate the extracted microservices. © 2022","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","","","","151","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Microservice; Microservices; Optimal systems; Cost effectiveness; Multiobjective optimization; Legacy systems; Microservice architecture; Microservices architecture; Semantics; Building softwares; Error prones; Evolutionary algorithms; Evolutionary search; Legacy decomposition; Loosely coupled; Search-based; Search-based software engineering; Software applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VH6XNE8Y","journalArticle","2023","Jain, M.; Kumar, D.; Chaudhary, J.; Kumar, S.; Sharma, S.; Singh Verma, A.","Review on E-waste management and its impact on the environment and society","Waste Management Bulletin","","","10.1016/j.wmb.2023.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185097073&doi=10.1016%2fj.wmb.2023.06.004&partnerID=40&md5=6e826c3f4097eed306c540a091a3cc38","Electronic trash, often known as E-waste, is a type of garbage generated by electronic in the industrial world, trash is one of the most difficult and rapidly expanding issues. E-waste is made up of old or end-of-life electronic appliances such as computers, laptops, televisions, generators, DVDs, mobile phones, freezers, and other items that are typically discarded by their original owners due to their short lifespan. It contains a number of hazardous constituents that have a negative impact on the environment and, more importantly, human health if not properly managed. Because it includes harmful chemical elements, E-waste proves to be a significant difficulty. Since it is believed that E-waste is a future of communications but due to the short life span of various appliances, they are being trashed and pollutes the environment. Many groups and governments from various nations have implemented a variety of ways to address the problem and threat to the environment and human health. Hence, this review presents a compendium of various sources of E-waste, environmental hazards, its composition and characterization, E-waste scenarios in India and global world. For the sake of the future, techniques of handling and processing, as well as E-waste recycling, should be used. This paper mainly outlines the issue of E-waste also covering the improvement and plan to tackle the issue. © 2023 The Authors","2023","2025-10-22 19:07:33","2025-10-22 19:07:33","","34-44","","3","1","","","","","","","","","","","","","Scopus","","","","","","","","E-waste management; E-waste recycling; Environmental pollution; Human health","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YYV5HBY","conferencePaper","2022","Badhoutiya, A.","Green Cloud Computing- Next Step Towards Eco-friendly Work Stations","","","","10.1109/ICECA55336.2022.10009629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147521755&doi=10.1109%2fICECA55336.2022.10009629&partnerID=40&md5=b2af86bcc17b05374a161ebdfc77dd14","Cloud computing is a solution to various computational problems by offering different services through the internet making use of various resources. IT industry always face energy consumption and carbon emission problems. Datacenters play crucial role as a support in cloud computing. That's why the urge to open more and more datacenters is increasing day by day. As a result of the higher power usage at data centers, this boosts the economic and environmental costs. Furthermore, the increased release of CO2 and other gases has resulted in an increase in carbon footprint and, as a result, the greenhouse effect. These are the forces that propel green computing technology forward. A brief introduction of cloud computing, related relevant researches and various approaches to use green computing is provided in this paper. Measurement, modelling and prediction of consumed energy by different organizations is necessary to maintain the environmental balance by reducing carbon emission as well as to make sure to avail the presently available energy resources for our upcoming future generations. The elaboration of several research issues in implementing green computing as well as their solutions is discussed in this paper.  © 2022 IEEE.","2022","2025-10-22 19:07:33","2025-10-22 19:07:33","","809-813","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Datacenter; Cloud computing; Cloud-computing; Cloud data centers; Green computing; Computing power; Google+; Carbon footprint; Carbon emissions; cloud data centers; Computational problem; Eco-friendly; electronic equipment; Energy resources; google search; Google search; Green Clouds; Greenhouse effect; Oscillators (electronic); power consumption; Work station","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","6th International Conference on Electronics, Communication and Aerospace Technology, ICECA 2022 - Proceedings","","","","","","","","","","","","","","",""
"I39774I3","conferencePaper","2021","Purnomo, A.; Anam, F.; Afia, N.; Septianto, A.; Mufliq, A.","Four decades of the green computing study: A bibliometric overview","","","","10.1109/ICIMTech53080.2021.9535069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116101481&doi=10.1109%2fICIMTech53080.2021.9535069&partnerID=40&md5=7325076e3b6add0c4b2528395e14d932","Study on green computing continues to develop but is limited to one country and/or one field. From a bibliometric overview, this study aims to visually study mapping and research trends in the field of green computing on an international scale. This study used bibliometric techniques with secondary data from Scopus. Analyze and visualize data using the VOSViewer program and the analyze search results function on Scopus. This study analyzed 2, 596 scientific documents published from 1979 to 2020. According to the research, the Chinese Academy of Sciences, China, and Rajkumar Buyya from the University of Melbourne had the most active organization and individual scientists in green computing research. China and IEEE Access were the most countries and disseminated outlets of green computing. There were five category maps of collaborative researchers from around the world. Based on the identification of a collection of knowledge created from forty-one years of publication, this research proposes a grouping of green computing study themes: Computer science, Environmental management, Mobile computing, Energy, and Sustainability, abbreviated as CEMES study themes.  © 2021 IEEE.","2021","2025-10-22 19:07:33","2025-10-22 19:07:33","","795-800","","","","","","","","","","","","","","","","Scopus","","","","","","","","Mapping; Green computing; Environmental management; Bibliometric; Bibliometric techniques; Computing research; International scale; Research mapping; Research trends; Scientific documents; Secondary datum; Study theme; Study themes; Sustainable development; University of Melbourne","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of 2021 International Conference on Information Management and Technology, ICIMTech 2021","","","","","","","","","","","","","","",""
"6RARQR3G","journalArticle","2008","Murugesan, S.","Harnessing green IT: Principles and practices","IT Professional","","","10.1109/MITP.2008.10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-38949154490&doi=10.1109%2fMITP.2008.10&partnerID=40&md5=0335ea79e81859dbd9ca0a58523e6066","The basic principles and practices that need to be adopted for a greener Information Technology (IT) regarding environmental impacts from IT and the regulations that need to be complied are discussed. Green IT includes various focus areas and activities such as design of environmental sustainability, energy-efficient computing, power management, and server visualization. Adoption of green IT practices offer financial and other benefits in terms of lesser power consumption. A holistic approach including green use, green disposal, green design, and green manufacturing address the problems faced while adopting green IT practices. The environmentally sound practices while achieving green IT include reduction of energy consumption by PCs, enabling power management features, using screensavers, and greening data centers.","2008","2025-10-22 19:07:34","2025-10-22 19:07:34","","24-33","","1","10","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Information management; Energy utilization; Information technology; Servers; Problem solving; Environmental sustainability; Greening data centers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SQ8YNM2K","journalArticle","2023","Adhikari, A.","GREEN INFORMATION AND COMMUNICATION TECHNOLOGY AT HIGHER EDUCATION ORGANIZATION: SOLUTION FOR SUSTENANCE OF ICT IN FUTURE","Int. J. Humanit. Eng. Sci. Manag","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207507159&partnerID=40&md5=3e69df54247b5fffb5735e6808bcfa35","","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","48-56","","1","4","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X24KXW7V","conferencePaper","2023","Pourreza, M.; Narasimhan, P.","An Empirical Study of Resource-Stressing Faults in Edge-Computing Applications","","","","10.1145/3578354.3592873","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159356560&doi=10.1145%2f3578354.3592873&partnerID=40&md5=431c73981c4bffea11cf7ef1177985c4","Our growing reliance on edge-computing applications makes it crucial to improve the reliability of edge-computing systems. With multiple classes of edge-computing applications, different types of faults, and different kinds of resources needed by the applications, it remains unclear which resource exhaustion has the most disruptive impact on the latency experienced by the edge applications. Without this information, it is challenging to determine which faults to prioritize when implementing fault tolerance for edge computing. To address this challenge, we conduct an empirical study on a representative edge computing environment using well-known edge-computing benchmark applications (DeFog and ComB) and injecting resource-stressing faults (via stress-ng and hping). Our study reveals that memory overloads, CPU cache thrashing, frequent context switching, and page faults are the biggest disruptors of latency for edge-based applications.  © 2023 Owner/Author(s).","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","54-59","","","","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Benchmarking; Empirical studies; Computing environments; edge computing; Benchmark; benchmark; Benchmark applications; Computing applications; Computing system; Context switching; fault injection; Fault injection; fault tolerance; Fault tolerance; Multiple class","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EdgeSys 2023 - Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking, Part of EuroSys 2023","","","","","","","","","","","","","","",""
"NFGB7DU5","journalArticle","2017","Ahmad, S.; Lavin, A.; Purdy, S.; Agha, Z.","Unsupervised real-time anomaly detection for streaming data","Neurocomputing","","","10.1016/j.neucom.2017.04.070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020719859&doi=10.1016%2fj.neucom.2017.04.070&partnerID=40&md5=9e99f987e8e50f3937ebf8b39a79cb6b","We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics. © 2017 The Author(s)","2017","2025-10-22 19:07:34","2025-10-22 19:07:34","","134-147","","","262","","","","","","","","","","","","","Scopus","","","","","","","","Real time systems; data analysis; Anomaly detection; benchmarking; Anomaly-detection algorithms; time series analysis; Unsupervised learning; Signal detection; Article; Benchmark dataset; Benchmark datasets; classification algorithm; Concept drift; Concept drifts; controlled study; Data streams; Hierarchical Temporal Memory; Hierarchical temporal memory (htm); learning algorithm; mathematical computing; online system; priority journal; Real-time anomaly detections; Streaming data; Technical challenges; Temporal memory; unsupervised machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J849ESMQ","conferencePaper","2018","Xu, H.; Chen, W.; Zhao, N.; Li, Z.; Bu, J.; Li, Z.; Liu, Y.; Zhao, Y.; Pei, D.; Feng, Y.; Chen, J.; Wang, Z.; Qiao, H.","Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications","","","","10.1145/3178876.3185996","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085158868&doi=10.1145%2f3178876.3185996&partnerID=40&md5=6fbda4532daa158dda4772ddf2a9fd25","To ensure undisrupted business, large Internet companies need to closely monitor various KPIs (e.g., Page Views, number of online users, and number of orders) of its Web applications, to accurately detect anomalies and trigger timely troubleshooting/mitigation. However, anomaly detection for these seasonal KPIs with various patterns and data quality has been a great challenge, especially without labels. In this paper, we proposed Donut, an unsupervised anomaly detection algorithm based on VAE. Thanks to a few of our key techniques, Donut greatly outperforms a state-of-arts supervised ensemble approach and a baseline VAE approach, and its best F-scores range from 0.75 to 0.9 for the studied KPIs from a top global Internet company. We come up with a novel KDE interpretation of reconstruction for Donut, making it the first VAE-based anomaly detection algorithm with solid theoretical explanation. © 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License.","2018","2025-10-22 19:07:34","2025-10-22 19:07:34","","187-196","","","","","","","","","","","","","","","","Scopus","","","","","","","","Signal encoding; Anomaly detection; Unsupervised anomaly detection; World Wide Web; Auto encoders; Anomaly-detection algorithms; Arts computing; Data quality; Ensemble approaches; Global Internet; Online users; Seasonal KPI; Signal detection; Variational auto-encoder; WEB application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018","","","","","","","","","","","","","","",""
"S59IMQRD","conferencePaper","2022","Yang, L.; Li, J.; Shi, K.; Yang, S.; Yang, Q.; Sun, J.","MicroMILTS: Fault Location for Microservices Based Mutual Information and LSTM Autoencoder","","","","10.23919/APNOMS56106.2022.9919941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142092014&doi=10.23919%2fAPNOMS56106.2022.9919941&partnerID=40&md5=f656f179b9ae17b27e203c312a65a85a","Driven by the development of cloud computing and artificial intelligence, architecture has dramatically improved in terms of flexibility and scalability in software development. Therefore, it is increasingly being used to build large-scale applications for agile development. However, along with the technology heterogeneity, the dynamics of running instances, and the complexity of service dependencies, fault localization is extraordinarily difficult. In this paper, we present MicroMILTS, a microservice fault location method based on mutual information and an LSTM Autoencoder. MicroMILTS first uses BIRCH for anomaly detection based on the analysis of the performance metrics data correlated to microservice anomalies. Once anomalies are detected, a service dependency property graph is constructed based on the real-time microservice invocation relationships and the reconstructed deviations of performance metrics with the LSTM Autoencoder. Next, MicroMILTS dynamically updates the weight of each node in the service dependency property graph. Then, a PageRank-based random walk is applied for further ranking root causes. Finally, a Sock-shop microservice system is built on the Huawei Cloud to evaluate the performance of MicroMILTS. The experiment shows that MicroMILTS achieves a good root cause location result, with 90.4 % in precision and 91.6% in mean average precision, outperforming state-of-the-art methods. © 2022 IEICE.","2022","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Cloud-computing; microservices; Software design; Large-scale applications; Learning systems; Anomaly detection; Long short-term memory; Root cause; Auto encoders; Performance metrices; fault location; Location; LSTM autoencoder; LSTM Autoencoder; Mutual informations; performance metrics; Property; Service dependency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","APNOMS 2022 - 23rd Asia-Pacific Network Operations and Management Symposium: Data-Driven Intelligent Management in the Era of beyond 5G","","","","","","","","","","","","","","",""
"A893G74E","conferencePaper","2022","Zhang, C.; Peng, X.; Sha, C.; Zhang, K.; Fu, Z.; Wu, X.; Lin, Q.; Zhang, D.","DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning","","","","10.1145/3510003.3510180","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133555577&doi=10.1145%2f3510003.3510180&partnerID=40&md5=c15de94f433782e8cc6a26ecf087108f","A microservice system in industry is usually a large-scale dis-tributed system consisting of dozens to thousands of services run-ning in different machines. An anomaly of the system often can be reflected in traces and logs, which record inter-service interactions and intra-service behaviors respectively. Existing trace anomaly detection approaches treat a trace as a sequence of service invocations. They ignore the complex structure of a trace brought by its invocation hierarchy and parallel/asynchronous invocations. On the other hand, existing log anomaly detection approaches treat a log as a sequence of events and cannot handle microservice logs that are distributed in a large number of services with complex interactions. In this paper, we propose DeepTraLog, a deep learning based microservice anomaly detection approach. DeepTraLog uses a unified graph representation to describe the complex structure of a trace together with log events embedded in the structure. Based on the graph representation, DeepTraLog trains a GGNNs based deep SVDD model by combing traces and logs and detects anom-alies in new traces and the corresponding logs. Evaluation on a microservice benchmark shows that DeepTraLog achieves a high precision (0.93) and recall (0.97), outperforming state-of-the-art trace/log anomaly detection approaches with an average increase of 0.37 in F1-score. It also validates the efficiency of DeepTraLog, the contribution of the unified graph representation, and the impact of the configurations of some key parameters. © 2022 ACM.","2022","2025-10-22 19:07:34","2025-10-22 19:07:34","","623-634","","","2022-May","","","","","","","","","","","","","Scopus","","","","","","","","Log analysis; Microservice; Deep learning; Tracing; Graphic methods; Deep neural networks; Complex networks; Anomaly detection; World Wide Web; Anomaly Detection; Complexes structure; Deep Learning; Detection approach; Graph Neural Network; Graph neural networks; Graph representation; Graph-based; Log Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"258L4QPH","journalArticle","2018","Ibidunmoye, O.; Rezaie, A.-R.; Elmroth, E.","Adaptive anomaly detection in performance metric streams","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2017.2750906","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043695414&doi=10.1109%2fTNSM.2017.2750906&partnerID=40&md5=ff1b87715b87270275d5c02e7db83fbc","Continuous detection of performance anomalies such as service degradations has become critical in cloud and Internet services due to impact on quality of service and end-user experience. However, the volume and fast changing behavior of metric streams have rendered it a challenging task. Many diagnosis frameworks often rely on thresholding with stationarity or normality assumption, or on complex models requiring extensive offline training. Such techniques are known to be prone to spurious false-alarms in online settings as metric streams undergo rapid contextual changes from known baselines. Hence, we propose two unsupervised incremental techniques following a two-step strategy. First, we estimate an underlying temporal property of the stream via adaptive learning and, then we apply statistically robust control charts to recognize deviations. We evaluated our techniques by replaying over 40 time-series streams from the Yahoo Webscope S5 datasets as well as four other traces of real Web service QoS and ISP traffic measurements. Our methods achieve high detection accuracy and few false-alarms, and better performance in general compared to an open-source package for time-series anomaly detection. © 2004-2012 IEEE.","2018","2025-10-22 19:07:34","2025-10-22 19:07:34","","217-231","","1","15","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Errors; Web services; Computer networks; Telecommunication services; anomaly detection; Anomaly detection; Performance monitoring; Time series analysis; computer network management; Continuous detections; Incremental techniques; Open source package; Performance anomaly; Performance metrices; Performance monitoring and measurement; Quality control; quality of service; Robust control; time series analysis; Traffic measurements; unsupervised learning; Unsupervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RMK4DCVF","conferencePaper","2023","Dave, D.; Sawhney, G.; Khut, D.; Nawale, S.; Aggrawal, P.; Bhavathankar, P.","AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised Scenarios","","","","10.1109/BdKCSE59280.2023.10339699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182274725&doi=10.1109%2fBdKCSE59280.2023.10339699&partnerID=40&md5=de6ed58ee60d4ab0249400fdd6b60879","Artificial intelligence operations (AIOps) play a pivotal role in identifying, mitigating, and analyzing anomalous system behaviors and alerts. However, the research landscape in this field remains limited, leaving significant gaps unexplored. This study introduces a novel hybrid framework through an innovative algorithm that incorporates an unsupervised strategy. This strategy integrates Principal Component Analysis (PCA) and Artificial Neural Networks (ANNs) and uses a custom loss function to substantially enhance the effectiveness of log anomaly detection. The proposed approach encompasses the utilization of both simulated and real-world datasets, including logs from SockShop and Hadoop Distributed File System (HDFS). The experimental results are highly promising, demonstrating significant reductions in pseudo-positives. Moreover, this strategy offers notable advantages, such as the ability to process logs in their raw, unprocessed form, and the potential for further enhancements. The successful implementation of this approach showcases a remarkable reduction in anomalous logs, thus un-equivocally establishing the efficacy of the proposed methodology. Ultimately, this study makes a substantial contribution to the advancement of log anomaly detection within AIOps platforms, addressing the critical need for effective and efficient log analysis in modern and complex systems.  © 2023 IEEE.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","File organization; Anomaly detection; Neural networks; Principal component analysis; % reductions; AIOps; anomaly log detection; Anomaly log detection; Artificial intelligence operation; Intelligence operations; Log data; Log data analyse; log data analysis; Pseudo positive; pseudo positives; recurring anomalies; Recurring anomaly; System behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 8th International Conference on Big Data, Knowledge and Control Systems Engineering, BdKCSE 2023","","","","","","","","","","","","","","",""
"7NSXNWAX","journalArticle","2022","Soldani, J.; Brogi, A.","Anomaly Detection and Failure Root Cause Analysis in (Micro) Service-Based Cloud Applications: A Survey","ACM Computing Surveys","","","10.1145/3501297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143306533&doi=10.1145%2f3501297&partnerID=40&md5=88ae0f33e8f50b1363c68cff414fc265","The proliferation of services and service interactions within microservices and cloud-native applications, makes it harder to detect failures and to identify their possible root causes, which is, on the other hand crucial to promptly recover and fix applications. Various techniques have been proposed to promptly detect failures based on their symptoms, viz., observing anomalous behaviour in one or more application services, as well as to analyse logs or monitored performance of such services to determine the possible root causes for observed anomalies. The objective of this survey is to provide a structured overview and qualitative analysis of currently available techniques for anomaly detection and root cause analysis in modern multi-service applications. Some open challenges and research directions stemming out from the analysis are also discussed. © 2022 Association for Computing Machinery.","2022","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","3","55","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Failure detection; anomaly detection; Anomaly detection; Root cause; root cause analysis; Micro services; Root cause analysis; Failure (mechanical); Failure root cause analysis; failure detection; Multi-service application; multi-service applications; Multi-services; Services applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35WKET6C","conferencePaper","2010","Wang, H.; Shi, Y.; Zhou, X.; Zhou, Q.; Shao, S.; Bouguettaya, A.","Web service classification using support vector machine","","","","10.1109/ICTAI.2010.9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751533734&doi=10.1109%2fICTAI.2010.9&partnerID=40&md5=79edf28a8230c1092727b8cff603f212","Classification is a widely used mechanism for facilitatingWeb service discovery. Existing methods for automaticWeb service classification only consider the case where the category set is small. When the category set is big, the conventional classification methods usually require a large sample collection, which is hardly available in real world settings. This paper presents a novel method to conduct service classification with a medium or big category set. It uses the descriptive information of categories in a large-scale taxonomy as sample data, so as to disengage from the dependence on sample service documents. A new feature selection method is introduced to enable efficient classification using this new type of sample data. We demonstrate the effectiveness of our classification method through extensive experiments. © 2010 IEEE.","2010","2025-10-22 19:07:34","2025-10-22 19:07:34","","3-6","","","1","","","","","","","","","","","","","Scopus","","","","","","","","Web services; Artificial intelligence; Feature extraction; Classification methods; Conventional classification methods; Descriptive information; Existing method; Feature selection methods; Novel methods; Real world setting; Sample collection; Sample data; Service discovery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","","","","","","","","","","","","","","",""
"WHQ9BR2S","conferencePaper","2022","Soldani, J.; Forti, S.; Brogi, A.","Failure Root Cause Analysis for Microservices, Explained","","","","10.1007/978-3-031-16092-9_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137990399&doi=10.1007%2f978-3-031-16092-9_6&partnerID=40&md5=6516f18d1faf8c8cc8c81e8d8a891b94","Determining the root causes of observed failures is a main issue in microservice-based applications. Unfortunately, available root cause analysis techniques do not focus on explaining how root failures actually caused the observed failure. On the other hand, the availability of such explanations would greatly help to pick adequate countermeasures, e.g., by introducing circuit breakers or bulkheads. We hence present a declarative root cause analysis technique, which can determine the cascading failures that possibly caused an observed failure, identifying also (or starting from) a root cause. We also introduce a prototype implementation of our technique, and we use it to assess our technique by means of controlled experiments. © 2022, IFIP International Federation for Information Processing.","2022","2025-10-22 19:07:34","2025-10-22 19:07:34","","74-91","","","13272 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Prototype implementations; Controlled experiment; Analysis techniques; Root cause; Root cause analysis; Cascading failures; Circuit-breakers; Electric circuit breakers; Failure (mechanical); Failure root cause analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"7PML2IQX","journalArticle","2021","Freitag, C.; Berners-Lee, M.; Widdicks, K.; Knowles, B.; Blair, G.S.; Friday, A.","The real climate and transformative impact of ICT: A critique of estimates, trends, and regulations","Patterns","","","10.1016/j.patter.2021.100340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122638594&doi=10.1016%2fj.patter.2021.100340&partnerID=40&md5=d7af9a116bbc52d9530b7e2158984995","In this paper, we critique ICT's current and projected climate impacts. Peer-reviewed studies estimate ICT's current share of global greenhouse gas (GHG) emissions at 1.8%–2.8% of global GHG emissions; adjusting for truncation of supply chain pathways, we find that this share could actually be between 2.1% and 3.9%. For ICT's future emissions, we explore assumptions underlying analysts' projections to understand the reasons for their variability. All analysts agree that ICT emissions will not reduce without major concerted efforts involving broad political and industrial action. We provide three reasons to believe ICT emissions are going to increase barring intervention and find that not all carbon pledges in the ICT sector are ambitious enough to meet climate targets. We explore the underdevelopment of policy mechanisms for enforcing sector-wide compliance, and contend that, without a global carbon constraint, a new regulatory framework is required to keep the ICT sector's footprint aligned with the Paris Agreement. © 2021 The Authors","2021","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","9","2","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; IoT; 'current; Carbon footprint; AI; big data; Block-chain; blockchain; Blockchain; carbon footprint; Climate impacts; Current share; data science; Gas emissions; Greenhouse gas emissions; Greenhouse gases; ICT; Industrial emissions; policy; Political actions; Regulation; regulations; Regulatory compliance; Supply chains; Trend; trends","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2F9PX82","conferencePaper","2013","Noureddine, A.; Rouvoy, R.; Seinturier, L.","A review of energy measurement approaches","","","","10.1145/2553070.2553077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901316580&doi=10.1145%2f2553070.2553077&partnerID=40&md5=e7ad9ded84795cab94da689f7cb9ca65","Reducing the energy footprint of digital devices and software is a task challenging the research in Green IT. Researches have proposed approaches for energy management, ranging from reducing usage of software and hardware, compilators optimization, to server consolidation and software migration. However, optimizing the energy consumption requires knowledge of that said consumption. In particular, measuring the energy consumption of hardware and software is an important requirement for efficient energy strategies. In this review, we outline the different categories of approaches in energy measurements, and provide insights into example of each category. We draw recommendations from our review on requirements on how to efficiently measure energy consumption of devices and software. © 2012 IEEE Computer Society Washington.","2013","2025-10-22 19:07:34","2025-10-22 19:07:34","","42-49","","","47","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Energy utilization; Middleware; Energy management; Electric power measurement; Hardware and software; Software and hardwares; Server consolidation; Green IT; Digital devices; Energy Management; Energy Measurement; Energy metrics; Energy Metrics; Energy strategy; Instruments; Software migration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Operating Systems Review (ACM)","","","","","","","","","","","","","","",""
"VSDRT2CE","conferencePaper","2019","Zhou, X.; Peng, X.; Xie, T.; Sun, J.; Ji, C.; Liu, D.; Xiang, Q.; He, C.","Latent error prediction and fault localization for microservice applications by learning from system trace logs","","","","10.1145/3338906.3338961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071904016&doi=10.1145%2f3338906.3338961&partnerID=40&md5=3c6b30fca792ecf2002e705b167b6395","In the production environment, a large part of microservice failures are related to the complex and dynamic interactions and runtime environments, such as those related to multiple instances, environmental configurations, and asynchronous interactions of microservices. Due to the complexity and dynamism of these failures, it is often hard to reproduce and diagnose them in testing environments. It is desirable yet still challenging that these failures can be detected and the faults can be located at runtime of the production environment to allow developers to resolve them efficiently. To address this challenge, in this paper, we propose MEPFL, an approach of latent error prediction and fault localization for microservice applications by learning from system trace logs. Based on a set of features defined on the system trace logs, MEPFL trains prediction models at both the trace level and the microservice level using the system trace logs collected from automatic executions of the target application and its faulty versions produced by fault injection. The prediction models thus can be used in the production environment to predict latent errors, faulty microservices, and fault types for trace instances captured at runtime. We implement MEPFL based on the infrastructure systems of container orchestrator and service mesh, and conduct a series of experimental studies with two opensource microservice applications (one of them being the largest open-source microservice application to our best knowledge). The results indicate that MEPFL can achieve high accuracy in intraapplication prediction of latent errors, faulty microservices, and fault types, and outperforms a state-of-the-art approach of failure diagnosis for distributed systems. The results also show that MEPFL can effectively predict latent errors caused by real-world fault cases. © 2019 ACM.","2019","2025-10-22 19:07:34","2025-10-22 19:07:34","","683-694","","","","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Forecasting; Microservices; Tracing; Errors; Open systems; Learning systems; Machine learning; Fault localization; Asynchronous interaction; Computer debugging; Debugging; Error prediction; Infrastructure systems; Production environments; Safety engineering; State-of-the-art approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering","","","","","","","","","","","","","","",""
"8PLGB8SC","conferencePaper","2019","Shan, H.; Zhang, Y.; Chen, Y.; Xiao, X.; Liu, H.; He, X.; Li, M.; Ding, W.","ϵ-Diagnosis: Unsupervised and real-time diagnosis of small-window long-tail latency in large-scale microservice platforms","","","","10.1145/3308558.3313653","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066912897&doi=10.1145%2f3308558.3313653&partnerID=40&md5=9dfebc5856fd8aca09b9594b4d34b753","Microservice architectures and container technologies are broadly adopted by giant internet companies to support their web services, which typically have a strict service-level objective (SLO), tail latency, rather than average latency. However, diagnosing SLO violations, e.g., long tail latency problem, is non-trivial for large-scale web applications in shared microservice platforms due to million-level operational data and complex operational environments. We identify a new type of tail latency problem for web services, small-window long-tail latency (SWLT), which is typically aggregated during a small statistical window (e.g., 1-minute or 1-second). We observe SWLT usually occurs in a small number of containers in microservice clusters and sharply shifts among different containers at different time points. To diagnose root-causes of SWLT, we propose an unsupervised and low-cost diagnosis algorithm-ϵ-Diagnosis, using two-sample test algorithm and ϵ-statistics for measuring similarity of time series to identify root-cause metrics from millions of metrics. We implement and deploy a real-time diagnosis system in our real-production microservice platforms. The evaluation using real web application datasets demonstrates that ϵ-Diagnosis can identify all the actual root-causes at runtime and significantly reduce the candidate problem space, outperforming other time-series distance based root-cause analysis algorithms. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.","2019","2025-10-22 19:07:34","2025-10-22 19:07:34","","3215-3222","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Real time systems; Web services; Websites; Service level objective; Root cause analysis; Diagnosis algorithms; Measuring similarities; Operational environments; Real-time diagnosis; Root-cause analysis; Statistical window; Tail latency; Time series; Time series analysis; Time series similarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019","","","","","","","","","","","","","","",""
"X4DYJ79Y","journalArticle","2000","Wohlin, C.; Runeson, P.; Host, M.; Ohlsson, M.C.; Regnell, B.; Wesslen, A.","","Experimentation in Software Engineering: An Introduction","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003639957&partnerID=40&md5=7341cbbc34c4d05ef0cc0917e28416e4","","2000","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KH4DZTSJ","conferencePaper","2021","Klaver, L.; van der Knaap, T.; van der Geest, J.; Harmsma, E.; van der Waaij, B.; Pileggi, P.","Towards Independent Run-time Cloud Monitoring","","","","10.1145/3447545.3451180","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104973631&doi=10.1145%2f3447545.3451180&partnerID=40&md5=1e96abf0390d8e5d948ec4231c3f440a","Cloud computing services are integral to the digital transformation. They deliver greater connectivity, tremendous savings, and lower total cost of ownership. Despite such benefits and benchmarking advances, costs are still quite unpredictable, performance is unclear, security is inconsistent, and there is minimal control over aspects like data and service locality. Estimating performance of cloud environments is very hard for cloud consumers. They would like to make informed decisions about which provider better suits their needs using specialized evaluation mechanisms. Providers have their own tools reporting specific metrics, but they are potentially biased and often incomparable across providers. Current benchmarking tools allow comparison but consumers need more flexibility to evaluate environments under actual operating conditions for specialized applications. Ours is early stage work and a step towards a monitoring solution that enables independent evaluation of clouds for very specific application needs. In this paper, we present our initial architecture of the Cloud Monitor that aims to integrate existing and new benchmarks in a flexible and extensible way. By way of a simplistic demonstrator, we illustrate the concept. We report some preliminary monitoring results after a brief time of monitoring and are able to observe unexpected anomalies. The results suggest an independent monitoring solution is a powerful enabler of next generation cloud computing, not only for the consumer but potentially the whole ecosystem. © 2021 Association for Computing Machinery.","2021","2025-10-22 19:07:34","2025-10-22 19:07:34","","21-26","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud environments; Benchmarking; Total cost of ownership; Cloud computing services; Benchmarking tools; Digital transformation; Informed decision; Monitoring results; Operating condition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2021 - Companion of the ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"JIYLLCMF","conferencePaper","2018","Khan, K.N.; Hirki, M.; Niemi, T.; Nurminen, J.K.; Ou, Z.","RAPL in action: Experiences in using RAPL for power measurements","","","","10.1145/3177754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057252724&doi=10.1145%2f3177754&partnerID=40&md5=49dadace1ce44c47e3440ed831b60ad1","To improve energy efficiency and comply with the power budgets, it is important to be able to measure the power consumption of cloud computing servers. Intel's Running Average Power Limit (RAPL) interface is a powerful tool for this purpose. RAPL provides power limiting features and accurate energy readings for CPUs and DRAM, which are easily accessible through different interfaces on large distributed computing systems. Since its introduction, RAPL has been used extensively in power measurement and modeling. However, the advantages and disadvantages of RAPL have not been well investigated yet. To fill this gap, we conduct a series of experiments to disclose the underlying strengths and weaknesses of the RAPL interface by using both customized microbenchmarks and three well-known application level benchmarks: Stream, Stress-ng, and ParFullCMS. Moreover, to make the analysis as realistic as possible, we leverage two production-level power measurement datasets from the Taito, a supercomputing cluster of the Finnish Center of Scientific Computing and also replicate our experiments on Amazon EC2. Our results illustrate different aspects of RAPL and document the findings through comprehensive analysis. Our observations reveal that RAPL readings are highly correlated with plug power, promisingly accurate enough, and have negligible performance overhead. Experimental results suggest RAPL can be a very useful tool to measure and monitor the energy consumption of servers without deploying any complex power meters. We also show that there are still some open issues, such as driver support, non-atomicity of register updates, and unpredictable timings that might weaken the usability of RAPL in certain scenarios. For such scenarios, we pinpoint solutions and workarounds. © 2018 ACM.","2018","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","3","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Power modeling; Program processors; Energy utilization; Cluster computing; Benchmarking; Green computing; RAPL; Budget control; Automobile drivers; Average power limit; Comprehensive analysis; Distributed computing systems; Dram power; Highly-correlated; Power model; Rapl accuracy; Rapl validation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM Transactions on Modeling and Performance Evaluation of Computing Systems","","","","","","","","","","","","","","",""
"C3BPI272","conferencePaper","2023","Huang, C.-K.; Pierre, G.","AdapPF: Self-Adaptive Scrape Interval for Monitoring in Geo-Distributed Cluster Federations","","","","10.1109/ISCC58397.2023.10218080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171980853&doi=10.1109%2fISCC58397.2023.10218080&partnerID=40&md5=e27b361fba831ec8629b45981f8f3a13","Monitoring plays a vital role in geo-distributed cluster federation environments to accurately schedule applications across geographically dispersed computing resources. However, using a fixed frequency for collecting monitoring data from clusters may waste network bandwidth and is not necessary for ensuring accurate scheduling. In this paper, we propose Adaptive Prometheus Federation (AdapPF), an extension of the widely-used open-source monitoring tool, Prometheus, and its feature, Prometheus Federation. AdapPF aims to dynamically adjust the collection frequency of monitoring data for each cluster in geo-distributed cluster federations. Based on actual deployment in the geo-distributed Grid'5000 testbed, our evaluations demonstrate that AdapPF can achieve comparable results to Prometheus Federation with 5-seconds scrape interval while reducing cross-cluster network traffic by 36%. © 2023 IEEE.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","417-423","","","2023-July","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Cluster computing; Open-source; Fog computing; Data acquisition; Self-Adaptive; Monitoring tools; Cluster federation; Computing resource; Distributed clusters; Fixed frequency; Geo-distributed cluster federation; Geo-distributed cluster federations; Network bandwidth; Prometheus; Self-adaptive","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Symposium on Computers and Communications","","","","","","","","","","","","","","",""
"IIPQPMVX","journalArticle","2003","Guo, G.; Wang, H.; Bell, D.; Bi, Y.; Greer, K.","KNN model-based approach in classification","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/978-3-540-39964-3_62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242712881&doi=10.1007%2f978-3-540-39964-3_62&partnerID=40&md5=dad6f64de7f0f167d788e0c382867023","The k-Nearest-Neighbours (kNN) is a simple but effective method for classification. The major drawbacks with respect to kNN are (1) its low efficiency - being a lazy learning method prohibits it in many applications such as dynamic web mining for a large repository, and (2) its dependency on the selection of a ""good value"" for k. In this paper, we propose a novel kNN type method for classification that is aimed at overcoming these shortcomings. Our method constructs a kNN model for the data, which replaces the data to serve as the basis of classification. The value of k is automatically determined, is varied for different data, and is optimal in terms of classification accuracy. The construction of the model reduces the dependency on k and makes classification faster. Experiments were carried out on some public datasets collected from the UCI machine learning repository in order to test our method. The experimental results show that the kNN based model compares well with C5.0 and kNN in terms of classification accuracy, but is more efficient than the standard kNN. © Springer-Verlag Berlin Heidelberg 2003.","2003","2025-10-22 19:07:34","2025-10-22 19:07:34","","986-996","","","2888","","","","","","","","","","","","","Scopus","","","","","","","","Artificial intelligence; Learning systems; Nearest neighbor search; Distributed database systems; Classification accuracy; K nearest neighbours (k-NN); Lazy learning; Model based approach; Multi agent systems; Semantic Web; Semantics; Type methods; UCI machine learning repository; Web Mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFVLZ9UR","conferencePaper","2021","Gan, Y.; Liang, M.; Dev, S.; Lo, D.; Delimitrou, C.","Sage: Practical and scalable ML-driven performance debugging in microservices","","","","10.1145/3445814.3446700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104802944&doi=10.1145%2f3445814.3446700&partnerID=40&md5=ac1119c03a8d48d24c437606287afbc7","Cloud applications are increasingly shifting from large monolithic services to complex graphs of loosely-coupled microservices. Despite the advantages of modularity and elasticity microservices offer, they also complicate cluster management and performance debugging, as dependencies between tiers introduce backpressure and cascading QoS violations. Prior work on performance debugging for cloud services either relies on empirical techniques, or uses supervised learning to diagnose the root causes of performance issues, which requires significant application instrumentation, and is difficult to deploy in practice. We present Sage, a machine learning-driven root cause analysis system for interactive cloud microservices that focuses on practicality and scalability. Sage leverages unsupervised ML models to circumvent the overhead of trace labeling, captures the impact of dependencies between microservices to determine the root cause of unpredictable performance online, and applies corrective actions to recover a cloud service's QoS. In experiments on both dedicated local clusters and large clusters on Google Compute Engine we show that Sage consistently achieves over 93% accuracy in correctly identifying the root cause of QoS violations, and improves performance predictability. © 2021 ACM.","2021","2025-10-22 19:07:34","2025-10-22 19:07:34","","135-151","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; cloud computing; Cloud-computing; microservices; performance debugging; Performance debugging; Program debugging; QoS; Cloud applications; Cloud services; Web services; Learning systems; Machine learning; Root cause; Auto encoders; Bayesia n networks; Bayesian network; Bayesian networks; counterfactual; Counterfactuals; Distributed database systems; variational autoencoder; Variational autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"N6DHDDZ2","journalArticle","2020","Joseph, C.T.; Chandrasekaran, K.","IntMA: Dynamic Interaction-aware resource allocation for containerized microservices in cloud environments","Journal of Systems Architecture","","","10.1016/j.sysarc.2020.101785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084330280&doi=10.1016%2fj.sysarc.2020.101785&partnerID=40&md5=e8e088ca640e149ab34a5a81754acb56","The Information Technology sector has undergone tremendous changes arising due to the emergence and prevalence of Cloud Computing. Microservice Architectures have also been attracting attention from several industries and researchers. Due to the suitability of microservices for the Cloud environments, an increasing number of Cloud applications are now provided as microservices. However, this transition to microservices brings a wide range of infrastructural orchestration challenges. Though several research works have discussed the engineering of microservice-based applications, there is an inevitable need for research on handling the operational phases of the microservice components. Microservice application deployment in containerized datacenters must be optimized to enhance the overall system performance. In this research work, the deployment of microservice application modules on the Cloud infrastructure is first modelled as a Binary Quadratic Programming Problem. In order to reduce the adverse impact of communication latencies on the response time, the interaction pattern between the microservice components is modelled as an undirected doubly weighted complete Interaction Graph. A novel, robust heuristic approach IntMA is also proposed for deploying the microservices in an interaction-aware manner with the aid of the interaction information obtained from the Interaction Graph. The proposed allocation policies are implemented in Kubernetes. The effectiveness of the proposed approach is evaluated on the Google Cloud Platform, using different microservice reference applications. Experimental results indicate that the proposed approach improves the response time and throughput of the microservice-based systems. © 2020 Elsevier B.V.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","111","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud computing; Performance optimization; Cloud infrastructures; Allocation policies; Application deployment; Binary quadratic programming problems; Communication latency; Container orchestration; Engineering research; Heuristic methods; Information technology sector; Interaction information; Interaction pattern; Microservice placement; Quadratic programming; Response time (computer systems); Service oriented computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJSAY6YW","conferencePaper","2020","Wang, L.; Zhao, N.; Chen, J.; Li, P.; Zhang, W.; Sui, K.","Root-Cause Metric Location for Microservice Systems via Log Anomaly Detection","","","","10.1109/ICWS49710.2020.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097182831&doi=10.1109%2fICWS49710.2020.00026&partnerID=40&md5=300256216fd6bc7b17219c74e3472fbc","Microservice systems are typically fragile and failures are inevitable in them due to their complexity and large scale. However, it is challenging to localize the root-cause metric due to its complicated dependencies and the huge number of various metrics. Existing methods are based on either correlation between metrics or correlation between metrics and failures. All of them ignore the key data source in microservice, i.e., logs. In this paper, we propose a novel root-cause metric localization approach by incorporating log anomaly detection. Our approach is based on a key observation, the value of root-cause metric should be changed along with the change of the log anomaly score of the system caused by the failure. Specifically, our approach includes two components, collecting anomaly scores by log anomaly detection algorithm and identifying root-cause metric by robust correlation analysis with data augmentation. Experiments on an open-source benchmark microservice system have demonstrated our approach can identify root-cause metrics more accurately than existing methods and only require a short localization time. Therefore, our approach can assist engineers to save much effort in diagnosing and mitigating failures as soon as possible.  © 2020 IEEE.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","142-150","","","","","","","","","","","","","","","","Scopus","","","","","","","","Data-source; Open systems; Web services; Websites; Anomaly detection; Correlation analysis; Root cause; Anomaly-detection algorithms; Data augmentation; Open sources; Two-component","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE 13th International Conference on Web Services, ICWS 2020","","","","","","","","","","","","","","",""
"A48BGDYZ","conferencePaper","2018","Du, Q.; Xie, T.; He, Y.","Anomaly detection and diagnosis for container-based microservices with performance monitoring","","","","10.1007/978-3-030-05063-4_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058619119&doi=10.1007%2f978-3-030-05063-4_42&partnerID=40&md5=9c09c0bbfda8e0cc3516ad3638ec227a","With emerging container technologies, such as Docker, microservices-based applications can be developed and deployed in cloud environment much agiler. The dependability of these microservices becomes a major concern of application providers. Anomalous behaviors which may lead to unexpected failures can be detected with anomaly detection techniques. In this paper, an anomaly detection system (ADS) is designed to detect and diagnose the anomalies in microservices by monitoring and analyzing real-time performance data of them. The proposed ADS consists of a monitoring module that collects the performance data of containers, a data processing module based on machine learning models and a fault injection module integrated for training these models. The fault injection module is also used to assess the anomaly detection and diagnosis performance of our ADS. Clearwater, an open source virtual IP Multimedia Subsystem, is used for the validation of our ADS and experimental results show that the proposed ADS works well. © Springer Nature Switzerland AG 2018.","2018","2025-10-22 19:07:34","2025-10-22 19:07:34","","560-572","","","11337 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Microservices; Data handling; Artificial intelligence; Learning systems; Machine learning; Parallel architectures; Software testing; Real time performance; Anomaly detection; Fault detection; Anomaly detection systems; Performance monitoring; Application providers; Chemical detection; Deceleration; IP multimedia subsystems; Unexpected Failures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"N3GNJTW8","conferencePaper","2019","Gan, Y.; Zhang, Y.; Hu, K.; Cheng, D.; He, Y.; Pancholi, M.; Delimitrou, C.","Seer: Leveraging Big Data to Navigate the Complexity of Performance Debugging in Cloud Microservices","","","","10.1145/3297858.3304004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064659746&doi=10.1145%2f3297858.3304004&partnerID=40&md5=67a5e54db5ebf1ecee4bb2bc5f5c7790","Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether.We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91% of the time, and avoids the QoS violation to begin with in 84% of cases. Finally, we show that Seer can identify applicationlevel design bugs, and provide insights on how to better architect microservices to achieve predictable performance. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:34","2025-10-22 19:07:34","","19-33","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Datacenter; Microservice; Big data; Cloud adoptions; cloud computing; Cloud computing; Cloud-computing; data mining; Data mining; datacenter; deep learning; Deep learning; Information management; microservices; monitoring; Online systems; Performance; Performance costs; performance debugging; Performance debugging; Program debugging; QoS; resource management; Resource management; tracing; Tracing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"JTSLCWJ6","conferencePaper","2004","Aversano, L.; Bodhuin, T.; Canfora, G.; Tortorella, M.","A framework for measuring business processes based on GQM","","","","10.1109/hicss.2004.1265061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-12344288282&doi=10.1109%2fhicss.2004.1265061&partnerID=40&md5=e19b39c197b73a054c7e5dfa47a2492b","The evolution of business processes and supporting software systems requires their analysis and assessment from both quantitative and qualitative points of view. The analysis and evaluation activities need the support of methodological and technological tools, customizable to the innovation requirements of the chosen processes and supporting software systems. This paper proposes a measurement framework based on the Goal-Question-Metric (GQM) paradigm. It is generally applicable to any business process and supporting software system after its instantiation. The collaborative software environment WebEv, Web for the Evaluation, is proposed for facilitating the collection and elaboration of the required measures. Finally, the paper describes the application of the measurement framework in a real context.","2004","2025-10-22 19:07:34","2025-10-22 19:07:34","","163-172","","","37","","","","","","","","","","","","","Scopus","","","","","","","","Online systems; Knowledge acquisition; Computer software; Data acquisition; Learning systems; Legacy systems; Risk assessment; Risk analysis; Business process reengineering (BPR); Characterization; Electronic commerce; Electronic mail; Goal-Question-Metric (GQM); Organizational goals; Societies and institutions; World Wide Web","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Hawaii International Conference on System Sciences","","","","","","","","","","","","","","",""
"HLXWDE6P","conferencePaper","2020","Bogatinovski, J.; Nedelkoski, S.; Cardoso, J.; Kao, O.","Self-supervised anomaly detection from distributed traces","","","","10.1109/UCC48980.2020.00054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099576837&doi=10.1109%2fUCC48980.2020.00054&partnerID=40&md5=183c99268d9949e744adc2aab1a7489a","Artificial Intelligence for IT Operations (AIOps) combines big data and machine learning to replace a broad range of IT Operations tasks including reliability and performance monitoring of services. By exploiting observability data, AIOps enable detection of faults and issues of services. The focus of this work is on detecting anomalies based on distributed tracing records that contain detailed information of the services of the distributed system. Timely and accurately detecting trace anomalies is very challenging due to the large number of underlying microservices and the complex call relationships between them. We addresses the problem anomaly detection from distributed traces with a novel self-supervised method and a new learning task formulation. The method is able to have high performance even in large traces and capture complex interactions between the services. The evaluation shows that the approach achieves high accuracy and solid performance in the experimental testbed. © 2020 IEEE.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","342-347","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Distributed systems; Artificial intelligence; Learning systems; Anomaly detection; Distributed database systems; Detecting trace; Distributed traces; Distributed tracing; Experimental testbed; High-accuracy; Learning tasks; Performance monitoring; Self-supervised learning; Supervised methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing, UCC 2020","","","","","","","","","","","","","","",""
"US8ZEEWD","conferencePaper","2020","Wu, L.; Tordsson, J.; Elmroth, E.; Kao, O.","MicroRCA: Root Cause Localization of Performance Issues in Microservices","","","","10.1109/NOMS47738.2020.9110353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086754646&doi=10.1109%2fNOMS47738.2020.9110353&partnerID=40&md5=1e3e7daea9f1f548cb845401f4281bb5","Software architecture is undergoing a transition from monolithic architectures to microservices to achieve resilience, agility and scalability in software development. However, with microservices it is difficult to diagnose performance issues due to technology heterogeneity, large number of microservices, and frequent updates to both software features and infrastructure. This paper presents MicroRCA, a system to locate root causes of performance issues in microservices. MicroRCA infers root causes in real time by correlating application performance symptoms with corresponding system resource utilization, with-out any application instrumentation. The root cause localization is based on an attributed graph that model anomaly propagation across services and machines. Our experimental evaluation where common anomalies are injected to a microservice benchmark running in a Kubernetes cluster shows that MicroRCA locates root causes well, with 89% precision and 97% mean average precision, outperforming several state-of-the-art methods. © 2020 IEEE.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","microservices; Network architecture; Software design; Experimental evaluation; Application performance; root cause analysis; Anomaly propagation; Monolithic architecture; performance degradation; Performance issues; Petroleum reservoir evaluation; Software features; State-of-the-art methods; System resource utilization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of IEEE/IFIP Network Operations and Management Symposium 2020: Management in the Age of Softwarization and Artificial Intelligence, NOMS 2020","","","","","","","","","","","","","","",""
"TZ8WZLUF","journalArticle","2009","Chandola, V.; Banerjee, A.; Kumar, V.","Anomaly detection: A survey","ACM Computing Surveys","","","10.1145/1541880.1541882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68049121093&doi=10.1145%2f1541880.1541882&partnerID=40&md5=5f32c8c06af2667c0db2c0c61fdf75b1","Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with. © 2009 ACM.","2009","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","3","41","","","","","","","","","","","","","Scopus","","","","","","","","Surveys; Real applications; Computational complexity; Anomaly detection; Research; Anomalous behavior; Application domains; Outlier detection; Research areas","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XU9Q4AK","conferencePaper","2019","Kang, M.; Shin, J.-S.; Kim, J.","Protected Coordination of Service Mesh for Container-Based 3-Tier Service Traffic","","","","10.1109/ICOIN.2019.8718120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066732778&doi=10.1109%2fICOIN.2019.8718120&partnerID=40&md5=c6df1567721aa2700367adc4222f2482","With the rapid expansion of cloud-native computing paradigm, a growing number of applications are adopting container-based microservices architecture (MSA). The resulting container-based MSA functions are required to be tightly stitched together and therefore the stitching interconnections need persistent monitor/control coordination. Recent service mesh approaches are trying to solve this maintenance problem in a transparent manner. However, with the popular Istio-based service mesh realization, the monitor/control traffic for coordination is exposed to application tenants, which could be a potential security concern. Typically, containers are limited with a single network interface and thus it is not possible to isolate control / monitor traffic from application data traffic. Thus, in this paper, we propose a protected coordination scheme for service mesh as a work-Around solution. For this protected coordination of service mesh, the monitor/control traffic for coordination is separated and encrypted while data traffic is treated in the same way with the existing service mesh approach. © 2019 IEEE.","2019","2025-10-22 19:07:34","2025-10-22 19:07:34","","427-429","","","2019-January","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Computer architecture; Network architecture; and protected coordination of service mesh; Application data; Computing paradigm; container-based cloud-native computing; Coordination scheme; Maintenance Problem; Mesh generation; Microservices architecture; Rapid expansion; service mesh; Service traffic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Information Networking","","","","","","","","","","","","","","",""
"VQ9MXQM6","conferencePaper","2021","Wu, L.; Tordsson, J.; Elmroth, E.; Kao, O.","Causal Inference Techniques for Microservice Performance Diagnosis: Evaluation and Guiding Recommendations","","","","10.1109/ACSOS52086.2021.00029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124790415&doi=10.1109%2fACSOS52086.2021.00029&partnerID=40&md5=786db1ae8ed4e81abc085f716a1b2de5","Causal inference (CI) is one of the popular performance diagnosis methods, which infers the anomaly propagation from the observed data for locating the root causes. Although some specific CI methods have been employed in the literature, the overall performance of this class of methods on microservice performance diagnosis is not well understood. To this end, we select six representative CI methods from three categories and evaluate their performance against the challenges of microservice operations, including the large-scale observable data, heterogeneous anomaly symptoms, and a wide range of root causes. Our experimental results show that 1) CI techniques must be integrated with anomaly detection or anomaly scores to differentiate the causality in normal and abnormal data; 2) CI techniques are more robust to false positives in anomaly detection than knowledge-based non-CI method; 3) To get the fine-grained root causes, an effective way with CI techniques is to identify the faulty service first and infer the detailed explanation of the service abnormality. Overall, this work broadens the understanding of how CI methods perform on microservice performance diagnosis and provides recommendations for an efficient application of CI methods.  © 2021 IEEE.","2021","2025-10-22 19:07:34","2025-10-22 19:07:34","","21-30","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Performance; Experimental evaluation; Anomaly detection; Causal inference; Causal inferences; Inference methods; Inference techniques; Knowledge based systems; Performance diagnosis; Root cause; Self-healing; Self-healing materials","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems, ACSOS 2021","","","","","","","","","","","","","","",""
"M8JUIHED","conferencePaper","2018","Wang, P.; Xu, J.; Ma, M.; Lin, W.; Pan, D.; Wang, Y.; Chen, P.","CloudRanger: Root cause identification for cloud native systems","","","","10.1109/CCGRID.2018.00076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050958994&doi=10.1109%2fCCGRID.2018.00076&partnerID=40&md5=162906183623bed7fd3d3dc29714a4be","As more and more systems are migrating to cloud environment, the cloud native system becomes a trend. This paper presents the challenges and implications when diagnosing root causes for cloud native systems by analyzing some real incidents occurred in IBM Bluemix (a large commercial cloud). To tackle these challenges, we propose CloudRanger, a novel system dedicated for cloud native systems. To make our system more general, we propose a dynamic causal relationship analysis approach to construct impact graphs amongst applications without given the topology. A heuristic investigation algorithm based on second-order random walk is proposed to identify the culprit services which are responsible for cloud incidents. Experimental results in both simulation environment and IBM Bluemix platform show that CloudRanger outperforms some state-of-the-art approaches with a 10% improvement in accuracy. It offers a fast identification of culprit services when an anomaly occurs. Moreover, this system can be deployed rapidly and easily in multiple kinds of cloud native systems without any predefined knowledge. © 2018 IEEE.","2018","2025-10-22 19:07:34","2025-10-22 19:07:34","","492-502","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cluster computing; Grid computing; Anomaly detection; Topology; Causality; Cloud native systems; Cloud natives; Micro service architecture; Micro services; Root cause analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2018","","","","","","","","","","","","","","",""
"IDR4CT82","journalArticle","2020","Jin, M.; Lv, A.; Zhu, Y.; Wen, Z.; Zhong, Y.; Zhao, Z.; Wu, J.; Li, H.; He, H.; Chen, F.","An Anomaly Detection Algorithm for Microservice Architecture Based on Robust Principal Component Analysis","IEEE Access","","","10.1109/ACCESS.2020.3044610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130828992&doi=10.1109%2fACCESS.2020.3044610&partnerID=40&md5=b9d7d008b39768cc71925147bfe1666c","Microservice architecture (MSA) is a new software architecture, which divides a large single application and service into dozens of supporting microservices. With the increasingly popularity of MSA, the security issues of MSA get a lot of attention. In this paper, we propose an algorithm for mining causality and the root cause. Our algorithm consists of two parts: invocation chain anomaly analysis based on robust principal component analysis (RPCA) and a single indicator anomaly detection algorithm. The single indicator anomaly detection algorithm is composed of Isolation Forest (IF) algorithm, One-Class Support Vector Machine (SVM) algorithm, Local Outlier Factor (LOF) algorithm, and 3σ principle. For general and network time-consuming anomaly in the process of the MSA, we formulate different anomaly time-consuming detection strategies. We select a batch of sample data and three batches of test data of the 2020 International AIOps Challenge to debug our algorithm. According to the scoring criteria of the competition organizers, our algorithm has an average score of 0.8304 (The full score is 1) in the four batches of data. Our proposed algorithm has higher accuracy than some traditional machine learning algorithms in anomaly detection. © 2013 IEEE.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","226397-226408","","","8","","","","","","","","","","","","","Scopus","","","","","","","","anomaly detection; Microservice architecture; root cause analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BPELDHF","conferencePaper","2023","Jay, M.; Ostapenco, V.; Lefevre, L.; Trystram, D.; Orgerie, A.-C.; Fichel, B.","An experimental comparison of software-based power meters: Focus on CPU and GPU","","","","10.1109/CCGrid57682.2023.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163867329&doi=10.1109%2fCCGrid57682.2023.00020&partnerID=40&md5=4a8d9932fa1d8e9882d85ec10ae66b7d","The global energy demand for digital activities is constantly growing. Computing nodes and cloud services are at the heart of these activities. Understanding their energy consumption is an important step towards reducing it. On one hand, physical power meters are very accurate in measuring energy but they are expensive, difficult to deploy on a large scale, and are not able to provide measurements at the service level. On the other hand, power models and vendor-specific internal interfaces are already available or can be implemented on existing systems. Plenty of tools, called software-based power meters, have been developed around the concepts of power models and internal interfaces, in order to report the power consumption at levels ranging from the whole computing node to applications and services. However, we have found that it can be difficult to choose the right tool for a specific need. In this work, we qualitatively and experimentally compare several software-based power meters able to deal with CPU or GPU-based infrastructures. For this purpose, we evaluate them against high-precision physical power meters while executing various intensive workloads. We extend this empirical study to highlight the strengths and limitations of each software-based power meter.  © 2023 IEEE.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","106-118","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Power modeling; Power; Energy utilization; Green computing; Computing power; Graphics processing unit; Powermeter; Electric power measurement; Computing nodes; Energy measurement; Experimental comparison; Global energy demand; Internal interfaces; Physical power; Power measurement; Software evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 23rd IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2023","","","","","","","","","","","","","","",""
"QH5JPQEM","conferencePaper","2023","Li, Y.; Lu, Y.; Wang, J.; Qi, Q.; Wang, J.; Wang, Y.; Liao, J.","TADL: Fault Localization with Transformer-based Anomaly Detection for Dynamic Microservice Systems","","","","10.1109/SANER56733.2023.00078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160528611&doi=10.1109%2fSANER56733.2023.00078&partnerID=40&md5=a693ac80cd929572fde44eb9c253c95e","Due to the complexity of microservice architecture, it is difficult to accomplish efficient microservice anomaly detection and localization tasks and achieve the target of high system reliability. For rapid failure recovery and user satisfaction, it is significant to detect and locate anomalies fast and accurately in microservice systems. In this paper, we propose an anomaly detection and localization model based on Transformer, named TADL (Transformer-based Anomaly Detector and Locator), which models the temporal features and dynamically captures container relationships using Transformer with sandwich structure. TADL uses readily available container performance metrics, making it easy to implement in already-running container clusters. Evaluations are conducted on a sock-shop dataset collected from a real microservice system and a publicly available dataset SMD. Empirical studies on the above two datasets demonstrate that TADL can outperform baseline methods in the performance of anomaly detection, the latency of anomaly detection, and the effect of anomalous container localization, which indicates that TADL is useful in maintaining complex and dynamic microservice systems in the real world. © 2023 IEEE.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","718-722","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; anomaly detection; Anomaly detection; System reliability; Anomaly detector; Anomaly localizations; Detection and localization; Failure recovery; Fault detection; fault localization; Fault localization; Microservice system; microservice systems; transformer; Transformer; Users' satisfactions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023","","","","","","","","","","","","","","",""
"MCVH8PIN","journalArticle","2021","Nassif, A.B.; Talib, M.A.; Nasir, Q.; Dakalbab, F.M.","Machine Learning for Anomaly Detection: A Systematic Review","IEEE Access","","","10.1109/ACCESS.2021.3083060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113269963&doi=10.1109%2fACCESS.2021.3083060&partnerID=40&md5=88521f3ba2e821eaa1752edce8c07c43","Anomaly detection has been used for decades to identify and extract anomalous components from data. Many techniques have been used to detect anomalies. One of the increasingly significant techniques is Machine Learning (ML), which plays an important role in this area. In this research paper, we conduct a Systematic Literature Review (SLR) which analyzes ML models that detect anomalies in their application. Our review analyzes the models from four perspectives; the applications of anomaly detection, ML techniques, performance metrics for ML models, and the classification of anomaly detection. In our review, we have identified 290 research articles, written from 2000-2020, that discuss ML techniques for anomaly detection. After analyzing the selected research articles, we present 43 different applications of anomaly detection found in the selected research articles. Moreover, we identify 29 distinct ML models used in the identification of anomalies. Finally, we present 22 different datasets that are applied in experiments on anomaly detection, as well as many other general datasets. In addition, we observe that unsupervised anomaly detection has been adopted by researchers more than other classification anomaly detection systems. Detection of anomalies using ML models is a promising area of research, and there are a lot of ML models that have been implemented by researchers. Therefore, we provide researchers with recommendations and guidelines based on this review.  © 2013 IEEE.","2021","2025-10-22 19:07:34","2025-10-22 19:07:34","","78658-78700","","","9","","","","","","","","","","","","","Scopus","","","","","","","","Performance metrics; Machine learning; Anomaly detection; machine learning; Anomalous component; Anomaly detection systems; Research papers; security and privacy protection; Systematic literature review (SLR); Systematic Review; Unsupervised anomaly detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KU3RUZQ","journalArticle","2023","Wang, D.; Nie, M.; Chen, D.","BAE: Anomaly Detection Algorithm Based on Clustering and Autoencoder","Mathematics","","","10.3390/math11153398","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167571991&doi=10.3390%2fmath11153398&partnerID=40&md5=9f9a1bf2f4ba1229ba04a5d9b184975d","In this paper, we propose an outlier-detection algorithm for detecting network traffic anomalies based on a clustering algorithm and an autoencoder model. The BIRCH clustering algorithm is employed as the pre-algorithm of the autoencoder to pre-classify datasets with complex data distribution characteristics, while the autoencoder model is used to detect outliers based on a threshold. The proposed BIRCH-Autoencoder (BAE) algorithm has been tested on four network security datasets, KDDCUP99, UNSW-NB15, CICIDS2017, and NSL-KDD, and compared with representative algorithms. The BAE algorithm achieved average F-scores of 96.160, 81.132, and 91.424 on the KDDCUP99, UNSW-NB15, and CICIDS2017 datasets, respectively. These experimental results demonstrate that the proposed approach can effectively and accurately detect anomalous data. © 2023 by the authors.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","15","11","","","","","","","","","","","","","Scopus","","","","","","","","anomaly detection; Autoencoder; BIRCH; pre-classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZI97SQ3","journalArticle","2024","Giamattei, L.; Guerriero, A.; Pietrantuono, R.; Russo, S.; Malavolta, I.; Islam, T.; Dînga, M.; Koziolek, A.; Singh, S.; Armbruster, M.; Gutierrez-Martinez, J.M.; Caro-Alvaro, S.; Rodriguez, D.; Weber, S.; Henss, J.; Vogelin, E.F.; Panojo, F.S.","Monitoring tools for DevOps and microservices: A systematic grey literature review","Journal of Systems and Software","","","10.1016/j.jss.2023.111906","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182148345&doi=10.1016%2fj.jss.2023.111906&partnerID=40&md5=95d4ebf97c7fd28d403838eacaf30ac2","Microservice-based systems are usually developed according to agile practices like DevOps, which enables rapid and frequent releases to promptly react and adapt to changes. Monitoring is a key enabler for these systems, as they allow to continuously get feedback from the field and support timely and tailored decisions for a quality-driven evolution. In the realm of monitoring tools available for microservices in the DevOps-driven development practice, each with different features, assumptions, and performance, selecting a suitable tool is an as much difficult as impactful task. This article presents the results of a systematic study of the grey literature we performed to identify, classify and analyze the available monitoring tools for DevOps and microservices. We selected and examined a list of 71 monitoring tools, drawing a map of their characteristics, limitations, assumptions, and open challenges, meant to be useful to both researchers and practitioners working in this area. Results are publicly available and replicable. Editor's note: Open Science material was validated by the Journal of Systems and Software Open Science Board. © 2023 The Author(s)","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","208","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Microservice; Performance; DevOps; Agile practices; Development practices; Grey literature; Literature reviews; Monitoring tools; MSA; Open science; Systematic study; Tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFMZSWJQ","journalArticle","2015","Newman, S.","","Building Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950338538&partnerID=40&md5=aec25db8f81564a4ab82f370c5e620cc","","2015","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVWAGB5V","conferencePaper","2012","Pecero, J.E.; Huacuja, H.J.F.; Bouvry, P.; Pineda, A.A.S.; Locés, M.C.L.; Barbosa, J.J.G.","On the energy optimization for precedence constrained applications using local search algorithms","","","","10.1109/HPCSim.2012.6266902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866976184&doi=10.1109%2fHPCSim.2012.6266902&partnerID=40&md5=3266477650faca0fb2f3573b9bb0de38","We investigate the problem of scheduling precedence constrained applications on a distributed heterogeneous computing system with the aim of minimizing schedule length and reducing energy consumption. We present a scheduling algorithm based on the best-effort idea that promotes local search algorithms and dynamic voltage scaling to reduce energy consumption. The final goal is to maintain a given performance while minimizing energy use. The proposed approach first uses a list-based scheduling algorithm to find near-optimal solutions for schedule length, then local search algorithms with dynamic voltage scaling are applied to reduce energy consumption. However the algorithm it's not allowed to deteriorate the schedule length computed by the best-effort algorithm. We discuss simulation results obtained with sets of real-world applications that emphasize the interest of the approach. © 2012 IEEE.","2012","2025-10-22 19:07:34","2025-10-22 19:07:34","","133-139","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Optimization; Distributed systems; Energy utilization; Energy conservation; Learning algorithms; optimization; Best-effort; Constrained optimization; Distributed heterogeneous computing; Dynamic voltage scaling; Energy optimization; greenIT; heterogenous distributed systems; Local search algorithm; Minimizing energy; Near-optimal solutions; performance of systems; Performance of systems; Real-world application; Reducing energy consumption; Schedule length; scheduling; Voltage stabilizing circuits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2012 International Conference on High Performance Computing and Simulation, HPCS 2012","","","","","","","","","","","","","","",""
"4ZSRMESJ","conferencePaper","2015","Tomas, L.; Klein, C.; Tordsson, J.; Hernandez-Rodriguez, F.","The straw that broke the camel's back: Safe cloud overbooking with application brownout","","","","10.1109/ICCAC.2014.10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923972497&doi=10.1109%2fICCAC.2014.10&partnerID=40&md5=8b2ea2c3f695f04eef39fc7e39e61500","Resource overbooking is an admission control technique to increase utilization in cloud environments. However, due to uncertainty about future application workloads, overbooking may result in overload situations and deteriorated performance. We mitigate this using brownout, a feedback approach to application performance steering, that ensures graceful degradation during load spikes and thus avoids overload. Additionally, brownout management information is included into the overbooking system, enabling the development of improved reactive methods to overload situations. Our combined brownout-overbooking approach is evaluated based on real-life interactive workloads and non-interactive batch applications. The results show that our approach achieves an improvement of resource utilization of 11 to 37 percentage points, while keeping response times lower than the set target of 1 second, with negligible application degradation. © 2014 IEEE.","2015","2025-10-22 19:07:34","2025-10-22 19:07:34","","151-160","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Cloud environments; Future applications; Computer science; Graceful degradation; Computer programming; Resource utilizations; Application performance; Management information; Over-booking approaches; Resource overbooking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2014 International Conference on Cloud and Autonomic Computing, ICCAC 2014","","","","","","","","","","","","","","",""
"MHCBJLB7","conferencePaper","2014","Klein, C.; Maggio, M.; Arzén, K.-E.; Hernández-Rodriguez, F.","Brownout: Building more robust cloud applications","","","","10.1145/2568225.2568227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994065778&doi=10.1145%2f2568225.2568227&partnerID=40&md5=65399bd44b01bdd11e43ebcda0ddb8ab","Self-adaptation is a first class concern for cloud applications, which should be able to withstand diverse runtime changes. Variations are simultaneously happening both at the cloud infrastructure level - for example hardware failures - and at the user workload level - flash crowds. However, robustly withstanding extreme variability, requires costly hardware over-provisioning. In this paper, we introduce a self-adaptation programming paradigm called brownout. Using this paradigm, applications can be designed to robustly withstand unpredictable runtime variations, without over-provisioning. The paradigm is based on optional code that can be dynamically deactivated through decisions based on control theory. We modified two popular web application prototypes - RUBiS and RUBBoS - with less than 170 lines of code, to make them brownout-compliant. Experiments show that brownout self-adaptation dramatically improves the ability to withstand flash-crowds and hardware failures. © 2014 ACM.","2014","2025-10-22 19:07:34","2025-10-22 19:07:34","","700-711","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Cloud applications; Clouds; Software engineering; Cloud infrastructures; Over provisioning; Cloud; Reconfigurable hardware; Hardware failures; Adaptive software; Adaptive Software; Brownout; Control theory; Control Theory; Programming paradigms; Run-time variations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"VRZKJ2PW","journalArticle","2013","Mastroianni, C.; Meo, M.; Papuzzo, G.","Probabilistic Consolidation of Virtual Machines in Self-Organizing Cloud Data Centers","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2013.17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969916663&doi=10.1109%2fTCC.2013.17&partnerID=40&md5=ca388967b1d387943d840d8ba2d0e6ec","Power efficiency is one of the main issues that will drive the design of data centers, especially of those devoted to provide Cloud computing services. In virtualized data centers, consolidation of Virtual Machines (VMs) on the minimum number of physical servers has been recognized as a very efficient approach, as this allows unloaded servers to be switched off or used to accommodate more load, which is clearly a cheaper alternative to buy more resources. The consolidation problem must be solved on multiple dimensions, since in modern data centers CPU is not the only critical resource: depending on the characteristics of the workload other resources, for example, RAM and bandwidth, can become the bottleneck. The problem is so complex that centralized and deterministic solutions are practically useless in large data centers with hundreds or thousands of servers. This paper presents ecoCloud a self-organizing and adaptive approach for the consolidation of VMs on two resources, namely CPU and RAM. Decisions on the assignment and migration of VMs are driven by probabilistic processes and are based exclusively on local information, which makes the approach very simple to implement. Both a fluid-like mathematical model and experiments on a real data center show that the approach rapidly consolidates the workload, and CPU-bound and RAM-bound VMs are balanced, so that both resources are exploited efficiently. © 2013 IEEE.","2013","2025-10-22 19:07:34","2025-10-22 19:07:34","","215-228","","2","1","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud data centers; Digital storage; Energy conservation; Virtual machine; Data centers; Network security; Virtualized data centers; VM consolidation; Cloud computing services; Critical resources; data center; energy saving; Multiple dimensions; Probabilistic consolidations; Probabilistic process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYR7UU25","journalArticle","2014","Hanumaiah, V.; Vrudhula, S.","Energy-efficient operation of multicore processors by DVFS, task migration, and active cooling","IEEE Transactions on Computers","","","10.1109/TC.2012.213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892391479&doi=10.1109%2fTC.2012.213&partnerID=40&md5=da0387e1b3aafbe6ffadf81a1306808d","Energy efficiency has taken center stage in all aspects of computing, regardless of whether it is performed on a portable battery-powered device, a desktop PC, on servers in a data center, or on a supercomputer. It is expressed as performance-per-watt (PPW), which is equal to the number of instructions that are executed per Joule of energy. The shift to multicore processors, with tens or hundreds of cores on a single die requires that the operation of the cores be dynamically controlled to maximize the processor's overall energy efficiency. This paper presents a unified formulation and an efficient solution for this problem. The solution considers dynamic frequency and voltage scaling, thread migration, and active cooling as the means to control the cores. The solution method is efficient for a real-time implementation. The formulation includes accurate power and thermal models, temperature constraints, and accounts for the dependence of leakage power and circuit delay on temperature. The PPW metric is extended to $(P^{\alpha }PW)$ (performance$(^\alpha) $-per-watt), which allows examining the tradeoffs between optimizing for performance versus optimizing for energy by varying $(\alpha)$. Simulation experiments assuming a four-core processor demonstrate that the derived control strategy can achieve 3.2× greater energy efficiency (i.e., executes more than three times the number of instructions per Joule) over the performance-optimal solution. The formulation and the efficiency of the solution method also allows for fast design space exploration. Specifically, it is shown how simply increasing the number of cores in a processor can significantly diminish its energy efficiency, and that there is an optimal number of cores that maximize the PPW. This number depends on the ratio of how much the power of an individual core is reduced by scaling, i.e., as the number of cores are increased. Finally, the proposed method is implemented on a quad-core Intel Sandy Bridge processor, and verified by running benchmarks. The experiments suggest that the proposed method results in an improvement of 37 percent over the current state-of-the-art energy-efficient schemes. © 2014 IEEE.","2014","2025-10-22 19:07:34","2025-10-22 19:07:34","","349-360","","2","63","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Multi core; Multicore; Optimization; Supercomputers; energy efficiency; active cooling; Active cooling; closed-loop control; Closed-loop control; Cooling; dynamic voltage and frequency scaling; Dynamic voltage and frequency scaling; Experiments; Leakage currents; Leakage power; leakage power dependence on temperature; optimization; performance/Watt; Real time control; task migration; Task migration; Temperature control; thermal management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ENP93WK","journalArticle","2015","Toosi, A.N.; Vanmechelen, K.; Ramamohanarao, K.; Buyya, R.","Revenue Maximization with Optimal Capacity Control in Infrastructure as a Service Cloud Markets","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2014.2382119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941000043&doi=10.1109%2fTCC.2014.2382119&partnerID=40&md5=acd8b114b2216c5cf24465dc742d5a09","Infrastructure-as-a-Service cloud providers offer diverse purchasing options and pricing plans, namely on-demand, reservation, and spot market plans. This allows them to efficiently target a variety of customer groups with distinct preferences and to generate more revenue accordingly. An important consequence of this diversification however, is that it introduces a non-trivial optimization problem related to the allocation of the provider's available data center capacity to each pricing plan. The complexity of the problem follows from the different levels of revenue generated per unit of capacity sold, and the different commitments consumers and providers make when resources are allocated under a given plan. In this work, we address a novel problem of maximizing revenue through an optimization of capacity allocation to each pricing plan by means of admission control for reservation contracts, in a setting where aforementioned plans are jointly offered to customers. We devise both an optimal algorithm based on a stochastic dynamic programming formulation and two heuristics that trade-off optimality and computational complexity. Our evaluation, which relies on an adaptation of a large-scale real-world workload trace of Google, shows that our algorithms can significantly increase revenue compared to an allocation without capacity control given that sufficient resource contention is present in the system. In addition, we show that our heuristics effectively allow for online decision making and quantify the revenue loss caused by the assumptions made to render the optimization problem tractable. © 2013 IEEE.","2015","2025-10-22 19:07:34","2025-10-22 19:07:34","","261-274","","3","3","","","","","","","","","","","","","Scopus","","","","","","","","Infrastructure as a service (IaaS); Economic and social effects; Decision making; Costs; Stochastic systems; Capacity allocation; Dynamic programming; Economics; On-line decision makings; Optimal algorithm; Optimal capacity; Optimization problems; Resource contention; Revenue maximization; Sales; Stochastic dynamic programming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69YRQ99N","conferencePaper","2014","Durango, J.; Dellkrantz, M.; Maggio, M.; Klein, C.; Papadopoulos, A.V.; Hernandez-Rodriguez, F.; Elmroth, E.; Arzen, K.-E.","Control-theoretical load-balancing for cloud applications with brownout","","","","10.1109/CDC.2014.7040221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931846547&doi=10.1109%2fCDC.2014.7040221&partnerID=40&md5=9bb0f0ace051d9fcae0a26db67ce43ea","Cloud applications are often subject to unexpected events like flash crowds and hardware failures. Without a predictable behaviour, users may abandon an unresponsive application. This problem has been partially solved on two separate fronts: first, by adding a self-adaptive feature called brownout inside cloud applications to bound response times by modulating user experience, and, second, by introducing replicas - copies of the applications having the same function-alities - for redundancy and adding a load-balancer to direct incoming traffic. © 2014 IEEE.","2014","2025-10-22 19:07:34","2025-10-22 19:07:34","","5320-5327","","","2015-February","","","","","","","","","","","","","Scopus","","","","","","","","Cloud applications; User experience; Control engineering; Flash crowd; Hardware failures; Incoming traffic; Load balancer; Self-Adaptive; Unexpected events","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the IEEE Conference on Decision and Control","","","","","","","","","","","","","","",""
"T3ZAUWSX","journalArticle","2011","Kim, K.H.; Beloglazov, A.; Buyya, R.","Power-aware provisioning of virtual machines for real-time Cloud services","Concurrency and Computation: Practice and Experience","","","10.1002/cpe.1712","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051798127&doi=10.1002%2fcpe.1712&partnerID=40&md5=99b529f15e78a203deecd0580efda5df","Reducing power consumption has been an essential requirement for Cloud resource providers not only to decrease operating costs, but also to improve the system reliability. As Cloud computing becomes emergent for the Anything as a Service (XaaS) paradigm, modern real-time services also become available through Cloud computing. In this work, we investigate power-aware provisioning of virtual machines for real-time services. Our approach is (i) to model a real-time service as a real-time virtual machine request; and (ii) to provision virtual machines in Cloud data centers using dynamic voltage frequency scaling schemes. We propose several schemes to reduce power consumption by hard real-time services and power-aware profitable provisioning of soft real-time services. © 2011 John Wiley & Sons, Ltd.","2011","2025-10-22 19:07:34","2025-10-22 19:07:34","","1491-1505","","13","23","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Electric power utilization; Energy efficiency; cloud computing; Cloud computing; Cloud data centers; Real time systems; Green computing; Web services; Dynamic frequency scaling; Virtual machine; Hard real-time; Operating costs; Network security; Information services; Resource providers; Dynamic voltage frequency scaling; Energy efficient computing; energy-efficient computing; green data centers; Green data centers; Real time service; real-time services; System reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7ZJXSKP","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034027192&partnerID=40&md5=360bff5b61c56cc45665f535d2fc3b94","","","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q2QDXVW7","journalArticle","2013","Beloglazov, A.; Buyya, R.","Managing overloaded hosts for dynamic consolidation of virtual machines in cloud data centers under quality of service constraints","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2012.240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878476684&doi=10.1109%2fTPDS.2012.240&partnerID=40&md5=01be4a531f0874fe562725f0dc176ae7","Dynamic consolidation of virtual machines (VMs) is an effective way to improve the utilization of resources and energy efficiency in cloud data centers. Determining when it is best to reallocate VMs from an overloaded host is an aspect of dynamic VM consolidation that directly influences the resource utilization and quality of service (QoS) delivered by the system. The influence on the QoS is explained by the fact that server overloads cause resource shortages and performance degradation of applications. Current solutions to the problem of host overload detection are generally heuristic based, or rely on statistical analysis of historical data. The limitations of these approaches are that they lead to suboptimal results and do not allow explicit specification of a QoS goal. We propose a novel approach that for any known stationary workload and a given state configuration optimally solves the problem of host overload detection by maximizing the mean intermigration time under the specified QoS goal based on a Markov chain model. We heuristically adapt the algorithm to handle unknown nonstationary workloads using the Multisize Sliding Window workload estimation technique. Through simulations with workload traces from more than a thousand PlanetLab VMs, we show that our approach outperforms the best benchmark algorithm and provides approximately 88 percent of the performance of the optimal offline algorithm. © 1990-2012 IEEE.","2013","2025-10-22 19:07:34","2025-10-22 19:07:34","","1366-1379","","7","24","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Performance degradation; cloud computing; Cloud computing; Algorithms; Distributed systems; Virtualizations; Benchmarking; Resource utilizations; Dynamic consolidation; Computer simulation; dynamic consolidation; energy efficiency; host overload detection; Overload detection; Quality of Service constraints; Utilization of resources; virtualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKVNU8BD","journalArticle","2016","Bawden, T.","Global Warming: Data Centres to Consume Three Times as Much Energy in Next Decade, Experts Warn. Independent","Global Warming: Data Centres to Consume Three Times As Much Energy in Next Decade, Experts Warn","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027445487&partnerID=40&md5=123e9283abd4476f899e2d3f932614ad","","2016","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFSLKSHZ","journalArticle","2011","Calheiros, R.N.; Ranjan, R.; Beloglazov, A.; De Rose, C.A.F.; Buyya, R.","CloudSim: A toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms","Software - Practice and Experience","","","10.1002/spe.995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650777991&doi=10.1002%2fspe.995&partnerID=40&md5=e5acc8ba81ccb3bce707222348c8d53b","Cloud computing is a recent advancement wherein IT infrastructure and applications are provided as 'services' to end-users under a usage-based payment model. It can leverage virtualized services even on the fly based on requirements (workload patterns and QoS) varying with time. The application services hosted under Cloud computing model have complex provisioning, composition, configuration, and deployment requirements. Evaluating the performance of Cloud provisioning policies, application workload models, and resources performance models in a repeatable manner under varying system and user configurations and requirements is difficult to achieve. To overcome this challenge, we propose CloudSim: an extensible simulation toolkit that enables modeling and simulation of Cloud computing systems and application provisioning environments. The CloudSim toolkit supports both system and behavior modeling of Cloud system components such as data centers, virtual machines (VMs) and resource provisioning policies. It implements generic application provisioning techniques that can be extended with ease and limited effort. Currently, it supports modeling and simulation of Cloud computing environments consisting of both single and inter-networked clouds (federation of clouds). Moreover, it exposes custom interfaces for implementing policies and provisioning techniques for allocation of VMs under inter-networked Cloud computing scenarios. Several researchers from organizations, such as HP Labs in U.S.A., are using CloudSim in their investigation on Cloud resource provisioning and energy-efficient management of data center resources. The usefulness of CloudSim is demonstrated by a case study involving dynamic provisioning of application services in the hybrid federated clouds environment. The result of this case study proves that the federated Cloud computing model significantly improves the application QoS requirements under fluctuating resource and service demand patterns. Copyright © 2010 John Wiley & Sons, Ltd.","2011","2025-10-22 19:07:34","2025-10-22 19:07:34","","23-50","","1","41","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; resource management; Resource management; Distributed computer systems; Clouds; Natural resources management; Resource allocation; Mathematical models; Performance evaluation; Research; application scheduling; Application scheduling; Computer simulation; modelling and simulation; Modelling and simulations; performance evaluation; Satellite communication systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKNTF4NL","journalArticle","2016","Xu, M.; Dastjerdi, A.V.; Buyya, R.","Energy Efficient Scheduling of Cloud Application Components with Brownout","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2017.2661339","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081713746&doi=10.1109%2fTSUSC.2017.2661339&partnerID=40&md5=e00446747da4f43b0f291cc8f5ee0154","It is common for cloud data centers meeting unexpected loads like request bursts, which may lead to overloaded situation and performance degradation. Dynamic Voltage Frequency Scaling and VM consolidation have been proved effective to manage overloads. However, they cannot function when the whole data center is overloaded. Brownout provides a promising direction to avoid overloads through configuring applications to temporarily degrade user experience. Additionally, brownout can also be applied to reduce data center energy consumption. As a complementary option for Dynamic Voltage Frequency Scaling and VM consolidation, our combined brownout approach reduces energy consumption through selectively and dynamically deactivating application optional components, which can also be applied to self-contained microservices. The results show that our approach can save more than 20 percent energy consumption and there are trade-offs between energy saving and discount offered to users. © 2016 IEEE.","2016","2025-10-22 19:07:34","2025-10-22 19:07:34","","40-43","","2","1","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; microservices; Application components; Cloud data centers; Energy efficient; Energy utilization; Economic and social effects; Green computing; Dynamic frequency scaling; application component; brownout; energy efficient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICFPMIPC","journalArticle","2014","Corradi, A.; Fanelli, M.; Foschini, L.","VM consolidation: A real case based on OpenStack Cloud","Future Generation Computer Systems","","","10.1016/j.future.2012.05.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891606241&doi=10.1016%2fj.future.2012.05.012&partnerID=40&md5=e3fd3a653ead49786de3f27b61d334e1","In recent years, Cloud computing has been emerging as the next big revolution in both computer networks and Web provisioning. Because of raised expectations, several vendors, such as Amazon and IBM, started designing, developing, and deploying Cloud solutions to optimize the usage of their own data centers, and some open-source solutions are also underway, such as Eucalyptus and OpenStack. Cloud architectures exploit virtualization techniques to provision multiple Virtual Machines (VMs) on the same physical host, so as to efficiently use available resources, for instance, to consolidate VMs in the minimal number of physical servers to reduce the runtime power consumption. VM consolidation has to carefully consider the aggregated resource consumption of co-located VMs, in order to avoid performance reductions and Service Level Agreement (SLA) violations. While various works have already treated the VM consolidation problem from a theoretical perspective, this paper focuses on it from a more practical viewpoint, with specific attention on the consolidation aspects related to power, CPU, and networking resource sharing. Moreover, the paper proposes a Cloud management platform to optimize VM consolidation along three main dimensions, namely power consumption, host resources, and networking. Reported experimental results point out that interferences between co-located VMs have to be carefully considered to avoid placement solutions that, although being feasible from a more theoretical viewpoint, cannot ensure VM provisioning with SLA guarantees.","2014","2025-10-22 19:07:34","2025-10-22 19:07:34","","118-127","","1","32","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Cloud computing; Service Level Agreements; Cloud architectures; Cloud managements; Open-source solutions; OpenStack; Resource consumption; Resource sharing; Virtualization Techniques; VM consolidation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BU4GM694","journalArticle","2014","Whitney, J.; Delforge, P.","Data center efficiency assessment-scaling up energy efficiency across the data center industry: Evaluating key drivers and barriers","Data Center Efficiency Assessment-Scaling Up Energy Efficiency Across the Data Center Industry: Evaluating Key Drivers and Barriers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957375958&partnerID=40&md5=74d0323715ac988c9cdcb79ae0c9b082","","2014","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RV7ZGL9","journalArticle","2006","Park, K.; Pai, V.S.","CoMon: A mostly-scalable monitoring system for PlanetLab","Operating Systems Review (ACM)","","","10.1145/1113361.1113374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845223204&doi=10.1145%2f1113361.1113374&partnerID=40&md5=109f1b187c53974942bb2a417154a8e0","CoMon is an evolving, mostly-scalable monitoring system for PlanetLab that has the goal of presenting environment-tailored information for both the administrators and users of the PlanetLab global testbed. In addition to passively reporting metrics provided by the operating system, CoMon also actively gathers a number of metrics useful for developers of networked systems. Using CoMon, PlanetLab administrators and users can easily spot problematic machines, where the problem may arise from the machine itself, local configuration/environment problems, or the workload running on the machine. Furthermore, users can easily observe many properties of all of the experiments running across multiple PlanetLab nodes, facilitating not only their own experiment monitoring and debugging, but also helping scale the task of finding PlanetLab problems. In this paper we describe CoMon's design and operation, including what kinds of data are gathered, the scale of the processing involved, and the approaches we have taken to keep CoMon running. Our goal is not only to illustrate the kinds of problems faced in this environment, but also to invite others to participate, either by experimenting with the data generated by CoMon, or by building on the CoMon system itself.","2006","2025-10-22 19:07:34","2025-10-22 19:07:34","","65-74","","1","40","","","","","","","","","","","","","Scopus","","","","","","","","Program debugging; Computer operating systems; User interfaces; Computer networks; Data acquisition; Problem solving; Information services; CoMon systems; Man machine systems; Networked systems; PlanetLab nodes; Testbeds","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24RQF2BU","conferencePaper","2015","Chen, Q.; Chen, J.; Zheng, B.; Cui, J.; Qian, Y.","Utilization-based VM consolidation scheme for power efficiency in cloud data centers","","","","10.1109/ICCW.2015.7247462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947776140&doi=10.1109%2fICCW.2015.7247462&partnerID=40&md5=c79891a7cdb7bf5e860a097a90b342c3","Cloud computing offers utility-oriented services to users, which is supported by large-scale data center. Although virtualized data centers provide high performance computing service, they also consume enormous amount of power. To solve the problem, dynamic consolidation of Virtual Machines (VMs) is considered as an efficient way to reduce power consumption and guarantee Quality of Service (QoS). Live migration is applied into the dynamic consolidation, which allows VMs to be migrated to other hosts and aims to minimize the number of hosts in data centers. However, the migration overhead is essential to be taken into account and massive migrations will lead to performance degradation and extra power consumption. In this paper, we propose a utilization-based migration algorithm (UMA) to migrate VMs to stable hosts, which efficiently reduces migration time and power consumption. Experiment results show that our UMA can reduce about 77.5%-82.4% migrations and save up to 39.3% -42.2% power consumption compared with the MinPower policy. © 2015 IEEE.","2015","2025-10-22 19:07:34","2025-10-22 19:07:34","","1928-1933","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Electric power utilization; Energy efficiency; Performance degradation; Cloud data centers; Virtual machine; Dynamic consolidation; High performance computing; Large scale data; Migration algorithms; Power efficiency; Virtualized data centers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 IEEE International Conference on Communication Workshop, ICCW 2015","","","","","","","","","","","","","","",""
"P4X6RUUT","journalArticle","2012","Beloglazov, A.; Abawajy, J.; Buyya, R.","Energy-aware resource allocation heuristics for efficient management of data centers for Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2011.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370722&doi=10.1016%2fj.future.2011.04.017&partnerID=40&md5=404d8a6f96e7208ce49f7fb3ffc699cd","Cloud computing offers utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of electrical energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only minimize operational costs but also reduce the environmental impact. In this paper, we define an architectural framework and principles for energy-efficient Cloud computing. Based on this architecture, we present our vision, open research challenges, and resource provisioning and allocation algorithms for energy-efficient management of Cloud computing environments. The proposed energy-aware allocation heuristics provision data center resources to client applications in a way that improves energy efficiency of the data center, while delivering the negotiated Quality of Service (QoS). In particular, in this paper we conduct a survey of research in energy-efficient computing and propose: (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering QoS expectations and power usage characteristics of the devices; and (c) a number of open research challenges, addressing which can bring substantial benefits to both resource providers and consumers. We have validated our approach by conducting a performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant cost savings and demonstrates high potential for the improvement of energy efficiency under dynamic workload scenarios. © 2011 Elsevier B.V. All rights reserved.","2012","2025-10-22 19:07:34","2025-10-22 19:07:34","","755-768","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Energy efficient; Virtualizations; Energy aware; Resource allocation; Energy-efficient resource allocation; Computing environments; Research challenges; Data centers; Client applications; Computer systems; Performance evaluation; Cost saving; Dynamic consolidation; Allocation algorithm; Architectural frameworks; Architectural principles; Business domain; Carbon footprint; Computing solutions; Electrical energy; Environmental impact; Green IT; High potential; IT services; Operational costs; Pay-as-you-go; Pervasive applications; Power usage; Research; Resource providers; Resource provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KY8DJSPV","conferencePaper","2014","Zheng, K.; Wang, X.; Li, L.; Wang, X.","Joint power optimization of data center network and servers with correlation analysis","","","","10.1109/INFOCOM.2014.6848207","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904410981&doi=10.1109%2fINFOCOM.2014.6848207&partnerID=40&md5=ec3b4daf09fd8b2c667563df1cd786e4","Data center power optimization has recently received a great deal of research attention. For example, server consolidation has been demonstrated as one of the most effective energy saving methodologies. Likewise, traffic consolidation has also been recently proposed to save energy for data center networks (DCNs). However, current research on data center power optimization focuses on servers and DCN separately. As a result, the optimization results are often inferior, because server consolidation without considering the DCN may cause traffic congestion and thus degraded network performance. On the other hand, server consolidation may change the DCN topology, allowing new opportunities for energy savings. In this paper, we propose PowerNetS, a power optimization strategy that leverages workload correlation analysis to jointly minimize the total power consumption of servers and the DCN. The design of PowerNetS is based on the key observations that the workloads of different servers and DCN traffic flows do not peak at exactly the same time. Thus, more energy savings can be achieved if the workload correlations are considered in server and traffic consolidations. In addition, PowerNetS considers the DCN topology during server consolidation, which leads to less inter-server traffic and thus more energy savings and shorter network delays. We implement PowerNetS on a hardware testbed composed of 10 virtual switches configured with a production 48-port OpenFlow switch and 6 servers. Our empirical results with Wikipedia, Yahoo!, and IBM traces demonstrate that PowerNetS can save up to 51.6% of energy for a data center. PowerNetS also outperforms two state-of-the-art baselines by 44.3% and 15.8% on energy savings, respectively. Our simulation results with 72 switches and 122 servers also show the superior energy efficiency of PowerNetS over the baselines. © 2014 IEEE.","2014","2025-10-22 19:07:34","2025-10-22 19:07:34","","2598-2606","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Data center networks; Data center networks (DCNs); Correlation analysis; Correlation methods; Hardware testbeds; Power Optimization; Server consolidation; Topology; Total power consumption; Traffic congestion; Workload correlations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"WQGB4EHM","journalArticle","1956","Bellman, R.","Dynamic programming and Lagrange multipliers","Proceedings of the National Academy of Sciences of the United States of America","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47149096461&partnerID=40&md5=123363222e36f8285ea8129a523035a5","","1956","2025-10-22 19:07:34","2025-10-22 19:07:34","","767-769","","10","42","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HV24TV95","conferencePaper","2016","Han, Z.; Tan, H.; Chen, G.; Wang, R.; Chen, Y.; Lau, F.C.M.","Dynamic virtual machine management via approximate Markov decision process","","","","10.1109/INFOCOM.2016.7524384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983261312&doi=10.1109%2fINFOCOM.2016.7524384&partnerID=40&md5=ad72f6d581877dfd92d061df60b3b28e","Efficient virtual machine (VM) management can dramatically reduce energy consumption in data centers. Existing VM management algorithms fall into two categories based on whether the VMs' resource demands are assumed to be static or dynamic. The former category fails to maximize the resource utilization as they cannot adapt to the dynamic nature of VMs' resource demands. Most approaches in the latter category are heuristical and lack theoretical performance guarantees. In this work, we formulate dynamic VM management as a large-scale Markov Decision Process (MDP) problem and derive an optimal solution. Our analysis of real-world data traces supports our choice of the modeling approach. However, solving the large-scale MDP problem suffers from the curse of dimensionality. Therefore, we further exploit the special structure of the problem and propose an approximate MDP-based dynamic VM management method, called MadVM. We prove the convergence of MadVM and analyze the bound of its approximation error. Moreover, MadVM can be implemented in a distributed system, which should suit the needs of real data centers. Extensive simulations based on two real-world workload traces show that MadVM achieves significant performance gains over two existing baseline approaches in power consumption, resource shortage and the number of VM migrations. Specifically, the more intensely the resource demands fluctuate, the more MadVM outperforms. © 2016 IEEE.","2016","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","2016-July","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Decision making; Extensive simulations; Resource utilizations; Approximation errors; Curse of dimensionality; Markov Decision Processes; Markov processes; Reduce energy consumption; Telecommunication networks; Theoretical performance; Virtual machine management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"NIXV5JCR","conferencePaper","2020","Jayabalan, M.","Towards an Approach of Risk Analysis in Access Control","","","","10.1109/DeSE51703.2020.9450772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112559026&doi=10.1109%2fDeSE51703.2020.9450772&partnerID=40&md5=1722a16f1a6214f59f2398b74ca4898f","Information security provides a set of mechanisms to be implemented in the organisation to protect the disclosure of data to the unauthorised person. Access control is the primary security component that allows the user to authorise the consumption of resources and data based on the predefined permissions. However, the access rules are static in nature, which does not adapt to the dynamic environment includes but not limited to healthcare, cloud computing, IoT, National Security and Intelligence Arena and multi-centric system. There is a need for an additional countermeasure in access decision that can adapt to those working conditions to assess the threats and to ensure privacy and security are maintained. Risk analysis is an act of measuring the threats to the system through various means such as, analysing the user behaviour, evaluating the user trust, and security policies. It is a modular component that can be integrated into the existing access control to predict the risk. This study presents the different techniques and approaches applied for risk analysis in access control. Based on the insights gained, this paper formulates the taxonomy of risk analysis and properties that will allow researchers to focus on areas that need to be improved and new features that could be beneficial to stakeholders.  © 2020 IEEE.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","287-292","","","2020-December","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Dynamic environments; Risk assessment; security; Access control; Access decision; Access rules; Information security; Modular components; National security; Privacy; Privacy and security; Privacy by design; Risk analysis; Security components; Security policy; User behaviour","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Developments in eSystems Engineering, DeSE","","","","","","","","","","","","","","",""
"C5IFCUMQ","journalArticle","2024","Khan, M.A.; Rais, R.N.B.; Khalid, O.; Ahmad, S.","Trust-Based Optimized Reporting for Detection and Prevention of Black Hole Attacks in Low-Power and Lossy Green IoT Networks","Sensors","","","10.3390/s24061775","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189028251&doi=10.3390%2fs24061775&partnerID=40&md5=37dbbd03feff9d8474a45707bf7fd402","The Internet of Things (IoT) is empowering various sectors and aspects of daily life. Green IoT systems typically involve Low-Power and Lossy Networks (LLNs) with resource-constrained nodes. Lightweight routing protocols, such as the Routing Protocol for Low-Power and Lossy Networks (RPL), are increasingly being applied for efficient communication in LLNs. However, RPL is susceptible to various attacks, such as the black hole attack, which compromises network security. The existing black hole attack detection methods in Green IoT rely on static thresholds and unreliable metrics to compute trust scores. This results in increasing false positive rates, especially in resource-constrained IoT environments. To overcome these limitations, we propose a delta-threshold-based trust model called the Optimized Reporting Module (ORM) to mitigate black hole attacks in Green IoT systems. The proposed scheme comprises both direct trust and indirect trust and utilizes a forgetting curve. Direct trust is derived from performance metrics, including honesty, dishonesty, energy, and unselfishness. Indirect trust requires the use of similarity. The forgetting curve provides a mechanism to consider the most significant and recent feedback from direct and indirect trust. To assess the efficacy of the proposed scheme, we compare it with the well-known trust-based attack detection scheme. Simulation results demonstrate that the proposed scheme has a higher detection rate and low false positive alarms compared to the existing scheme, confirming the applicability of the proposed scheme in green IoT systems. © 2024 by the authors.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","6","24","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Low power electronics; article; Network security; benchmarking; black hole; black hole attack; Black hole attack; diagnosis; Direct trusts; Gravitation; Green internet of thing; green internet of things; Green internets; honesty; human; Indirect trusts; internet of things; Lossy networks; Low Power Networks; Low-power and lossy network; low-power and lossy networks (LLNs); network security; prevention; Routing protocols; RPL; simulation; Stars; trust-based; Trust-based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NP7DXIP","journalArticle","2024","Hernandez-Jaimes, M.L.; Martinez-Cruz, A.; Ramírez-Gutiérrez, K.A.","A Machine Learning approach for anomaly detection on the Internet of Things based on Locality-Sensitive Hashing","Integration","","","10.1016/j.vlsi.2024.102159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184140607&doi=10.1016%2fj.vlsi.2024.102159&partnerID=40&md5=3cdf9838bd1d08fa0e7aa80a18743f75","The increasing connectivity of devices on the Internet of Things (IoT) has created a favorable field for attacks. Consequently, current anomaly-based intrusion detection systems (AIDS) integrate artificial intelligence algorithms, such as machine learning (ML) and deep learning (DL), to manage high data volumes, recognize complex patterns, and detect unknown anomalies. However, the effectiveness of these methods is contingent upon the quality and meaningfulness of the extracted features from IoT-based communications. Also, with the growth of the IoT, feature extraction and selection are becoming increasingly difficult due to data heterogeneity, the generation of massive amounts of information, and the lack of feature standardization. Moreover, current proposals rely on complex feature extraction and selection techniques. As a result, this study introduces a novel approach for ML modeling, including decision trees and random forests, to detect anomalies in IoT. This study aims to overcome feature extraction and selection process dependency by integrating fingerprinting techniques based on locality-sensitive hashing (LSH) to represent network packet information in a suitable format for ML modeling and detecting harmful sequential network packets. The anomaly detection performance was assessed using two benchmark IoT datasets, ToN-IoT and MQTT-IoT, which contain cyberattacks threatening IoT networks. The proposal outperforms other methods regarding accuracy, precision, and FPR with values of 99.82%, 99.93%, and 0.13%, respectively. © 2024 Elsevier B.V.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","96","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Information management; Internet of things; Benchmarking; Artificial intelligence; Learning systems; Machine learning; Complex networks; Internet of Things; Anomaly detection; Machine-learning; Decision trees; Intrusion detection; Feature extraction; Intrusion-Detection; 'current; Anomaly based intrusion detection systems; Extraction; Feature extraction and selection; Locality sensitive hashing; Locality-sensitive hashing; Machine learning approaches; Machine learning models; Network packets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QW3T656","journalArticle","2024","Kotronis, C.; Nikolaidou, M.; Tsadimas, A.; Michalakelis, C.; Anagnostopoulos, D.","Extending SysML to Integrate Cost Analysis into Model-Based Systems Engineering","IEEE Transactions on Engineering Management","","","10.1109/TEM.2022.3200148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137553281&doi=10.1109%2fTEM.2022.3200148&partnerID=40&md5=34ce187b42416a10c1fd5ca2dc59a3bc","Model-based systems design (MBSD), a current trend adopted by INCOSE, employs the systems modeling language (SysML), a standard introduced by OMG and INCOSE. Though there are numerous works on integrating performance exploitation in SysML, cost is not sufficiently explored as a driving design parameter. By integrating cost analysis in a popular modeling language like SysML, the proposed approach may be applied to any system designed using standardized languages and tools. In this work, we integrate cost analysis within SysML models at a generic level to explore design alternatives under specific cost and performance restrictions and perform tradeoff analysis. The proposed SysML extensions provide: 1) cost-related entities to encode cost aspects, such as capital and operating expenses, and 2) functions that enable the automatic computation of costs; these extensions are contained in a custom SysML cost profile. The feasibility and benefits of the approach are explored in two distinct real-world case studies with different purpose and characteristics. 1) Configuring a remote elderly monitoring system, taking into consideration patients' budgetary and operational concerns regarding the equipment installed in their homes. In this case, patients had the opportunity to evaluate and prioritize their concerns prior to using the system. 2) Exploring the improvement of the passengers' comfort as a level of service indicator in the Athens Metro railway system, taking into account operational cost constraints. In this case, the operator obtained forecasts of performance and cost of the metro system operation in order to choose between different operational policies.  © 1988-2012 IEEE.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","2865-2880","","","71","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Systems analysis; Budget control; Cost benefit analysis; Cost engineering; Model-based system engineering; Model-based system engineerings; System modeling language; System models; Systems engineering; Capital expenditure; Capital expenditures; Capital expenditures (CapEx); cost analysis; Cost analysis; Cost-benefits analysis; Elderly monitoring; model-based system engineering (MBSD); Modeling; Object oriented modelling; Operating expense; operating expenses (OpEx); Railroads; Railway transportation; railway transportation system; Railway transportation system; remote elderly monitoring; Remote elderly monitoring; System analysis and design; systems modeling language (SysML); Transportation system; Unified Modeling Language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TANCHHLG","conferencePaper","2016","Palmer, D.; Fazzari, S.; Wartenberg, S.","Defense systems and IoT: Security issues in an era of distributed command and control","","","","10.1145/2902961.2903038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974716011&doi=10.1145%2f2902961.2903038&partnerID=40&md5=a9bdaa21d8e06a7453dbc52e139eda79","Welcome to the 26th edition of the Great Lakes Symposium on VLSI (GLSVLSI) 2016, held at Boston University Department of Electrical and Computer Engineering in Boston, MA, USA. GLSVLSI is a premier venue for the dissemination of manuscripts of the highest quality in all areas related to VLSI, devices, and system-level design. The location of this year's GLSVLSI is Boston, which continues GLSVLSI's tradition of organizing meetings near noted bodies of water. While not a ""great lake"", the Charles River flows across the Greater Boston area, separating the city of Boston from Cambridge. The basin of the Charles River is located in Hopkinton, Massachusetts, and serves as the starting point of the Boston Marathon. While the marathoners run 26 miles to the city, the Charles River twists and turns for 80 miles before ending its journey in Boston Harbor, where it meets the Atlantic Ocean. The Greater Boston area, consisting of Boston and its surrounding neighborhoods, is the 10th largest metropolitan area of the US. Boston is one of the oldest cities in the US, and was the first city to open a public school and a transportation system in the country. Boston is truly an intellectual, technological, and political hub. It is home to around 50 universities and colleges, making it one of the most prominent centers of higher education and medicine internationally. Boston is experiencing substantial industrial growth, particularly in the fields of computer and electrical engineering. Each year, millions of tourists visit Boston to explore the city's historic landmarks, to include Faneuil Hall, Fenway Park (home of the Boston Red Sox), Boston Common, and Harvard Square. Boston University, located along the Charles River, is in the heart of the city with easy access to all major tourist attractions, parks, concert venues, and museums. Boston is a great location for this highquality symposium on VLSI, and we believe that you will enjoy the beautiful city as well as the symposium. This year's special theme for GLSVLSI is Hardware and System Design for Security and Privacy. To support this theme, we have organized several keynote talks by recognized experts and dedicated three special sessions to this topic. On Wednesday we will open the symposium with Marc Witteman, the Chief Executive Officer of Riscure in the Netherlands, who will speak about building secure chips. Kevin Fu, professor at University of Michigan and the Chief Scientist of Virta Labs, will talk about medical device security on Thursday afternoon. On Friday, Ingrid Verbauwhede, professor at University of Leuven in Belgium and at UCLA, will deliver another keynote talk on low power embedded encryption. Special sessions on the hardware security theme cover Internet-of-Things security (Wednesday), emerging technologies and security (Thursday), and a panel on future of hardware security research with speakers from industry, government agencies, and academia (Friday). In addition to including a substantial amount of focus on the hardware security theme, we made sure to provide perspectives on other cutting edge topics to enrich and diversify the symposium program. Yusuf Leblebici, professor at the Swiss Federal Institute of Technology, will talk about multi-sensor vision system design on Thursday. Also on Thursday, we have an exciting special session discussing synthetic biology research, explicitly targeting the VLSI and EDA communities. As for the technical content, GLSVLSI 2016 had outstanding statistics: 197 papers were submitted, by authors from 25 different countries, of which 50 papers were accepted as full papers for oral presentation (with a 25% acceptance rate). Including poster papers, a total of 71 papers will be included in the symposium and published in the proceedings. Of the authors of these papers in the program, 53% are from the Americas, 28% from Asia, and 19% from Europe. The final technical program consists of 21 long presentations and 29 short presentations in 12 oral sessions, and 21 posters in two poster sessions. Special sessions add another 9 exciting papers to the proceedings of the symposium. GLSVLSI 2016 starts on Wednesday, May 18th 2016, with an exciting line up of speakers on a broad range of issues including hardware security, encryption, new methods in CAD and network-on-chips (NoCs), low-power systems and emerging memory designs, and stochastic computing applications. On the second day, in addition to continuing the discussion on CAD and VLSI design challenges, we have technical sessions focused on error resilience and robustness, emerging technologies and post-CMOS VLSI. On the third day, further discussions are dedicated to the innovative solutions for emerging technologies, low-power systems, and VLSI design. The technical program of GLSVLSI 2016 contains two parallel tracks to allow the inclusion of more papers and extensive discussions during the three days of the symposium. Overall, there are 12 regular sessions, 4 special sessions, and 2 poster sessions in the technical program. Four outstanding papers have been selected as candidates for the best paper award and will be presented in different technical sessions (as marked in the program). The best paper award will be announced at the symposium banquet on Thursday evening. The social events of GLSVLSI 2016 include two special events this year. The first event is a reception cocktail on Wednesday evening at the historic Boston University Castle. Then, on Thursday, May 19th, in a special version of the famous ""Boston Duck Tour"", attendees will get a chance to see various Boston monuments and neighborhoods, and enjoy a short trip on the river. The 1-hour tour will be followed by the symposium banquet that will be held at the Boston University Trustees Ballroom. © 2016 ACM.","2016","2025-10-22 19:07:34","2025-10-22 19:07:34","","175-179","","","18-20-May-2016","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Distributed computer systems; Internet of things; Design; Emerging technologies; Systems analysis; Cryptography; Hardware security; Integrated circuit design; Low power electronics; Network-on-chip; Network security; Biomedical equipment; Chief executive officer; Command and control systems; Computer aided design; Computer vision; Education; Electrical and computer engineering; Multi-sensor vision system; Paper; Reconfigurable hardware; Rivers; Stochastic systems; Surrounding neighborhood; Swiss Federal Institute of Technology; Universities and colleges; University of Michigan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Great Lakes Symposium on VLSI, GLSVLSI","","","","","","","","","","","","","","",""
"W9D5B8ZF","journalArticle","2024","Ghadi, Y.Y.; Mazhar, T.; Shloul, T.A.; Shahzad, T.; Salaria, U.A.; Ahmed, A.; Hamam, H.","Machine Learning Solutions for the Security of Wireless Sensor Networks: A Review","IEEE Access","","","10.1109/ACCESS.2024.3355312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182939547&doi=10.1109%2fACCESS.2024.3355312&partnerID=40&md5=cd43d440f86cacba7d01d4a102310101","Energy efficiency and safety are two essential factors that play a significant role in operating a wireless sensor network. However, it is claimed that these two factors are naturally conflicting. The level of electrical consumption required by a security system is directly proportional to its degree of complexity. Wireless sensor networks require additional security measures above the capabilities of conventional network security protocols, such as encryption and key management. The potential application of machine learning techniques to address network security concerns is frequently discussed. These devices will have complete artificial intelligence capabilities, enabling them to understand their environment and respond. During the training phase, machine-learning systems may face challenges due to the large amount of data required and the complex nature of the training procedure. The main objective of the article is to know about different machine learning algorithms that are used to solve the security issues of wireless sensor networks. This study also focuses on the use of wireless sensor networks in different fields. Furthermore, this study also focuses on different Machine learning algorithms that are used to secure wireless sensor networks. Moreover, this study also addresses issues of adapting machine learning algorithms to accommodate the sensors' functionalities in the network configuration. Furthermore, this article also focuses on open issues in this field that must be solved.  © 2013 IEEE.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","12699-12719","","","12","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Internet of things; Cryptography; Network protocols; Wireless sensor networks; Artificial intelligence; Learning algorithms; Learning systems; Complex networks; Network security; Security; machine learning; Machine-learning; IoT; Accident prevention; Electrical consumption; LoWPAN; Machine learning algorithms; Security of wireless sensor networks; WSN security; WSNs securities; WSNs security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MG3UHCLV","journalArticle","2020","Pham, H.A.; Soriano, T.; Ngo, V.H.; Gies, V.","Distributed adaptive neural network control applied to a formation tracking of a group of low-cost underwater drones in hazardous environments","Applied Sciences (Switzerland)","","","10.3390/app10051732","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081980126&doi=10.3390%2fapp10051732&partnerID=40&md5=32da075ecf072039b645612a6485f503","This paper addresses a formation tracking problem of multiple low-cost underwater drones by implementing distributed adaptive neural network control (DANNC). It is based on a leader-follower architecture to operate in hazardous environments. First, unknown parameters of underwater vehicle dynamics, which are important requirements for real-world applications, are approximated by a neural network using a radial basis function. More specifically, those parameters are only calculated by local information, which can be obtained by an on-board camera without using an external positioning system. Secondly, a potential function is employed to ensure there is no collision between the underwater drones. We then propose a desired configuration of a group of unmanned underwater vehicles (UUVs) as a time-variant function so that they can quickly change their shape between them to facilitate the crossing in a narrow area. Finally, three UUVs, based on a robot operating system (ROS) platform, are used to emphasize the realistic low-cost aspect of underwater drones. The proposed approach is validated by evaluating in different experimental scenarios. © 2020 by the authors.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","5","10","","","","","","","","","","","","","Scopus","","","","","","","","Collision and obstacle avoidance; Distributed adaptive neural network control; Gazebo; Low-cost underwater robotics; Robot operating system (ROS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4X8SIGG","journalArticle","2024","Ghaderi, M.R.; Amiri, N.","LoRaWAN sensor: energy analysis and modeling","Wireless Networks","","","10.1007/s11276-023-03542-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175201730&doi=10.1007%2fs11276-023-03542-y&partnerID=40&md5=242af800826237ea1c64ee246746cf90","Nowadays, with the increasing growth of the Internet of Things (IoT), where reliable sensors are needed to operate for extended periods, the issue of energy consumption efficiency has become crucial. To address this, it is suggested to utilize low-power network (LPN) technology for IoT sensor networks. Additionally, a detailed analysis of sensor node performance and a comprehensive understanding of energy consumption sources in the sensor are necessary to tackle the energy management challenge. Therefore, it is highly valuable to have a model that can analyze the performance of the sensor node in various operation modes. In this article, we analyze the impact of various parameters on sensor node performance and present a comprehensive model for the sensor node energy consumption in the network based on long-range/long-range wide-area network (LoRa/LoRaWAN) technologies. This model enables the analysis of network performance and the estimation of energy consumption in different modes of the sensor node. The model can be practically utilized in the optimal design of sensor nodes in IoT networks based on LoRa/LoRaWAN technology, with a focus on increasing sensor lifetime. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","1013-1036","","2","30","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Internet of things; Energy management; Energy-consumption; Low power electronics; LoRa; LoRaWAN; Sensor nodes; Network-based; IoT; Analysis and models; Energy analysis; Energy model; Lora; Network technologies; Node performance; Sensor; Wide area networks; Wide-area networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZHXD7U9","journalArticle","2023","Hazman, C.; Guezzaz, A.; Benkirane, S.; Azrour, M.","lIDS-SIoEL: intrusion detection framework for IoT-based smart environments security using ensemble learning","Cluster Computing","","","10.1007/s10586-022-03810-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142454304&doi=10.1007%2fs10586-022-03810-0&partnerID=40&md5=5fbddb9fb9db2235565f9b89750ee6d6","Smart cities are being enabled all around the world by Internet of Things (IoT) applications. A smart city idea necessitates the integration of information and communication technologies and devices throughout a network in order to provide improved services to consumers. Because of their increasing amount and mobility, they are increasingly appealing to attackers. Therefore, several solutions, including as encryptions, authentication, availability, and data integrity, have been combined to protect IoT. Intrusion detection systems (IDSs) are a powerful security tool that may be improved by incorporating machine learning (ML) and deep learning (DP) techniques. This paper presents a novel intrusion detection framework for IoT-based smart environments with Ensemble Learning called IDS-SIoEL. Typically, the framework proposed an optimal anomaly detection model that uses AdaBoost, and combining different feature selection techniques Boruta, mutual information and correlation furthermore. The proposed model was evaluated on IoT-23, BoT-IoT, and Edge-IIoT datasets using the GPU. When compared to existing IDS, our approach provides good rating performance features of ACC, recall, and precision, with around 99.9% on record detection and calculation time of 33.68 s for learning and 0.02156 s for detection. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","4069-4083","","6","26","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Internet of things; Smart city; Learning systems; Network security; Anomaly detection; Machine-learning; Intrusion detection; Intrusion Detection Systems; IoT; Adaptive boosting; BoT-internet of thing; BoT-IoT; Detection framework; Edge-IIoT; Ensemble learning; Feature extraction; Information and Communication Technologies; Internet of thing-23; Intrusion-Detection; IoT-23; ML; Smart environment; Smart environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VY2P63N","journalArticle","2024","Mao, G.; Liu, Y.; Dai, W.; Li, G.; Zhang, Z.; Lam, A.H.F.; Cheung, R.C.C.","REALISE-IoT: RISC-V-Based Efficient and Lightweight Public-Key System for IoT Applications","IEEE Internet of Things Journal","","","10.1109/JIOT.2023.3296135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165422366&doi=10.1109%2fJIOT.2023.3296135&partnerID=40&md5=a1a5b68bb84d4d7f2f995ee4162f387d","LoRa is a promising choice for deploying an IoT network due to its lightweight feature and the extensive support by LoRa Alliance. However, as a fundamental part of LoRa, the typical LoRaWAN protocol confronts severe security challenges because it insecurely utilizes AES-128 to support the low-cost feature. In this article, we propose a systematic solution that is compatible with LoRaWAN for IoT applications. We extend the standard LoRaWAN protocol with public-key infrastructures. Public-key features like key exchange and authentication are supported by lightweight hardware implementations of SHA-2, ECDH, EdDSA, and TRNG. A lightweight RISC-V processor with a security coprocessor is implemented and verified using FPGA technology. The security protocol and the prototype hardware system are validated and evaluated on practical applications from our industrial partner. The prototyped development board consumes a static power of 0.116 W and a dynamic power of 0.206 W. The proposed system can achieve a $5.6\times $ - $144.7\times $ speed up and reduce memory usage by $2.4\times $ - $12.3\times $ for security computations.  © 2014 IEEE.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","3044-3055","","2","11","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Internet of things; Hardware security; Network protocols; Light-weight cryptography; Network security; Security; Internet of Things (IoT); LoRaWAN; lightweight cryptography; Lora network; LoRa network; Low-costs; Public key cryptography; Public key infrastructure; Public key systems; public-key cryptography; RISC-V; Security challenges; Software prototyping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VFXKY44Y","conferencePaper","2017","Oh, S.-R.; Kim, Y.-G.","Security Requirements Analysis for the IoT","","","","10.1109/PlatCon.2017.7883727","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018188263&doi=10.1109%2fPlatCon.2017.7883727&partnerID=40&md5=04fbc9d69f37da28dfd372b842596484","Due to the rapid growth of network infrastructure and sensor, the age of the IoT (internet of things) that can be implemented into the smart car, smart home, smart building, and smart city is coming. IoT is a very useful ecosystem that provides various services (e.g., amazon echo); however, at the same time, risk can be huge too. Collecting information to help people could lead serious information leakage, and if IoT is combined with critical control system (e.g., train control system), security attack would cause loss of lives. Furthermore, research on IoT security requirements is insufficient now. Therefore, this paper focuses on IoT security, and its requirements. First, we propose basic security requirements of IoT by analyzing three basic characteristics (i.e., heterogeneity, resource constraint, dynamic environment). Then, we suggest six key elements of IoT (i.e., IoT network, cloud, user, attacker, service, platform) and analyze their security issues for overall security requirements. In addition, we evaluate several IoT security requirement researches. © 2017 IEEE.","2017","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Dynamic environments; Automation; Internet of things; Cryptography; Smart city; Information leakage; Network security; Internet of Things; Intelligent buildings; Basic characteristics; Control systems; Critical control systems; Network infrastructure; Resource Constraint; Security requirements; Security Requirements; Train control systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 International Conference on Platform Technology and Service, PlatCon 2017 - Proceedings","","","","","","","","","","","","","","",""
"GCDUHK6K","journalArticle","2024","Thalor, M.; Gharat, Y.","A proposed healthcare architecture using cloud computing in WSN environment with a case study","Int. J. Integr. Sci. Technol.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209186722&partnerID=40&md5=846a970606f52fb6f05ce6a45e1c72ac","","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","37-44","","1","2","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GEM4PWHK","journalArticle","2024","Narasimha Swamy, S.; Anna, D.M.; Vijayalakshmi, M.N.; Kota, S.R.","Enabling Lightweight Device Authentication in Message Queuing Telemetry Transport Protocol","IEEE Internet of Things Journal","","","10.1109/JIOT.2024.3349394","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182377899&doi=10.1109%2fJIOT.2024.3349394&partnerID=40&md5=913a5583e27655ab9a18464227f97b78","Recent advancements in Internet of Things (IoT) have led to emergence of fascinating breakthroughs in diverse applications. Nowadays, the use cases of smart home systems are augmenting as they provide functionalities like real-time monitoring and high degree of remote control. Message queuing telemetry transport (MQTT) protocol is one of the most widely used messaging protocols in IoT-based applications including smart homes. This protocol lacks required security features owing to which, the intruders can launch variety of attacks easily. Stirred by this, we proposed a lightweight device authentication scheme for MQTT protocol. In this work, publisher/subscriber, and broker use lightweight cryptographic operations to enable device authentication. Also, this mechanism utilizes the lightweight cryptographic keys, such as one-time key (mathbf {mathrm {OT}}_{mathbf {mathrm {Key}}}) and Tokens ({T}_{i}) to complete registration and authentication process, respectively. Compared to other protocols, our approach reduces both communication and computation costs while maintaining the security demands. We put a prototype into practice to assess the performance of the proposed authentication mechanism. Further, we perform the formal analysis of the proposed authentication mechanism using automated validation of Internet security protocols and application protocol analyzer tool. The proposed security mechanism is resistant to various attacks, such as replay attack, device impersonate attack, malicious node attack, etc., and it enables the security features like device authentication and device anonymity in smart homes. © 2014 IEEE.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","15792-15807","","9","11","","","","","","","","","","","","","Scopus","","","","","","","","Automation; Internet of things; Real time systems; Edge computing; Security systems; Cryptography; edge computing; Industrial internet of thing; Network security; Security; Internet of Things (IoT); Authentication; Bandpass filters; Cuckoo filter; Cuckoo filters; device authentication; Device authentications; Intelligent buildings; IoT; message queuing telemetry transport (MQTT); MQTT; Remote control; security; smart homes; Smart homes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKDXH4EE","journalArticle","2022","Jabbar, W.A.; Subramaniam, T.; Ong, A.E.; Shu'Ib, M.I.; Wu, W.; de Oliveira, M.A.","LoRaWAN-Based IoT System Implementation for Long-Range Outdoor Air Quality Monitoring","Internet of Things (Netherlands)","","","10.1016/j.iot.2022.100540","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129939051&doi=10.1016%2fj.iot.2022.100540&partnerID=40&md5=366f1114414f8d20dea2c956c9bc7be1","This study proposes a smart long-range (LoRa) sensing node to timely collect the air quality information and update it on the cloud. The developed long-range wide area network (LoRaWAN)-based Internet of Things (IoT) air quality monitoring system (AQMS), hereafter called LoRaWAN-IoT-AQMS, was deployed in an outdoor environment to validate its reliability and effectiveness. The system is composed of multiple sensors (NO2, SO2, CO2, CO, PM2.5, temperature, and humidity), Arduino microcontroller, LoRa shield, LoRaWAN gateway, and The Thing Network (TTN) IoT platform. The LoRaWAN-IoT-AQMS is a standalone system powered continuously by a rechargeable battery with a photovoltaic solar panel via a solar charger shield for sustainable operation. Our system simultaneously gathers the considered air quality information by using the smart sensing unit. Then, the system transmits the information through the gateway to the TTN platform, which is integrated with the ThingSpeak IoT server. This action updates the collected data and displays these data on a developed Web-based dashboard and a Graphical User Interface (GUI) that uses the Virtuino mobile application. Thus, the displayed information can be easily accessed by users via their smartphones. The results obtained by the developed LoRaWAN-IoT-AQMS are validated by comparing them with experimental results based on the high-technology Aeroqual air quality monitoring devices. Our system can reliably monitor various air quality indicators and efficiently transmit the information in real time over the Internet. © 2022","2022","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","19","","","","","","","","","","","","","Scopus","","","","","","","","Air quality monitoring; Iot lora lorawan; TTN ThingSpeak Virtuino","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"34EHD8JH","conferencePaper","2021","Schmidt, D.; Tagliaro, C.; Borgolte, K.; Lindorfer, M.","IoTFlow: Inferring IoT Device Behavior at Scale through Static Mobile Companion App Analysis","","","","10.1145/3576915.3623211","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179840428&doi=10.1145%2f3576915.3623211&partnerID=40&md5=c0df5839671bd44f1ee55a5913117d99","The number of “smart” devices, that is, devices making up the Internet of Things (IoT), is steadily growing. They suffer from vulnerabilities just as other software and hardware. Automated analysis techniques can detect and address weaknesses before attackers can misuse them. Applying existing techniques or developing new approaches that are sufficiently general is challenging though. Contrary to other platforms, the IoT ecosystem features various software and hardware architectures. We introduce IoTFlow, a new static analysis approach for IoT devices that leverages their mobile companion apps to address the diversity and scalability challenges. IoTFlow combines Value Set Analysis (VSA) with more general data-flow analysis to automatically reconstruct and derive how companion apps communicate with IoT devices and remote cloud-based backends, what data they receive or send, and with whom they share it. To foster future work and reproducibility, our IoTFlow implementation is open source. We analyze 9,889 manually verified companion apps with IoTFlow to understand and characterize the current state of security and privacy in the IoT ecosystem, which also demonstrates the utility of IoTFlow. We compare how these IoT apps differ from 947 popular general-purpose apps in their local network communication, the protocols they use, and who they communicate with. Moreover, we investigate how the results of IoTFlow compare to dynamic analysis, with manual and automated interaction, of 13 IoT devices when paired and used with their companion apps. Overall, utilizing IoTFlow, we discover various IoT security and privacy issues, such as abandoned domains, hard-coded credentials, expired certificates, and sensitive personal information being shared. © 2023 Copyright held by the owner/author(s).","2021","2025-10-22 19:07:34","2025-10-22 19:07:34","","681-695","","","","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Data flow analysis; New approaches; Internet of things; Static analysis; Network security; Internet of Things (IoT); Analysis techniques; Automated analysis; Companion app; companion apps; Ecosystems; Hardware architecture; Internet of thing; Internet of thing privacy; Internet of thing security; IoT privacy; IoT security; network analysis; Sensitive data; Smart devices; Software and hardwares; static analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CCS 2023 - Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security","","","","","","","","","","","","","","",""
"NG3D2PZT","journalArticle","2022","Spadaccino, P.; Crinó, F.G.; Cuomo, F.","LoRaWAN Behaviour Analysis through Dataset Traffic Investigation","Sensors","","","10.3390/s22072470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126743315&doi=10.3390%2fs22072470&partnerID=40&md5=055edd64e974fa99a91d55501f5df5fb","The large development of Internet of Things technologies is increasing the use of smart-devices to solve and support several real-life issues. In many cases, the aim is to move toward systems that, even if significant demands are not required in terms of quantity of exchanged data, they should be very reliable in terms of battery life and signal coverage. Networks that have these characteristics are the Low Power WAN (LPWAN). One of the most interesting LPWAN is LoRaWAN. LoRaWAN is a network with four principal components: end-devices, gateways, network servers, and application servers. It uses a LoRa physical layer to exchange messages between end-devices and gateways that forward these messages, through classic TCP/IP protocol, to the network server. In this work, we analyse LoRa and LoRaWAN by looking at its transmission characteristics and network behaviour, respectively, explaining the role of its components and showing the message exchange. This analysis is performed through the exploration of a dataset taken from the literature collecting real LoRaWAN packets. The goal of the work is twofold: (1) to investigate, under different perspectives, how a LoRaWAN works and (2) to provide software tools that can be used in several other LoraWAN datasets to measure the network behaviour. We carry out six different analyses to look at the most important features of LoRaWAN. For each analysis we present the adopted measurement strategy as well as the obtained results in the specific use case. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2022","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","7","22","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Gateways (computer networks); Low power electronics; Software; Network layers; LoRaWAN; Behavior analysis; Electric Power Supplies; End-devices; Internet of things technologies; LoRA; Low Power; Low power WAN; LPWAN; Network behaviors; Network server; Performances analysis; power supply; software","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZ76CM6I","journalArticle","2024","Michelena, Á.; Aveleira-Mata, J.; Jove, E.; Bayón-Gutiérrez, M.; Novais, P.; Romero, O.F.; Calvo-Rolle, J.L.; Aláiz-Moretón, H.","A novel intelligent approach for man-in-the-middle attacks detection over internet of things environments based on message queuing telemetry transport","Expert Systems","","","10.1111/exsy.13263","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149345425&doi=10.1111%2fexsy.13263&partnerID=40&md5=cd711e3c7af302116f0021d935dca1b9","One of the most common attacks is man-in-the-middle (MitM) which, due to its complex behaviour, is difficult to detect by traditional cyber-attack detection systems. MitM attacks on internet of things systems take advantage of special features of the protocols and cause system disruptions, making them invisible to legitimate elements. In this work, an intrusion detection system (IDS), where intelligent models can be deployed, is the approach to detect this type of attack considering network alterations. Therefore, this paper presents a novel method to develop the intelligent model used by the IDS, being this method based on a hybrid process. The first stage of the process implements a feature extraction method, while the second one applies different supervised classification techniques, both over a message queuing telemetry transport (MQTT) dataset compiled by authors in previous works. The contribution shows excellent performance for any compared classification methods. Likewise, the best results are obtained using the method with the highest computational cost. Thanks to this, a functional IDS will be able to prevent MQTT attacks. © 2023 The Authors. Expert Systems published by John Wiley & Sons Ltd.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","2","41","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Classification (of information); Network security; Cyber security; cybersecurity; Cybersecurity; artificial neural networks; Attack detection; Computer crime; decision trees; Decision trees; Intelligent models; Intrusion detection; intrusion detection system; Intrusion Detection Systems; K-near-neighbor; K-nearest-neighbours; Man in the middle; man-in-the-middle; message queuing telemetry transport; Message queuing telemetry transport; Nearest neighbor search; Nearest-neighbour; Neural networks; principal component analysis; Principal component analysis; Principal-component analysis; random forest; Random forests","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F9WTNWI8","journalArticle","2017","Chang, K.-T.","Geographic information system","Geographic Information System","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030028858&partnerID=40&md5=a3a85241c51a0994d7a81cd5c09d61fa","","2017","2025-10-22 19:07:34","2025-10-22 19:07:34","","1-9","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4Q547J2","journalArticle","2019","Polonelli, T.; Brunelli, D.; Marzocchi, A.; Benini, L.","Slotted ALOHA on LoRaWAN-design, analysis, and deployment","Sensors (Switzerland)","","","10.3390/s19040838","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061858181&doi=10.3390%2fs19040838&partnerID=40&md5=aa88ce4e8e482f3864bdf5559278497f","LoRaWAN is one of the most promising standards for long-range sensing applications. However, the high number of end devices expected in at-scale deployment, combined with the absence of an effective synchronization scheme, challenge the scalability of this standard. In this paper, we present an approach to increase network throughput through a Slotted-ALOHA overlay on LoRaWAN networks. To increase the single channel capacity, we propose to regulate the communication of LoRaWAN networks using a Slotted-ALOHA variant on the top of the Pure-ALOHA approach used by the standard; thus, no modification in pre-existing libraries is necessary. Our method is based on an innovative synchronization service that is suitable for low-cost wireless sensor nodes. We modelled the LoRaWAN channel with extensive measurement on hardware platforms, and we quantified the impact of tuning parameters on physical and medium access control layers, as well as the packet collision rate. Results show that Slotted-ALOHA supported by our synchronization service significantly improves the performance of traditional LoRaWAN networks regarding packet loss rate and network throughput. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","2019","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","4","19","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Low power electronics; Wireless sensor networks; Packet networks; ALOHA; Information services; Internet of Things; Long range radio; LoRa; LoRaWAN; Low-energy wireless protocols; Medium access control; Sensor nodes; Slotted Aloha; Slotted ALOHA; Synchronization; Wireless protocol","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"THVJ5WDM","conferencePaper","2024","Kotenko, I.; Levshun, D.","Anomaly Detection in IoT Networks Based on Intelligent Security Event Correlation","","","","10.1109/COMSNETS59351.2024.10426939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186714164&doi=10.1109%2fCOMSNETS59351.2024.10426939&partnerID=40&md5=749d50da3bc3aa8bb0b08a2e883ed550","Modern Internet of Things networks combine many devices and sensors that transmit and process large amounts of data. Security tools identify security events that contain information about detected system or network states. In turn, high-performance data anomaly detection methods are required to ensure stability and reliability of work processes. Information about the correlation of identified security events can be used to detect and explain deviations from normal states. This study proposes an anomaly detection approach based on the causal correlation of security events using machine learning. The proposed approach does not require prior knowledge of event scenarios. Using cluster analysis and a convolutional recurrent neural network, we construct a security state correlation graph corresponding to the normal behavior of the system. Cluster analysis determines the similarity of events to each other. A convolutional LSTM, analyzes the spatio-temporal relationship of events. Using the identified event correlation thresholds, we look for anomalies in real time. Experimental results on an Internet of Things sensor dataset show that the proposed method is efficient in anomaly detection tasks.  © 2024 IEEE.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","816-824","","","","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Convolutional neural networks; Network security; anomaly detection; Anomaly detection; Cluster analysis; Convolution; Cyber security; cybersecurity; Cybersecurity; event correlation; Event correlation; Intelligent security; Large amounts of data; Long short-term memory; machine learning; Machine-learning; Network-based; Security events; Security tools; System state","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2024 16th International Conference on COMmunication Systems and NETworkS, COMSNETS 2024","","","","","","","","","","","","","","",""
"5D26CDMA","journalArticle","2023","Velichkovska, B.; Cholakoska, A.; Atanasovski, V.","Machine Learning Based Classification of IoT Traffic","Radioengineering","","","10.13164/re.2023.0256","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160644768&doi=10.13164%2fre.2023.0256&partnerID=40&md5=94cb84a2106208008cfc8c5a82fa000b","With the rapid expansion and widespread adoption of the Internet of Things (IoT), maintaining secure connections among active devices can be challenging. Since IoT devices are limited in power and storage, they cannot performcomplex tasks, which makes them vulnerable to different types of attacks. Given the volume of data generated daily, detecting anomalous behavior can be demanding. However, machine learning (ML) algorithms have proven successful in extracting complex patterns from big data, which has led to active applications in IoT. In this paper, we perform a comprehensive analysis, including 4 ML algorithms and 3 neural networks (NNs), and propose a pipeline which analyzes the influence data reduction (loss) has on the performance of these algorithms. We use random undersampling as a data reduction technique, which simulates reduced network traffic data. The pipeline investigates several degrees of data loss. The results show that models trained on the original data distribution obtain accuracy that verges on 100%. XGBoost performs best from the classic ML algorithms. From the deep learning models, the 2-layered NN provides excellent results and has sufficient depth for practical application. On the other hand, when the models are trained on the undersampled data, there is a decrease in performance, most notably in the case of NNs. The most prominent change is seen in the 4-layered NN, where the model trained on the original dataset detects attacks with a success of 93.53%, whereas the model trained on the maximally reduced data has a success of only 39.39%. © 2023, Radioengineering. All Rights Reserved.","2023","2025-10-22 19:07:34","2025-10-22 19:07:34","","256-263","","2","32","","","","","","","","","","","","","Scopus","","","","","","","","deep learning; Machine learning; Internet of Things (IoT); intrusion detection; traffic modelling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B57D4LTJ","journalArticle","2024","Soler, D.; Cillero, I.; Dafonte, C.; Fernández-Veiga, M.; Vilas, A.F.; Nóvoa, F.J.","QKDNetSim+: Improvement of the quantum network simulator for NS-3","SoftwareX","","","10.1016/j.softx.2024.101685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188569139&doi=10.1016%2fj.softx.2024.101685&partnerID=40&md5=21ea72e8c89919c1bb700302b664bb94","The first Quantum Key Distribution (QKD) networks are currently being deployed, but the implementation cost is still prohibitive for most researchers. As such, there is a need for realistic QKD network simulators. The QKDNetSim module for the network simulator NS-3 focuses on the representation of packets and the management of key material in a QKD network at the application layer. Although QKDNetSim's representation of a QKD network is insightful, some its components lack the depth that would allow the simulator to faithfully represent the behaviour of a real quantum network. In this work, we analyse QKDNetSim's architecture to identify its limitations, and we present an enhanced version of QKDNetSim in which some of its components have been modified to provide a more realistic simulation environment. © 2024 The Author(s)","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","26","","","","","","","","","","","","","Scopus","","","","","","","","Application layers; Implementation cost; Key materials; Network layers; Network simulation; Network simulators; NS-3; QKD; Quantum communication; Quantum communications; Quantum cryptography; Quantum network; Realistic simulation; Simulation environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EKXQMY3","journalArticle","2024","Ershadi, F.; Nazari, M.; Chegenie, M.S.","Native speakerism as a source of agency-related critical incidents: Implications for non-native English teachers’ professional identity construction","System","","","10.1016/j.system.2023.103182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549523&doi=10.1016%2fj.system.2023.103182&partnerID=40&md5=539081115f841d305f56f8703b1c6c4d","Despite the developments on the contributions of native speakerism (NS) for the professionalism of non-native English-speaking teachers (NNESTs), little is known about how NS influences NNESTs' agency and identity construction. The present study draws on an ecological-poststructural lens and explores such a contribution through critical incidents that happened to 15 Iranian NNESTs. Data were collected from a questionnaire, narrative frames, and semi-structured interviews. The analysis of the data revealed three major themes: (1) native speakerism as a source of NNEST marginalization, (2) the role of school policymakers in NS-induced inequality, and (3) native speakerism as a source of pedagogy of doubt. The findings showed that NS not only serves as a discourse that transcends geographical borders to shape NNESTs' agency and identity, but institutional participants also add to the negative effects of NS on NNESTs' professional practice. The study concludes with implications for institutional policymakers and teacher educators to revisit their understanding of NS and the ripple effects that NS bears for NNESTs’ agency and identity construction. © 2023","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","","","","120","","","","","","","","","","","","","Scopus","","","","","","","","Critical incidents; Language teacher agency; Language teacher identity; Native speakerism; NESTs; NNESTs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5IVKS4L","journalArticle","2024","Maier, L.; Jansen, D.; Wüllhorst, F.; Kremer, M.; Kümpel, A.; Blacha, T.; Müller, D.","AixLib: an open-source Modelica library for compound building energy systems from component to district level with automated quality management","Journal of Building Performance Simulation","","","10.1080/19401493.2023.2250521","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169156047&doi=10.1080%2f19401493.2023.2250521&partnerID=40&md5=f6fc2f92cffa1c62ba562454251b71e3","Open-source modelling libraries facilitate the standardization and harmonization of model development. In the context of building energy systems, Modelica is a suitable modelling language as it is equation-based and object-oriented. As an outcome of the IBPSA project 1 cooperation, four open-source modelling libraries have been successfully deployed which all share the core library Modelica IBPSA. One of them is the AixLib modelling library. AixLib supports different modelling depths ranging from component to district level and covers all relevant domains in the context of building energy systems. To ensure high-quality simulations, continuous integration has been successfully added to automatically compare simulation results with existing validation data. This paper presents AixLib's key features, scope, and associated tools. We present three use cases that highlight the broad application range of AixLib models. Furthermore, an overview of relevant research and industry projects is provided. Finally, we give an outlook on future development goals. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","196-219","","2","17","","","","","","","","","","","","","Scopus","","","","","","","","Open systems; Open-source; Industrial research; Modeling languages; building energy system; Building energy systems; Buildings; continuous integration; Continuous integrations; Equation based; Harmonisation; HVAC; Libraries; Model development; Model library; Modelica; modelling library; Object oriented; Open-source model; Quality management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DXF9N48F","journalArticle","2020","Hussain, N.A.A.; Ali, S.S.A.; Ridao, P.; Cieslak, P.; Al-Saggaf, U.M.","Implementation of Nonlinear Adaptive U-Model Control Synthesis Using a Robot Operating System for an Unmanned Underwater Vehicle","IEEE Access","","","10.1109/ACCESS.2020.3037122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097383471&doi=10.1109%2fACCESS.2020.3037122&partnerID=40&md5=04a558ce36cf433d508747a0f3909770","This paper presents the development of unmanned marine robotic control modelling and control synthesis using a coupled multivariable underactuated nonlinear adaptive U-model approach. The proposed controller was developed using thru an open source robot operating system (ROS) platform. The new adaptive coupled U-model based internal model control (IMC) node was successfully developed and tested. The proposed controller demonstrated the simplicity of the control synthesis process and the implementation of the mathematical algorithm in real-time. The controller was compared with the proven existing GIRONA 500 UUV for real-time performance. The ROS environment provides fast and reliable controller design and development compared to conventional software architecture. Simulation and real-time experiment were conducted using ROS via the GIRONA 500 UUV platform and compared with a PID mission controller. A new ROS node of nonlinear adaptive U-model based IMC was developed using ROS. The results showed good control signal convergence and tracking performance between the plant or system model with the proposed method.  © 2013 IEEE.","2020","2025-10-22 19:07:34","2025-10-22 19:07:34","","205685-205695","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Open systems; Robots; Adaptive control; Adaptive control systems; Control system synthesis; Controllers; Internal model control; Mathematical algorithms; Model predictive control; Modelling and controls; nonlinear; Real time performance; Real-time experiment; Robot operating system; Robot operating systems (ROS); ROS; Tracking performance; underactuated; Unmanned underwater vehicles; UUV","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDWJAQ3L","journalArticle","2024","Tran, K.T.M.; Pham, A.X.; Nguyen, N.P.; Dang, P.T.","Analysis and Performance Comparison of IoT Message Transfer Protocols Applying in Real Photovoltaic System","International Journal of Networked and Distributed Computing","","","10.1007/s44227-024-00021-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187241415&doi=10.1007%2fs44227-024-00021-4&partnerID=40&md5=8289764daec2eb3afded98c71b982feb","The adoption of reliable and real-time communication technology is an absolute necessity for the advancement of Internet of Things (IoT) applications. Messaging protocols such as MQTT, AMQP, and HTTP are frequently used for communication with resource-constrained IoT devices. However, choosing a suitable and effective messaging protocol presents a daunting challenge for organizations, as it depends on the specific characteristics and messaging requirements of the IoT system. Therefore, it is crucial to have a comprehensive understanding of three established messaging protocols, such as the Hypertext Transfer Protocol (HTTP), the Message Queuing Telemetry Transport (MQTT), and the Advanced Message Queuing Protocol (AMQP), to appropriately apply them in practical projects. In this paper, information technology solutions are provided for a chain of solar farms to improve harvest productivity, facilitate warning notifications, and enable remote control. Subsequently, a detailed comparative analysis is performed, considering various interconnected criteria, to gain valuable insight into the strengths and limitations of these protocols. The results show that MQTT and AMQP play a role in enhancing overall efficiency and speed within the framework of our suggested photovoltaic system. © The Author(s) 2024.","2024","2025-10-22 19:07:34","2025-10-22 19:07:34","","131-143","","1","12","","","","","","","","","","","","","Scopus","","","","","","","","Advanced Message Queuing Protocol; Hypertext Transfer Protocol; IoT Message Transfer Protocols; IoT smart agriculture; Message Queuing Telemetry Transport","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RWGTQ5B","journalArticle","2024","Mittal, V.; Gillespie, S.","Using Model-Based Systems Engineering to Avoid Unnecessary Technology Resulting from Dynamic Requirements","IEEE Transactions on Engineering Management","","","10.1109/TEM.2022.3181268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134242081&doi=10.1109%2fTEM.2022.3181268&partnerID=40&md5=fa10a876fe3e82dcc34dafaae2384691","As systems develop and evolve, operational requirements, system architecture, and technological capabilities change. These changes can result in design changes, making once necessary components unnecessary. Engineering managers are often hesitant to remove these unnecessary components though the driving requirements no longer apply. This issue, 'technology for the sake of technology,' occurs frequently when a system is the product of a long development time line, such as those implemented by the defense community. Model-based systems engineering (MBSE) enables engineering managers to identify unnecessary technology, and accurately and quickly update the design and assess risk associated with removing unnecessary technology. A proposed methodology uses MBSE products to identify and mitigate 'technology for the sake of technology'. A case study is presented of this process based on the power system for a robotic exoskeleton under development where the power draw and mission requirements changed significantly over the development life cycle. When the design team followed traditional systems engineering processes, they included many unnecessary components in the final design; however, an MBSE approach identified numerous components that were no longer necessary, resulting in a simpler and more robust design. This approach can be used to improve design quality and cost for varied systems.  © 1988-2012 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","2660-2671","","","71","","","","","","","","","","","","","Scopus","","","","","","","","Life cycle; Complexity theory; Cost engineering; Defense engineering; Exoskeleton (Robotics); Managers; Model-based system engineering; Model-based system engineerings; model-based systems engineering (MBSE); Modeling languages; Network security; Risk assessment; Security; Software; Stakeholder; System modeling language; System models; Systems engineering; technology evaluation; Technology evaluation; technology forecasting; Technology forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"67G8MPGJ","journalArticle","2024","Villegas-Ch, W.; Garcia-Ortiz, J.; Sanchez-Viteri, S.","Toward Intelligent Monitoring in IoT: AI Applications for Real-Time Analysis and Prediction","IEEE Access","","","10.1109/ACCESS.2024.3376707","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187987118&doi=10.1109%2fACCESS.2024.3376707&partnerID=40&md5=4f43ada4170ea3e3ee50930a60e2d041","In the contemporary era, the intersection of the Internet of Things and artificial intelligence revolutionizes how industries monitor and optimize their operations. In this work, we present a system that combines real-time monitoring provided by Internet of Things devices with predictive analytics based on artificial intelligence. This system detects anomalies in real-time and anticipates possible failures, allowing proactive interventions to maximize efficiency and minimize operating costs. Our findings reveal a significant improvement in the early detection of abnormal trends, as the system consistently identifies potential problems long before they become critical failures. Our evaluation employed data sets collected from controlled and industrial production environments, with more than 1 million records, including critical parameters such as temperature, humidity, and pressure. The results highlight a significant improvement in the early detection of abnormal trends, with a temperature detection accuracy of 98.7%, exceeding reference values and demonstrating the system's effectiveness in preventing critical failures. The analysis also revealed previously unrecognized operational patterns, offering opportunities for industrial process optimization. This work highlights the effective integration of the Internet of Things and artificial intelligence to improve industrial monitoring, highlighting the tangible benefits of such integration, such as the adaptability and continuous learning of the system, ensuring its long-term effectiveness. © 2013 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","40368-40386","","","12","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Internet of things; Real time systems; Artificial intelligence; Interactive computer systems; Adaptive feedback; Critical failures; Feedback; Humidity control; intelligent adaptation; Intelligent adaptation; Intelligent monitoring; IoT-based optimization; Operating costs; Optimisations; Predictive analytics; Proposal; Real - Time system; Real- time; real-time precision; Real-time precision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3YYJ7RW","journalArticle","2022","Zeeshan, M.; Riaz, Q.; Bilal, M.A.; Shahzad, M.K.; Jabeen, H.; Haider, S.A.; Rahim, A.","Protocol-Based Deep Intrusion Detection for DoS and DDoS Attacks Using UNSW-NB15 and Bot-IoT Data-Sets","IEEE Access","","","10.1109/ACCESS.2021.3137201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122069667&doi=10.1109%2fACCESS.2021.3137201&partnerID=40&md5=6258f31ba9b429aec7a1acce29008d15","Since its inception, the Internet of Things (IoT) has witnessed mushroom growth as a breakthrough technology. In a nutshell, IoT is the integration of devices and data such that processes are automated and centralized to a certain extent. IoT is revolutionizing the way business is done and is transforming society as a whole. As this technology advances further, the need to exploit detection and weakness awareness increases to prevent unauthorized access to critical resources and business functions, thereby rendering the system unavailable. Denial of Service (DoS) and Distributed DoS attacks are all too common. In this paper, we propose a Protocol Based Deep Intrusion Detection (PB-DID) architecture, in which we created a data-set of packets from IoT traffic by comparing features from the UNSWNB15 and Bot-IoT data-sets based on flow and Transmission Control Protocol (TCP). We classify non-anomalous, DoS, and DDoS traffic uniquely by taking care of the problems like imbalanced and over-fitting. We have achieved a classification accuracy of 96.3& by using deep learning (DL) technique. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","2269-2283","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Internet of things; Network architecture; Support vector machines; Network security; Security; Computer crime; Intrusion detection; Intrusion-Detection; Training; Denial-of-service attack; Personal computing; Computer hacking; DDoS detection; Deep learning for intrusion detection; Denial of Service; Denial of service detection; Intrusion detection in internet of thing; Support vectors machine; Transmission control protocol","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W4WU7JY7","conferencePaper","2023","Fares, N.Y.; Nedeljkovic, D.; Jammal, M.","AI-enabled IoT Applications: Towards a Transparent Governance Framework","","","","10.1109/GCAIoT61060.2023.10385106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184666640&doi=10.1109%2fGCAIoT61060.2023.10385106&partnerID=40&md5=9ba550cc6ea3f858cd0713d6ef72865f","Internet of Things (IoT) and Artificial Intelligence (AI) systems have become prevalent across various industries, steering to diverse and far-reaching outcomes, and their convergence has garnered significant attention in the tech world. Studies and reviews are instrumental in supplying industries with the nuanced understanding of the multifaceted developments of this joint domain. This paper undertakes a critical examination of existing perspectives and governance policies, adopting a contextual approach, and addressing not only the potential but also the limitations of these governance policies. In the complex landscape of AI-infused IoT systems, transparency and interpretability are pivotal qualities for informed decision-making and effective governance. In AI governance, transparency allows for scrutiny and accountability, while interpretability facilitates trust and confidence in AI-driven decisions. Therefore, we also evaluate and advocate for the use of two very popular eXplainable AI (XAI) techniques-SHAP and LIME-in explaining the predictive results of AI models. Subsequently, this paper underscores the imperative of not only maximizing the advantages and services derived from the incorporation of IoT and AI but also diligently minimizing possible risks and challenges.  © 2023 IEEE.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","109-114","","","","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Decision making; Smart city; IoT; AI; Informed decision; Artificial intelligence systems; Decisions makings; Ethical regulation; Ethical Regulations; Ethical technology; Explainable AI; Explainable artificial intelligence; Governance; Intelligence models; Interpretability; Lime; Smart Cities; Transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2023 IEEE Global Conference on Artificial Intelligence and Internet of Things, GCAIoT 2023","","","","","","","","","","","","","","",""
"568MTQ5W","journalArticle","2024","Kathole, A.B.; Vhatkar, K.N.; Patil, S.D.","IoT-Enabled Pest Identification and Classification with New Meta-Heuristic-Based Deep Learning Framework","Cybernetics and Systems","","","10.1080/01969722.2022.2122001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139129575&doi=10.1080%2f01969722.2022.2122001&partnerID=40&md5=f310e17e409691477564f622323f5c31","The pest and insect affected crop is an important concern to cause damage to the agricultural sector. While identifying the pest in the crop, the camera placement is not supported in an inconsistent manner to capture the pest images. Hence, certain Internet of Things (IoT) devices are used to catch the pest images with its corresponding agriculture based sensor, yet it also faces some limitations to provide the accurate results. In order to alleviate the problem, an IoT-assisted pest identification and classification method is proposed. Initially, the IoT sensors are used to collect the required images. Subsequently, the input images are used to perform the object detection phase that is accomplished by the Yolov3, where the pest is detected significantly. Further, the detected images are fed into the model of “Convolutional Neural Network (CNN),” in which the deep features are fetched and finally given as input to the classifier model of “Convolution Neural Long Short-Term Memory (CNLSTM),” in turn some hyper parameters are optimally tuned by “Adaptive Honey Badger Algorithm (AHBA).” Hence, the experimental results prove that the recommended method achieves the better performance in terms of diverse metrics. © 2022 Taylor & Francis Group, LLC.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","380-408","","2","55","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Convolutional neural networks; Convolution; Long short-term memory; internet of things; Metaheuristic; Object detection; Agriculture systems; Smart agricultures; Brain; Adaptive honey badger algorithm; Agricultural sector; agriculture; convolution neural long short-term memory; Convolution neural long short-term memory; Crops; Food products; Learning frameworks; pest identification and classification; Pest identification and classification; Pests images; smart agriculture system; Smart agriculture system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWT962M8","journalArticle","2023","Elsayed, R.; Hamada, R.; Hammoudeh, M.; Abdalla, M.; Elsaid, S.A.","A Hierarchical Deep Learning-Based Intrusion Detection Architecture for Clustered Internet of Things","Journal of Sensor and Actuator Networks","","","10.3390/jsan12010003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148581471&doi=10.3390%2fjsan12010003&partnerID=40&md5=1c89ac6cd0f22f31adc9ef8e5c29bd4b","The Internet of Things (IoT) system’s ever-expanding attack surface calls for a new intrusion detection system (IDS). These systems may include thousands of wireless devices that need to be protected from cyberattacks. Recent research efforts used machine learning to analyze and identify various attacks and abnormal behavior on IoT systems. Most of these techniques are characterized by low accuracy and they do not scale to today’s IoT-enabled smart cities applications. This article proposes a secure automatic two-levels intrusion detection system (SATIDS) which utilizes the minimum redundancy maximum relevance (MRMR) feature selection technique and an enhanced version of long short-term memory (LSTM) based on an artificial recurrent neural network (RNN) to enhance the IDS performance. SATIDS aims at detecting traffic anomalies with greater accuracy while also reducing the time it takes to perform this task. The proposed algorithm was trained and evaluated using two of the most recent datasets based on realistic data: ToN-IoT and InSDN datasets. The performance analysis of the proposed system proves that it can differentiate between attacks and normal traffic, identify the attack category, and finally define the type of sub-attack with high accuracy. Comparing the performance of the proposed system with the existing IDSs reveals that it outperforms its best rivals from the literature in detecting many types of attacks. It improves accuracy, detection rates, F1-score, and precision. Using 500 hidden and two LSTM layers achieves accuracy of 97.5%, precision of 98.4%, detection rate of 97.9%, and F1-score of 98.05% on ToN-IoT dataset, and precision of 99%, detection rate of 99.6%, and F1-score of 99.3% on InSDN dataset. Finally, SATIDS was applied to an IoT network which utilizes the energy harvesting real-time routing protocol (EHRT). EHRT optimizes the low-energy adaptive clustering hierarchy (LEACH) routing technique using a modified artificial fish swarm algorithm. The integration between the optimized LEACH and the proposed IDS enhances the network lifetime, energy consumption, and security. © 2022 by the authors.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","1","12","","","","","","","","","","","","","Scopus","","","","","","","","internet of things (IoT); artificial fish swarm algorithm (AFSA); deep learning (DL); energy harvesting real-time routing protocol (EHRT); InSDN dataset; intrusion detection system (IDS); long short-term memory (LSTM); low-energy adaptive clustering hierarchy (LEACH); ToN-IoT dataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RUTHA3XA","journalArticle","2022","Kumar, P.; Bagga, H.; Netam, B.S.; Uduthalapally, V.","SAD-IoT: Security Analysis of DDoS Attacks in IoT Networks","Wireless Personal Communications","","","10.1007/s11277-021-08890-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113386313&doi=10.1007%2fs11277-021-08890-6&partnerID=40&md5=73856522d14209936c3a84befb26646c","Internet of Things is one of the most versatile technologies in existence today. It has taken over our day to day activities and thus has many applications that are designed to make life easier and simpler. Partly because IoT is new, it is replete with insecurities and vulnerabilities. Due to the lack of fundamental security controls, and the integration of real-world objects with the Internet, IoT devices are facile targets for cyber-criminals and other aggressors. This means that these vulnerabilities can be exploited for hacking, adding to Botnets, and then used to launch DoS and DDoS against organizations. To provide security from DoS and DDoS attacks, various solutions have been proposed. In this paper, Machine Learning, as well as Deep Learning algorithms, have been employed to analyze the DoS and DDoS attacks. The Bot-IoT dataset of the Centre of UNSW Canberra Cyber was used for training purposes. ARGUS software was used to generate the features from the pcap files of UNSW. A testbed was setup using 20 devices and generated dataset. From the result, the best accuracy of attack classification is 99.5% and 99.9% for Deep Learning and Machine Learning algorithms respectively. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","87-108","","1","122","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Internet of things; Learning algorithms; Learning systems; Machine Learning; Network security; Internet of Things (IoT); Attack detection; Deep Learning; Attack classifications; Cyber criminals; DDoS Attack; DDoS attacks; Denial-of-service attack; IOT networks; Keras; Personal computing; Real-world objects; Security analysis; Security controls; Training purpose","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62BKKI5W","journalArticle","2021","Marini, R.; Mikhaylov, K.; Pasolini, G.; Buratti, C.","Lorawansim: A flexible simulator for lorawan networks","Sensors (Switzerland)","","","10.3390/s21030695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099686108&doi=10.3390%2fs21030695&partnerID=40&md5=328f8edd64e3ddb7bcd452373bd26244","Among the low power wide area network communication protocols for large scale Internet of Things, LoRaWAN is considered one of the most promising, owing to its flexibility and energy-saving capabilities. For these reasons, during recent years, the scientific community has invested efforts into assessing the fundamental performance limits and understanding the trade-offs between the parameters and performance of LoRaWAN communication for different application scenarios. However, this task cannot be effectively accomplished utilizing only analytical methods, and precise network simulators are needed. To that end, this paper presents LoRaWANSim, a LoRaWAN simulator implemented in MATLAB, developed to characterize the behavior of LoRaWAN networks, accounting for physical, medium access control and network aspects. In particular, since many simulators described in the literature are deployed for specific research purposes, they are usually oversimplified and hold a number of assumptions affecting the accuracy of their results. In contrast, our simulator has been developed for the sake of completeness and it is oriented towards an accurate representation of the LoRaWAN at the different layers. After a detailed description of the simulator, we report a validation of the simulator itself and we then conclude by presenting some results of its use revealing notable and non-intuitive trade-offs present in LoRaWAN. Assuming the acceptance of the paper, the simulator will be made available via open access to the research community. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","1-19","","3","21","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Internet of things; Economic and social effects; Application scenario; Energy conservation; Low power electronics; Commerce; Network simulators; LoRa; LoRaWAN; Medium access control; LPWAN; Wide area networks; Research communities; Simulation; Simulators; Analysis; Flexible simulators; Fundamental performance limits; Large scale Internet; MATLAB; Model; Network simulator; Scientific community; Wide area network communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VS8DDH4D","journalArticle","2024","Song, J.; Lee, S.; Karagiannis, D.; Lee, M.","Process Algebraic Approach for Probabilistic Verification of Safety and Security Requirements of Smart IoT (Internet of Things) Systems in Digital Twin","Sensors","","","10.3390/s24030767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184721934&doi=10.3390%2fs24030767&partnerID=40&md5=0b65e14254f9d2551d3af9b531797b33","Process algebra can be considered one of the most practical formal methods for modeling Smart IoT Systems in Digital Twin, since each IoT device in the systems can be considered as a process. Further, some of the algebras are applied to predict the behavior of the systems. For example, PALOMA (Process Algebra for Located Markovian Agents) and PACSR (Probabilistic Algebra of Communicating Shared Resources) process algebras are designed to predict the behavior of IoT Systems with probability on choice operations. However, there is a lack of analytical methods in the algebras to predict the nondeterministic behavior of the systems. Further, there is no control mechanism to handle undesirable nondeterministic behavior of the systems. In order to overcome these limitations, this paper proposes a new process algebra, called dTP-Calculus, which can be used (1) to specify the nondeterministic behavior of the systems with static probability, (2) verify the safety and security requirements of the nondeterministic behavior with probability requirements, and (3) control undesirable nondeterministic behavior with dynamic probability. To demonstrate the feasibility and practicality of the approach, the SAVE (Specification, Analysis, Verification, Evaluation) tool has been developed on the ADOxx Meta-Modeling Platform and applied to a SEMS (Smart Emergency Medical Service) example. In addition, a miniature digital twin system for the SEMS example was constructed and applied to the SAVE tool as a proof of concept for Digital Twin. It shows that the approach with dTP-Calculus on the tool can be very efficient and effective for Smart IoT Systems in Digital Twin. © 2024 by the authors.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","3","24","","","","","","","","","","","","","Scopus","","","","","","","","Forecasting; Internet of things; Safety and securities; Cryptography; article; Security requirements; internet of things; digital twin; ADOxx; Algebra; Analysis verification; analytic method; dTP-Calculus; DTP-calculus; emergency health service; Emergency services; female; formal method; Formal methods; mathematics; Nondeterministic behavior; probability; process algebra; Process algebras; proof of concept; safety; Safety requirements; SAVE; Smart internet of thing; smart IoT; Specification, analyse, verification, evaluation; stone formation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KCXTBG35","journalArticle","2023","Ziyatbekova, G.Z.; Aralbayev, S.U.; Kisala, P.P.","Security issues of containerization of microservices","KazUTB","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209185143&partnerID=40&md5=366014530dfcca3a276d4d9e2bd5c0ca","","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","1-7","","21","4","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RK4WITQL","journalArticle","2022","Algarni, A.; Thayananthan, V.","Autonomous Vehicles: The Cybersecurity Vulnerabilities and Countermeasures for Big Data Communication","Symmetry","","","10.3390/sym14122494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144844081&doi=10.3390%2fsym14122494&partnerID=40&md5=0b036f761e47e0f743af617148645521","The possible applications of communication based on big data have steadily increased in several industries, such as the autonomous vehicle industry, with a corresponding increase in security challenges, including cybersecurity vulnerabilities (CVs). The cybersecurity-related symmetry of big data communication systems used in autonomous vehicles may raise more vulnerabilities in the data communication process between these vehicles and IoT devices. The data involved in the CVs may be encrypted using an asymmetric and symmetric algorithm. Autonomous vehicles with proactive cybersecurity solutions, power-based cyberattacks, and dynamic countermeasures are the modern issues/developments with emerging technology and evolving attacks. Research on big data has been primarily focused on mitigating CVs and minimizing big data breaches using appropriate countermeasures known as security solutions. In the future, CVs in data communication between autonomous vehicles (DCAV), the weaknesses of autonomous vehicular networks (AVN), and cyber threats to network functions form the primary security issues in big data communication, AVN, and DCAV. Therefore, efficient countermeasure models and security algorithms are required to minimize CVs and data breaches. As a technique, policies and rules of CVs with proxy and demilitarized zone (DMZ) servers were combined to enhance the efficiency of the countermeasure. In this study, we propose an information security approach that depends on the increasing energy levels of attacks and CVs by identifying the energy levels of each attack. To show the results of the performance of our proposed countermeasure, CV and energy consumption are compared with different attacks. Thus, the countermeasures can secure big data communication and DCAV using security algorithms related to cybersecurity and effectively prevent CVs and big data breaches during data communication. © 2022 by the authors.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","12","14","","","","","","","","","","","","","Scopus","","","","","","","","autonomous vehicles; cybersecurity vulnerabilities; security solutions; vehicular communications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4T2NEQ86","journalArticle","2024","Mishra, M.; Reddy, S.R.N.","Performance assessment and comparison of lightweight D2D-IoT communication protocols over resource constraint environment","Multimedia Tools and Applications","","","10.1007/s11042-024-18132-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183125753&doi=10.1007%2fs11042-024-18132-z&partnerID=40&md5=c4e18db4d2cdfa9b5c8ad835bdef5f54","The Internet of Things (IoT) based smart strategies are often resource constrained with respect to energy, computation and memory. Outdated communication protocols are inappropriate for IoT ecosystem because of large overhead, lack of Quality of Service (QoS) and increased complexity. As billions of devices are required to be deployed over diverse applications, the IoT communication system acts as a prominent aspect and so the selection of suitable IoT communication protocol is highly essential. Also, there is a greater need of analysing the protocol behaviour under diverse network conditions. Hence to select a suitable protocol by addressing the limitations, this research paper mainly focuses on comparing lightweight application layer protocols, including Message Queuing Telemetry Transport (MQTT), Constrained Application Protocol (CoAP) and MQTT for sensor Network (MQTTSN). Evaluating the performance of protocol libraries in real environment is highly significant because it helps to discover potential interoperability and compatibility challenges. Also, it can reveal the protocol’s ability in handling scalability and its support in dealing a number of devices efficiently. A testbed named “ProtoLab” has been created for evaluating the performances of CoAP, MQTT and MQTTSN protocols under variable network condition. Using the testbed, the client and server can exchange the data packets under the variable network condition created with the help of network emulator. The data packets can be received and exported using the wireshark application to create a dataset for analysis. Different parameters like round trip time, duplication, round trip reliability, server response time, reliability towards the client to server and client overhead are analysed by configuring loss, corruption, reordering and network delay in the network emulator using wide area network emulator (WANEM) to evaluate the performance of IoT communication protocols. Variable network conditions are considered and analysed using real-time ProtoLab testbed by varying the parameters. The results and observations analyzed through this research can support IoT application developers in making informed decisions while selecting communication protocols for different applications. On analysing the parameters under diverse network conditions, the MQTTSN protocol performs comparatively better in terms of resource efficient delivery in constrained environment. Meanwhile, the MQTT protocol is analysed to be better when concerned with reliability. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","67569-67598","","26","83","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Application protocols; Internet protocols; Performance; Internet of things; Quality-of-service; Sensor networks; Message Queuing Telemetry Transport; Message queuing telemetry transport; Resource Constraint; Wide area networks; Testbeds; Reliability; Network condition; Telemetering equipment; Communications protocols; Constrained application protocol resource constraint; Network emulators; Protocol stack; Quality of Service","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6A27IDL","journalArticle","2022","Naqvi, M.R.; Iqbal, M.W.; Ashraf, M.U.; Ahmad, S.; Soliman, A.T.; Khurram, S.; Shafiq, M.; Choi, J.-G.","Ontology driven testing strategies for IoT applications","Computers, Materials and Continua","","","10.32604/cmc.2022.019188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117021689&doi=10.32604%2fcmc.2022.019188&partnerID=40&md5=fdda5a9bcae6305ad586e8700f61aff5","Internet-of-Things (IoT) has attained a major share in embedded software development. The new era of specialized intelligent systems requires adaptation of customized software engineering approaches. Currently, software engineering has merged the development phases with the technologies provided by industrial automation. The improvements are still required in testing phase for the software developed to IoT solutions. This research aims to assist in developing the testing strategies for IoT applications, therein ontology has been adopted as a knowledge representation technique to different software engineering processes. The proposed ontological model renders 101 methodology by using Protégé. After completion, the ontology was evaluated in three-dimensional view by the domain experts of software testing, IoT and ontology engineering. Satisfied results of the research are showed in interest of the specialists regarding proposed ontology development and suggestions for improvements. The Proposed reasoning-based ontological model for development of testing strategies in IoT application contributes to increase the general understanding of tests in addition to assisting for the development of testing strategies for different IoT devices. © 2022 Tech Science Press. All rights reserved.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","5855-5869","","3","70","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Automation; Internet of things; Software design; Software testing; Planning; Intelligent systems; Customized software; Development phasis; Embedded software development; Industrial automation; Knowledge representation; Knowledge-representation; Ontological modeling; Ontology; Ontology's; Software testings; Testing phase; Testing strategies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHWEBDRH","journalArticle","2020","Sanjuan, E.B.; Cardiel, I.A.; Cerrada, J.A.; Cerrada, C.","Message Queuing Telemetry Transport (MQTT) Security: A Cryptographic Smart Card Approach","IEEE Access","","","10.1109/ACCESS.2020.3003998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087834582&doi=10.1109%2fACCESS.2020.3003998&partnerID=40&md5=d349786d7ad7e3cd153b3d7a3868e484","The Message Queuing Telemetry Transport (MQTT) protocol is one of the most extended protocols on the Internet of Things (IoT). However, this protocol does not implement a strong security scheme by default, which does not allow a secure authentication mechanism between participants in the communication. Furthermore, we cannot trust the confidentiality and integrity of data. Lightweight IoT devices send more and more sensible data in areas of Smart Building, Smart City, Smart House, Smart Car, Connected Car, Health Care, Smart Retail, Industrial IoT (IIoT), etc. This makes the security challenges in the protocols used in the IoT particularly important. The standard of MQTT protocol strongly recommends implement it over Transport Layer Security (TLS) instead of plain TCP. Nonetheless, this option is not possible in most lightweight devices that make up the IoT ecosystem. Quite often, the constrained resources of IoT devices prevent the use of secure asymmetric cryptography algorithms implemented by themselves. In this article, we propose making a security schema in MQTT protocol using Cryptographic Smart Cards, for both challenges, the authentication schema and the trusted data confidentiality and data integrity. We carry out this security schema without modifying the standard protocol messages. And finally, we present a time results experiment using an example implementation model with JavaCard library. © 2013 IEEE.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","115051-115062","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Cryptography; Hardware security; Network security; Internet of Things (IoT); Authentication; message queuing telemetry transport (MQTT); Security challenges; Internet of thing (IOT); Asymmetric cryptography; Constrained resources; Data confidentiality; Implementation models; Industrial internet of things (IIoT); javacard; mutual authentication; Secure authentications; smart card; Smart cards; Telemetering equipment; Transport layer security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTJMBUW9","journalArticle","2020","Lawal, M.A.; Shaikh, R.A.; Hassan, S.R.","An anomaly mitigation framework for iot using fog computing","Electronics (Switzerland)","","","10.3390/electronics9101565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091643039&doi=10.3390%2felectronics9101565&partnerID=40&md5=f341fcd436c906761deb00e660cbd271","The advancement in IoT has prompted its application in areas such as smart homes, smart cities, etc., and this has aided its exponential growth. However, alongside this development, IoT networks are experiencing a rise in security challenges such as botnet attacks, which often appear as network anomalies. Similarly, providing security solutions has been challenging due to the low resources that characterize the devices in IoT networks. To overcome these challenges, the fog computing paradigm has provided an enabling environment that offers additional resources for deploying security solutions such as anomaly mitigation schemes. In this paper, we propose a hybrid anomaly mitigation framework for IoT using fog computing to ensure faster and accurate anomaly detection. The framework employs signature-and anomaly-based detection methodologies for its two modules, respectively. The signature-based module utilizes a database of attack sources (blacklisted IP addresses) to ensure faster detection when attacks are executed from the blacklisted IP address, while the anomaly-based module uses an extreme gradient boosting algorithm for accurate classification of network traffic flow into normal or abnormal. We evaluated the performance of both modules using an IoT-based dataset in terms response time for the signature-based module and accuracy in binary and multiclass classification for the anomaly-based module. The results show that the signature-based module achieves a fast attack detection of at least six times faster than the anomaly-based module in each number of instances evaluated. The anomaly-based module using the XGBoost classifier detects attacks with an accuracy of 99% and at least 97% for average recall, average precision, and average F1 score for binary and multiclass classification. Additionally, it recorded 0.05 in terms of false-positive rates. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","1-24","","10","9","","","","","","","","","","","","","Scopus","","","","","","","","Fog computing; Internet of things (IoT); Anomaly mitigation; Classification algorithms; Intrusion Detection System (IDS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5YDTHB6U","journalArticle","2023","Darwesh, G.; Hammoud, J.; Vorobeva, A.A.","A novel approach to feature collection for anomaly detection in Kubernetes environment and agent for metrics collection from Kubernetes nodes","Scientific and Technical Journal of Information Technologies, Mechanics and Optics","","","10.17586/2226-1494-2023-23-3-538-546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166756074&doi=10.17586%2f2226-1494-2023-23-3-538-546&partnerID=40&md5=6b89b4dde71458c7febc883a475b9662","Kubernetes is a widely adopted open-source platform for managing containerized workloads and deploying applications in a microservices architecture. Despite its popularity, Kubernetes has faced numerous security challenges; deployments using Kubernetes are vulnerable to security risks. The current solutions for detecting anomalous behavior within a Kubernetes cluster lack real-time detection capabilities allowing hackers to exploit vulnerabilities and cause damage to production assets. This study aims to address these security concerns by proposing a new approach and novel agent to feature collection for anomaly detection in Kubernetes environment. It is proposed to use metrics (related to disk usage, CPU and network) collected by node exporter (Prometeus) directly from Kubernetes nodes. The simulation was conducted in a real-world production Kubernetes environment hosted on the Microsoft Azure, with results indicating the agent success in collecting 24 security metrics in a short amount of time. These metrics can be used to create a labeled time-series dataset of anomalies produced by microservices, enabling real-time detection of attacks based on the behavior of compromised nodes within the Kubernetes cluster. The proposed approach and developed agent for monitoring can be used to generate datasets for training anomaly detection models in the Kubernetes environment, based on artificial intelligence technologies, in real-time mode. The obtained results will be useful for researchers and specialists in the field of Kubernetes cybersecurity. © 2023 Mechanics and Optics. All rights reserved.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","538-546","","3","23","","","Новый способ сбора данных для обнаружения аномального поведения в среде Kubernetes и агент для сбора метрик с узлов","","","","","","","","","","Scopus","","","","","","","","Kubernetes; security; anomalies detection; attack detection; Kubernetes monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GH6FL9AB","journalArticle","2020","Adel, A.","Utilizing technologies of fog computing in educational IoT systems: privacy, security, and agility perspective","Journal of Big Data","","","10.1186/s40537-020-00372-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095934542&doi=10.1186%2fs40537-020-00372-z&partnerID=40&md5=8587c12e3e14f0d2b6ed514adbb3e655","Fog computing architecture is referred to the architecture that is distributed over the geographical area. This architectural arrangement mainly focuses on physical and logical network elements, and software for the purpose of implementing proper network. Fog computing architecture allows the users to have a flexible communication and also ensures that the storage services are maintained efficiently for the purpose of managing the data. However, it has been observed that in the field of education fog computing architecture has gained huge importance due to its real time application feature. The main objective of the survey is to develop a systematic literature review for the technology of fog computing in the education IoT system. The survey will also focus on evaluating the essential factors that has a crucial role in the fields of education as well as investigating the limitation and findings associated with the fog computing technologies in educational systems from the perspective of privacy, security, and agility. © 2020, The Author(s).","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","1","7","","","","","","","","","","","","","Scopus","","","","","","","","Virtualization; Internet of things; Virtualizations; Computer architecture; Network architecture; Edge computing; Digital storage; Fog computing; IoT; Computing architecture; Fog; Geographical area; Education system; Education systems; Flexible communication; Logical network; Network element; Physical network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTVN2FVD","journalArticle","2024","Tran, H.-B.; Phan, V.T.-A.","Potential usage of fly ash and nano silica in high-strength concrete: Laboratory experiment and application in rigid pavement","Case Studies in Construction Materials","","","10.1016/j.cscm.2024.e02856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182258179&doi=10.1016%2fj.cscm.2024.e02856&partnerID=40&md5=1791ade1e036b0dcb38d142bbbf74a43","High-strength concrete (HSC) using supplementary cementitious material of 30% fly ash (FA) and various nano silica (NS) contents were investigated in this study. FA and NS are waste materials collected from local thermal plants and rice husk ash in Southern Vietnam, respectively. Different concentrations of NS at 0%, 0.5%, 1.0%, and 1.5% were incorporated into the base mixture in place of cement and FA. The water-to-binder ratio of 0.32 was constant for all the mixtures. Results indicated that the combination binder of cement, FA, and NS satisfied the setting time as pure cement binder. The slump test value was in the range of 30–40 mm by adjusting the superplasticzer. Mechanical properties of HSC were studied at various curing ages of 3, 7, 28, and 56 days, including compressive strength, flexural strength, elastic modulus, and abrasion resistance. Results indicated that 1% NS can be considered as optimum content for preparing an HSC mixture, which showed the best mechanical properties. Furthermore, a good correlation between compressive strength and flexural strength was obtained from the results. Finally, rigid pavement calculation revealed that the addition of 1% NS resulted in a reduction in the thickness of the concrete slab by 30 mm (around 10.7%) compared to non-NS concrete. These findings suggest that incorporating nano-silica into concrete can lead to thinner concrete slabs with improved performance characteristics. © 2024 The Authors","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","20","","","","","","","","","","","","","Scopus","","","","","","","","Bending strength; Cements; Compressive strength; Concrete mixtures; Concrete slabs; Fly ash; High performance concrete; High strength concretes; High-strength concrete; Laboratory experiments; Mechanical properties; Nano silica; Nano Silica; Pavements; Rice-husk ash; Rigid pavement; Rigid pavements; Setting; Silica; Silica content; Supplementary cementitious material; Thermal plants; Viet Nam; Water-to-binder ratio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLRXMD7H","conferencePaper","2023","Luo, S.; Xu, H.; Ye, K.; Xu, G.; Zhang, L.; He, J.; Yang, G.; Xu, C.","Erms: Efficient Resource Management for Shared Microservices with SLA Guarantees","","","","10.1145/3567955.3567964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145590582&doi=10.1145%2f3567955.3567964&partnerID=40&md5=766ccd04af408fccedd66abdced59467","A common approach to improving resource utilization in data centers is to adaptively provision resources based on the actual workload. One fundamental challenge of doing this in microservice management frameworks, however, is that different components of a service can exhibit significant differences in their impact on end-to-end performance. To make resource management more challenging, a single microservice can be shared by multiple online services that have diverse workload patterns and SLA requirements. We present an efficient resource management system, namely Erms, for guaranteeing SLAs in shared microservice environments. Erms profiles microservice latency as a piece-wise linear function of the workload, resource usage, and interference. Based on this profiling, Erms builds resource scaling models to optimally determine latency targets for microservices with complex dependencies. Erms also designs new scheduling policies at shared microservices to further enhance resource efficiency. Experiments across microservice benchmarks as well as trace-driven simulations demonstrate that Erms can reduce SLA violation probability by 5× and more importantly, lead to a reduction in resource usage by 1.6×, compared to state-of-the-art approaches.  © 2022 ACM.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","62-77","","","1","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Resource management; Resource usage; Natural resources management; Resource allocation; On-line service; Resources utilizations; Management frameworks; End-to-end performance; Resource Management; Resources based; Shared microservice; Shared Microservices; SLA guarantee; SLA Guarantees","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"8BQLJ5NS","journalArticle","2019","Lin, M.; Xi, J.; Bai, W.; Wu, J.","Ant Colony Algorithm for Multi-Objective Optimization of Container-Based Microservice Scheduling in Cloud","IEEE Access","","","10.1109/ACCESS.2019.2924414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068797342&doi=10.1109%2fACCESS.2019.2924414&partnerID=40&md5=c1956fbc2c5eb82d3bc88c87d86cf3c6","In cloud architectures, the microservice model divides an application into a set of loosely coupled and collaborative fine-grained services. As a lightweight virtualization technology, the container supports the encapsulation and deployment of microservice applications. Despite a large number of solutions and implementations, there remain open issues that have not been completely addressed in the deployment and management of the microservice containers. An effective method for container resource scheduling not only satisfies the service requirements of users but also reduces the running overhead and ensures the performance of the cluster. In this paper, a multi-objective optimization model for the container-based microservice scheduling is established, and an ant colony algorithm is proposed to solve the scheduling problem. Our algorithm considers not only the utilization of computing and storage resources of the physical nodes but also the number of microservice requests and the failure rate of the physical nodes. Our algorithm uses the quality evaluation function of the feasible solutions to ensure the validity of pheromone updating and combines multi-objective heuristic information to improve the selection probability of the optimal path. By comparing with other related algorithms, the experimental results show that the proposed optimization algorithm achieves better results in the optimization of cluster service reliability, cluster load balancing, and network transmission overhead. © 2013 IEEE.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","83088-83100","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Containers; Microservices; Cloud computing; Failure analysis; Clustering algorithms; Multiobjective optimization; Virtualization technologies; Genetic algorithms; Container scheduling; Ant colony optimization; Multi-objective optimization; Multi-objective optimization models; Ant colony algorithm; Ant colony algorithms; Heuristic information; Optimization algorithms; Selection probabilities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EZGQUU5","conferencePaper","2017","Yu, S.; Wang, X.; Langar, R.","Computation offloading for mobile edge computing: A deep learning approach","","","","10.1109/PIMRC.2017.8292514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045273064&doi=10.1109%2fPIMRC.2017.8292514&partnerID=40&md5=3378e12c00da12a403ad544698cbe98f","Computation offloading has already shown itself to be successful for enabling resource-intensive applications on mobile devices. Moreover, in view of mobile edge computing (MEC) system, mobile devices can offload compute-intensive tasks to a nearby cloudlet, so as to save the energy and enhance the processing speed. However, due to the varying network conditions and limited computation resources of cloudlets, the offloading actions taken by a mobile user may not achieve the lowest cost. In this paper, we develop a dynamic offloading framework for mobile users, considering the local overhead in the mobile terminal side, as well as the limited communication and computation resources in the network side. We formulate the offloading decision problem as a multi-label classification problem and develop the Deep Supervised Learning (DSL) method to minimize the computation and offloading overhead. Simulation results show that our proposal can reduce system cost up to 49.24%, 23.87%, 15.69%, and 11.18% compared to the ""no offloading"" scheme, ""random offloading"" scheme, ""total offloading"" scheme and ""multi-label linear classifier-based offloading"" scheme, respectively. © 2017 IEEE.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","1-6","","","2017-October","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Computation offloading; Energy; Mobile telecommunication systems; Classification (of information); Mobile edge computing; Mobile users; computation offloading; Low-costs; Computing system; Computation resources; Compute-intensive tasks; Learning approach; Network condition; Processing speed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Symposium on Personal, Indoor and Mobile Radio Communications, PIMRC","","","","","","","","","","","","","","",""
"R7L75RGF","journalArticle","2020","Wen, Z.; Lin, T.; Yang, R.; Ji, S.; Ranjan, R.; Romanovsky, A.; Lin, C.; Xu, J.","GA-Par: Dependable Microservice Orchestration Framework for Geo-Distributed Clouds","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2019.2929389","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077089009&doi=10.1109%2fTPDS.2019.2929389&partnerID=40&md5=79383bc854066cbcb1850be77d2887db","Recent advances in composing Cloud applications have been driven by deployments of inter-networking heterogeneous microservices across multiple Cloud datacenters. System dependability has been of the upmost importance and criticality to both service vendors and customers. Security, a measurable attribute, is increasingly regarded as the representative example of dependability. Literally, with the increment of microservice types and dynamicity, applications are exposed to aggravated internal security threats and externally environmental uncertainties. Existing work mainly focuses on the QoS-aware composition of native VM-based Cloud application components, while ignoring uncertainties and security risks among interactive and interdependent container-based microservices. Still, orchestrating a set of microservices across datacenters under those constraints remains computationally intractable. This paper describes a new dependable microservice orchestration framework GA-Par to effectively select and deploy microservices whilst reducing the discrepancy between user security requirements and actual service provision. We adopt a hybrid (both whitebox and blackbox based) approach to measure the satisfaction of security requirement and the environmental impact of network QoS on system dependability. Due to the exponential grow of solution space, we develop a parallel Genetic Algorithm framework based on Spark to accelerate the operations for calculating the optimal or near-optimal solution. Large-scale real world datasets are utilized to validate models and orchestration approach. Experiments show that our solution outperforms the greedy-based security aware method with 42.34 percent improvement. GA-Par is roughly 4x faster than a Hadoop-based genetic algorithm solver and the effectiveness can be constantly guaranteed under different application scales. © 1990-2012 IEEE.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","129-143","","1","31","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Security requirements; Environmental impact; Near-optimal solutions; Genetic algorithms; microservice; dependability; Service orchestration; Environmental uncertainty; Large dataset; Parallel genetic algorithms; System dependability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SN5WJEUV","journalArticle","2017","Sun, L.; Li, Y.; Memon, R.A.","An open IoT framework based on microservices architecture","China Communications","","","10.1109/CC.2017.7868163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015161312&doi=10.1109%2fCC.2017.7868163&partnerID=40&md5=1e8bc5d8fbd474a9854e3989393ad074","With the continuous development and evolvement of Internet of Things (IoT), monolithic application becomes much larger in scale and even more complex in structure. This leads to poor scalability, extensibility and maintainability. In response to those challenges, microservice architecture has been introduced in the field of IoT application, due to its flexibility, lightweight and loose coupling. However, the existing IoT framework of microservice mainly focus on a specific domain, therefore, this greatly limits its application. In this paper, we propose a general microservice system framework for the IoT application, which is a better scalable, extendable and maintainable architecture. We introduce its system design and related microservices, and emphasize on core service and device communication from service layer to physical layer. It has better capacity to support interoperability and accommodate heterogeneous objects. In addition, this framework can easily achieve more application integration such as automation, intelligence, Geo service and Big Data. © 2013 IEEE.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","154-162","","2","14","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; IoT; software architecture; micro service","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GIK233KR","journalArticle","2022","Mahmud, R.; Pallewatta, S.; Goudarzi, M.; Buyya, R.","iFogSim2: An extended iFogSim simulator for mobility, clustering, and microservice management in edge and fog computing environments","Journal of Systems and Software","","","10.1016/j.jss.2022.111351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130094579&doi=10.1016%2fj.jss.2022.111351&partnerID=40&md5=b650072584d3ec15cdfca92a7638dd74","Internet of Things (IoT) has already proven to be the building block for next-generation Cyber–Physical Systems (CPSs). The considerable amount of data generated by the IoT devices needs latency-sensitive processing, which is not feasible by deploying the respective applications in remote Cloud datacentres. Edge/Fog computing, a promising extension of Cloud at the IoT-proximate network, can meet such requirements for smart CPSs. However, the structural and operational differences of Edge/Fog infrastructure resist employing Cloud-based service regulations directly to these environments. As a result, many research works have been recently conducted, focusing on efficient application and resource management in Edge/Fog computing environments. Scalable Edge/Fog infrastructure is a must to validate these policies, which is also challenging to accommodate in the real-world due to high cost and implementation time. Considering simulation as a key to this constraint, various software have been developed that can imitate the physical behavior of Edge/Fog computing environments. Nevertheless, the existing simulators often fail to support advanced service management features because of their monolithic architecture, lack of actual dataset, and limited scope for a periodic update. To overcome these issues, we have developed modular simulation models for service migration, dynamic distributed cluster formation, and microservice orchestration for Edge/Fog computing based on real datasets and extended the basic components of iFogSim, a widely used Edge/Fog computing simulator for their ease of adoption as iFogSim2. The performance of iFogSim2 and its built-in service management policies are evaluated using three use case scenarios and compared with the contemporary simulators and benchmark policies under different settings. Results indicate that our simulator consumes less memory and minimizes simulation time by an average of 28% when compared to other simulators. © 2022 Elsevier Inc.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","190","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Microservice; Microservices; Internet of things; Cluster computing; Benchmarking; Computer software; Fog computing; Computing environments; Building blockes; Environmental management; Internet of Things; Simulation; Cyber-physical systems; Edge/fog computing; Simulators; Clustering; Clusterings; Cybe-physical systems; Edge/Fog computing; Mobility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FSIJM4G","conferencePaper","2016","Mnih, V.; Badia, A.P.; Mirza, L.; Graves, A.; Harley, T.; Lillicrap, T.P.; Silver, D.; Kavukcuoglu, K.","Asynchronous methods for deep reinforcement learning","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999036937&partnerID=40&md5=e49f5cfd9d8c4eec69ab63009c3d8037","Wc propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input. © 2016 by the author(s).","2016","2025-10-22 19:07:35","2025-10-22 19:07:35","","2850-2869","","","4","","","","","","","","","","","","","Scopus","","","","","","","","State of the art; Artificial intelligence; Learning algorithms; Learning systems; Deep neural networks; Reinforcement learning; Asynchronous methods; Gradient descent; Lightweight frameworks; Multi-core cpus; Neural network controllers; Stabilizing effects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","33rd International Conference on Machine Learning, ICML 2016","","","","","","","","","","","","","","",""
"CAI5IRRT","conferencePaper","2021","Zhou, P.; Wu, G.; Alzahrani, B.; Barnawi, A.; Alhindi, A.; Chen, M.","Reinforcement Learning for Task Placement in Collaborative Cloud- Edge Computing","","","","10.1109/GLOBECOM46510.2021.9685049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184631292&doi=10.1109%2fGLOBECOM46510.2021.9685049&partnerID=40&md5=de6fe62523754f051477463d8b713173","With the advantage of being close to the network, edge cloud-enabled computing mode brings flexibility to task scheduling. However, with the heterogeneity of computing resources between cloud and edge cloud, and the complexity of computing and communication processes between multi-edge cloud, challenges have been brought to the deployment and computing of tasks in cloud-edge collaborative environments. In order to solve this challenge, firstly a deep reinforcement learning controller based cloud-edge collaborative computing framework has been proposed. Then a system QoS model has been estab-lished considering both the user benefits and the service provider benefits. By using deep Q-network, a deep reinforcement learning based collaborative task placement algorithm has been proposed for dynamically optimizing the target system utility. Finally, the experimental results show that the proposed method has a good learning ability for the computing cost of cloud and edge cloud as well as the communication cost between multi-edge cloud. In addition, compared with Q-table learning, random computing and cloud computing, a 10% improvement of system utility has been achieved with the proposed method. © 2021 IEEE.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Edge computing; Edge clouds; Learning systems; Reinforcement learning; Reinforcement learnings; Resources allocation; Reinforcement Learning; Tasks scheduling; Network edges; Collaborative cloud-edge computing; Collaborative Cloud-Edge Computing; Crowd Management; Crowd managements; Multi-edge cloud; Multi-Edge Cloud; Resource Allocation; Task placement; Task Placement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Global Communications Conference, GLOBECOM","","","","","","","","","","","","","","",""
"IJRIPEBR","bookSection","2018","Mousavi, S.S.; Schukat, M.; Howley, E.","Deep Reinforcement Learning: An Overview","Lecture Notes in Networks and Systems","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054286523&doi=10.1007%2f978-3-319-56991-8_32&partnerID=40&md5=72571879e22527b6864886d1fecbe3c9","In recent years, a specific machine learning method called deep learning has gained huge attraction, as it has obtained astonishing results in broad applications such as pattern recognition, speech recognition, computer vision, and natural language processing. Recent research has also been shown that deep learning techniques can be combined with reinforcement learning methods to learn useful representations for the problems with high dimensional raw data input. This article reviews the recent advances in deep reinforcement learning with focus on the most used deep architectures such as autoencoders, convolutional neural networks and recurrent neural networks which have successfully been come together with the reinforcement learning framework. © Springer International Publishing AG 2018.","2018","2025-10-22 19:07:35","2025-10-22 19:07:35","","426-440","","","16","","","","","","","","","","","","","Scopus","","","","","","","","Reinforcement learning; Neural networks; Deep leaning; MDPs; Observable MDPs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGJI2GHE","journalArticle","2019","Zhou, Z.; Chen, X.; Li, E.; Zeng, L.; Luo, K.; Zhang, J.","Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing","Proceedings of the IEEE","","","10.1109/JPROC.2019.2918951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067598102&doi=10.1109%2fJPROC.2019.2918951&partnerID=40&md5=ad91a6e8db4dce26e5c696ede789d627","| With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","1738-1762","","8","107","","","","","","","","","","","","","Scopus","","","","","","","","Big data; deep learning; Deep learning; Internet of things; Computer architecture; Edge computing; Surveys; Security systems; edge computing; Artificial intelligence; Computational modelling; Job analysis; Task analysis; edge intelligence; Edge intelligence; Network edges; Edge intelligence.; Last mile","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSHSXF3R","conferencePaper","2023","Tong, G.; Meng, C.; Song, S.; Pan, M.; Yu, Y.","GMA: Graph Multi-agent Microservice Autoscaling Algorithm in Edge-Cloud Environment","","","","10.1109/ICWS60048.2023.00058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173838267&doi=10.1109%2fICWS60048.2023.00058&partnerID=40&md5=4a7180e1b5dfdd272ac4abd1d90905b0","The emerging edge-cloud computing paradigm, comprising cloud centers and multiple distributed edge servers, extends the computing capability from the cloud center to a range of servers. Although the microservice autoscaling problem has been intensively studied in the context of cloud computing, existing algorithms in most cases cannot be effectively migrated to the edge-cloud environment because servers are geographically distributed and heterogeneous, and information is not synchronized between servers. Existing works, however, mainly focus on centralized strategies with time-consuming synchronization methods, i.e. strategies shared by all servers, without comprehensively considering the heterogeneity and distribution of the environment. Soft information synchronization, autonomy and collaboration is proposed to tackle the aforementioned issues, and refer to it as SAC paradigm. According to the SAC paradigm, each server with inferred information of other servers can collaborate with others by a dedicated autoscaling strategy, that is, server collaboration. The microservice autoscaling problem is then transformed into the Graph-based Jointly Microservice Autoscaling (GJMA) problem based on spectral graph theory. GJMA problem aims to minimize average waiting time of microservice-based application while reducing service-level agreement(SLA) violation rate and fluctuations in the autoscaling process, taking into account resource heterogeneity. Graph-based Multi-agent Algorithm(GMA), an implementation of SAC paradigm based on graph convolutional networks and multi-agent reinforcement learning, is implemented to solve GJMA problem. Experimental results show that the proposed algorithm for the edge-cloud environment is always efficient to find a better autoscaling strategy compared to the implemented comparison algorithms. © 2023 IEEE.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","393-404","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud environments; Computation theory; Edge clouds; Graphic methods; Learning algorithms; Autoscaling; Graph theory; Reinforcement learning; Synchronization; Convolution; Multi agent systems; Multi agent; Convolutional networks; Edge-cloud environment; Graph convolutional network; Graph convolutional networks; Microservice autoscaling; Multi-agent reinforecment learning; Server collaboration; Software agents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2023 IEEE International Conference on Web Services, ICWS 2023","","","","","","","","","","","","","","",""
"6FKVPDGM","conferencePaper","2019","Pallewatta, S.; Kostakos, V.; Buyya, R.","Microservices-based IoT application placement within heterogeneous and resource constrained fog computing environments","","","","10.1145/3344341.3368800","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078454708&doi=10.1145%2f3344341.3368800&partnerID=40&md5=b99c5eccd2b311a7d66f0b4f73c80c63","Fog computing paradigm has created innovation opportunities within Internet of Things (IoT) domain by extending cloud services to the edge of the network. Due to the distributed, heterogeneous and resource constrained nature of the Fog computing nodes, Fog applications need to be developed as a collection of interdependent, lightweight modules. Since this concept aligns with the goals of microservices architecture, efficient placement of microservices-based IoT applications within Fog environments has the potential to fully leverage capabilities of Fog devices. In this paper, we propose a decentralized microservices-based IoT application placement policy for heterogeneous and resource constrained Fog environments. The proposed policy utilizes the independently deployable and scalable nature of microservices to place them as close as possible to the data source to minimize latency and network usage. Moreover, it aims to handle service discovery and load balancing related challenges of the microservices architecture. We implement and evaluate our policy using iFogSim simulated Fog environment. Results of the simulations show around 85% improvement in latency and network usage for the proposed microservice placement policy when compared with Cloud-only placement approach and around 40% improvement over an alternative Fog application placement method known as Edge-ward placement policy. Moreover, the decentralized placement approach proposed in this paper demonstrates significant reduction in microservice placement delay over centralized placement. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","71-81","","","","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Network architecture; Internet of Things (IOT); Fog computing; Computing environments; Computing paradigm; Microservices architecture; Application deployment; Service discovery; Fog; Application placement; Application placements; IOT applications; Internet of things (IoT); Simulated fog environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","UCC 2019 - Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing","","","","","","","","","","","","","","",""
"CE5MKP2D","journalArticle","2023","He, X.; Tu, Z.; Wagner, M.; Xu, X.; Wang, Z.","Online Deployment Algorithms for Microservice Systems With Complex Dependencies","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2022.3161684","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127076615&doi=10.1109%2fTCC.2022.3161684&partnerID=40&md5=8dc6248dded8fe69867d7169681c8286","Cloud and edge computing have been widely adopted in many application scenarios. With the increasing demand of fast iteration and complexity of business logic, it is challenging to achieve rapid development and continuous delivery in such highly distributed cloud and edge computing environment. At present, the microservice-based architecture has been the dominant deployment style, and a microservice system has to evolve agilely to offer stable Quality of Service (QoS) in the situation where user requirement changes frequently. A lot of research have been conducted to optimally re-deploy microservices to adapt to changing requirements. Nevertheless, complex dependencies between microservices and the existence of multiple instances of one single microservice in a microservice system together have not been fully considered in existing work. This article defines SPPMS, the Service Placement Problem in Microservice Systems that feature complex dependencies and multiple instances, as a Fractional Polynomial Problem (FPP). Considering the high computation complexity of FPP, it is then transformed into a Quadratic Sum-of-Ratios Fractional Problem (QSRFP) which is further solved by the our proposed greedy-based algorithms. Experiments demonstrate that our models and algorithms outperform existing approaches in both qualities of the generated solutions and computation speed. 2022 IEEE. © 2023 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","1746-1763","","2","11","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Cloud-computing; Online systems; Quality-of-service; Computer architecture; Edge computing; Iterative methods; Job analysis; Task analysis; Microservice system; microservice systems; Microservice architecture; Service dependency; Time factors; service placement; Service placements; multiple instance coexistence; Multiple instance coexistence; Multiple instances; Production facility; service dependencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XA45A3TG","conferencePaper","2017","Heinrich, R.; Van Hoorn, A.; Knoche, H.; Li, F.; Lwakatare, L.E.; Pahl, C.; Schulte, S.; Wettinger, J.","Performance engineering for microservices: Research challenges & directions","","","","10.1145/3053600.3053653","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019457941&doi=10.1145%2f3053600.3053653&partnerID=40&md5=6cb0eb2434a77000e1386723f784863d","Microservices complement approaches like DevOps and continuous delivery in terms of software architecture. Along with this architectural style, several important deployment technologies, such as container-based virtualization and container orchestration solutions, have emerged. These technologies allow to efficiently exploit cloud platforms, providing a high degree of scalability, availability, and portability for microservices. Despite the obvious importance of a sufficient level of performance, there is still a lack of performance engineering approaches explicitly taking into account the particularities of microservices. In this paper, we argue why new solutions to performance engineering for microservices are needed. Furthermore, we identify open issues and outline possible re- search directions with regard to performance-Aware testing, monitoring, and modeling of microservices. © 2017 ACM.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","223-226","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Performance engineering; Research challenges; Architectural style; Cloud platforms; Degree of scalability; Engineering; Industrial engineering; New solutions; Search direction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"SYILQWS2","journalArticle","2024","Tian, X.; Meng, H.; Shen, Y.; Zhang, J.; Chen, Y.; Li, Y.","Dynamic Microservice Deployment and Offloading for Things-Edge-Cloud Computing","IEEE Internet of Things Journal","","","10.1109/JIOT.2024.3370170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187013269&doi=10.1109%2fJIOT.2024.3370170&partnerID=40&md5=9a2be96345626229ed141489f8e6142a","The growing edge cloud computing paradigm allows flexible handling of latency-sensitive and computation-intensive applications operating on user devices as the Internet of Things and 5G technologies gain in popularity. Microservices based on container technology are regarded as a potential architecture when applied to edge computing because of their lightweight and layered image properties. However, many current studies on the combination of the two simply treat microservices as a replacement for traditional virtual machine architecture without fully utilizing its advantages. In addition to discussing the impact of image loading strategy on neighboring time slots, this article also focuses on the advantages of microservices layered image sharing. Our research in this article studies the microservice deployment and task offloading of a mobility-aware things-edge-cloud system, and a deep reinforcement learning-based algorithm is proposed in this work to make decisions that optimize the system's long-term throughput and delay utility.  © 2014 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","19537-19548","","11","11","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Microservice; Cloud-computing; Deep learning; Computer architecture; Computation offloading; Edge clouds; 5G mobile communication systems; Heuristic algorithms; Learning algorithms; Deep reinforcement learning; Job analysis; Reinforcement learning; Reinforcement learnings; Task analysis; Markov Decision Processes; Markov processes; Microservice architecture; Heuristics algorithm; Image edge detection; E-learning; Edge detection; Markov decision process (MDP); microservice online offloading; Online offloading; Thing-edge-cloud computing; things-edge-cloud (TEC) computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SLQZ8LS2","journalArticle","2019","Tang, Z.; Zhou, X.; Zhang, F.; Jia, W.; Zhao, W.","Migration Modeling and Learning Algorithms for Containers in Fog Computing","IEEE Transactions on Services Computing","","","10.1109/TSC.2018.2827070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045628753&doi=10.1109%2fTSC.2018.2827070&partnerID=40&md5=4d8c2542a77e034c13ebffee101ee3cd","Fog Computing (FC) is a flexible architecture to support distributed domain-specific applications with cloud-like quality of service. However, current FC still lacks the mobility support mechanism when facing many mobile users with diversified application quality requirements. Such mobility support mechanism can be critical such as in the industrial internet where human, products, and devices are moveable. To fill in such gaps, in this paper we propose novel container migration algorithms and architecture to support mobility tasks with various application requirements. Our algorithms are realized from three aspects: 1) We consider mobile application tasks can be hosted in a container of a corresponding fog node that can be migrated, taking the communication delay and computational power consumption into consideration; 2) We further model such container migration strategy as multiple dimensional Markov Decision Process (MDP) spaces. To effectively reduce the large MDP spaces, efficient deep reinforcement learning algorithms are devised to achieve fast decision-making and 3) We implement the model and algorithms as a container migration prototype system and test its feasibility and performance. Extensive experiments show that our strategy outperforms the existing baseline approaches 2.9, 48.5 and 58.4 percent on average in terms of delay, power consumption, and migration cost, respectively. © 2019 IEEE.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","712-725","","5","12","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Behavioral research; Electric power utilization; Containers; Cloud computing; Deep learning; Resource management; Mobile applications; Mobile computing; Decision making; Green computing; Power demands; Fog computing; Learning algorithms; Machine learning; Job analysis; Reinforcement learning; Task analysis; Markov processes; power consumption; Fog; Delays; delay; deep reinforcement learning; container migration; user mobility; User mobility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKHIAQKM","journalArticle","2022","Lv, W.; Wang, Q.; Yang, P.; Ding, Y.; Yi, B.; Wang, Z.; Lin, C.","Microservice Deployment in Edge Computing Based on Deep Q Learning","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2022.3150311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124746898&doi=10.1109%2fTPDS.2022.3150311&partnerID=40&md5=ed190a294b1f4bb5c1840c962fd259f4","The microservice deployment strategy is promising in reducing the overall service response time in the microservice-oriented edge computing platform. However, existing works ignore the effect of different interaction frequencies among microservices and the decrease in service execution performance caused by the increased node loads. In this article, we first model the invocation relationships among microservices as an undirected and weighted interaction graph to characterize the communication overhead. Then, we propose a multi-objective microservice deployment problem (MMDP) in edge computing. MMDP aims to minimize the communication overhead while achieving load balance between edge nodes. Without the requirement for domain experts, we propose Reward Sharing Deep Q Learning (RSDQL), a learning-based algorithm, to solve MMDP and obtain the optimal deployment strategy. In addition, to improve the scalability of the services, we propose an Elastic Scaling algorithm (ES) based on heuristics to deal with the dynamic pressure of requests. Finally, we conduct a series of experiments in Kubernetes to evaluate the performance of our approach. Experimental results indicate that, compared with interaction-aware strategy and Kubernetes default strategy, RSDQL has shorter response times, more balanced resource loads, and makes services scale elastically according to the request pressure. © 1990-2012 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","2968-2978","","11","33","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Deep learning; Edge computing; Learning algorithms; Reinforcement learning; Elastic scaling; load balancing; Multi objective; Scalings; deep Q learning; Deep Q learning; elastic scaling; interaction awareness; Interaction awareness; Load-Balancing; multi-objective model; Multiobjective modeling; Q-learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZHY9VBJ","conferencePaper","2016","Hassan, S.; Bahsoon, R.","Microservices and their design trade-offs: A self-adaptive roadmap","","","","10.1109/SCC.2016.113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989952704&doi=10.1109%2fSCC.2016.113&partnerID=40&md5=9f19cdb66a2b79f1c63821348e8afa34","Migrating to microservices (microservitization) enablesoptimising the autonomy, replaceability, decentralisedgovernance and traceability of software architectures. Despitethe hype for microservitization, the state of the art still lacksconsensus on the definition of microservices, their propertiesand their modelling techniques. This paper summarises viewsof microservices from informal literature to reflect on the foundationalcontext of this paradigm shift. A strong foundationalcontext can advance our understanding of microservitizationand help guide software architects in addressing its designproblems. One such design problem is finalising the optimallevel of granularity of a microservice architecture. Relateddesign trade-offs include: balancing the size and numberof microservices in an architecture and balancing the nonfunctionalrequirement satisfaction levels of the individualmicroservices as well as their satisfaction for the overall system. We propose how self-adaptivity can assist in addressing thesedesign trade-offs and discuss some of the challenges such a selfadaptivesolution. We use a hypothetical online movie streamingsystem to motivate these design trade-offs. A solution roadmapis presented in terms of the phases of a feedback control loop. © 2016 IEEE.","2016","2025-10-22 19:07:35","2025-10-22 19:07:35","","813-818","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Software architecture; Economic and social effects; Decision making; Commerce; Trade off; Decision-making; Feedback control; Granularity; Non-functional requirements; Self-adaptativity; Trade-offs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 IEEE International Conference on Services Computing, SCC 2016","","","","","","","","","","","","","","",""
"ULDXMXYA","journalArticle","2021","Chen, L.; Xu, Y.; Lu, Z.; Wu, J.; Gai, K.; Hung, P.C.K.; Qiu, M.","IoT Microservice Deployment in Edge-Cloud Hybrid Environment Using Reinforcement Learning","IEEE Internet of Things Journal","","","10.1109/JIOT.2020.3014970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099587770&doi=10.1109%2fJIOT.2020.3014970&partnerID=40&md5=ebfdb53382bb060f17a2fc9bcf63a784","The edge-cloud hybrid environment requires complex deployment strategies to enable the smart Internet-of-Things (IoT) system. However, current service deployment strategies use simple, generalized heuristics and ignore the heterogeneous characteristics in the edge-cloud hybrid environment. In this article, we devise a method to find a microservice-based service deployment strategy that can reduce the average waiting time of IoT devices in the hybrid environment. For this purpose, we first propose a microservice-based deployment problem (MSDP) based on the heterogeneous and dynamic characteristics in the edge-cloud hybrid environment, including heterogeneity of edge server capacities, dynamic geographical information of IoT devices, and changing device preference for applications and complex application structures. We then propose a multiple buffer deep deterministic policy gradient (MBDDPG) to provide more preferable service deployment solutions. Our algorithm leverages reinforcement learning and neural network to learn a deployment strategy without any human instruction. Therefore, the service provider can make full use of limited resources to improve the Quality of Service (QoS). Finally, we implement MBDDPG based on real-world data sets and some synthetic data, and we also implement another two algorithms, genetic algorithm and random algorithm, as a contrast. The experimental results demonstrate that MBDDPG is able to learn a preferable strategy which, in terms of average waiting time, outperforms genetic algorithm and the random algorithm by 32% and 44%, respectively. © 2014 IEEE.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","12610-12622","","16","8","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Internet of things; Edge clouds; Complex networks; Reinforcement learning; Reinforcement learnings; Genetic algorithms; Deployment strategy; Service deployment; reinforcement learning; Microservice deployment; Deterministics; Edge-cloud hybrid environment; Heterogeneous characteristic; microservice deployment; Policy gradient; Smart internet-of-thing  system; smart Internet-of-Things (IoT) system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57LIB3KW","journalArticle","2020","Mukherjee, M.; Matam, R.; Mavromoustakis, C.X.; Jiang, H.; Mastorakis, G.; Guo, M.","Intelligent Edge Computing: Security and Privacy Challenges","IEEE Communications Magazine","","","10.1109/MCOM.001.2000297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092524517&doi=10.1109%2fMCOM.001.2000297&partnerID=40&md5=20fa71e66ac59a48ad8680efb759b933","Edge computing has already shown its potential benefits to support the delay-sensitive and computation-intensive service provisioning in the Internet-of-Things-based environments. Simultaneously, artificial intelligence is expected to enhance the cognizance and intelligence of edge computing, resulting in a new paradigm, intelligent edge computing. However, as is evident, several new security and privacy-related issues will arise due to the distinct characteristics and working principles of intelligent edge computing. In this article, we focus on malicious attacks targeting the intelligent engines of edge computing. These attacks counteract the gains from intelligent systems and also compromise the edge computing system. We provide the main factors that are responsible for the security and privacy-related challenges in intelligent edge computing. Finally, the potential research directions in privacy and security-related issues are outlined for intelligent edge computing.  © 2020 IEEE.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","26-31","","9","58","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Network security; Privacy and security; Potential researches; Intelligent systems; Intelligent computing; Service provisioning; Computation intensives; Intelligent engines; Malicious attack; Potential benefits; Security and privacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5PAQREN","journalArticle","2019","De Donno, M.; Tange, K.; Dragoni, N.","Foundations and Evolution of Modern Computing Paradigms: Cloud, IoT, Edge, and Fog","IEEE Access","","","10.1109/ACCESS.2019.2947652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078341344&doi=10.1109%2fACCESS.2019.2947652&partnerID=40&md5=f0ed9688504d4eeb4a589c1f86754d67","In the last few years, Internet of Things, Cloud computing, Edge computing, and Fog computing have gained a lot of attention in both industry and academia. However, a clear and neat definition of these computing paradigms and their correlation is hard to find in the literature. This makes it difficult for researchers new to this area to get a concrete picture of these paradigms. This work tackles this deficiency, representing a helpful resource for those who will start next. First, we show the evolution of modern computing paradigms and related research interest. Then, we address each paradigm, neatly delineating its key points and its relation with the others. Thereafter, we extensively address Fog computing, remarking its outstanding role as the glue between IoT, Cloud, and Edge computing. In the end, we briefly present open challenges and future research directions for IoT, Cloud, Edge, and Fog computing. © 2013 IEEE.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","150936-150948","","","7","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; Internet of things; Edge computing; Research interests; Mobile cloud computing; mobile cloud computing; Fog computing; edge computing; Internet of Things; Computing paradigm; mobile edge computing; Fog; Future research directions; Keypoints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPYYTMQD","journalArticle","2016","Fazio, M.; Celesti, A.; Ranjan, R.; Liu, C.; Chen, L.; Villari, M.","Open Issues in Scheduling Microservices in the Cloud","IEEE Cloud Computing","","","10.1109/MCC.2016.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996569901&doi=10.1109%2fMCC.2016.112&partnerID=40&md5=d52198bb1cc22e10b6f9e5e3d6df7c95","The adoption of container-based microservices architectures is revolutionizing application design. By adopting a microservices architecture, developers can engineer applications that are composed of multiple lightweight, self-contained, and portable runtime components deployed across a large number of geodistributed servers. © 2016 IEEE.","2016","2025-10-22 19:07:35","2025-10-22 19:07:35","","81-88","","5","3","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Cloud computing; microservices; Internet of things; Cloud systems; Runtimes; Software developer; Distributed applications; Application architecture; Application design; Cloud computing architecture; Federated clouds; Independent components; Service deployment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRIFC9B9","journalArticle","2021","Chen, X.; Xiao, S.","Multi-objective and parallel particle swarm optimization algorithm for container-based microservice scheduling","Sensors","","","10.3390/s21186212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114941810&doi=10.3390%2fs21186212&partnerID=40&md5=28c2691de5e2093cd82ccd481182b736","An application based on a microservice architecture with a set of independent, fine-grained modular services is desirable, due to its low management cost, simple deployment, and high portability. This type of container technology has been widely used in cloud computing. Several methods have been applied to container-based microservice scheduling, but they come with significant disadvantages, such as high network transmission overhead, ineffective load balancing, and low service reliability. In order to overcome these disadvantages, in this study, we present a multi-objective optimization problem for container-based microservice scheduling. Our approach is based on the particle swarm optimization algorithm, combined parallel computing, and Pareto-optimal theory. The particle swarm optimization algorithm has fast convergence speed, fewer parameters, and many other advantages. First, we detail the various resources of the physical nodes, cluster, local load balancing, failure rate, and other aspects. Then, we discuss our improvement with respect to the relevant parameters. Second, we create a multi-objective optimization model and use a multi-objective optimization parallel particle swarm optimization algorithm for container-based microservice scheduling (MOPPSO-CMS). This algorithm is based on user needs and can effectively balance the performance of the cluster. After comparative experiments, we found that the algorithm can achieve good results, in terms of load balancing, network transmission overhead, and optimization speed. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","18","21","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Containers; Cloud computing; Failure analysis; Computation theory; Clustering algorithms; Multiobjective optimization; Particle swarm optimization (PSO); Particle swarm optimization algorithm; Service reliability; Multi-objective optimization; Comparative experiments; Container-based microservice scheduling; Fast convergence speed; Multi-objective optimization models; Multi-objective optimization problem; Network transmission; Parallel particle swarm optimization; Pareto principle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XBUUJXDP","journalArticle","2020","Faticanti, F.; De Pellegrini, F.; Siracusa, D.; Santoro, D.; Cretti, S.","Throughput-Aware Partitioning and Placement of Applications in Fog Computing","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3023011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090929963&doi=10.1109%2fTNSM.2020.3023011&partnerID=40&md5=878b902c11074aed1ebbc176d3fa548a","Fog computing promises to extend cloud computing to match emerging demands for low latency, location-awareness and dynamic computation. It thus brings data processing close to the edge of the network by leveraging on devices with different computational characteristics. However, the heterogeneity, the geographical distribution, and the data-intensive profiles of IoT deployments render the placement of fog applications a fundamental problem to guarantee target performance figures. This is a core challenge for fog computing providers to offer fog infrastructure as a service, while satisfying the requirements of this new class of microservices-based applications. In this article we root our analysis on the throughput requirements of the applications while exploiting offloading towards different regions. The resulting resource allocation problem is developed for a fog-native application architecture based on containerised microservice modules. An algorithmic solution is designed to optimise the placement of applications modules either in cloud or in fog. Finally, the overall solution consists of two cascaded algorithms. The first one performs a throughput-oriented partitioning of fog application modules. The second one rules the orchestration of applications over a region-based infrastructure. Extensive numerical experiments validate the performance of the overall scheme and confirm that it outperforms state-of-the-art solutions adapted to our context.  © 2004-2012 IEEE.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","2436-2450","","4","17","","","","","","","","","","","","","Scopus","","","","","","","","microservices; Infrastructure as a service (IaaS); State of the art; Fog computing; Data handling; IoT; Application architecture; resource allocation; Fog; Algorithmic solutions; Application module; applications partitioning; Dynamic computations; Geographical distribution; Location awareness; Numerical experiments; Resource allocation problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RNZ7J3N8","journalArticle","2023","Souza, P.S.; Ferreto, T.; Calheiros, R.N.","EdgeSimPy: Python-based modeling and simulation of edge computing resource management policies","Future Generation Computer Systems","","","10.1016/j.future.2023.06.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163891959&doi=10.1016%2fj.future.2023.06.013&partnerID=40&md5=695770f8524f07a75dc3debfcf4f85ba","The increasing popularity of applications with tight latency requirements has motivated research on Edge Computing, which positions computing resources near data sources at the Internet's edge. Despite the emergence of simulation tools that make prototype validation less complex, time-consuming, and expensive, researchers and practitioners still face significant challenges when developing resource management strategies for the edge, as existing simulators fall short in providing a fine-grained model of edge applications provisioning. To overcome this challenge, we propose EdgeSimPy, a simulation framework written in Python for modeling and evaluating resource management policies in Edge Computing environments. EdgeSimPy features a modular architecture that incorporates several functional abstractions for edge servers, network devices, and applications with built-in models for user mobility, application composition, and power consumption that allow the simulation of various scenarios. Furthermore, we propose a novel conceptual model that accurately represents the entire lifecycle of edge applications and ensures seamless integration with real application traces. In addition to submitting EdgeSimPy to an in-depth verification that checks the simulator implementation, we discuss case studies that show EdgeSimPy in action in different large-scale scenarios. © 2023 Elsevier B.V.","2023","2025-10-22 19:07:35","2025-10-22 19:07:35","","446-459","","","148","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Data-source; Resource management; Edge computing; Computing power; Computer software; Life cycle; Natural resources management; Resource allocation; Resource management policy; Modeling; Computing resource; Model and simulation; Simulation; Python; Based modelling; Computing resource management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMFX9BHG","journalArticle","2020","Le Duc, T.; Leiva, R.G.; Casari, P.; Östberg, P.-O.","Machine learning methods for reliable resource provisioning in edge-cloud computing: A survey","ACM Computing Surveys","","","10.1145/3341145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072380854&doi=10.1145%2f3341145&partnerID=40&md5=47076a686bc04cca9a6254ea60f18b51","Large-scale software systems are currently designed as distributed entities and deployed in cloud data centers. To overcome the limitations inherent to this type of deployment, applications are increasingly being supplemented with components instantiated closer to the edges of networks—a paradigm known as edge computing. The problem of how to efficiently orchestrate combined edge-cloud applications is, however, incompletely understood, and a wide range of techniques for resource and application management are currently in use. This article investigates the problem of reliable resource provisioning in joint edge-cloud environments, and surveys technologies, mechanisms, and methods that can be used to improve the reliability of distributed applications in diverse and heterogeneous network environments. Due to the complexity of the problem, special emphasis is placed on solutions to the characterization, management, and control of complex distributed applications using machine learning approaches. The survey is structured around a decomposition of the reliable resource provisioning problem into three categories of techniques: workload characterization and prediction, component placement and system consolidation, and application elasticity and remediation. Survey results are presented along with a problem-oriented discussion of the state-of-the-art. A summary of identified challenges and an outline of future research directions are presented to conclude the article. © 2019 Association for Computing Machinery.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","5","52","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Cloud computing; Cloud-computing; Distributed systems; Edge computing; Surveys; Edge clouds; Machine learning; Distributed applications; Autoscaling; Complex networks; Optimisations; Machine-learning; Reliability; Placement; Consolidation; Heterogeneous networks; Machine learning methods; Remediation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QI27DRVY","journalArticle","2017","Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; Klimov, O.","Proximal policy optimization algorithms","Proximal Policy Optimization Algorithms","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041194636&partnerID=40&md5=83b11cddc6f5a1263e16098bcdf57974","","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IG8MGR4","journalArticle","2020","Fan, G.; Chen, L.; Yu, H.; Qi, W.","Multi-objective optimization of container-based microservice scheduling in edge computing","Computer Science and Information Systems","","","10.2298/CSIS200229041F","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100578451&doi=10.2298%2fCSIS200229041F&partnerID=40&md5=469c3de7ec132fe2f19f9688e9f1ec9a","Edge computing provides physical resources closer to end users, becoming a good complement to cloud computing. With the rapid development of container technology and microservice architecture, container orchestration has become a hot issue. However, the container-based microservice scheduling problem in edge computing is still urgent to be solved. In this paper, we first formulate the container-based microservice scheduling as a multi-objective optimization problem, aiming to optimize network latency among microservices, reliability of microservice applications and load balancing of the cluster. We further propose a latency, reliability and load balancing aware scheduling (LRLBAS) algorithm to determine the container-based microservice deployment in edge computing. Our proposed algorithm is based on particle swarm optimization (PSO). In addition, we give a handling strategy to separate the fitness function from constraints, so that each particle has two fitness values. In the proposed algorithm, a new particle comparison criterion is introduced and a certain proportion of infeasible particles are reserved adaptively. Extensive simulation experiments are conducted to demonstrate the effectiveness and efficiency of the proposed algorithm compared with other related algorithms. © 2020, ComSIS Consortium. All rights reserved.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","23-42","","1","18","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Edge computing; Container orchestration; Particle swarm optimization; Multi-objective optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3II6KGN","journalArticle","2022","Tabatabaee Malazi, H.; Chaudhry, S.R.; Kazmi, A.; Palade, A.; Cabrera, C.; White, G.; Clarke, S.","Dynamic Service Placement in Multi-Access Edge Computing: A Systematic Literature Review","IEEE Access","","","10.1109/ACCESS.2022.3160738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127032753&doi=10.1109%2fACCESS.2022.3160738&partnerID=40&md5=bc63487fa7bb2b72a15e15b6f7b233ca","The advent of new cloud-based applications such as mixed reality, online gaming, autonomous driving, and healthcare has introduced infrastructure management challenges to the underlying service network. Multi-access edge computing (MEC) extends the cloud computing paradigm and leverages servers near end-users at the network edge to provide a cloud-like environment. The optimum placement of services on edge servers plays a crucial role in the performance of such service-based applications. Dynamic service placement problem addresses the adaptive configuration of application services at edge servers to facilitate end-users and those devices that need to offload computation tasks. While reported approaches in the literature shed light on this problem from a particular perspective, a panoramic study of this problem reveals the research gaps in the big picture. This paper introduces the dynamic service placement problem and outline its relations with other problems such as task scheduling, resource management, and caching at the edge. We also present a systematic literature review of existing dynamic service placement methods for MEC environments from networking, middleware, applications, and evaluation perspectives. In the first step, we review different MEC architectures and their enabling technologies from a networking point of view. We also introduce different cache deployment solutions in network architectures and discuss their design considerations. The second step investigates dynamic service placement methods from a middleware viewpoint. We review different service packaging technologies and discuss their trade-offs. We also survey the methods and identify eight research directions that researchers follow. Our study categorises the research objectives into six main classes, proposing a taxonomy of design objectives for the dynamic service placement problem. We also investigate the reported methods and devise a solutions taxonomy comprising six criteria. In the third step, we concentrate on the application layer and introduce the applications that can take advantage of dynamic service placement. The fourth step investigates evaluation environments used to validate the solutions, including simulators and testbeds. We introduce real-world datasets such as edge server locations, mobility traces, and service requests used to evaluate the methods. We compile a list of open issues and challenges categorised by various viewpoints in the last step.  © 2013 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","32639-32688","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Cloud-computing; resource management; Resource management; Economic and social effects; Network architecture; Edge computing; Taxonomies; Memory architecture; Mobile edge computing; Natural resources management; Resource allocation; Multiaccess; Job analysis; Task analysis; Service deployment; computational offloading; service orchestration; Service caching; Service orchestration; Computational offloading; service deployment; Decentralised; decentralised cloud; Decentralized cloud; MEC server; Mixed reality; Multi-access edge computing server; service caching; service offloading; Service offloading; Vehicle's dynamics; Wireless fidelities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K4JLV3JB","journalArticle","2018","Filip, I.-D.; Pop, F.; Serbanescu, C.; Choi, C.","Microservices scheduling model over heterogeneous cloud-edge environments as support for IoT applications","IEEE Internet of Things Journal","","","10.1109/JIOT.2018.2792940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041178328&doi=10.1109%2fJIOT.2018.2792940&partnerID=40&md5=a37ccd9b469584b0b2b9b54c8557d0a0","Motivated by the high-interest in increasing the utilization of nongeneral purpose devices in reaching computational objectives with a reduced cost, we propose a new model for scheduling microservices over heterogeneous cloud-edge environments. Our model uses a particular mathematical formulation for describing an architecture that includes heterogeneous machines that can handle different microservices. Since any new model asks for an early risk-analysis of the solution, we improved the CloudSim simulation framework to be suitable for an experiment that includes that kind of systems. In this paper, we discuss two examples of real-life utilizations of our proposed scheduling architecture. For an objective appreciation of the first example, we also include some experimental results based on the developed simulation tool. As a result of our interpretation of the experimental results we find out that some very simple scheduling algorithms may outperform some others in given situations that are frequently present in cloud-edge environments when we are using a microservice-oriented approach. © 2018 IEEE.","2018","2025-10-22 19:07:35","2025-10-22 19:07:35","","2672-2681","","4","5","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Energy efficiency; Cloud computing; Internet of things; Computer architecture; Edge computing; Green computing; Mathematical models; Scheduling algorithms; Processor scheduling; Risk assessment; Risk analysis; Computational model; Heterogeneous systems; IOT applications; Mathematical formulation; Microservice scheduling; Scheduling architecture; Scheduling models; Simulation framework","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S45Z7WP3","bookSection","2017","Dragoni, N.; Giallorenzo, S.; Lafuente, A.L.; Mazzara, M.; Montesi, F.; Mustafin, R.; Safina, L.","Microservices: Yesterday, today, and tomorrow","Present and Ulterior Software Engineering","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054938535&doi=10.1007%2f978-3-319-67425-4_12&partnerID=40&md5=a052a4a4bb9e8ef78561c5d7aefbe45c","Microservices is an architectural style inspired by service-oriented computing that has recently started gaining popularity. Before presenting the current state of the art in the field, this chapter reviews the history of software architecture, the reasons that led to the diffusion of objects and services first, and microservices later. Finally, open problems and future challenges are introduced. This survey primarily addresses newcomers to the discipline, while offering an academic viewpoint on the topic. In addition, we investigate some practical issues and point out a few potential solutions. © Springer International Publishing AG 2017.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","195-216","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JAR3K2IQ","journalArticle","2024","Pallewatta, S.; Kostakos, V.; Buyya, R.","MicroFog: A framework for scalable placement of microservices-based IoT applications in federated Fog environments","Journal of Systems and Software","","","10.1016/j.jss.2023.111910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179470424&doi=10.1016%2fj.jss.2023.111910&partnerID=40&md5=21b1ceef6e8bb21ec1a6750b388908d6","MicroService Architecture (MSA) is gaining rapid popularity for developing large-scale IoT applications for deployment within distributed and resource-constrained Fog computing environments. As a cloud-native application architecture, the true power of microservices comes from their loosely coupled, independently deployable and scalable nature, enabling distributed placement and dynamic composition across federated Fog and Cloud clusters. Thus, it is necessary to develop novel placement algorithms that utilise these microservice characteristics to improve the performance of the applications. However, existing Fog computing frameworks lack support for integrating such placement policies due to their shortcomings in multiple areas, including MSA application placement and deployment across multi-fog multi-cloud environments, dynamic microservice composition across multiple distributed clusters, scalability of the framework to operate within federated environments, support for deploying heterogeneous microservice applications, etc. To this end, we design and implement MicroFog, a Fog computing framework compatible with cloud-native technologies such as Docker, Kubernetes and Istio. MicroFog provides an extensible and configurable control engine that executes placement algorithms and deploys applications across federated Fog environments. Furthermore, MicroFog provides a sufficient abstraction over container orchestration and dynamic microservice composition, thus enabling users to easily incorporate new placement policies and evaluate their performance. The capabilities of the MicroFog framework, such as the scalability and flexibility of the design and deployment architecture of MicroFog and its ability to ensure the deployment and composition of microservices across distributed fog–cloud environments, are validated using multiple use cases. Experiments also demonstrate MicroFog's ability to integrate and evaluate novel placement policies and load-balancing techniques. To this end, we integrate multiple microservice placement policies to demonstrate MicroFog's ability to support horizontally scaled placement, service discovery and load balancing of microservices across federated environments, thus reducing the application service response time up to 54%. © 2023 The Authors","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","209","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Performance; Cloud environments; Internet of things; Large-scales; Memory architecture; Computing frameworks; Fog computing; Computing environments; Balancing; Scalability; Application architecture; Placement algorithm; Fog; Application placement; Application placements; Microservice composition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RCY52WRQ","journalArticle","2024","Peng, K.; He, J.; Guo, J.; Liu, Y.; He, J.; Liu, W.; Hu, M.","Delay-Aware Optimization of Fine-Grained Microservice Deployment and Routing in Edge via Reinforcement Learning","IEEE Transactions on Network Science and Engineering","","","10.1109/TNSE.2024.3436616","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200823725&doi=10.1109%2fTNSE.2024.3436616&partnerID=40&md5=93c6b92ee94a899ec9859293195b965c","Microservices have exerted a profound impact on the development of internet applications. Meanwhile, the growing number of mobile terminal user requests has made the communication between microservices extremely complex, significantly impacting the quality of user service experience in mobile edge computing. Therefore, the joint optimization of microservice deployment and request routing is necessary to alleviate server pressure and enhance overall performance of large-scaled MEC applications. However, most existing work studies the microservice deployment and request routing as two isolated problems and neglects the dependencies between microservices. This paper focuses on the data dependency relationship of request and multi-instance processing problem, and then formulate the joint problem of microservice deployment and request routing as an integer nonlinear program and queuing optimization model under complex constraints. To address this problem, we propose a fine-grained reinforcement learning-based algorithm named Reward Memory Shaping Deep Deterministic Policy Gradient (RMS DDPG). Furthermore, we introduce the Long Short-Term Memory (LSTM) block into the actor network and critical network to make actions memorable. Finally, our experiments demonstrate that our algorithm is more superior in terms of delay target, load balancing and algorithm robustness compared with four baseline algorithms.  © 2024 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","6024-6037","","6","11","","","","","","","","","","","","","Scopus","","","","","","","","Fine grained; Memory architecture; Mobile edge computing; Integer programming; Heuristic algorithms; Complex networks; Reinforcement learning; Reinforcement learnings; Optimisations; Long short-term memory; Microservice architecture; Delay; Heuristics algorithm; Nonlinear programming; reinforcement learning; Routings; request routing; Request routing; Routing algorithms; Brain; long short-term memory; Microservice deployment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5T2JHWM","journalArticle","2024","Zhang, Z.; Zhao, Y.; Li, H.; Lin, C.; Liu, J.","DVFO: Learning-Based DVFS for Energy-Efficient Edge-Cloud Collaborative Inference","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2024.3357218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183648571&doi=10.1109%2fTMC.2024.3357218&partnerID=40&md5=2e9ac1bf6456b1c28f02c12a71b93629","Due to limited resources on edge and different characteristics of deep neural network (DNN) models, it is a big challenge to optimize DNN inference performance in terms of energy consumption and end-to-end latency. In addition to dynamic voltage frequency scaling (DVFS) technique, edge-cloud architecture provides a collaborative approach for efficient DNN inference. However, current edge-cloud collaborative inference methods have not optimized various compute resources on edge devices. Thus, we propose DVFO, a novel DVFS-enabled edge-cloud collaborative inference framework, which co-optimizes DVFS and offloading parameters via deep reinforcement learning (DRL). Specifically, DVFO automatically co-optimizes 1) the CPU, GPU and memory frequencies of edge devices, and 2) the offloaded feature map. In addition, it leverages a thinking-while-moving concurrent mechanism to accelerate the DRL learning process, and a spatial-channel attention mechanism to identify the less important DNN feature map for efficient offloading. This approach improves inference performance for different DNN models under various edge-cloud network conditions. Extensive evaluations using two datasets and six widely-deployed DNN models on five heterogeneous edge devices show that DVFO significantly reduces the energy consumption by 33% on average, compared to state-of-the-art schemes. Moreover, DVFO achieves up to 28.6%sim∼59.1% end-to-end latency reduction, while maintaining accuracy within 1% loss on average. © 2002-2012 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","9042-9059","","10","23","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Program processors; Energy utilization; Edge computing; Computation offloading; Energy-consumption; Green computing; Graphics processing unit; Dynamic frequency scaling; Deep neural networks; Computational modelling; Deep reinforcement learning; Reinforcement learning; Reinforcement learnings; Computer graphics; Dynamic voltage; Frequency-scaling; Voltage frequency; Performances evaluation; deep reinforcement learning; Collaboration; collaborative inference; Collaborative inference; DVFS technology; Dynamic voltage frequency scaling technology; Scaling technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FV9YABRN","journalArticle","2022","Wang, S.; Yuen, C.; Ni, W.; Guan, Y.L.; Lv, T.","Multiagent Deep Reinforcement Learning for Cost- and Delay-Sensitive Virtual Network Function Placement and Routing","IEEE Transactions on Communications","","","10.1109/TCOMM.2022.3187146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133579989&doi=10.1109%2fTCOMM.2022.3187146&partnerID=40&md5=38e35eb2e9748640ce89a4a53678c3d7","This paper proposes an effective and novel multi-agent deep reinforcement learning (MADRL)-based method for solving the joint virtual network function (VNF) placement and routing (P&R), where multiple service requests with differentiated demands are delivered at the same time. The differentiated demands of the service requests are reflected by their delay- and cost-sensitive factors. We first construct a VNF P&R problem to jointly minimize a weighted sum of service delay and resource consumption cost, which is NP-complete. Then, the joint VNF P&R problem is decoupled into two iterative subtasks: placement subtask and routing subtask. Each subtask consists of multiple concurrent parallel sequential decision processes. By invoking the deep deterministic policy gradient method and multi-agent technique, an MADRL-P&R framework is designed to perform the two subtasks. The new joint reward and internal rewards mechanism is proposed to match the goals and constraints of the placement and routing subtasks. We also propose the parameter migration-based model-retraining method to deal with changing network topologies. Corroborated by experiments, the proposed MADRL-P&R framework is superior to its alternatives in terms of service cost and delay, and offers higher flexibility for personalized service demands. The parameter migration-based model-retraining method can efficiently accelerate convergence under moderate network topology changes. © 1972-2012 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","5208-5224","","8","70","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; Deep learning; Virtual reality; Virtual networks; Network functions; Transfer functions; Network function virtualization; Reinforcement learning; Reinforcement learnings; Optimisations; Multi agent systems; Delay; Routings; Network topology; Placement and routing; Network routing; Cost functions; E-learning; Gradient methods; Minimisation; Multi agent; multi-agent deep reinforcement learning; Multi-agent deep reinforcement learning; Virtual network function; virtual network functions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QG2WP8Y3","journalArticle","2021","Luo, J.; Li, J.; Jiao, L.; Cai, J.","On the Effective Parallelization and Near-Optimal Deployment of Service Function Chains","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2020.3043768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098782371&doi=10.1109%2fTPDS.2020.3043768&partnerID=40&md5=0230d22db125cebfb02db9741e8969f1","Network operators compose Service Function Chains (SFCs) by tying different network functions (e.g., packet inspection, flow shaping, network address translation) together and process traffic flows in the order the network functions are chained. Leveraging the technique of Network Function Virtualization (NFV), each network function can be 'virtualized' and decoupled from its dedicated hardware, and therefore can be deployed flexibly for better performance at any appropriate location of the underlying network infrastructure. However, an SFC often incurs high latency as traffic goes through the virtual network functions one after another. In this article, we first design an algorithm that leverages virtual network function dependency to convert an original SFC into a parallelized SFC (p-SFC). Then, to deploy multiple p-SFCs over the network for serving a large number of users, we model the deployment problem as an Integer Linear Program and propose a heuristic, ParaSFC, based on the Viterbi dynamic programming algorithm to estimate each p-SFC's occupation of the bottleneck resources and adjust the processing order of the p-SFCs in order to approximate the optimal solution. Finally, we conduct extensive trace-driven evaluations and exhibit that, compared to the Greedy method and the state-of-the-art CoordVNF method, ParaSFC reduces the average service latency of all the deployed p-SFCs by about 15 percent through parallelization while accommodating more SFC deployment requests over resource-limited networks.  © 1990-2012 IEEE.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","1238-1255","","5","32","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Virtual reality; Quality-of-service; Network operator; Virtual networks; Network functions; Transfer functions; Integer programming; Heuristic algorithms; Network function virtualization; Dynamic programming; quality of service; Deployment; deployment; Service functions; service function chain; Near-optimal; Optimal deployment; parallelization; Parallelizations; Service function chain; Viterbi algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8NBRBYE","conferencePaper","2017","Xiao, Y.; Xue, Y.; Nazarian, S.; Bogdan, P.","A load balancing inspired optimization framework for exascale multicore systems: A complex networks approach","","","","10.1109/ICCAD.2017.8203781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043503412&doi=10.1109%2fICCAD.2017.8203781&partnerID=40&md5=19a24624d0052b995a4680de4748a9da","Many-core multi-threaded performance is plagued by on-chip communication nonidealities, limited memory bandwidth, and critical sections. Inspired by complex network theory of social communities, we propose a novel methodology to model the dynamic execution of an application and partition the application into an optimal number of clusters for parallel execution. We first adopt an LLVM IR compiler analysis of a specific application and construct a dynamic application dependency graph encoding its computational and memory operations. Next, based on this graph, we propose an optimization model to find the optimal clusters such that (1) the intra-cluster edges are maximized, (2) the execution times of the clusters are nearly equalized, for load balancing, and (3) the cluster size does not exceed the core count. Our novel approach confines data movement to be mainly inside a cluster for power reduction and congestion prevention. Finally, we propose an algorithm to sort the graph of connected clusters topologically and map the clusters onto NoC. Experimental results on a 32-core NoC demonstrate a maximum speedup of 131.82% when compared to thread-based execution. Furthermore, the scalability of our framework makes it a promising software design automation platform. © 2017 IEEE.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","217-224","","","2017-November","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Software design; Parallel executions; Computation theory; Network-on-chip; Complex networks; Computer aided design; Topology; Dynamic applications; Design automations; Multi-core systems; On chip communication; Optimization framework; Optimization modeling; Social communities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD","","","","","","","","","","","","","","",""
"QWQFL5K6","journalArticle","2022","Guan, F.; Peng, L.; Qiao, J.","A Fluid Scheduling Algorithm for DAG Tasks With Constrained or Arbitrary Deadlines","IEEE Transactions on Computers","","","10.1109/TC.2021.3111512","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114739677&doi=10.1109%2fTC.2021.3111512&partnerID=40&md5=d061d3074485eaf1c5d2889f79a9f947","A number of scheduling algorithms have been proposed for real-time parallel tasks modeled as Directed Acyclic Graphs (DAGs). Many of them focus on scheduling DAG tasks with implicit deadlines. Fewer studies have considered DAG tasks with constrained deadlines or arbitrary deadlines. In this study, we propose a scheduling strategy based on fluid scheduling theory and we target DAG tasks with constrained or arbitrary deadlines. We prove that the proposed algorithm has a capacity augmentation bound of $\frac{1}{2}(1+\beta +\sqrt{(1+\beta)^2-\frac{4}{m}})$12(1+β+(1+β)2-4m) when scheduling multiple DAG tasks with constrained deadlines, in which $m$m is the number of processors and $\beta$β is the maximum ratio of task period to deadline. This value is lower than the current best result $\beta +2\sqrt{(\beta +1-\frac{1}{m})(1-\frac{1}{m})}$β+2(β+1-1m)(1-1m). We also prove that a capacity augmentation bound of $\frac{1}{2}(1+\sqrt{2}+\sqrt{(1+\sqrt{2})^2-\frac{4\sqrt{2}}{m}})$12(1+2+(1+2)2-42m) is guaranteed by our algorithm in the case of scheduling multiple DAG tasks with deadlines greater than periods. To the best of our knowledge, this is the first capacity augmentation bound that has been proven for scheduling multiple DAG tasks with deadlines greater than periods. Our experiments show that our algorithm outperforms the state of the art scheduling algorithms in the percentage of schedulable task sets.  © 1968-2012 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","1860-1873","","8","71","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; State of the art; Directed graphs; Directed acyclic graphs; Real time; Graph algorithms; multi-processor system; parallel task; Parallel task; Real-time scheduling; Arbitrary deadlines; Maximum ratio; Scheduling strategies; Scheduling theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ349W2V","journalArticle","2010","Ge, R.; Feng, X.; Song, S.; Chang, H.-C.; Li, D.; Cameron, K.W.","PowerPack: Energy profiling and analysis of high-performance systems and applications","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2009.76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950629423&doi=10.1109%2fTPDS.2009.76&partnerID=40&md5=d1073f75a6d11d21af117f3d2c0cde9d","Energy efficiency is a major concern in modern high-performance computing system design. In the past few years, there has been mounting evidence that power usage limits system scale and computing density, and thus, ultimately system performance. However, despite the impact of power and energy on the computer systems community, few studies provide insight to where and how power is consumed on high-performance systems and applications. In previous work, we designed a framework called PowerPack that was the first tool to isolate the power consumption of devices including disks, memory, NICs, and processors in a high-performance cluster and correlate these measurements to application functions. In this work, we extend our framework to support systems with multicore, multiprocessor-based nodes, and then provide in-depth analyses of the energy consumption of parallel applications on clusters of these systems. These analyses include the impacts of chip multiprocessing on power and energy efficiency, and its interaction with application executions. In addition, we use PowerPack to study the power dynamics and energy efficiencies of dynamic voltage and frequency scaling (DVFS) techniques on clusters. Our experiments reveal conclusively how intelligent DVFS scheduling can enhance system energy efficiency while maintaining performance. © 2010 IEEE.","2010","2025-10-22 19:07:35","2025-10-22 19:07:35","","658-671","","5","21","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Multi core; Distributed systems; Energy management; Energy consumption; Electric power measurement; Computer systems; Parallel application; Power managements; Power usage; Dynamic voltage and frequency scaling; Power measurement; In-depth analysis; Application execution; Application functions; Chip multiprocessing; CMP-based cluster; Distributed system; Energy profiling; High performance computing systems; High performance systems; High-performance clusters; Measurements; Nanotechnology; Power Consumption; Power dynamics; Support systems; System energy; System tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FA6L3IUC","journalArticle","2017","Fu, T.Z.J.; Ding, J.; Ma, R.T.B.; Winslett, M.; Yang, Y.; Zhang, Z.","DRS: Auto-Scaling for Real-Time Stream Analytics","IEEE/ACM Transactions on Networking","","","10.1109/TNET.2017.2741969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029168732&doi=10.1109%2fTNET.2017.2741969&partnerID=40&md5=387f66002bc59eb98878e9b444d156c8","In a stream data analytics system, input data arrive continuously and trigger the processing and updating of analytics results. We focus on applications with real-time constraints, in which, any data unit must be completely processed within a given time duration. To handle fast data, it is common to place the stream data analytics system on top of a cloud infrastructure. Because stream properties, such as arrival rates can fluctuate unpredictably, cloud resources must be dynamically provisioned and scheduled accordingly to ensure real-time responses. It is essential, for existing systems or future developments, to possess the ability of scaling resources dynamically according to the instantaneous workload, in order to avoid wasting resources or failing in delivering the correct analytics results on time. Motivated by this, we propose DRS, a dynamic resource scaling framework for cloud-based stream data analytics systems. DRS overcomes three fundamental challenges: 1 how to model the relationship between the provisioned resources and the application performance, 2 where to best place resources, and 3 how to measure the system load with minimal overhead. In particular, DRS includes an accurate performance model based on the theory of Jackson open queueing networks and is capable of handling arbitrary operator topologies, possibly with loops, splits, and joins. Extensive experiments with real data show that DRS is capable of detecting sub-optimal resource allocation and making quick and effective resource adjustment. © 2017 IEEE.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","3338-3352","","6","25","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Cloud computing; Program processors; Distributed computer systems; Real time systems; Computation theory; Data reduction; Interactive computer systems; Feature extraction; Topology; Electronic mail; Queueing networks; Queueing theory; Dynamic scheduling; Optimal scheduling; queueing network model; Queueing network model; resource auto-scaling; Stream data; stream data analytics; Termsa-Cloud computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SK6UHY5F","journalArticle","2021","Ma, G.; Xiao, Y.; Willke, T.; Ahmed, N.; Nazarian, S.; Bogdan, P.","A distributed graph-theoretic framework for automatic parallelization in multi-core systems","Proc. Mach. Learn. Syst.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130032940&partnerID=40&md5=bedf4e54b873e424d70a9e1124f727d8","","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","550-568","","","3","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"899IR9GY","journalArticle","2013","","What is big data? Bringing big data to the enterprise","What Is Big Data? Bringing Big Data to the Enterprise","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898602221&partnerID=40&md5=19231e4d37d6599c5ed33bebbc7200c8","","2013","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGVFCTMK","journalArticle","2021","Guan, F.; Qiao, J.; Han, Y.","DAG-Fluid: A Real-Time Scheduling Algorithm for DAGs","IEEE Transactions on Computers","","","10.1109/TC.2020.2990282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101446740&doi=10.1109%2fTC.2020.2990282&partnerID=40&md5=2857fd5fc0f496cb0b6f078555d6a2f2","Various scheduling algorithms have been proposed for real-time parallel tasks modeled as a Directed Acyclic Graph (DAG). The capacity augmentation bound is a quantitative metric widely used in this field to compare the algorithms. Among the existing algorithms, the lowest capacity augmentation bound for DAG tasks with implicit deadlines is 2, which has been achieved by federated scheduling. To improve the schedulability and lower the capacity augmentation bound, this paper proposes DAG-Fluid, an algorithm based on fluid scheduling. We prove that DAG-Fluid has a capacity augmentation bound of $2-\frac{1}{m+1}$2-1m+1, in which $m$m is the number of processors in the system. Experiments show that DAG-Fluid performs better than the state of the art scheduling algorithms.  © 1968-2012 IEEE.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","471-482","","3","70","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Real time systems; State of the art; Directed graphs; Real time; Graph algorithms; Directed acyclic graph (DAG); multi-processor system; parallel task; Parallel task; Quantitative metric; Real-time scheduling; Real-time scheduling algorithms; Schedulability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ET7SM3RW","journalArticle","2017","Marotta, A.; D'Andreagiovanni, F.; Kassler, A.; Zola, E.","On the energy cost of robustness for green virtual network function placement in 5G virtualized infrastructures","Computer Networks","","","10.1016/j.comnet.2017.04.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019009444&doi=10.1016%2fj.comnet.2017.04.045&partnerID=40&md5=8d4da6071f8a9805794af4cb7b95b6b9","Next generation 5G networks will rely on virtualized Data Centers (vDC) to host virtualized network functions on commodity servers. Such Network Function Virtualization (NFV) will lead to significant savings in terms of infrastructure cost and reduced management complexity. However, green strategies for networking and computing inside data centers, such as server consolidation or energy aware routing, should not negatively impact the quality and service level agreements expected from network operators. In this paper, we study how robust strategies that place virtual network functions (VNF) inside vDC impact the energy savings and the protection level against resource demand uncertainty. We propose novel optimization models that allow the minimization of the energy of the computing and network infrastructure which is hosting a set of service chains that implement the VNFs. The model explicitly provides for robustness to unknown or imprecisely formulated resource demand variations, powers down unused routers, switch ports and servers, and calculates the energy optimal VNF placement and network embedding also considering latency constraints on the service chains. We propose both exact and heuristic methods. Our experiments were carried out using the virtualized Evolved Packet Core (vEPC), which allows us to quantitatively assess the trade-off between energy cost, robustness and the protection level of the solutions against demand uncertainty. Our heuristic is able to converge to a good solution in a very short time, in comparison to the exact solver, which is not able to output better results in a longer run as demonstrated by our numerical evaluation. We also study the degree of robustness of a solution for a given protection level and the cost of additional energy needed because of the usage of more computing and network elements. © 2017 Elsevier B.V.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","64-75","","","125","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Optimization; Virtual reality; Virtualization; Service Level Agreements; Economic and social effects; Green computing; 5G mobile communication systems; Transfer functions; Energy conservation; Power management (telecommunication); Network function virtualization; Costs; Chains; Network infrastructure; Virtualized data centers; Heuristic methods; 5G; Energy-aware routing; Linear programming; Binary linear programming; Degree of robustness; EPC; Management complexity; Network function virtualization (NFV); Robust optimization; Uncertainty analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBE5VHNK","journalArticle","2022","Hazra, A.; Adhikari, M.; Amgoth, T.; Srirama, S.N.","Intelligent Service Deployment Policy for Next-Generation Industrial Edge Networks","IEEE Transactions on Network Science and Engineering","","","10.1109/TNSE.2021.3122178","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118557915&doi=10.1109%2fTNSE.2021.3122178&partnerID=40&md5=00a1e344f0b7b81124625443e28e4c9d","Edge computing has appeared as a promising technology for realizing industrial computation data at the edge of the network. The fundamental challenge in edge-enabled industrial networks is how to deploy the service requests while utilizing the available edge resources efficiently. In this paper, we aim to design an intelligent service deployment strategy for simultaneously handling both Industrial Internet of Things (IIoT) generated dynamic service requests and edge resources in the next-generation industrial networks. Initially, we present the objective function as the mixed-integer nonlinear programming problem for optimizing the weighted energy-delay in the edge environment. To accomplish this objective, we model a heuristic-based task execution strategy and exploit the advantage of Deep Reinforcement Learning (DRL) to make accurate decisions in industrial networks. The proposed DRL-based strategy can learn well to control the industrial networks from its own experience and guarantees to handle as many service requests as possible using the set of available resource constraint edge servers. Experimental analysis reveals that the proposed strategy is robust to network changes and achieves better performance than existing algorithms in terms of energy consumption up to 13%, delay minimization by 23%, and other Quality of Service (QoS) parameters.  © 2013 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","3057-3066","","5","9","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Deep learning; Energy utilization; Internet of things; Economic and social effects; Quality-of-service; Edge computing; Energy-consumption; Green computing; Integer programming; edge computing; Computational modelling; Deep reinforcement learning; Industrial internet of thing; Job analysis; Reinforcement learning; Reinforcement learnings; Task analysis; energy efficiency; Quality control; Service deployment; Delay; Nonlinear programming; deep reinforcement learning; industrial networks; Industrial networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98589IF3","journalArticle","2022","Casas-Velasco, D.M.; Rendon, O.M.C.; Da Fonseca, N.L.S.","DRSIR: A Deep Reinforcement Learning Approach for Routing in Software-Defined Networking","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2021.3132491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120854771&doi=10.1109%2fTNSM.2021.3132491&partnerID=40&md5=99374df5ada0208d2bec3614dfd64d5b","Traditional routing protocols employ limited information to make routing decisions, which leads to slow adaptation to traffic variability and restricted support to the quality of service requirements of applications. To address these shortcomings, in previous work, we proposed RSIR, a routing solution based on Reinforcement Learning (RL) in Software-Defined Networking (SDN). However, RL-based solutions usually suffer an increase in time during the learning process when dealing with large action and state spaces. This paper introduces a different routing approach, called Deep Reinforcement Learning and Software-Defined Networking Intelligent Routing (DRSIR). DRSIR defines a routing algorithm based on Deep RL (DRL) in SDN that overcomes the limitations of RL-based solutions. DRSIR considers path-state metrics to produce proactive, efficient, and intelligent routing that adapts to dynamic traffic changes. DRSIR was evaluated by emulation using real and synthetic traffic matrices. The results show that this solution outperforms the routing algorithms based on Dijkstra's algorithm and RSIR in relation to stretch, packet loss, and delay. Moreover, the results obtained demonstrate that DRSIR provides a practical and feasible solution for routing in SDN.  © 2004-2012 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","4807-4820","","4","19","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Application programs; Deep learning; Computer architecture; Network architecture; Computational modelling; Deep reinforcement learning; Reinforcement learning; Reinforcement learnings; Neural networks; Topology; Routings; Network topology; Software defined networking; Software-defined networkings; routing; Network routing; Intelligent routing; software defined networking; Software-defined networking.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"239F9K5S","journalArticle","2021","Wang, Y.; Huang, C.-K.; Shen, S.-H.; Chiu, G.-M.","Adaptive Placement and Routing for Service Function Chains with Service Deadlines","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2021.3086977","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111010229&doi=10.1109%2fTNSM.2021.3086977&partnerID=40&md5=49330c4614bc2296270223e3633e8f9c","Network Function Virtualization (NFV) pushes the hardware-based network functions to generic servers as software and brings a highly flexible for deployment. The availability of Virtual Machines (VMs) enables the dynamic placement of Virtual Network Functions (VNFs) on demand, and it can reduce a large number of manual configuration processes that increase deployment efficiency. However, some services require more than one VNF to process. Therefore, the network flows need to traverse a set of sequential network functions called Service Function Chain (SFC). How to efficiently route traffic along service function chain and place VNFs in a network under operational constraints is a crucial issue. In this paper, we must overcome two challenges: (1) determining a flow path that traverses suitable network functions in the required order to meet the requirement of services, and (2) considering network loading and other dynamic characteristics when traffic is routed through existing VNFs. Thus, we present methods to solve the routing and placement problems for the service function chain. Our solutions transform the network representation to a virtual layered graph that considers NFV processing latency and allows conventional shortest path algorithms to solve the problem. We are not only pursuing high success rates to serve more flows but also taking into account the execution time of the algorithms.  © 2004-2012 IEEE.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","3021-3036","","3","18","","","","","","","","","","","","","Scopus","","","","","","","","Transfer functions; Network function virtualization; Graph theory; scheduling; Placement problems; Service functions; Placement and routing; routing; network function virtualization (NFV); service function chain (SFC); Configuration process; Dynamic characteristics; Graph algorithms; Network representation; Operational constraints; Shortest path algorithms; Software-defined networking (SDN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DP96VHC2","journalArticle","2024","Xu, B.; Guo, J.; Ma, F.; Hu, M.; Liu, W.; Peng, K.","On the Joint Design of Microservice Deployment and Routing in Cloud Data Centers","Journal of Grid Computing","","","10.1007/s10723-024-09759-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188655111&doi=10.1007%2fs10723-024-09759-1&partnerID=40&md5=4f644c5b031b06eb5798982d5f32a085","In recent years, internet enterprises have transitioned from traditional monolithic service to microservice architecture to better meet evolving business requirements. However, it also brings great challenges to the resource management of service providers. Existing research has not fully considered the request characteristics of internet application scenarios. Some studies apply traditional task scheduling models and strategies to microservice scheduling scenarios, while others optimize microservice deployment and request routing separately. In this paper, we propose a microservice instance deployment algorithm based on genetic and local search, and a request routing algorithm based on probabilistic forwarding. The service graph with complex dependencies is decomposed into multiple service chains, and the open Jackson queuing network is applied to analyze the performance of the microservice system. Data evaluation results demonstrate that our scheme significantly outperforms the benchmark strategy. Our algorithm has reduced the average response latency by 37%-67% and enhanced request success rate by 8%-115% compared to other baseline algorithms. © The Author(s), under exclusive licence to Springer Nature B.V. 2024.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","2","22","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Resource management; Cloud data centers; Service dependency; Business requirement; Routings; Request routing; Joint designs; Monolithics; Service dependencies; Service placement; Service placements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZHYQHI4Z","journalArticle","2017","Mao, Y.; You, C.; Zhang, J.; Huang, K.; Letaief, K.B.","A Survey on Mobile Edge Computing: The Communication Perspective","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2017.2745201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028734877&doi=10.1109%2fCOMST.2017.2745201&partnerID=40&md5=6d1262992dcf95ea5c521e168f340065","Driven by the visions of Internet of Things and 5G communications, recent years have seen a paradigm shift in mobile computing, from the centralized mobile cloud computing toward mobile edge computing (MEC). The main feature of MEC is to push mobile computing, network control and storage to the network edges (e.g., base stations and access points) so as to enable computation-intensive and latency-critical applications at the resource-limited mobile devices. MEC promises dramatic reduction in latency and mobile energy consumption, tackling the key challenges for materializing 5G vision. The promised gains of MEC have motivated extensive efforts in both academia and industry on developing the technology. A main thrust of MEC research is to seamlessly merge the two disciplines of wireless communications and mobile computing, resulting in a wide-range of new designs ranging from techniques for computation offloading to network architectures. This paper provides a comprehensive survey of the state-of-the-art MEC research with a focus on joint radio-and-computational resource management. We also discuss a set of issues, challenges, and future research directions for MEC research, including MEC system deployment, cache-enabled MEC, mobility management for MEC, green MEC, as well as privacy-aware MEC. Advancements in these directions will facilitate the transformation of MEC from theory to practice. Finally, we introduce recent standardization efforts on MEC as well as some typical MEC application scenarios. © 1998-2012 IEEE.","2017","2025-10-22 19:07:35","2025-10-22 19:07:35","","2322-2358","","4","19","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; resource management; Resource management; Energy utilization; Network architecture; Edge computing; Surveys; Mobile computing; Computation offloading; Mobile cloud computing; Mobile telecommunication systems; Computation theory; Green computing; Mobile edge computing; 5G mobile communication systems; computation offloading; fog computing; green computing; mobile cloud computing; Mobile communications; Natural resources management; Resource allocation; Wireless communications; Wireless telecommunication systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Y8JZKCF","journalArticle","2022","Nemeth, B.; Molner, N.; Martin-Perez, J.; Bernardos, C.J.; De La Oliva, A.; Sonkoly, B.","Delay and Reliability-Constrained VNF Placement on Mobile and Volatile 5G Infrastructure","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2021.3055426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100456492&doi=10.1109%2fTMC.2021.3055426&partnerID=40&md5=ee15f63ddb408daf7356f39912386746","Ongoing research and industrial exploitation of SDN and NFV technologies promise higher flexibility on network automation and infrastructure optimization. Choosing the location of Virtual Network Functions is a central problem in the automation and optimization of the software-defined, virtualization-based next generation of networks such as 5G and beyond. Network services provided for autonomous vehicles, factory automation, e-health and cloud robotics often require strict delay bounds and reliability constraints influenced by the location of its composing Virtual Network Functions. Robots, vehicles and other end-devices provide significant capabilities such as actuators, sensors and local computation which are essential for some services. Moreover, these devices are continuously on the move and might lose network connection or run out of battery, which further challenge service delivery in this dynamic environment. This work tackles the mobility, and battery restrictions; as well as the temporal aspects and conflicting traits of reliable, low latency service deployment over a volatile network, where mobile compute nodes act as an extension of the cloud and edge computing infrastructure. The problem is formulated as a cost-minimizing Virtual Network Function placement optimization and an efficient heuristic is proposed. The algorithms are extensively evaluated from various aspects by simulation on detailed real-world scenarios. © 2002-2012 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","3150-3162","","9","21","","","","","","","","","","","","","Scopus","","","","","","","","Dynamic environments; Optimization; Infrastructure as a service (IaaS); cloud; Industrial research; 5G mobile communication systems; Transfer functions; Network function virtualization; Placement optimization; optimization; Service deployment; edge; Computing infrastructures; 5G; VNF placement; Real-world scenario; Factory automation; Network automations; Next generation of network; Reliability constraints; robots; Secondary batteries; URLLC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WGIVFCZ7","journalArticle","2024","Hu, M.; Guo, Z.; Wen, H.; Wang, Z.; Xu, B.; Xu, J.; Peng, K.","Collaborative Deployment and Routing of Industrial Microservices in Smart Factories","IEEE Transactions on Industrial Informatics","","","10.1109/TII.2024.3424347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202445680&doi=10.1109%2fTII.2024.3424347&partnerID=40&md5=a923af3067b1dafbf4d6b476432bdb1c","In large smart factories, massive microservices compose complicated modular IT systems, providing various service functions. However, large microservices-based IT systems incur sophisticated communications and invocations among the massive microservices, which calls for efficient orchestration techniques to meet the high requirements in smart factories. Also, complex data interdependencies among microservices tightly couple deployment with routing, further intensifying the difficulties in orchestration. Such challenges demand delicate joint optimization of service deployment and request routing, which however, are neglected by previous work. In this case, this article investigates the collaborative optimization of microservice deployment and routing in smart factories. First, we construct a communication queuing network model to analyze service performance under dynamic load. Second, two heuristics are proposed to provide differentiated deployment and routing schemes for various demands. Finally, rigorous experiments validate that our approach significantly enhances network efficiency across various production scenarios in smart factories.  © 2005-2012 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","12758-12770","","11","20","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Joint optimization; Queueing networks; Service deployment; Routings; IT system; Service functions; request routing; Request routing; service deployment; Complex data; Modulars; Queuing network; queuing networks; smart factory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PNW7UWC","journalArticle","","","","Alibab cluster data","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216655226&partnerID=40&md5=d8996e093749339f4bff73a32384598e","","","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTEIUB4H","journalArticle","2022","Lv, W.; Wang, Q.; Yang, P.; Ding, Y.; Yi, B.; Wang, Z.; Lin, C.","Microservice Deployment in Edge Computing Based on Deep Q Learning","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2022.3150311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124746898&doi=10.1109%2fTPDS.2022.3150311&partnerID=40&md5=ed190a294b1f4bb5c1840c962fd259f4","The microservice deployment strategy is promising in reducing the overall service response time in the microservice-oriented edge computing platform. However, existing works ignore the effect of different interaction frequencies among microservices and the decrease in service execution performance caused by the increased node loads. In this article, we first model the invocation relationships among microservices as an undirected and weighted interaction graph to characterize the communication overhead. Then, we propose a multi-objective microservice deployment problem (MMDP) in edge computing. MMDP aims to minimize the communication overhead while achieving load balance between edge nodes. Without the requirement for domain experts, we propose Reward Sharing Deep Q Learning (RSDQL), a learning-based algorithm, to solve MMDP and obtain the optimal deployment strategy. In addition, to improve the scalability of the services, we propose an Elastic Scaling algorithm (ES) based on heuristics to deal with the dynamic pressure of requests. Finally, we conduct a series of experiments in Kubernetes to evaluate the performance of our approach. Experimental results indicate that, compared with interaction-aware strategy and Kubernetes default strategy, RSDQL has shorter response times, more balanced resource loads, and makes services scale elastically according to the request pressure. © 1990-2012 IEEE.","2022","2025-10-22 19:07:35","2025-10-22 19:07:35","","2968-2978","","11","33","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Deep learning; Edge computing; Learning algorithms; Reinforcement learning; Elastic scaling; load balancing; Multi objective; Scalings; deep Q learning; Deep Q learning; elastic scaling; interaction awareness; Interaction awareness; Load-Balancing; multi-objective model; Multiobjective modeling; Q-learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDRI258D","journalArticle","","","DAPR","Microsoft","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002381577&partnerID=40&md5=0ab337a6605031f498d47b70ef5bf467","","","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IUWR593Z","journalArticle","2024","Peng, K.; Wang, L.; He, J.; Cai, C.; Hu, M.","Joint Optimization of Service Deployment and Request Routing for Microservices in Mobile Edge Computing","IEEE Transactions on Services Computing","","","10.1109/TSC.2024.3349408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181562777&doi=10.1109%2fTSC.2024.3349408&partnerID=40&md5=1480f033711980d5b0d0ad57dc8d3105","Microservices as an emerging architecture are creating new opportunities to enable superior network services in Mobile Edge Computing (MEC). In the presence of huge amounts of user requests, the massive communications among microservices have become notoriously complicated. Due to the intricate data dependencies of the microservices, the overall performance of large-scale MEC applications simultaneously depends on both service deployment and request routing. However, most existing work ignores the interdependencies of microservices and studies the deployment and routing as two isolated problems. In this case, this article investigates the joint optimization of service deployment and request routing in edge computing. We first formulate a delay minimization problem via mixed integer linear programming and queuing analysis, and then provide a hardness proof on the problem. In addition, this article presents a 2-approximation algorithm, followed with rigorous mathematical proofs to demonstrate the approximation ratio. The proposed two-phase algorithm consists of rounding based service deployment and adaptive-scaling-based request routing policies, which employ fine grained joint optimization to minimize service response delay. Finally, we illustrate the near-optimal performance of the proposed algorithm via comprehensive experiments.  © 2008-2012 IEEE.","2024","2025-10-22 19:07:35","2025-10-22 19:07:35","","1016-1028","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","Computer architecture; Network architecture; Mobile computing; Mobile edge computing; Integer programming; Heuristic algorithms; Approximation algorithms; Microservice architecture; Service computing; Service deployment; Delay; Heuristics algorithm; mobile computing; Routings; Queueing analysis; request routing; Request routing; service deployment; approximation; Approximation; Mobile-computing; Routing algorithms; Services computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LM8B2YGT","journalArticle","2018","Liu, L.; Chang, Z.; Guo, X.; Mao, S.; Ristaniemi, T.","Multiobjective Optimization for Computation Offloading in Fog Computing","IEEE Internet of Things Journal","","","10.1109/JIOT.2017.2780236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038366106&doi=10.1109%2fJIOT.2017.2780236&partnerID=40&md5=605cb33fa35e39deb25888c36a3361d1","Fog computing system is an emergent architecture for providing computing, storage, control, and networking capabilities for realizing Internet of Things. In the fog computing system, the mobile devices (MDs) can offload its data or computational expensive tasks to the fog node within its proximity, instead of distant cloud. Although offloading can reduce energy consumption at the MDs, it may also incur a larger execution delay including transmission time between the MDs and the fog/cloud servers, and waiting and execution time at the servers. Therefore, how to balance the energy consumption and delay performance is of research importance. Moreover, based on the energy consumption and delay, how to design a cost model for the MDs to enjoy the fog and cloud services is also important. In this paper, we utilize queuing theory to bring a thorough study on the energy consumption, execution delay, and payment cost of offloading processes in a fog computing system. Specifically, three queuing models are applied, respectively, to the MD, fog, and cloud centers, and the data rate and power consumption of the wireless link are explicitly considered. Based on the theoretical analysis, a multiobjective optimization problem is formulated with a joint objective to minimize the energy consumption, execution delay, and payment cost by finding the optimal offloading probability and transmit power for each MD. Extensive simulation studies are conducted to demonstrate the effectiveness of the proposed scheme and the superior performance over several existed schemes are observed. © 2014 IEEE.","2018","2025-10-22 19:07:35","2025-10-22 19:07:35","","283-294","","1","5","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Cloud computing; Distributed computer systems; Energy utilization; Internet of things; Edge computing; Mobile cloud computing; Mobile telecommunication systems; Computation theory; Green computing; fog computing; Mobile communications; Digital storage; Costs; Cost benefit analysis; Multiobjective optimization; energy consumption; Queueing theory; Fog; Delays; Computational model; cost; execution delay; offloading probability; power allocation; Power allocations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIJFZS2H","journalArticle","2020","Qu, L.; Assi, C.; Khabbaz, M.J.; Ye, Y.","Reliability-Aware Service Function Chaining with Function Decomposition and Multipath Routing","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2019.2961153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086637787&doi=10.1109%2fTNSM.2019.2961153&partnerID=40&md5=f60f858a9e20e96f9c81077a837ac08c","Network Function Virtualization (NFV) converts network functions executed by costly middleboxes into instances of Virtual Network Functions (VNFs) hosted by industry-standard Physical Machines (PMs). This has proven to be quite an efficient approach when it comes to enabling automated network operations and the elastic provisioning of resources to support heterogeneous services. Today's revolutionary services impose a remarkably elevated reliability together with ultra-low latency requirements. Therefore, in addition to having highly reliable VNFs, these VNFs have to be optimally placed in such a way to rapidly route traffic among them with the least utilization of bandwidth. Hence, the proper selection of PMs to meet the above-mentioned reliability and delay requirements becomes a remarkably challenging problem. None of the existing publications addressing such a problem concurrently adopts VNF decomposition to enhance the flexibility of the VNFs' placement and a hybrid routing scheme to achieve an optimal trade-off between the above-mentioned objectives. In this paper, a VNF-decomposition-based backup strategy is proposed together with a delay-aware hybrid multipath routing scheme for enhancing the reliability of NFV-enabled network services while jointly reducing delays these services experience. The problem is formulated as a Mixed Integer Linear Program (MILP) whose resolution yields an optimal VNF placement and traffic routing policy. Next, the delay-aware hybrid shortest path-based heuristic algorithm is proposed to work around the MILP's complexity. Thorough numerical analysis and simulations are conducted to validate the proposed algorithm and evaluate its performance. Results show that the proposed algorithm outperforms its existing counterparts by 7.53% in terms of computing resource consumption. © 2019 IEEE.","2020","2025-10-22 19:07:35","2025-10-22 19:07:35","","835-848","","2","17","","","","","","","","","","","","","Scopus","","","","","","","","Economic and social effects; Industry standards; Transfer functions; Integer programming; Heuristic algorithms; Network function virtualization; Routing protocols; optimization; Reliability; delay; Analysis and simulation; Function decomposition; Heterogeneous services; Mixed integer linear program; Multi path routing; Multi-path routing schemes; multipath routing; network functions decomposition; Network operations; Network routing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CADDX64N","journalArticle","2021","Varasteh, A.; Madiwalar, B.; Van Bemten, A.; Kellerer, W.; Mas-Machuca, C.","Holu: Power-Aware and Delay-Constrained VNF Placement and Chaining","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2021.3055693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100498450&doi=10.1109%2fTNSM.2021.3055693&partnerID=40&md5=40d10ec633bf722773b2c1cd333c1b17","Service function chains (SFCs) are an ordered set of virtual network functions (VNFs) which can realize a specific network service. Enabled by virtualization technologies, these VNFs are hosted on physical machines (PMs), and interconnected by network switches. In today networks, these resources are usually under-utilized and/or over-provisioned, resulting in power-inefficient deployments. To improve power-efficiency, SFCs should be deployed utilizing the minimum number of PMs and network equipment, which are not concomitant. Considering the existing PM and switch power consumption models and their resource constraints, we formulate the power-aware and delay-constrained joint VNF placement and routing (PD-VPR) problem as an Integer Linear Program (ILP). Due to the NP-completeness of the problem, we propose Holu, a fast heuristic framework that efficiently solves the PD-VPR problem in an online manner. Specifically, Holu decomposes the PD-VPR into two sub-problems and solve them sequentially: i) a VNF placement problem that consists of mapping the VNFs to PMs using a centrality-based ranking method, and ii) a routing problem that efficiently splits the delay budget between consecutive VNFs of the SFC, and finds a Delay-Constrained Least-Cost (DCLC) shortest-path through the selected PMs (hosting VNFs) using the Lagrange Relaxation based Aggregated Cost (LARAC) algorithm. Our simulation results indicate that Holu outperforms the state-of-the-art algorithms in terms of total power consumption and acceptance rate by 24.7% and 31%, respectively.  © 2004-2012 IEEE.","2021","2025-10-22 19:07:35","2025-10-22 19:07:35","","1524-1539","","2","18","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Integer programming; Power management (telecommunication); Budget control; Resource Constraint; Total power consumption; energy efficiency; Virtualization technologies; State-of-the-art algorithms; VNF placement; power efficiency; Placement and routing; Delay constrained least cost; Integer linear programs; Lagrange relaxation; Power optimization; service function chaining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CE3JBVTN","journalArticle","2016","Sill, A.","The Design and Architecture of Microservices","IEEE Cloud Computing","","","10.1109/MCC.2016.111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997402736&doi=10.1109%2fMCC.2016.111&partnerID=40&md5=f4a9d927dbbe0c63632bfb31c6c8a4d1","Microservices are sweeping through cloud design architectures, at once embodying new trends and making use of previous paradigms. This column explores the basis for these trends in both modern and historical standards, and sets out a direction for the future of microservices development. © 2016 IEEE.","2016","2025-10-22 19:07:35","2025-10-22 19:07:35","","76-80","","5","3","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Microservices; Automation; Computer architecture; Network architecture; architecture; Architecture; automation; cloud; Clouds; containers; data; design; Design; Design architecture; networks; Networks (circuits); standards; Standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VU33NSBN","conferencePaper","2018","Zhou, L.; Chou, C.-H.; Bhuyan, L.N.; Ramakrishnan, K.K.; Wong, D.","Joint server and network energy saving in data centers for latency-sensitive applications","","","","10.1109/IPDPS.2018.00079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052245147&doi=10.1109%2fIPDPS.2018.00079&partnerID=40&md5=7fc7ec89939d770e61f46cf47eafbebd","Achieving energy proportionality in data centers supporting latency-sensitive applications is challenging because of the strict Service Level Agreements. Previous works individually focus on making the server energy proportional or reducing the data center network's power consumption for latency-Tolerant applications. In this paper, we propose EPRONS to minimize the overall data center's power consumption with latency-sensitive applications by trading-off network slack in favor of providing additional slack for computations. We utilize the linear programming model to consolidate latency-sensitive search queries and latency-Tolerant background flows to a minimal subnet of the topology by turning off unused switches and links without violating the application deadlines. Servers take advantage of the additional 'network-provided' slack to allow slowing down request processing. For servers, we design a novel power saving technique using Dynamic Voltage and Frequency Scaling (DVFS) based on the average tail latency of a request. If needed, we turn on a minimal number of additional network links and switches to reduce network latency while still maximizing entire data center's power saving. Experimental results show that our scheme saves up to 31.25% of a data center's total power budget. © 2018 IEEE.","2018","2025-10-22 19:07:35","2025-10-22 19:07:35","","700-709","","","","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Electric power utilization; Service Level Agreements; Green computing; Dynamic frequency scaling; Energy conservation; Data centers; Budget control; Energy proportionalities; Topology; Dynamic voltage and frequency scaling; DVFS; Data Center; Energy Proportional; Latency-Sensitive; Linear programming; Linear programming models; Traffic Consolidation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2018 IEEE 32nd International Parallel and Distributed Processing Symposium, IPDPS 2018","","","","","","","","","","","","","","",""
"SF26YRGF","conferencePaper","2019","Gedeon, J.; Wagner, M.; Heuschkel, J.; Wang, L.; Muhlhauser, M.","A microservice store for efficient edge offloading","","","","10.1109/GLOBECOM38437.2019.9014114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078267072&doi=10.1109%2fGLOBECOM38437.2019.9014114&partnerID=40&md5=8142f21ef34e01d2675b526cc53336b5","Current edge computing frameworks require tight coupling between mobile clients and surrogates, i.e., the offloaded code has been preconfigured with its required execution environment. In many cases, this includes prior transfers of code blocks or execution environments from mobile devices to the offloading infrastructure. This approach incurs additional latency and is detrimental for the energy consumption of the mobile devices. In this paper, we propose the concept of a microservice store. Using the microservice abstraction common in software development and following the serverless paradigm, we envision a repository through which said services are made accessible to developers and can be re-used across applications. We implement a proof-of-concept edge computing system based on a microservice repository and demonstrate its benefits with real-world applications on mobile devices. Our results show that we were able to reduce latencies by up to 14x and save up to 94% of battery life. © 2019 IEEE.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Codes (symbols); Microservice; Microservices; Energy utilization; Serverless; Software design; Cyber foraging; Edge computing; Computation offloading; computation offloading; Computing frameworks; Fog computing; Execution environments; 'current; Mobile client; Tight coupling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Global Communications Conference, GLOBECOM","","","","","","","","","","","","","","",""
"NRS2X7PY","journalArticle","2019","Jin, P.; Hao, X.; Wang, X.; Yue, L.","Energy-efficient task scheduling for cpu-intensive streaming jobs on hadoop","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2018.2881176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056563947&doi=10.1109%2fTPDS.2018.2881176&partnerID=40&md5=8261e99b441c86172b6945e2365de31a","Hadoop, especially Hadoop 2.0, has been a dominant framework for real-Time big data processing. However, Hadoop is not optimized for energy efficiency. Aiming to solve this problem, in this paper, we propose a new framework to improve the energy efficiency of Hadoop 2.0. We focus on the resource manager in Hadoop 2.0, namely YARN, and propose energy-efficient task scheduling mechanisms on YARN. Particularly, we focus on CPU-intensive streaming jobs and classify streaming jobs into two types, namely batch streaming jobs (i.e., a set of jobs are submitted simultaneously) and online streaming jobs (i.e., jobs are continuously submitted one by one). We devise different energy-efficient task scheduling algorithms for each kind of streaming jobs. Specially, we first propose to abstractly model performance and energy consumption by considering the characteristics of tasks as well as the computational resources in YARN. Based on this model, we study the energy efficiency of streaming tasks which consist of the performance model and energy consumption model of task. We propose two key principles for improving energy efficiency: 1) CPU usage aware task allocation, partitions tasks to NMs based on the task characteristic in term of CPU usage; and 2) resource efficient task allocation, reduce idle resource. Then, we propose a D-based binning algorithm for the batch task scheduling and K-based binning algorithm for the online task scheduling that can adapt to continuously arriving tasks. We conduct extensive experiments on a real Hadoop 2.0 cluster and use two kinds of workloads to evaluate the performance and energy efficiency of our proposal. Compared with Storm (the streaming data processing tool in Hadoop 2.0) and other approaches including TAPA and DVFS-MR, our proposal is more energy efficient. The batch task scheduling algorithm reduces up to 10 percent of energy consumption and keeps comparable performance. In addition, the online task scheduling algorithm reduces up to 7 percent over the existing algorithms. © 1990-2012 IEEE.","2019","2025-10-22 19:07:35","2025-10-22 19:07:35","","1298-1311","","6","30","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Multitasking; Big data; Energy utilization; Green computing; Servers; Data handling; Scheduling algorithms; Job analysis; Processor scheduling; Task analysis; Computational resources; Hadoop; scheduling algorithms; Model performance; Resource managers; Resource-efficient; Task-scheduling algorithms; Wool; Yarn; YARN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YDFNW4IX","journalArticle","2021","Petrocelli, D.; De Giusti, A.; Naiouf, M.","Collaborative, distributed, scalable and low-cost platform based on microservices, containers, mobile devices and cloud services to solve compute-intensive tasks","Proc. Eur. Conf. Parallel Process.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002370244&partnerID=40&md5=1c5d75ca542955c2f0cc3ccc0c0a0402","","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","545-548","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JAZ3PPP6","conferencePaper","2019","Bermejo, B.; Juiz, C.; Guerrero, C.","On the Linearity of Performance and Energy at Virtual Machine Consolidation: The CiS2 Index for CPU Workload in Server Saturation","","","","10.1109/HPCC/SmartCity/DSS.2018.00154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062433188&doi=10.1109%2fHPCC%2fSmartCity%2fDSS.2018.00154&partnerID=40&md5=14f92fbad14e438cfffe87d51844b465","HPC-based datacenters consume significant energy, despite of a multitude of efforts in reducing it. Virtual Machine Consolidation is an effective technique to minimize the number of physical servers in order to reduce energy consumption, and, consequently, data center costs. However, consolidating virtual machines also reduces performance of servers. Thus, an efficient number of virtual machines consolidated in a physical server is one key issue to optimize the tradeoff between performance and energy efficiency in datacenters. In this paper, we propose a new index, namely CiS2 (Consolidation index for Server CPU in Saturation), to quantify the relation of performance degradation and energy efficiency of virtual machine consolidation under parallel workload execution, that is, the tradeoff of performance and energy in consolidation. As a result, CiS2 provides an approach to help performance engineers to decide about the suitability of a number of consolidated virtual machines. CiS2 could be modified and extended to any other non-functional features for servers. © 2018 IEEE.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","928-933","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Performance degradation; Data communication systems; Virtualization; Energy utilization; Virtual machine consolidations; Green computing; Smart city; Virtual machine; Data centers; Network security; Reduce energy consumption; Consolidation; Energy and performance tradeoff; Key Issues; Non-functional features; Parallel workloads; VM performance degradation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 20th International Conference on High Performance Computing and Communications, 16th International Conference on Smart City and 4th International Conference on Data Science and Systems, HPCC/SmartCity/DSS 2018","","","","","","","","","","","","","","",""
"4HL3VJBX","journalArticle","2022","Mahapatra, R.; Ahn, B.H.; Wang, S.-T.; Xu, H.; Esmaeilzadeh, H.","Exploring efficient ML-based scheduler for microservices in heterogenous clusters","Proc. Mach. Learn. Comput. Archit. Syst.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190293145&partnerID=40&md5=90d0084ef4f9c08a4d997d9044afe803","","2022","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVML8JL9","journalArticle","2022","Guo, S.; Qi, Y.; Jin, Y.; Li, W.; Qiu, X.; Meng, L.","Endogenous Trusted DRL-Based Service Function Chain Orchestration for IoT","IEEE Transactions on Computers","","","10.1109/TC.2021.3051681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099727569&doi=10.1109%2fTC.2021.3051681&partnerID=40&md5=49e53a9b6cd92ecfb13d19aa7cb3763d","With the development of the Internet of Things, trust has become a limited factor in the integration of heterogeneous IoT networks. In this regard, we use the combination of blockchain technology and SDN/NFV to build a heterogeneous IoT network resource management model based on the consortium chain. In order to solve the efficiency problem caused by the full amount of data on the chain, we deploy light nodes and full nodes for the consortium chain. At the same time, we use the idea of identification to realize the separation of identification and resource information, build the application mode of on-chain identification and off-chain information, and realize resources endogenous trust management. We also propose a practical Byzantine fault-tolerant consensus mechanism based on reputation value to save consensus costs and improve efficiency. Combined with artificial intelligence technology, we introduce deep reinforcement learning for service function chain orchestration, and design a service function chain orchestration algorithm based on Asynchronous Advantage Actor-Critic to optimize orchestration costs. The final simulation results show that the consensus algorithm and service function chain orchestration algorithm we designed have good performance in terms of cost saving and efficiency improvement.  © 1968-2012 IEEE.","2022","2025-10-22 19:07:36","2025-10-22 19:07:36","","397-406","","2","71","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Information management; resource management; Internet of things; Efficiency; Reinforcement learning; Internet of Things; blockchain; Service functions; Application modes; Artificial intelligence technologies; Byzantine fault; Consensus algorithms; Efficiency improvement; endogenous trust; Resource information; service function chain; Trust management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YDA66IRE","journalArticle","2023","Hu, Y.; Wang, H.; Wang, L.; Hu, M.; Peng, K.; Veeravalli, B.","Joint Deployment and Request Routing for Microservice Call Graphs in Data Centers","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2023.3311767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171593998&doi=10.1109%2fTPDS.2023.3311767&partnerID=40&md5=82cdb534f807349b9a3d1ebe6273d335","Microservices are an architectural and organizational paradigm for Internet application development. In cloud data centers, delay-sensitive applications receive massive user requests, which are fed into multiple queues and subsequently served by multiple microservice instances. Accordingly, effective deployment of multiple queues and containers can significantly reduce queuing delay, processing delay, and communication delay. Due to the increased complexity of call dependencies and probabilistic routing paths, the deployment of service instances fully interacts with request routing, bringing great difficulties to service orchestration. In this case, it is valuable to simultaneously consider service deployment and request routing in a fine-grained manner. However, most existing studies considered them as two independent components with local optimization, while data dependencies and the instance-level deployment are ignored. Therefore, this paper proposes to jointly optimize the deployment and request routing of microservice call graphs based on fine-grained queuing network analysis and container orchestration. We first formulate the problem as a mixed-integer nonlinear program and exploit open Jackson queuing networks to model intrinsic data dependencies and analyze response latency. To optimize the overall cost and latency, this paper presents an efficient two-stage heuristic algorithm, which consists of a resource-splitting-based deployment approach and a partition-mapping-based routing method. Further, this paper also provides mathematical analysis on the performance and complexity of the proposed algorithm. Finally, comprehensive trace-driven experiments demonstrate that the overall performance of our approach is better than existing microservice benchmarks. The average deployment cost is reduced by 27.4% and end-to-end response latency is reduced by 15.1% on average. © 2023 IEEE.","2023","2025-10-22 19:07:36","2025-10-22 19:07:36","","2994-3011","","11","34","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Datacenter; Cloud data centers; Benchmarking; Integer programming; Complex networks; Optimisations; Microservice architecture; Service computing; Queueing networks; Service deployment; Delay; Nonlinear programming; Queueing theory; Delay-sensitive applications; queuing theory; Queuing theory; Routings; Queueing analysis; Call graphs; Microservice call graph; microservice call graphs; request routing; Request routing; service deployment; services computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5CBJUL8","journalArticle","2021","Yang, S.; Li, F.; Trajanovski, S.; Chen, X.; Wang, Y.; Fu, X.","Delay-Aware Virtual Network Function Placement and Routing in Edge Clouds","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2019.2942306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099536735&doi=10.1109%2fTMC.2019.2942306&partnerID=40&md5=b380ca694fed9df8a50b0120e29be872","Mobile Edge Computing (MEC) offers a way to shorten the cloud servicing delay by building the small-scale cloud infrastructures at the network edge, which are in close proximity to the end users. Moreover, Network Function Virtualization (NFV) has been an emerging technology that transforms from traditional dedicated hardware implementations to software instances running in a virtualized environment. In NFV, the requested service is implemented by a sequence of Virtual Network Functions (VNF) that can run on generic servers by leveraging the virtualization technology. Service Function Chaining (SFC) is defined as a chain-ordered set of placed VNFs that handles the traffic of the delivery and control of a specific application. NFV therefore allows to allocate network resources in a more scalable and elastic manner, offer a more efficient and agile management and operation mechanism for network functions and hence can largely reduce the overall costs in MEC. In this paper, we study the problem of how to place VNFs on edge and public clouds and route the traffic among adjacent VNF pairs, such that the maximum link load ratio is minimized and each user's requested delay is satisfied. We consider this problem for both totally ordered SFCs and partially ordered SFCs. We prove that this problem is NP-hard, even for the special case when only one VNF is requested. We subsequently propose an efficient randomized rounding approximation algorithm to solve this problem. Extensive simulation results show that the proposed approximation algorithm can achieve close-to-optimal performance in terms of acceptance ratio and maximum link load ratio.  © 2002-2012 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","445-459","","2","20","","","","","","","","","","","","","Scopus","","","","","","","","Virtualized environment; Emerging technologies; Transfer functions; Network function virtualization; Extensive simulations; Cloud infrastructures; Approximation algorithms; Virtualization technologies; mobile edge computing; placement; delay; NP-hard; Optimal performance; Placement and routing; Randomized rounding; routing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XR9UF7GB","journalArticle","2022","Li, B.; He, Q.; Cui, G.; Xia, X.; Chen, F.; Jin, H.; Yang, Y.","READ: Robustness-Oriented Edge Application Deployment in Edge Computing Environment","IEEE Transactions on Services Computing","","","10.1109/TSC.2020.3015316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089450751&doi=10.1109%2fTSC.2020.3015316&partnerID=40&md5=431de19bf0c171d769c3d3b5c9344b23","In recent years, edge computing has emerged as a prospective distributed computing paradigm that overcomes several limitations of cloud computing. In the edge computing environment, a service provider can deploy its application instances on edge servers at the edge of the network to serve its own users with low latency. Given a limited budget KK for deploying applications on the edge servers in a particular geographical area, a number of approaches have been proposed very recently to determine the optimal deployment strategy that achieves various optimization objectives, e.g., to maximize the servers' coverage, to minimize the average network latency, etc. However, the robustness of the services collectively delivered by the service provider's applications deployed on the edge servers has not been considered at all. This is a critical issue, especially in the highly distributed, dynamic and volatile edge computing environment. In this article, we make the first attempt to tackle this challenge. Specifically, we formulate this Robustness-oriented Edge Application Deployment (READ) problem as a constrained optimization problem and prove its NP NP-hardness. Then, we provide an integer programming based approach named READ-O for solving this problem precisely. We also provide an approximation algorithm, namely READ-A, for finding near-optimal solutions to large-scale READ problems efficiently. We prove its approximation ratio is not worse than K/2K/2, which is a constant regardless of the total number of edge servers. We evaluate our approaches experimentally on a widely-used real-world dataset against five representative approaches. The experiment results demonstrate that our approaches can solve the READ problem effectively and efficiently.  © 2008-2012 IEEE.","2022","2025-10-22 19:07:36","2025-10-22 19:07:36","","1746-1759","","3","15","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Integer programming; Computing environments; Budget control; Approximation algorithms; Constrained optimization; Near-optimal solutions; Application deployment; Constrained optimi-zation problems; Network latencies; robustness; application deployment; approximation approach; Approximation ratios; Geographical area; integer programming; Large-scale problem; optimal approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6W38MF5I","journalArticle","2023","Panda, S.K.; Lin, M.; Zhou, T.","Energy-Efficient Computation Offloading With DVFS Using Deep Reinforcement Learning for Time-Critical IoT Applications in Edge Computing","IEEE Internet of Things Journal","","","10.1109/JIOT.2022.3153399","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125328925&doi=10.1109%2fJIOT.2022.3153399&partnerID=40&md5=a26d92e26b17118fa1b89b019c11670c","Internet of Things (IoT) is a technology that allows ordinary physical devices to collect, process, and share data with other physical devices and systems over the Internet. It provides pervasively connected infrastructures to support innovative applications and services that can automate otherwise intensely laborious manual effort. Edge computing (EC) complements the powerful centralized cloud servers by providing powerful computation capability close to the data source, minimizing communication latency, and securing data privacy. The energy consumption problem has continued to receive much attention from the IoT community in applying various techniques to reduce energy consumption while still meeting the computational demand. In this article, we propose an application-deadline-aware data offloading scheme using deep reinforcement learning and dynamic voltage and frequency scaling (DVFS) in an EC environment to reduce the energy consumption of IoT devices. The proposed scheme learns the optimal data distribution policies and local computation DVFS frequency scaling by interacting with the system environment and learning the behavior of the device, network, and edge servers. The proposed scheme was tested on multiple EC environments with different IoT devices. Experimental results show that this scheme can reduce energy consumption while achieving the IoT application and services timing and computational goals. The proposed scheme has substantial energy savings when compared with the native Linux governors.  © 2014 IEEE.","2023","2025-10-22 19:07:36","2025-10-22 19:07:36","","6611-6621","","8","10","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Deep learning; Computer operating systems; Energy utilization; Internet of things; offloading; Real time systems; Edge computing; Offloading; Energy-consumption; Green computing; computation offloading; Dynamic frequency scaling; Interactive computer systems; Computational modelling; Deep reinforcement learning (DRL); Job analysis; Reinforcement learning; Reinforcement learnings; Task analysis; Real - Time system; Internet of Things (IoT); dynamic voltage and frequency scaling; Dynamic voltage and frequency scaling; energy consumption; Performances evaluation; Deep reinforcement learning.; edge computing (EC); edge server; Edge server","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7C6TD75S","journalArticle","2018","Mo, L.; Kritikakou, A.; Sentieys, O.","Energy-quality-time optimized task mapping on DVFS-enabled multicores","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","","10.1109/TCAD.2018.2857300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050245250&doi=10.1109%2fTCAD.2018.2857300&partnerID=40&md5=671caf21b52f9a6a05957a2fca5e4fdc","Multicore architectures have great potential for energy-constrained embedded systems, such as energy-harvesting wireless sensor networks. Some embedded applications, especially the real-time ones, can be modeled as imprecise computation tasks. A task is divided into a mandatory subtask that provides a baseline quality-of-service (QoS) and an optional subtask that refines the result to increase the QoS. Combining dynamic voltage and frequency scaling, task allocation, and task adjustment, we can maximize the system QoS under real-time and energy supply constraints. However, the nonlinear and combinatorial nature of this problem makes it difficult to solve. This paper first formulates a mixed-integer nonlinear programming problem to concurrently carry out task-to-processor allocation, frequency-to-task assignment and optional task adjustment. We provide a mixed-integer linear programming form of this formulation without performance degradation and we propose a novel decomposition algorithm to provide an optimal solution with reduced computation time compared to state-of-the-art optimal approaches (22.6% in average). We also propose a heuristic version that has negligible computation time. © 2018 IEEE.","2018","2025-10-22 19:07:36","2025-10-22 19:07:36","","2428-2439","","11","37","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Voltage scaling; Embedded systems; Software architecture; Computer architecture; Network architecture; Mapping; Dynamic frequency scaling; Integer programming; Wireless sensor networks; Nonlinear programming; Problem decomposition; MILP; Energy harvesting; Mixed-integer linear programming (MILP); multicore architectures; Multicore architectures; problem decomposition; quality-of-service (QoS); Real time; real-time and energy constraints; task mapping; Task mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H4W8NMAK","journalArticle","2017","Mach, P.; Becvar, Z.","Mobile Edge Computing: A Survey on Architecture and Computation Offloading","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2017.2682318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028360031&doi=10.1109%2fCOMST.2017.2682318&partnerID=40&md5=f8175210396621bb960b65c83bb5e929","Technological evolution of mobile user equipment (UEs), such as smartphones or laptops, goes hand-in-hand with evolution of new mobile applications. However, running computationally demanding applications at the UEs is constrained by limited battery capacity and energy consumption of the UEs. A suitable solution extending the battery life-time of the UEs is to offload the applications demanding huge processing to a conventional centralized cloud. Nevertheless, this option introduces significant execution delay consisting of delivery of the offloaded applications to the cloud and back plus time of the computation at the cloud. Such a delay is inconvenient and makes the offloading unsuitable for real-time applications. To cope with the delay problem, a new emerging concept, known as mobile edge computing (MEC), has been introduced. The MEC brings computation and storage resources to the edge of mobile network enabling it to run the highly demanding applications at the UE while meeting strict delay requirements. The MEC computing resources can be exploited also by operators and third parties for specific purposes. In this paper, we first describe major use cases and reference scenarios where the MEC is applicable. After that we survey existing concepts integrating MEC functionalities to the mobile networks and discuss current advancement in standardization of the MEC. The core of this survey is, then, focused on user-oriented use case in the MEC, i.e., computation offloading. In this regard, we divide the research on computation offloading to three key areas: 1) decision on computation offloading; 2) allocation of computing resource within the MEC; and 3) mobility management. Finally, we highlight lessons learned in area of the MEC and we discuss open research challenges yet to be addressed in order to fully enjoy potentials offered by the MEC. © 1998-2012 IEEE.","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","1628-1656","","3","19","","","","","","","","","","","","","Scopus","","","","","","","","Electric batteries; Energy utilization; Computer architecture; Network architecture; Edge computing; Surveys; Mobile applications; Computation offloading; Mobile telecommunication systems; Mobile edge computing; computation offloading; allocation of computing resources; Allocation of computing resources; mobile network architecture; mobility management; Mobility management; Real-time application; Research challenges; standardization; Standardization; Technological evolution; use-cases; Wireless networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4I6RWFH","journalArticle","2021","Bi, Y.; Meixner, C.C.; Bunyakitanon, M.; Vasilakos, X.; Nejabati, R.; Simeonidou, D.","Multi-Objective Deep Reinforcement Learning Assisted Service Function Chains Placement","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2021.3127685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118978329&doi=10.1109%2fTNSM.2021.3127685&partnerID=40&md5=4dca8f90e49383b3a798f5e5150acaf9","The study of Service Function Chains (SFCs) placement problem is crucial to support services flexibly and use resources efficiently. Solutions should satisfy various Quality of Service requirements, avoid edge resource congestion, and improve service acceptance ratio (SAR). This work presents a novel approach to address these challenges by solving a multi-objective SFCs placement problem based on the Pointer Network in multi-layer edge and cloud networks. We design a Deep Reinforcement Learning algorithm, called Chebyshev-assisted Actor-Critic SFCs Placement Algorithm, to overcome the limitations of traditional heuristic and evolutionary algorithms. Then, we run this algorithm iteratively with a set of weights to obtain non-dominated fronts, which have much higher hypervolume values than those obtained from other state-of-the-art algorithms. Moreover, running our algorithm individually with selected weights from non-dominated fronts can avoid edge resource congestion and achieve 98% SARs of low-latency services during high-workload periods. Finally, based on both simulation and real testbed experimental results, it is validated that the proposed algorithm fits for pragmatic service deployment while achieving 100% of SARs in the use cases deployed on the testbed. © 2004-2012 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","4134-4150","","4","18","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; Cloud-computing; Deep learning; Distributed computer systems; Quality-of-service; Edge computing; Iterative methods; Heuristic algorithms; Multiaccess; Network function virtualization; Learning algorithms; Chains; Approximation algorithms; Computational modelling; Reinforcement learning; Optimisations; Network layers; Markov processes; Testbeds; Evolutionary algorithms; Heuristics algorithm; Multi-access edge computing; Multi objective; Service functions; Multi-objective deep reinforcement learning; Network function virtualisation; Optical network; Optical network.; Service function chaining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NN7XXW43","journalArticle","2020","Sun, G.; Zhou, R.; Sun, J.; Yu, H.; Vasilakos, A.V.","Energy-Efficient Provisioning for Service Function Chains to Support Delay-Sensitive Applications in Network Function Virtualization","IEEE Internet of Things Journal","","","10.1109/JIOT.2020.2970995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082944215&doi=10.1109%2fJIOT.2020.2970995&partnerID=40&md5=d5b0857caed3ac4216a59a27af859485","The efficient deployment of virtual network functions (VNFs) for network service provisioning is key for achieving network function virtualization (NFV); however, most existing studies address only offline or one-off deployments of service function chains (SFCs) while neglecting the dynamic (i.e., online) deployment and expansion requirements. In particular, many methods of energy/resource cost reduction are achieved by merging VNFs. However, the energy waste and device wear for large-scale collections of servers (e.g., cloud networks and data centers) caused by sporadic request updating are ignored. To solve these problems, we propose an energy-aware routing and adaptive delayed shutdown (EAR-ADS) algorithm for dynamic SFC deployment, which includes the following features: 1) energy-aware routing (EAR): by considering a practical deployment environment, a flexible solution is developed based on reusing open servers and selecting paths with the aims of balancing energy and resources and minimizing the total cost and 2) adaptive delayed shutdown (ADS): the delayed shutdown time of the servers can be flexibly adjusted in accordance with the usage of each device in each time slot, thus eliminating the no-load wait time of the servers and frequent on/off switching. Therefore, the EAR-ADS can achieve dual-energy savings by both decreasing the number of open servers and reducing the idle/switching energy consumption of these servers. The simulation results show that EAR-ADS not only minimizes the cost of energy and resources but also achieves an excellent success rate and stability. Moreover, EAR-ADS is efficient compared with an improved Markov algorithm (SAMA), reducing the average deployment time by more than a factor of 40. © 2014 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","6116-6131","","7","7","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy efficient; Energy utilization; Green computing; Virtual networks; Network services; Transfer functions; Power management (telecommunication); Network function virtualization; energy efficient; Deceleration; Cost reduction; Virtual addresses; Delay-sensitive applications; Service functions; Balancing energy; Cost of energies; Dynamic deployment; Energy-aware routing; network function virtualization (NFV); service function chain (SFC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGB9JAFN","journalArticle","2021","Vieira, M.A.M.; Castanho, M.S.; Pacífico, R.D.G.; Santos, E.R.S.; Câmara, E.P.M.; Vieira, L.F.M.","Fast packet processing with EBPF and XDP: Concepts, code, challenges, and applications","ACM Computing Surveys","","","10.1145/3371038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079572561&doi=10.1145%2f3371038&partnerID=40&md5=ff564b94cfa31c849985ed61e8350d5e","Extended Berkeley Packet Filter (eBPF) is an instruction set and an execution environment inside the Linux kernel. It enables modification, interaction, and kernel programmability at runtime. eBPF can be used to program the eXpress Data Path (XDP), a kernel network layer that processes packets closer to the NIC for fast packet processing. Developers can write programs in C or P4 languages and then compile to eBPF instructions, which can be processed by the kernel or by programmable devices (e.g., SmartNICs). Since its introduction in 2014, eBPF has been rapidly adopted by major companies such as Facebook, Cloudflare, and Netronome. Use cases include network monitoring, network traffic manipulation, load balancing, and system profiling. This work aims to present eBPF to an inexpert audience, covering the main theoretical and fundamental aspects of eBPF and XDP, as well as introducing the reader to simple examples to give insight into the general operation and use of both technologies. © 2020 Association for Computing Machinery.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","1","53","","","","","","","","","","","","","Scopus","","","","","","","","Computer operating systems; Runtimes; Network functions; Linux kernel; Packet networks; Execution environments; Network layers; Packet processing; Berkeley packet filters; C (programming language); Computer networking; Data paths; Instruction set; Network coding; Programmability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SFNLRGYA","journalArticle","2021","Bassoli, R.; Granelli, F.; Arzo, S.T.; Di Renzo, M.","Toward 5G cloud radio access network: An energy and latency perspective","Transactions on Emerging Telecommunications Technologies","","","10.1002/ett.3669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067701113&doi=10.1002%2fett.3669&partnerID=40&md5=f55c7a9e02ad4fd27ce30a21b752a9b4","Future generation networks will entirely deploy virtualization paradigms to enhance performance and capabilities of current cellular networks. In order to achieve the vision of fifth-generation networks, software-defined networking and network function virtualization will be applied not only at the core network but also at the radio access network. That will help to achieve significant reduction in power consumption while increasing energy efficiency, flexibility, and scalability. This article proposes a general mathematical model that can correctly and accurately describe spatial/topological characteristics, power consumption, and latency of Cloud radio access network in future generation networks. Thanks to the development of this novel model based on stochastic geometry, tessellation theory, and random multilayer hypergraphs, we can numerically estimate the overall energy efficiency (in bit per Joule) of Cloud radio access network in 5G (considering either edge or cloud computing), and we can compare that to energy efficiency of legacy radio access network of current 4G cellular networks. Moreover, the analysis includes a preliminary discussion about latency; that shows edge computing to be the best paradigm for 5G radio access network, which can concurrently satisfy energy efficiency and latency requirements. © 2019 John Wiley & Sons, Ltd.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","1","32","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Mobile telecommunication systems; Computation theory; Radio access networks; Green computing; 5G mobile communication systems; Network function virtualization; Wireless networks; Graph theory; Stochastic systems; Stochastic models; Model-based OPC; Cellular network; Core networks; Future generations; Hyper graph; Overall energy efficiency; Radio; Random multilayers; Stochastic geometry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"96875VTN","conferencePaper","2019","Gawel, M.; Zielinski, K.","Analysis and evaluation of kubernetes based NFV management and orchestration","","","","10.1109/CLOUD.2019.00094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072319638&doi=10.1109%2fCLOUD.2019.00094&partnerID=40&md5=37e6fcd4a2f614a54ca05fa436954b05","The paper confronts MANO specification aspects with Kubernetes fundamental containers orchestration mechanisms. It evaluates in which degree Containerized Network Functions (CNFs) can be managed with the use of Kubernetes platform. To confirm the analysis, a series of stress and chaos tests are conducted on the Kubernetes testbed with the use of an exemplary virtual IP Multimedia System. © 2019 IEEE.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","511-513","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Kubernetes; Cloud computing; Network functions; Network function virtualization; NFV; Multimedia systems; Orchestration; Management; Analysis and evaluation; IP multimedia system; MANO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"QDMHVP7P","journalArticle","2019","Chowdhury, S.R.; Salahuddin, M.A.; Limam, N.; Boutaba, R.","Re-architecting nfv ecosystem with microservices: State of the art and research challenges","IEEE Network","","","10.1109/MNET.2019.1800082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068862049&doi=10.1109%2fMNET.2019.1800082&partnerID=40&md5=72276c7566e74c7b6b4d51b16055eeae","Network Function Virtualization (NFV), considered a key enabler of network ""softwarization"", promises to reduce capital and operational expenditures for network operators by moving packet processing from purpose-built hardware to software running on commodity servers. However, the state-of-the-art in NFV is merely replacing monolithic hardware with monolithic VNFs, the software that realizes different network functions (e.g., firewalls, WAN optimizers, and so on). Although this is a first step toward deploying NFV, common functionality is repeatedly implemented in monolithic VNFs. Repeated execution of such redundant functionality introduces processing overhead when VNFs are chained to realize Service Function Chains and leads to sub-optimal usage of infrastructure resources. This stresses the need for re-architecting the NFV ecosystem, from VNFs to their orchestration, through modular VNF design and flexible service composition. In that perspective, we make the case for using the microservice software architecture, proven to be effective for building large-scale cloud applications from reusable and independently deployable components, to re-architect the NFV ecosystem. We also discuss the state-of-the-art in realizing modular VNFs from both industry and academia. Finally, we outline a set of research challenges for microservice-based NFV platforms. © 1986-2012 IEEE.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","168-176","","3","33","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Application programs; Cloud applications; Network functions; Transfer functions; Network function virtualization; Research challenges; Ecosystems; Infrastructure resources; Computer software reusability; Computer system firewalls; Operational expenditures; Packet processing; Processing overhead; Service functions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2UMH4GX","journalArticle","2021","Qin, M.; Cheng, N.; Jing, Z.; Yang, T.; Xu, W.; Yang, Q.; Rao, R.R.","Service-Oriented Energy-Latency Tradeoff for IoT Task Partial Offloading in MEC-Enhanced Multi-RAT Networks","IEEE Internet of Things Journal","","","10.1109/JIOT.2020.3015970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100243699&doi=10.1109%2fJIOT.2020.3015970&partnerID=40&md5=10240033a60eeb1dd0cfc960c8baac34","The development of the 5G network is envisioned to offer various types of services like virtual reality/augmented reality and autonomous vehicles applications with low-latency requirements in Internet-of-Things (IoT) networks. Mobile-edge computing (MEC) has become a promising solution for enhancing the computation capacity of mobile devices at the edge of the network in a 5G wireless network. Additionally, multiple radio access technologies (multi-RATs) have been verified with the potential in lowering the transmission latency and energy consumption, while improving the Quality of Services (QoS). Benefiting from the cooperation of multi-RATs, large latency-sensitive computing service tasks (L2SC) can be offloaded by different RATs simultaneously, which has great practical significance for data partitioned oriented applications with large task sizes. In this article, to enhance the L2SC offloading services for satisfying low-latency requirements with low energy consumption, we investigate the energy-latency tradeoff problem for partial task offloading in the MEC-enhanced multi-RAT network, considering the limitation of energy and computing in capability-constrained end devices in IoT networks. Specifically, we formulated the L2SC task computation offloading problem to minimize the weighted sum of the latency cost and the energy consumption by jointly optimizing the local computing frequency, task splitting, and transmit power, while guaranteeing the stringent latency requirement and the residual energy constraint. Due to the nonsmoothness and nonconvexity of the formulated problem with high complexity, we convert the tradeoff problem into a smooth biconvex problem and propose an alternate convex search-based algorithm, which can greatly reduce the computational complexity. Numerical simulation results show the effectiveness of the proposed algorithm with various performance parameters.  © 2014 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","1896-1907","","3","8","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy utilization; Internet of things; Internet of Things (IOT); Computation offloading; Radio access networks; Green computing; 5G mobile communication systems; Low power electronics; Complex networks; Internet of Things (IoT); resource allocation; Computing services; Computation capacity; Formulated problems; latency-sensitive services; Low energy consumption; mobile-edge computing (MEC); multiple radio access technology (multi-RAT); partial offloading; Performance parameters; Radio transmission; Rats; Search-based algorithms; task splitting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5S4L5R4G","journalArticle","2021","Li, X.; Ren, F.; Yang, B.","Modeling and analyzing the performance of high-speed packet I/O","Tsinghua Science and Technology","","","10.26599/TST.2019.9010080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099145278&doi=10.26599%2fTST.2019.9010080&partnerID=40&md5=0eb4d6e26b07a3519c3f911c0e21829c","Recently, 10 Gbps or higher speed links are being widely deployed in data centers. Novel high-speed packet I/O frameworks have emerged to keep pace with such high-speed links. These frameworks mainly use techniques, such as memory preallocation, busy polling, zero copy, and batch processing, to replace costly operations (e.g., interrupts, packet copy, and system call) in native OS kernel stack. For high-speed packet I/O frameworks, costs per packet, saturation throughput, and latency are performance metrics that are of utmost concern, and various factors have an effect on these metrics. To acquire a comprehensive understanding of high-speed packet I/O, we propose an analytical model to formulate its packet forwarding (receiving-processing-sending) flow. Our model takes the four main techniques adopted by the frameworks into consideration, and the concerned performance metrics are derived from it. The validity and correctness of our model are verified by real system experiments. Moreover, we explore how each factor impacts the three metrics through a model analysis and then provide several useful insights and suggestions for performance tuning. © 1996-2012 Tsinghua University Press.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","426-439","","4","26","","","","","","","","","","","","","Scopus","","","","","","","","Performance metrics; System calls; Batch data processing; latency; modeling; costs per packet; High-speed links; high-speed packet I/O; Model analysis; Packet forwarding; Performance tuning; Real systems; saturation throughput; Saturation throughput; Speed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HEXTT8ZF","journalArticle","2020","","","Vector Packet Processor (VPP)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132019193&partnerID=40&md5=4855a08e2a9a84df103a50dbd2ca1321","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJWR4XLQ","journalArticle","2017","Kawashima, R.; Nakayama, H.; Hayashi, T.; Matsuo, H.","Evaluation of forwarding efficiency in NFV-nodes toward predictable service chain performance","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2017.2734560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028990365&doi=10.1109%2fTNSM.2017.2734560&partnerID=40&md5=2c6d1521a5372ee3c2f8b93677f45df8","The concept of network functions virtualization (NFV) has been embodied in commercial networks over the past years. Software-based virtual network functions have forwarding performance concerns in general, and various acceleration technologies have been developed so far, such as DPDK and vhost-user. Existence of several alternatives requires network engineers or operators to select appropriate technologies; however, no pragmatic criterion exists for constructing high-performance NFV-nodes. From their points of view, a lack of common benchmark and understanding of performance characteristics makes it difficult to predict hop-by-hop performance in a service chain, which results in prevention of NFV deployment in mission-critical networks. In this paper, we clarify performance characteristics of packet forwarding in NFV nodes focusing on three types of acceleration technologies; packet I/O architecture, virtual network I/O, and forwarding engine in a practical stage. We examined three packet I/O architectures (NAPI, netmap, and DPDK), three virtual I/O mechanisms (vhost-net, vhost-user, and SR-IOV), and four practical forwarding programs (Open vSwitch, OVS-DPDK, xDPd-DPDK, and Lagopus) with three referential programs (Linux Bridge, VALE, and L2FWD-DPDK). The experiment was conducted on a 40 GbE environment and we examined two device-under-Test machines having different CPU performance. We argue performance characteristics of each technology and give quantitative analyses of the result. The key findings are: 1) CPU core speed has impact on both throughput and latency/jitter; 2) DPDK can allow performance prediction; 3) vhost-user is appropriate for real environment; and 4) OVS-DPDK provides a good combination of performance and functionality. © 2017 IEEE.","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","920-933","","4","14","","","","","","","","","","","","","Scopus","","","","","","","","Virtual reality; Virtualization; Computer operating systems; Network architecture; Benchmarking; Network functions; Function evaluation; Linux; Transfer functions; Network function virtualization; Chains; Software testing; Throughput; Performance evaluation; Network functions virtualization; Benchmark testing; Kernel; Software defined networking; Acceleration; DPDK; Engines; Service chaining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KEM4QED5","conferencePaper","2017","Sapio, A.; Abdelaziz, I.; Aldilaijan, A.; Canini, M.; Kalnis, P.","In-network computation is a dumb idea whose time has come","","","","10.1145/3152434.3152461","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041220007&doi=10.1145%2f3152434.3152461&partnerID=40&md5=68566ea2a85969713f49bdc889901815","Programmable data plane hardware creates new opportunities for infusing intelligence into the network. This raises a fundamental question: what kinds of computation should be delegated to the network? In this paper, we discuss the opportunities and challenges for co-designing data center distributed systems with their network layer. We believe that the time has finally come for offloading part of their computation to execute in-network. However, in-network computation tasks must be judiciously crafted to match the limitations of the network machine architecture of programmable devices. With the help of our experiments on machine learning and graph analytics workloads, we identify that aggregation functions raise opportunities to exploit the limited computation power of networking hardware to lessen network congestion and improve the overall application performance. Moreover, as a proof-of-concept, we propose DAIET, a system that performs in-network data aggregation. Experimental results with an initial prototype show a large data reduction ratio (86.9%-89.3%) and a similar decrease in the workers' computation time. © 2017 Copyright held by the owner/author(s).","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","150-156","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Distributed systems; Computation power; Learning systems; Application performance; Network layers; Aggregation functions; In-network computations; In-network data aggregation; Network congestions; Programmable devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","HotNets 2017 - Proceedings of the 16th ACM Workshop on Hot Topics in Networks","","","","","","","","","","","","","","",""
"RT4ET9T3","conferencePaper","2012","Balaji, B.; McCullough, J.; Gupta, R.K.; Agarwal, Y.","Accurate characterization of the variability in power consumption in modern mobile processors","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093861219&partnerID=40&md5=08c0bf64735e6f429e539fa38714e0ef","The variability in performance and power consumption is slated to grow further with continued scaling of process technologies. While this variability has been studied and modeled before, there is lack of empirical data on its extent, as well as the factors affecting it, especially for modern general purpose microprocessors. Using detailed power measurements we show that the part to part variability for modern processors utilizing the Nehalem microarchitecture is indeed significant. We chose six Core i5-540M laptop processors marketed in the same frequency bins - thus presumed to be identical - and characterized their power consumption for a variety of representative single-threaded and multi-threaded application workloads. Our data shows processor power variation ranging from 7% - 17% across different applications and configuration options such as Hyper-Threading and Turbo Boost. We present our hypotheses on the underlying causes of this observed power variation and discuss its potential implications. © 2012 Power-Aware Computing Systems, HotPower 2012.All right reserved.","2012","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Electric power utilization; Multi- threaded applications; Modern processors; Micro architectures; Configuration options; General-purpose microprocessors; Mobile processors; Process Technologies; Underlying cause","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2012 Workshop on Power-Aware Computing Systems, HotPower 2012","","","","","","","","","","","","","","",""
"4A45WJTG","journalArticle","","Karlsson, M.","","Fundamental Technologies We Need to Work on for Cloud-Native Networking","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132031351&partnerID=40&md5=0fea8c2858fdafc451967ea7d2fe1461","","","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAABJA7T","journalArticle","2021","Qi, S.; Kulkarni, S.G.; Ramakrishnan, K.K.","Assessing Container Network Interface Plugins: Functionality, Performance, and Scalability","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3047545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098759828&doi=10.1109%2fTNSM.2020.3047545&partnerID=40&md5=c3729316286e0f8f37d923a43c7838c6","Kubernetes, an open-source container orchestration platform, has been widely adopted by cloud service providers (CSPs) for its advantages in simplifying container deployment, scalability, and scheduling. Networking is one of the central components of Kubernetes, providing connectivity between different Pods (a group of containers) both within the same host and across hosts. To bootstrap Kubernetes networking, the Container Network Interface (CNI) provides a unified interface for the interaction between container runtimes. There are several CNI implementations, available as open-source 'CNI plugins'. While they differ in functionality and performance, it is a challenge for a cloud provider to differentiate and choose the appropriate plugin for their environment. In this article, we compare the various open-source CNI plugins available from the community, qualitatively, and through detailed quantitative measurements. With our experimental evaluation, we analyze the overheads and bottlenecks for each CNI plugin, especially because of the interaction with the datapath/iptables as well as the host network stack. Overlay tunnel offload support in the network interface card plays a significant role in achieving the good performance of CNIs that use overlay tunnels for inter-host Pod-to-Pod communication. We also study scalability with an increasing number of Pods, as well as with HTTP workloads, and briefly evaluate Pod startup latency. Our measurement results inform the outline of an ideal CNI environment for Kubernetes.  © 2021 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","656-671","","1","18","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Kubernetes; Experimental evaluation; Cloud providers; Scalability; Cloud service providers; Petroleum reservoir evaluation; Open sources; scalability; performance; Central component; container networking interface; Network interface cards; Network stack; Quantitative measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSLCTWWV","journalArticle","2021","Zhang, T.; Linguaglossa, L.; Giaccone, P.; Iannone, L.; Roberts, J.","Performance benchmarking of state-of-the-art software switches for NFV","Computer Networks","","","10.1016/j.comnet.2021.107861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100639701&doi=10.1016%2fj.comnet.2021.107861&partnerID=40&md5=d435b6f042235e3109f150bb5791fa67","With the ultimate goal of replacing proprietary hardware appliances with Virtual Network Functions (VNFs) implemented in software, Network Function Virtualization (NFV) has gained popularity in the past few years. Software switches are widely employed to route traffic between VNFs and physical Network Interface Cards (NICs). It is thus of paramount importance to compare the performance of different switch designs and architectures. In this paper, we propose a methodology to compare fairly and comprehensively the performance of software switches. We first explore the design spaces of 7 state-of-the-art software switches and then compare their performance under four representative test scenarios. Each scenario corresponds to a specific case of routing NFV traffic between NICs and/or VNFs. In our experiments, we evaluate the throughput and latency between VNFs in two of the most popular virtualization environments, namely virtual machines (VMs) and containers. Our experimental results show that no single software switch prevails in all scenarios. It is, therefore, crucial to choose the most suitable solution for the given use case. At the same time, the presented results and analysis provide a more in-depth insight into the design tradeoffs and identify potential performance bottlenecks that could inspire new designs. © 2021 Elsevier B.V.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","188","","","","","","","","","","","","","Scopus","","","","","","","","Benchmarking; State of the art; Virtual networks; Transfer functions; Network function virtualization; Software testing; Physical network; Performance bottlenecks; High-speed packet processing; Software switches; Design tradeoff; Network Function Virtualization (NFV); Performance benchmarking; Performance benchmarking methodology; Service Function Chain (SFC); Software switch; Suitable solutions; Virtual Network Functions (VNF); Virtual switch","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNQKDC46","journalArticle","2020","","","Mizar Project Documentation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132007808&partnerID=40&md5=196319cc000590ddb9f9b9adc04622c2","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENM4D9JX","journalArticle","2015","Han, S.; Jang, K.; Panda, A.; Palkar, S.; Han, D.; Ratnasamy, S.","SoftNIC: A software NIC to augment hardware","SoftNIC: A Software NIC to Augment Hardware","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042347159&partnerID=40&md5=a9e1357bee38f8e1fb1e3bc780a04ebf","","2015","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S99B9ZPB","journalArticle","2019","Daly, L.; Hunt, D.; MacNamara, C.; Ramakrishnan, K.","","Intel Speed Select Technology-Base Frequency (Intel_ SSTBF) with Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132026618&partnerID=40&md5=a754ff05c65d6e919abbfbbd8928deb9","","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N8XZFCZT","conferencePaper","2020","Zheng, C.; Liu, S.; Huang, Y.; Yang, L.","MEC-Enabled Wireless VR Video Service: A Learning-Based Mixed Strategy for Energy-Latency Tradeoff","","","","10.1109/WCNC45663.2020.9120529","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087278990&doi=10.1109%2fWCNC45663.2020.9120529&partnerID=40&md5=d683a113fa599f4ffd1ceaa6a61bfd82","Mobile edge computing (MEC) has received broad attention as an effective network architecture and a key enabler of the wireless virtual reality (VR) video service which is expected to take a huge share of communication traffic. In this work, we investigate the scenario of multi-tiles-based wireless VR video service with the aid of MEC network, where the primary objective is to minimize the system energy consumption and the latency as well as to arrive at a tradeoff between these two metrics. To this end, we first cast the time-varying view popularity as a modelfree Markov chain and use a long short-term memory autoencoder network to predict its dynamics. Then, a mixed strategy, which jointly considers the dynamic caching replacement and the deterministic offloading, is designed to fully utilize the caching and computing resource in the system. The underlying multiobjective optimization problem is reformulated as a partially observable Markov decision process and solved by using a deep deterministic policy gradient algorithm. The effectiveness of the proposed scheme is confirmed by numerical simulations. © 2020 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","2020-May","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Network architecture; Clustering algorithms; Learning algorithms; Multiobjective optimization; Computing resource; Markov chains; Multi-objective optimization problem; Policy gradient; Dynamic caching; Partially observable Markov decision process; Primary objective; System energy consumption; Video services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE Wireless Communications and Networking Conference, WCNC","","","","","","","","","","","","","","",""
"KM9C5WD5","journalArticle","2021","Töpel, B.","","Introducing AFXDP Support","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132045110&partnerID=40&md5=51c3f99d8be2516018bf26a8b8b50e85","","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PEP2EYD","journalArticle","2020","Chowdhury, S.R.; Bian, H.; Bai, T.; Boutaba, R.","A disaggregated packet processing architecture for network function virtualization","IEEE Journal on Selected Areas in Communications","","","10.1109/JSAC.2020.2986611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085591728&doi=10.1109%2fJSAC.2020.2986611&partnerID=40&md5=3ac93be323fcd1189dac8ecc61f77349","Network Function Virtualization (NFV) promises to reduce the capital and operational expenditure for network operators by moving packet processing from purpose-built hardware to software running on commodity servers. However, the state-of-the-art in NFV is merely replacing monolithic hardware with monolithic Virtual Network Functions (VNFs), i.e., software that realizes different network functions. This is a good first step towards transitioning to NFV, however, common functionality is repeatedly implemented in monolithic VNFs. Repeated execution of such redundant functionality is particularly common when VNFs are chained to realize Service Function Chains (SFCs) and results in wasted infrastructure resources. This stresses the need for re-architecting the NFV ecosystem, through modular VNF design and flexible service composition. From this perspective, we propose MicroNF (μ NF in short), a disaggregated packet processing architecture facilitating the deployment of VNFs and SFCs using reusable, loosely-coupled, and independently deployable components. We have implemented the proposed system, including the different architecture components and optimizations for improving packet processing throughput and latency. Extensive experiments on a testbed demonstrate that: (i) compared to monolithic VNF based SFCs, those composed of μ NFs achieve the same packet processing throughput while using less CPU cycles per packet on average; and (ii) μ NF-based SFCs can sustain the same packet processing throughput as those based on state-of-the-art run-to-completion VNF architecture while using lesser number of CPU cores. © 1983-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","1075-1088","","6","38","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; microservices; Network operator; Computer architecture; Virtual networks; Network functions; Transfer functions; Network function virtualization; Packet networks; Infrastructure resources; Operational expenditures; Packet processing; Service functions; middleboxes; Packet-processing architectures; virtual network function decomposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUE94V7C","journalArticle","2021","Bhardwaj, A.; Krishna, C.R.","Virtualization in Cloud Computing: Moving from Hypervisor to Containerization—A Survey","Arabian Journal for Science and Engineering","","","10.1007/s13369-021-05553-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104544140&doi=10.1007%2fs13369-021-05553-3&partnerID=40&md5=826155bb661c7d28b85c62aff15913d6","Containers emerged as a lightweight alternative to virtual machines that offer better microservice architecture support. They are widely used by organizations to deploy their increasingly diverse workloads derived from modern applications such as big data, IoT, and edge/fog computing in either proprietary clusters or private, public cloud data centers. With the growing interest in container-based virtualization technologies, the requirement to explore the deployment and orchestration of clusters of containers has become a central research problem. Although progress has been made to study containerization, systematic consolidation of the existing literature with a summative evaluation is still missing. To fill this gap, in this paper, we first taxonomically classify the existing research studies on the performance comparison between hypervisor and container technology and then analyze state-of-the-art for container cluster management orchestration systems, its performance monitoring tools, and finally future research trends. This results in a better understanding of container technology with attention to provide summative analysis in terms of (i) how much performance overhead is generated by a hypervisor compared to container-based virtualization, (ii) which container technology is suited for a cloud application deployment based on the type of benchmark executing, (iii) how to provide management of containers deployed in a cluster environment, (iv) container performance monitoring tools, and (v) finally emerging concerns for future research directions. © 2021, King Fahd University of Petroleum & Minerals.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","8585-8601","","9","46","","","","","","","","","","","","","Scopus","","","","","","","","Hypervisor; Cloud computing; Virtualization; Containerization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9JEIQ3TQ","journalArticle","2022","Taskou, S.K.; Rasti, M.; Nardelli, P.H.J.","Energy and Cost Efficient Resource Allocation for Blockchain-Enabled NFV","IEEE Transactions on Services Computing","","","10.1109/TSC.2021.3050717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099549098&doi=10.1109%2fTSC.2021.3050717&partnerID=40&md5=75997ec3595b2d1785c1155d1e7bc446","Network function virtualization (NFV) is a promising technology to make 5G networks flexible and agile. NFV decreases operators' OPEX and CAPEX by decoupling the physical hardware from the functions they perform. In NFV, users' service request can be viewed as a service function chain (SFC) consisting of several virtual network functions (VNFs) which are connected through virtual links. Resource allocation in NFV is done through a centralized authority called NFV Orchestrator (NFVO). This centralized authority suffers from some drawbacks such as single point of failure and security. Blockchain (BC) technology is able to address these problems by decentralizing resource allocation. The drawbacks of NFVO in NFV architecture and the exceptional BC characteristics to address these problems motivate us to focus on NFV resource allocation to users' SFCs without the need for an NFVO. To this end, we assume there are two types of users: users who send SFC requests (SFC requesting users) and users who perform mining process (miner users). For SFC requesting users, we formulate NFV resource allocation (NFV-RA) problem as a multi-objective problem to minimize the energy consumption and utilized resource cost, simultaneously. To address this problem, we propose an Approximation-based Resource Allocation algorithm (ARA) using Majorization-Minimization approximation method to convexify NFV-RA problem. Furthermore, due to the high complexity of ARA algorithm, we propose a low complexity Hungarian-based Resource Allocation (HuRA) algorithm using Hungarian algorithm for server allocation. Through the simulation results, we show that our proposed ARA and HuRA algorithms achieve near-optimal performance with lower computational complexity. Also, ARA algorithm outperforms the existing algorithms in terms of number of active servers, energy consumption, and average latency. Moreover, the mining process is the foundation of BC technology. In wireless networks, mining is performed by resource-limited mobile users. Since the mining process requires high computational complexity, miner users cannot perform it alone. So, in this article, we assume that miner users can perform mining process with participating of other users. For mining process, the problem of minimizing the energy consumption and cost of users' processing resources is formulated as a linear programming problem that can be optimally solved in polynomial time.  © 2022 IEEE.","2022","2025-10-22 19:07:36","2025-10-22 19:07:36","","2328-2341","","4","15","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Virtual networks; 5G mobile communication systems; Resource allocation; Transfer functions; Network function virtualization; Service requests; blockchain; Blockchain; Service functions; virtual network function; consensus mechanism; Energy and cost; mining; Mining process; Multi-objective problem; Single point; Utilized resources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IA2VJYHY","journalArticle","2021","Sheoran, A.; Fahmy, S.; Cao, L.; Sharma, P.","AI-Driven Provisioning in the 5G Core","IEEE Internet Computing","","","10.1109/MIC.2021.3056230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100778760&doi=10.1109%2fMIC.2021.3056230&partnerID=40&md5=4c6a71ee3f21d41b9a5454fcc83c26bd","Network slicing enables communication service providers to partition physical infrastructure into logically independent networks. Network slices must be provisioned to meet the service-level objectives (SLOs) of disparate offerings, such as enhanced mobile broadband, ultrareliable low-latency communications, and massive machine-type communications. Network orchestrators must customize service placement and scaling to achieve the SLO of each network slice. In this article, we discuss the challenges encountered by network orchestrators in allocating resources to disparate 5G network slices, and propose the use of artificial intelligence to make core placement and scaling decisions that meet the requirements of network slices deployed on shared infrastructure. We explore how artificial intelligence-driven scaling algorithms, coupled with functionality-aware placement, can enable providers to design closed-loop solutions to meet the disparate SLOs of future network slices. © 1997-2012 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","18-25","","2","25","","","","","","","","","","","","","Scopus","","","","","","","","5G mobile communication systems; Artificial intelligence; Service level objective; AI; 5G; Telecommunications; Service placements; Low-latency communication; Scaling algorithm; Closed-loop solution; Communication service; Machine type communications; Network Functions Virtualization; Shared infrastructure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5GH4MBXU","journalArticle","2020","Höweler, M.","","XDP-Monitoring Energy-Adaptive Network Functions (X-MAN) Source Code","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132024950&partnerID=40&md5=b95de512e50a43b117f975cd82b05c05","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IR6XVDEJ","conferencePaper","2017","Sattar, D.; Matrawy, A.","An empirical model of packet processing delay of the Open vSwitch","","","","10.1109/ICNP.2017.8117597","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041384741&doi=10.1109%2fICNP.2017.8117597&partnerID=40&md5=578d2b621a2aca548c826637b9fc2d15","Network virtualization offers flexibility by decoupling virtual network from the underlying physical network. Software-Defined Network (SDN) could utilize the virtual network. For example, in Software-Defined Networks, the entire network can be run on commodity hardware and operating systems that use virtual elements. However, this could present new challenges of data plane performance. In this paper, we present an empirical model of the packet processing delay of a widely used OpenFlow virtual switch, the Open vSwitch. In the empirical model, we analyze the effect of varying Random Access Memory (RAM) and network parameters on the performance of the Open vSwitch. Our empirical model captures the non-network processing delays, which could be used in enhancing the network modeling and simulation. © 2017 IEEE.","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","2017-October","","","","","","","","","","","","","Scopus","","","","","","","","Internet protocols; Network protocols; Network virtualization; Random access storage; Random access memory; Packet processing; Commodity hardware; Network modeling and simulations; Network parameters; Network processing; Underlying physical networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Network Protocols, ICNP","","","","","","","","","","","","","","",""
"HQKAYTLX","journalArticle","2021","Hoeschele, T.; Dietzel, C.; Kopp, D.; Fitzek, F.H.P.; Reisslein, M.","Importance of Internet Exchange Point (IXP) infrastructure for 5G: Estimating the impact of 5G use cases","Telecommunications Policy","","","10.1016/j.telpol.2020.102091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100436753&doi=10.1016%2fj.telpol.2020.102091&partnerID=40&md5=b7945017a0e2892d044d4b5c3725daac","While the Internet is ubiquitous in most parts of the world today, the dominant network access technology is gradually shifting from wired to wireless connections. Notably, the ever increasing bandwidth, together with reduced latency in mobile networks, enables a multitude of new use cases for a wide range of industries. These new use cases have typically increased quality requirements for the wireless connection. Accordingly, the Internet architecture needs to keep pace with the recent developments, particularly in light of the holistic approach of the new fifth generation (5G) mobile communication standard. In this study, we shed light on the effects of 5G on the Internet's core, i.e., on the Internet interdomain traffic. The interdomain traffic between distinct autonomous systems (ASs) is exchanged by transit networks as well as through peerings at private network interconnects (PNIs) and public Internet Exchange Points (IXPs). 5G interdomain traffic estimation is especially important for IXPs as these are focal points that aggregate high traffic volumes. We coherently derive twelve 5G use case groups and present an overview of their individual associated 5G use cases. We characterize the communication networking (connection) requirements and the resulting implications of these use cases. Further, we develop and apply a methodology to assess the 5G use cases, so as to rank them in terms of their projected impact on the overall internet traffic growth. Based on this systematic approach, we conclude that the traffic for the use case groups Video in 5G, Health, and Virtual & Augmented Reality will have the largest impact. We identify a large number of other use case groups, e.g., Live Events, Tactile Internet, and Manufacturing, that will contribute rather small individual fractions to the overall growth of Internet traffic. However, their aggregated contribution to the internet traffic growth will be significant. Our traffic estimation can inform interdomain infrastructure providers, such as IXPs, and policy makers about the likely impact of the introduction of 5G on the interdomain traffic in the Internet. © 2020 Elsevier Ltd","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","3","45","","","","","","","","","","","","","Scopus","","","","","","","","Mobile telecommunication systems; 5G mobile communication systems; Augmented reality; 5G wireless use cases; Autonomous system (ASs); Communication networking; Infrastructure providers; Inter-domain traffic; Internet architecture; Internet Exchange Point (IXP); Internet exchange points; Internet traffic growth; Mobile communication standards; Quality requirements; Traffic projection model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MK2X9VKV","journalArticle","2022","Ghanavati, S.; Abawajy, J.; Izadi, D.","An Energy Aware Task Scheduling Model Using Ant-Mating Optimization in Fog Computing Environment","IEEE Transactions on Services Computing","","","10.1109/TSC.2020.3028575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135806143&doi=10.1109%2fTSC.2020.3028575&partnerID=40&md5=1f9a67831fc25e069961511a1cb47863","Fog computing has become a platform of choice for executing emerging applications with low latency requirements. Since the devices in fog computing tend to be resource constraint and highly distributed, how fog computing resources can be effectively utilized for executing delay-sensitive tasks is a fundamental challenge. To address this problem, we propose and evaluate a new task scheduling algorithm with the aim of reducing the total system makespan and energy consumption for fog computing platform. The proposed approach consists of two key components: 1) a new bio-inspired optimization approach called Ant Mating Optimization (AMO) and 2) optimized distribution of a set of tasks among the fog nodes within proximity. The objective is to find an optimal trade-off between the system makespan and the consumed energy required by the fog computing services, established by end-user devices. Our empirical performance evaluation results demonstrate that the proposed approach outperforms the bee life algorithm, traditional particle swarm optimization and genetic algorithm in terms of makespan and consumed energy.  © 2022 IEEE.","2022","2025-10-22 19:07:36","2025-10-22 19:07:36","","2007-2017","","4","15","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Multitasking; Energy utilization; Internet of things; Economic and social effects; Energy-consumption; Fog computing; Computing environments; Scheduling algorithms; Optimisations; Internet of Things; Genetic algorithms; task offloading; energy consumption; Makespan; Particle swarm optimization (PSO); Fog; Delay-sensitive applications; Scheduling models; ant mating optimization; Ant mating optimization; Biomimetics; Consumed energy; Energy-aware task scheduling; Matings; Task offloading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMBE5LIV","journalArticle","2019","Linguaglossa, L.; Rossi, D.; Pontarelli, S.; Barach, D.; Marjon, D.; Pfister, P.","High-speed data plane and network functions virtualization by vectorizing packet processing","Computer Networks","","","10.1016/j.comnet.2018.11.033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058036682&doi=10.1016%2fj.comnet.2018.11.033&partnerID=40&md5=56ed9d2011411a8ff24e3c82f7a7a581","In the last decade, a number of frameworks started to appear that implement, directly in user-space with kernel-bypass mode, high-speed software data plane functionalities on commodity hardware. This may be the key to replace specific hardware-based middleboxes with custom pieces of software, as advocated by the recent Network Function Virtualization (NFV) paradigm. Vector Packet Processor (VPP) is one of such frameworks, representing an interesting point in the design space in that it offers: (i) in user-space networking, (ii) the flexibility of a modular router (Click and variants) with (iii) high-speed performance (several millions of packets per second on a single CPU core), achieved through techniques such as batch processing that have become commonplace in high-speed networking stacks (e.g. netmap or DPDK). Similarly to Click, VPP lets users arrange functions as a processing graph, providing a full-blown stack of network functions. However, unlike Click where the whole tree is traversed for each packet, in VPP each traversed node processes all packets in the batch (or vector) before moving to the next node. This design choice enables several code optimizations that greatly improve the achievable throughput. This paper introduces the main VPP concepts and architecture, and experimentally evaluates the impact of its design choices (such as batch packet processing) on its performance. © 2018 Elsevier B.V.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","187-199","","","149","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Virtual reality; Transfer functions; Network function virtualization; Packet networks; Batch data processing; Speed; Packet processing; Software routers; Achievable throughputs; High-speed networking; High-speed performance; Interesting points; Kernel bypass; Kernel-bypass; Packets per seconds; Vector packet processing; Vector spaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EWCFE6N7","conferencePaper","2015","Barbette, T.; Soldani, C.; Mathy, L.","Fast userspace packet processing","","","","10.1109/ANCS.2015.7110116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936120771&doi=10.1109%2fANCS.2015.7110116&partnerID=40&md5=273947133afdfb20766bd5058fbf291a","In recent years, we have witnessed the emergence of high speed packet I/O frameworks, bringing unprecedented network performance to userspace. Using the Click modular router, we rst review and quantitatively compare several such packet I/O frameworks, showing their superiority to kernel-based forwarding. We then reconsider the issue of software packet processing, in the context of modern commodity hardware with hardware multi-queues, multi-core processors and non-uniform memory access. Through a combination of existing techniques and improvements of our own, we derive modern general principles for the design of software packet processors. Our implementation of a fast packet processor framework, integrating a faster Click with both Netmap and DPDK, ex-hibits up-to about 2.3x speed-up compared to other software implementations, when used as an IP router. © 2015 IEEE.","2015","2025-10-22 19:07:36","2025-10-22 19:07:36","","5-16","","","","","","","","","","","","","","","","Scopus","","","","","","","","Memory architecture; Packet processing; Commodity hardware; Click modular router; Design of softwares; Multi-core processor; Non uniform memory access; Packet processors; Software implementation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ANCS 2015 - 11th 2015 ACM/IEEE Symposium on Architectures for Networking and Communications Systems","","","","","","","","","","","","","","",""
"W7JX6E8S","conferencePaper","2018","Zhang, T.; Linguaglossa, L.; Gallo, M.; Giaccone, P.; Rossi, D.","FlowMon-DPDK: Parsimonious Per-Flow Software Monitoring at Line Rate","","","","10.23919/TMA.2018.8506565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056453581&doi=10.23919%2fTMA.2018.8506565&partnerID=40&md5=9a03bc267901072d037cdb936a646e61","Testing experimental network devices requires deep performance analysis, which is usually performed with expensive, not flexible, hardware equipment. With the advent of highspeed packet I/O frameworks, general purpose equipments have narrowed the performance gap in respect of dedicated hardware and a variety of software-based solutions have emerged for handling traffic at very high speed. While the literature abounds with software traffic generators, existing monitoring solutions do not target worst-case scenarios (i.e., 64B packets at line rate) that are particularly relevant for stress-testing high-speed network functions, or occupy too many resources. In this paper we first analyse the design space for high-speed traffic monitoring that leads us to specific choices characterizing FlowMon-DPDK, a DPDK-based software traffic monitor that we release as an open source project. In a nutshell, FlowMon-DPDK provides tunable fine-grained statistics at both packet and flow levels. Experimental results demonstrate that our traffic monitor is able to provide per-flow statistics with 5-nines precision at high-speed (14.88 Mpps) using an exiguous amount of resources. Finally, we showcase FlowMon-DPDK usage by testing two open source prototypes for stateful flow-level end-host and in-network packet processing. © 2018 IFIP.","2018","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Performance analysis; Dedicated hardware; HIgh speed networks; Open source software; Traffic monitoring; Open systems; Software testing; Traffic generators; Open source projects; Software-based solutions; Software monitoring; Worst case scenario","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","TMA 2018 - Proceedings of the 2nd Network Traffic Measurement and Analysis Conference","","","","","","","","","","","","","","",""
"AE5FEJ8F","journalArticle","2020","Ranjan, R.; Thakur, I.S.; Aujla, G.S.; Kumar, N.; Zomaya, A.Y.","Energy-Efficient Workflow Scheduling Using Container-Based Virtualization in Software-Defined Data Centers","IEEE Transactions on Industrial Informatics","","","10.1109/TII.2020.2985030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092197336&doi=10.1109%2fTII.2020.2985030&partnerID=40&md5=838e6b08755cc6a14abbd8d21dfbd57d","Workflow scheduling is one of the most difficult tasks due to the variation in the traffic flows generated from diverse cloud applications. Hence, in this article, a container-based virtualization is used to design an energy-efficient workflow scheduling in software-defined data centers. The containers provide the flexibility to the applications to access the underlying resource as per their requirements. Moreover, a runtime scheduler is responsible to handle all the scheduling decisions in the proposed workflow scheduling scheme. Even more, a doubly linked list-based access mechanism is used to provide access to the servers and virtual machines by traversing both ways. Finally, a hashing scheme is used to select an ideal location for the allocation of the containers. The proposed scheme is evaluated with respect to different performance metrics (makespan, execution time, fault tolerance, energy consumption, etc.) on the real data traces. The results obtained depict the superiority of the proposed scheme in comparison to the other existing schemes of its category.  © 2005-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","7646-7657","","12","16","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Containers; Energy efficiency; Performance metrics; Cloud computing; Cloud applications; Virtualization; Energy efficient; Energy utilization; containers; Data centers; Scheduling decisions; workflow scheduling; Workflow scheduling; Fault tolerance; virtual machine; Access mechanism; software-defined data centers (SDDCs); Traffic flow","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYPF7QZT","journalArticle","2021","Miano, S.; Risso, F.; Bernal, M.V.; Bertrone, M.; Lu, Y.","A Framework for eBPF-Based Network Functions in an Era of Microservices","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2021.3055676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100455153&doi=10.1109%2fTNSM.2021.3055676&partnerID=40&md5=3c7fe2ca914b4808278cd8ceba2f90a0","By moving network functionality from dedicated hardware to software running on end-hosts, Network Functions Virtualization (NFV) pledges the benefits of cloud computing to packet processing. While most of the NFV frameworks today rely on kernel-bypass approaches, no attention has been given to kernel packet processing, which has always proved hard to evolve and to program. In this article, we present Polycube, a software framework whose main goal is to bring the power of NFV to in-kernel packet processing applications, enabling a level of flexibility and customization that was unthinkable before. Polycube enables the creation of arbitrary and complex network function chains, where each function can include an efficient in-kernel data plane and a flexible user-space control plane with strong characteristics of isolation, persistence, and composability. Polycube network functions, called Cubes, can be dynamically generated and injected into the kernel networking stack, without requiring custom kernels or specific kernel modules, simplifying the debugging and introspection, which are two fundamental properties in recent cloud environments. We validate the framework by showing significant improvements over existing applications, and we prove the generality of the Polycube programming model through the implementation of complex use cases such as a network provider for Kubernetes.  © 2004-2012 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","133-151","","1","18","","","","","","","","","","","","","Scopus","","","","","","","","Computer systems programming; Application programs; Dedicated hardware; Cloud environments; Network functions; Transfer functions; Network function virtualization; NFV; Programming models; Complex networks; Packet processing; XDP; eBPF; Fundamental properties; linux; Network provider; Software frameworks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZLPDUMB","journalArticle","2021","Duan, Q.","Intelligent and autonomous management in cloud-native future networks — A survey on related standards from an architectural perspective","Future Internet","","","10.3390/fi13020042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100709118&doi=10.3390%2ffi13020042&partnerID=40&md5=68153def97613d46fe5976dfdfaa148c","Cloud-native network design, which leverages network virtualization and softwarization together with the service-oriented architectural principle, is transforming communication networks to a versatile platform for converged network-cloud/edge service provisioning. Intelligent and autonomous management is one of the most challenging issues in cloud-native future networks, and a wide range of machine learning (ML)-based technologies have been proposed for addressing different aspects of the management challenge. It becomes critical that the various management technologies are applied on the foundation of a consistent architectural framework with a holistic vision. This calls for standardization of new management architecture that supports seamless the integration of diverse ML-based technologies in cloud-native future networks. The goal of this paper is to provide a big picture of the recent developments of architectural frameworks for intelligent and autonomous management for future networks. The paper surveys the latest progress in the standardization of network management architectures including works by 3GPP, ETSI, and ITU-Tand analyzes how cloud-native network design may facilitate the architecture development for addressing management challenges. Open issues related to intelligent and autonomous management in cloud-native future networks are also discussed in this paper to identify some possible directions for future research and development. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","1-20","","2","13","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Computer architecture; Network architecture; Surveys; Network virtualization; Standardization; Machine learning; Architectural frameworks; Architectural principles; Research and development; Autonomous managements; Cloud-native network design; Intelligent and autonomous management; Management architectures; Management technologies; Network and service management; Network management architectures; Research and development management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IF2XIETA","journalArticle","2021","Kawashima, R.","Software Physical/Virtual Rx Queue Mapping Toward High-Performance Containerized Networking","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3049053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099425306&doi=10.1109%2fTNSM.2020.3049053&partnerID=40&md5=ab9a2ab50962b5186442412bccc4bf9f","Softwarization of Network Functions (NFs) accelerates automated deployment and management of services on next-gen networks. Combining flexibility and high-performance is a vital requirement for Network Functions Virtualisation (NFV); however, many studies have demonstrated that containerization or virtualization of NFs severely degrades the fundamental efficiency of packet forwarding. Virtual network I/O, a mechanism of packet transferring between a guest and the host, has been seen as the performance bottleneck in the PVP (Physical-Virtual-Physical) datapath, and one of the main causes of this deterioration is packet copy between them. Various techniques, such as zero-copy, pass-through, and hardware offloading, have been examined to alleviate the performance overhead. However, existing designs and implementations incur pragmatic issues, such as compatibility, manageability, and insufficient quality of performance. We propose yet another design and implementation of zero-copy/pass-through acceleration (named IOVTee) to resolve real-world problems as well as to enhance the forwarding efficiency. IOVTee takes advantage of pre-processing of virtual switches with achieving zero-copy on the receive (Rx) path. The pluggable style of IOVTee for vhost-user (the de-facto virtual network I/O) enables our approach to be transparent to both containers/VMs and virtual switches. In this article, we explain the heart of IOVTee, a fully software-based Rx queue mapping mechanism (between physical and virtual) that enables a concept of Virtual DMA Write-through (to the NF). Our evaluation results showed that applying IOVTee to vhost-user drastically increased efficiency of packet forwarding in the PVP datapath (by 45% and 98% for traffic of 64-byte and 1514-byte packets respectively).  © 2021 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","687-700","","1","18","","","","","","","","","","","","","Scopus","","","","","","","","Design and implementations; Containers; Evaluation results; Mapping; Network functions; Transfer functions; Efficiency; Network function virtualization; container; Network functions virtualization; Packet forwarding; DPDK; Performance bottlenecks; Deterioration; Mapping mechanism; pass-through; Pragmatic issues; Real-world problem; Vhost-user; zero-copy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSXWAXTT","journalArticle","2020","Milocco, R.; Minet, P.; Renault, E.; Boumerdassi, S.","Evaluating the Upper Bound of Energy Cost Saving by Proactive Data Center Management","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.2988346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091167277&doi=10.1109%2fTNSM.2020.2988346&partnerID=40&md5=5898a7c4839a629fb30177827109bf25","Data Centers (DCs) need to periodically configure their servers in order to meet user demands. Since appropriate proactive management to meet demands reduces the cost, either by improving Quality of Service (QoS) or saving energy, there is a great interest in studying different proactive strategies based on predictions of the energy used to serve CPU and memory requests. The amount of savings that can be achieved depends not only on the selected proactive strategy but also on user-demand statistics and the predictors used. Despite its importance, it is difficult to find theoretical studies that quantify the savings that can be made, due to the problem complexity. A proactive DC management strategy is presented together with its upper bound of energy cost savings obtained with respect to a purely reactive management. Using this method together with records of the recent past, it is possible to quantify the efficiency of different predictors. Both linear and nonlinear predictors are studied, using a Google data set collected over 29 days, to evaluate the benefits that can be obtained with these two predictors.  © 2004-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","1527-1541","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Networks (circuits); Computer networks; Proactive management; machine learning; Data center management; Data center (DCs); energy cost; Energy cost savings; Management strategies; Nonlinear predictors; prediction; proactive management; Problem complexity; Theoretical study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZ7AB2DE","conferencePaper","2015","Emmerich, P.; Gallenmüller, S.; Raumer, D.; Wohlfart, F.; Carle, G.","MoonGen: A scriptable high-speed packet generator","","","","10.1145/2815675.2815692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954101391&doi=10.1145%2f2815675.2815692&partnerID=40&md5=2287e9b1f85c0174101e0fa8aad8e788","We present MoonGen, a flexible high-speed packet generator. It can saturate 10GbE links with minimum-sized packets while using only a single CPU core by running on top of the packet processing framework DPDK. Linear multicore scaling allows for even higher rates: We have tested MoonGen with up to 178.5 Mpps at 120Gbit/s. Moving the whole packet generation logic into user-controlled Lua scripts allows us to achieve the highest possible flexibility. In addition, we utilize hardware features of commodity NICs that have not been used for packet generators previously. A key feature is the measurement of latency with sub-microsecond precision and accuracy by using hardware timestamping capabilities of modern commodity NICs. We address timing issues with software-based packet generators and apply methods to mitigate them with both hardware support and with a novel method to control the inter-packet gap in software. Features that were previously only possible with hardware-based solutions are now provided by MoonGen on commodity hardware. MoonGen is available as free software under the MIT license in our git repository at https://github.com/emmericp/MoonGen. © 2015 ACM.","2015","2025-10-22 19:07:36","2025-10-22 19:07:36","","275-287","","","2015-October","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Internet; HTTP; Hardware supports; Packet networks; Reconfigurable hardware; DPDK; Packet processing; Commodity hardware; Hardware features; Lua; Packet generation; Packet generations; User space networking; User spaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM SIGCOMM Internet Measurement Conference, IMC","","","","","","","","","","","","","","",""
"J8UQ3UMX","conferencePaper","2018","Abdollahi Vayghan, L.; Saied, M.A.; Toeroe, M.; Khendek, F.","Deploying Microservice Based Applications with Kubernetes: Experiments and Lessons Learned","","","","10.1109/CLOUD.2018.00148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057488012&doi=10.1109%2fCLOUD.2018.00148&partnerID=40&md5=887f0d831b37008f1ba41fdff4a7f72a","Microservices represent a new architectural style where small and loosely coupled modules can be developed and deployed independently to compose an application. This architectural style brings various benefits such as maintainability and flexibility in scaling and aims at decreasing downtime in case of failure or upgrade. One of the enablers is Kubernetes, an open source platform that provides mechanisms for deploying, maintaining, and scaling containerized applications across a cluster of hosts. Moreover, Kubernetes enables healing through failure recovery actions to improve the availability of applications. As our ultimate goal is to devise architectures to enable high availability (HA) with Kubernetes for microservice based applications, in this paper we examine the availability achievable through Kubernetes under its default configuration. We have conducted a set of experiments which show that the service outage can be significantly higher than expected. © 2018 IEEE.","2018","2025-10-22 19:07:36","2025-10-22 19:07:36","","970-973","","","2018-July","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Docker; Kubernetes; Microservices; Cloud computing; Computer system recovery; Architecture; Architectural style; High availability; Orchestration; Availability; Failure; Open source platforms; Default configurations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"CNL3XAW7","journalArticle","2020","","","Cloud-native Network Function (CNF) Testbed","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132012337&partnerID=40&md5=070af8103e252b3130a35a5dc5d7b658","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SXW4JENN","journalArticle","2015","Raumer, D.; Wohlfart, F.; Scholz, D.; Emmerich, P.; Carle, G.","Performance exploration of software-based packet processing systems","Leistungs-, Zuverlässigkeits-und Verlässlichkeitsbewertung von Kommunikationsnetzen und verteilten Systemen","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006995088&partnerID=40&md5=a8cb390b614c3a69ddc2e18b4e390920","","2015","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJEGMWQS","journalArticle","2020","Nguyen, V.; Tasdemir, E.; Nguyen, G.T.; Lucani, D.E.; Fitzek, F.H.P.; Reisslein, M.","DSEP Fulcrum: Dynamic sparsity and expansion packets for fulcrum network coding","IEEE Access","","","10.1109/ACCESS.2020.2989619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084789500&doi=10.1109%2fACCESS.2020.2989619&partnerID=40&md5=e789a14a8638393a8fa69ce8c2cbaa5e","Fulcrum coding combines a high-field outer Random Linear Network Coding (RLNC) that generates outer coding expansion packets with a small-field inner RLNC that combines the source packets and the outer coding expansion packets. This two-layer Fulcrum coding allows flexible decoding in receivers with heterogeneous computational capabilities. Fulcrum coding has so far only been studied for conventional dense RLNC, which randomly selects all coding coefficients, and only for a statically fixed number of outer expansion packets. However, the probability that the coding coefficient row of a newly received packet is linearly independent of prior received coding coefficient rows (a prerequisite for successful decoding) is highly dynamic. We propose to exploit the dynamics of this probability to reduce the computational complexity of Fulcrum coding. In particular, we vary the density of non-zero coding coefficients, i.e., equivalently, the sparsity of coding coefficients, and the number of outer expansion packets to keep the complexity low while maintaining a reasonably high decoding probability. We introduce the general principles of dynamic sparsity and expansion packets (DSEP) for Fulcrum coding as well as two specific example DSEP policies. Our evaluations indicate that DSEP Fulcrum can increase the encoding throughput tenfold and increase the decoding throughput 1.4 to 4.3 fold while achieving decoding probabilities that are typically less than 1% lower than the conventional Fulcrum decoding probabilities. We also find that DSEP achieves somewhat higher encoding and decoding throughputs than the CodornicesRq (Release 2.1) implementation of RaptorQ block coding for small blocks (generations) of source packets, while RaptorQ is substantially faster for large generation sizes. Furthermore, we develop and evaluate an elementary DSEP recoding mechanism that achieves a recoding throughput more than double the decoding throughput. © 2013 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","78293-78314","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Computational complexity; Packet networks; Encoding (symbols); Complex networks; throughput; Network coding; Probability; Decoding; Block coding; Computational capability; Encoding and decoding; Encoding throughput; Expansion; Fixed numbers; heterogeneous devices; High field; Linear networks; Linearly independents; Random Linear Network Coding; random linear network coding (RLNC); RaptorQ; recoding; sparsity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSGFEAKL","journalArticle","2020","Wang, T.; Zhang, W.; Xu, J.; Gu, Z.","Workflow-Aware Automatic Fault Diagnosis for Microservice-Based Applications with Statistics","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3022028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090950489&doi=10.1109%2fTNSM.2020.3022028&partnerID=40&md5=0e18c64082c18bf44f144799a4764966","Microservice architectures bring many benefits, e.g., faster delivery, improved scalability, and greater autonomy, so they are widely adopted to develop and operate Internet-based applications. How to effectively diagnose the faults of applications with lots of dynamic microservices has become a key to guarantee applications' performance and reliability. As a microservice performs various behaviors in different workflows of processing requests, existing approaches often cannot accurately locate the root cause of an application with interactive microservices in a dynamic deployment environment. We propose a workflow-aware automatic fault diagnosis approach for microservice-based applications with statistics. We characterize traces across microservices with calling trees, and then learn trace patterns as baselines. For the faults affecting the workflows of processing requests, we estimate the workflows' anomaly degrees, and then locate the microservices causing anomalies by comparing the difference between current traces and learned baselines with tree edit distance. For performance anomalies causing significantly increased response time, we employ principal component analysis to extract suspicious microservices with large fluctuation in response time. Finally, we evaluate our approach on three typical microservice-based applications with a series of experiments. The results show that our approach can accurately locate the microservices causing anomalies. © 2004-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","2350-2363","","4","17","","","","","","","","","","","","","Scopus","","","","","","","","Failure analysis; Fault detection; Performance anomaly; microservice; workflow; execution traces; Dynamic deployment; Anomaly degrees; Automatic fault diagnosis; Current traces; Electric fault currents; Fault diagnosis; Forestry; Internet based application; Performance and reliabilities; statistics; Tree edit distance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBISRCY2","journalArticle","2021","Botez, R.; Costa-Requena, J.; Ivanciu, I.-A.; Strautiu, V.; Dobrota, V.","Sdn-based network slicing mechanism for a scalable 4g/5g core network: A kubernetes approach","Sensors","","","10.3390/s21113773","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106739884&doi=10.3390%2fs21113773&partnerID=40&md5=8ba15b751674a9b759ad8e25ce633ad3","Managing the large volumes of IoT and M2M traffic requires the evaluation of the scala-bility and reliability for all the components in the end-to-end system. This includes connectivity, mobile network functions, and application or services receiving and processing the data from end devices. Firstly, this paper discusses the design of a containerized IoT and M2M application and the mechanisms for delivering automated scalability and high availability when deploying it in: (1) the edge using balenaCloud; (2) the Amazon Web Services cloud with EC2 instances; and (3) the dedi-cated Amazon Web Services IoT service. The experiments showed that there are no significant differences between edge and cloud deployments regarding resource consumption. Secondly, the solutions for scaling the 4G/5G network functions and mobile backhaul that provide the connectivity between devices and IoT/M2M applications are analyzed. In this case, the scalability and high availability of the 4G/5G components are provided by Kubernetes. The experiments showed that our proposed scaling algorithm for network slicing managed with SDN guarantees the necessary radio and network resources for end-to-end high availability. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","11","21","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; cloud computing; Cloud computing; Internet of things; Web services; Network functions; Transfer functions; NFV; Websites; Data handling; Amazon web services; High availability; algorithm; article; Scalability; IoT; Resource consumption; Network resource; SDN; 5G; Cloud deployments; EPC; Network slicing; 4G mobile communication systems; End-to-end systems; Machine-to-machine communication; Scaling algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVZZNVKQ","journalArticle","2011","Li, Y.; Soljanin, E.; Spasojevic, P.","Effects of the generation size and overlap on throughput and complexity in randomized linear network coding","IEEE Transactions on Information Theory","","","10.1109/TIT.2010.2095111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251485294&doi=10.1109%2fTIT.2010.2095111&partnerID=40&md5=d461fe42a5c6ecc5ae1cf0f2f54694ca","To reduce computational complexity and delay in randomized network coded content distribution, and for some other practical reasons, coding is not performed simultaneously over all content blocks, but over much smaller, possibly overlapping subsets of these blocks, known as generations. A penalty of this strategy is throughput reduction. To analyze the throughput loss, we model coding over generations with random generation scheduling as a coupon collector's brotherhood problem. This model enables us to derive the expected number of coded packets needed for successful decoding of the entire content as well as the probability of decoding failure (the latter only when generations do not overlap) and further, to quantify the tradeoff between computational complexity and throughput. Interestingly, with a moderate increase in the generation size, throughput quickly approaches link capacity. Overlaps between generations can further improve throughput substantially for relatively small generation sizes. © 2006 IEEE.","2011","2025-10-22 19:07:36","2025-10-22 19:07:36","","1111-1123","","2","57","","","","","","","","","","","","","Scopus","","","","","","","","Computational complexity; Throughput; Network coding; Coded packet; Content distribution; Coupon collector's problem; Decoding; Decoding failure; Information theory; Linear network coding; Link capacities; Random generation; Rate-less codes; rateless codes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZNWBRM9","journalArticle","2020","Gholipoor, N.; Saeedi, H.; Mokari, N.; Jorswieck, E.A.","E2E QoS Guarantee for the Tactile Internet via Joint NFV and Radio Resource Allocation","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3001359","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086725328&doi=10.1109%2fTNSM.2020.3001359&partnerID=40&md5=fab4f089eaba251d666d543e44db3284","The Tactile Internet (TI) is one of the next generation wireless network services with end to end (E2E) delay as low as 1 ms. Since this ultra low E2E delay cannot be met in the current 4G network architecture, it is necessary to investigate this service in the next generation wireless network by considering new technologies such as networks function virtualization (NFV). On the other hand, given the importance of E2E delay in the TI service, it is crucial to consider the delay of all parts of the network, including the radio access part and the NFV core part. In this paper, for the first time, we investigate the joint radio resource allocation (R-RA) and NFV resource allocation (NFV-RA) in a heterogeneous network where queuing delays, transmission delays, and delays resulting from virtual network function (VNF) execution are jointly considered. For this setup, we formulate a new resource allocation (RA) problem to minimize the total cost function subject to guaranteeing E2E delay of each connection. Since the proposed optimization problem is highly non-convex, we exploit alternative search method (ASM), successive convex approximation (SCA), and heuristic algorithms to solve it. Besides, for the NFV-RA, we propose an online heuristic algorithm, and analyze its performance for the TI service. Simulation results reveal that the proposed scheme can significantly reduce the network costs compared to the case where the two problems are optimized separately. Moreover, we compare the online algorithm with its offline counterpart as well as a baseline approach and it is shown that the online algorithm outperforms both of them.  © 2004-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","1788-1804","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; Virtual networks; Resource allocation; Heuristic algorithms; Network function virtualization; Wireless networks; Approximation algorithms; Optimization problems; Heuristic methods; Queueing networks; On-line algorithms; Radio transmission; network function virtualization (NFV); Cost functions; Heterogeneous networks; virtualized network function (VNF); end-to-end (E2E) delay; network service (NS); Next generation networks; Next-generation wireless network; queuing delay; Radio resource allocation; Successive convex approximations; Tactile Internet (TI); Total cost function; transmission delay; Transmission delays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KU9X2BEU","journalArticle","2021","Shah, S.D.A.; Gregory, M.A.; Li, S.","Cloud-Native Network Slicing Using Software Defined Networking Based Multi-Access Edge Computing: A Survey","IEEE Access","","","10.1109/ACCESS.2021.3050155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099553598&doi=10.1109%2fACCESS.2021.3050155&partnerID=40&md5=c8d253d87d2e8c0ca378ca2fb479f705","Fifth-Generation (5G) mobile cellular networks provide a promising platform for new, innovative and diverse IoT applications, such as ultra-reliable and low latency communication, real-time and dynamic data processing, intensive computation, and massive device connectivity. End-to-End (E2E) network slicing candidates present a promising approach to resource allocation and distribution that permit operators to flexibly provide scalable virtualized and dedicated logical networks over common physical infrastructure. Though network slicing promises the provision of services on demand, many of its use cases, such as self-driving cars and Google's Stadia, would require the integration of a Multi-Access Edge Computing (MEC) platform in 5G networks. Edge Computing is envisioned as one of the key drivers for 5G and Sixth-Generation (6G) mobile cellular networks, but its role in network slicing remains to be fully explored. We investigate MEC and network slicing for the provision of 5G service focused use cases. Recently, changes to the cloud-native 5G core are a focus with MEC use cases providing network scalability, elasticity, flexibility, and automation. A cloud-native microservices architecture, along with its potential use cases for 5G network slicing, is envisioned. This paper also elaborates on the recent advances made in enabling E2E network slicing, its enabling technologies, solutions, and current standardization efforts. Finally, this paper identifies open research issues and challenges and provides possible solutions and recommendations.  © 2013 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","10903-10924","","","9","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Mobile telecommunication systems; 5G mobile communication systems; multi-access edge computing; Wireless networks; Data handling; Queueing networks; cloud native; Software defined networking; software defined networking; IOT applications; Enabling technologies; Low-latency communication; Network slicing; and low latency communication; Mobile cellular networks; Network scalability; Research issues; Services on demand; ultra-reliable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBM5Z26R","journalArticle","2020","Yu, H.; Yang, J.; Fung, C.","Fine-Grained Cloud Resource Provisioning for Virtual Network Function","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.2986223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083456353&doi=10.1109%2fTNSM.2020.2986223&partnerID=40&md5=bb9fe1a877ffd318d188fed2d478c885","The deployment of Virtualized Network Functions is expected to be dynamic and swift when using Network Function Virtualization technology. The dynamic nature of workload from users requires the resource allocation of underlying infrastructure to be flexible to cope with the changes. Existing works investigated elastic NFV solutions by dynamically creating and dismantling Virtual Machine (VM) replicas, while maintaining balanced workload among VMs. However, those solutions are coarse-grained which may cause unnecessary resource over-provisioning as different network functions consume different amount of resources. In this paper, we present ElasticNFV, a dynamic and fine-grained cloud resource provisioning solution for VNF. ElasticNFV takes real-time resource demand of multiple service chains and allocates resources through an elastic provision mechanism. When a scaling conflict occurs, ElasticNFV provides a two-phase minimal migration algorithm to optimize the migration time and embedding cost of VNF instances. We implement ElasticNFV on top of the KVM platform to provide elastic VM for each VNF instance and Open vSwitch to form elastic intra-cloud network with virtual links between VNF instances. Our evaluation results show that ElasticNFV can improve VNF performance significantly, and achieve high resource utilization and fast migration time with low cost.  © 2004-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","1363-1376","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Evaluation results; Virtual networks; Network functions; Transfer functions; Network function virtualization; Virtual machine; Over provisioning; Balanced work-load; Resource utilizations; Migration algorithms; resource allocation; resource scaling; network function virtualization (NFV); Middlebox; Multiple services; service chain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRINKVS2","journalArticle","2021","","","Configure Traffic Capturing Options","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132006209&partnerID=40&md5=b7a648e16a3f0eb4bbe3c818a90e083c","","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URF5YPWD","journalArticle","","Joseph, O.; Micheal, C.; Tom, P.","","Benefitting Power and Performance Sleep Loops","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132022475&partnerID=40&md5=19f655a73f3ffc6195c802d42ffb64f0","","","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JDVQKLLA","journalArticle","2020","Van Tu, N.; Yoo, J.-H.; Won-Ki Hong, J.","Accelerating Virtual Network Functions with Fast-Slow Path Architecture Using eXpress Data Path","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3000255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091158178&doi=10.1109%2fTNSM.2020.3000255&partnerID=40&md5=e657455c9ec1cfd0e097402e4684c7c9","By decoupling network functions from dedicated, proprietary hardware network devices, Network Function Virtualization (NFV) allows building Virtual Network Functions (VNFs) that can run on standard, commodity servers to reduce cost and gain flexibility in network deployment, operation, and management. However, building VNFs with high-throughput and low-latency is a big challenge. In this paper, we propose eVNF - a hybrid fast-slow path architecture to build and accelerate VNFs with eXpress Data Path (XDP), which is a Linux kernel framework that enables high performance and programmable network processing. The programmability of XDP is limited to ensure kernel safety, thus causing difficulties when using XDP to accelerate VNFs. eVNF solves this problem by taking a hybrid approach: leave the simple but critical tasks inside the kernel with XDP, and let complex tasks be processed outside XDP, e.g., in user-space. With the hybrid architecture, eVNF allows building fast and flexible VNFs. We applied eVNF to build four prototype VNFs: Flow Monitoring (eFM), Firewall (eFW), Deep Packet Inspection (eDPI), and Load Balancer (eLB). These VNFs are evaluated individually and in service function chains (SFCs) using OpenStack. Our experiments showed that eVNF can significantly improve service throughput as well as reduce latency and CPU usage. eVNF-based VNFs also can scale out with the number of CPU cores and can combine with Open vSwitch - Data Plane Development Kit (OvS-DPDK) for better performance.  © 2004-2012 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","1474-1486","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","Virtual networks; Linux; Transfer functions; Network function virtualization; Network management; Service functions; Programmability; network function virtualization; virtual network function; AF_XDP; Decoupling network; Deep packet inspection; eBPF; eXpress data path; Flow monitoring; high-throughput packet processing; Hybrid architectures; low latency; Programmable network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z9LXVCN7","journalArticle","2020","Xiang, Z.; Höweler, M.; Zhang, R.; Xia, F.","","Build-VNF A Collection of Utilities to Build, Test, and Benchmark Practical and High-Performance VNFs Using Containers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132005087&partnerID=40&md5=13875e2f40bd37b4110bfecbe808ead6","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PVV6MXK","journalArticle","2020","Borylo, P.; Tornatore, M.; Jaglarz, P.; Shahriar, N.; Chołda, P.; Boutaba, R.","Latency and energy-aware provisioning of network slices in cloud networks","Computer Communications","","","10.1016/j.comcom.2020.03.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082922044&doi=10.1016%2fj.comcom.2020.03.050&partnerID=40&md5=09956ea49da4735a0aa9f37843f50b1e","Modern network services are constantly increasing their requirements in terms of bandwidth, latency and cost efficiency. To satisfy these requirements, the concept of network slicing has been introduced in the context of next-generation 5G networks. However, to successfully provision resources to slices, a complex optimization problem must be addressed to allocate resources over a cloud network, i.e., a distributed computing infrastructure interconnected through high-capacity network links. In this study, we propose two new latency and energy-aware optimization models for provisioning 5G slices in cloud networks comprising both distributed computing and network resources. The proposed approaches differ from other existing solutions since we conduct our studies with respect to the end-to-end latency. Relevant models of latency and energy consumption are proposed based on a comprehensive review of the state-of-the-art. To effectively solve those optimization problems, a configurable heuristic is also proposed and investigated over different network topologies. Performance of the proposed heuristic is compared against near-optimal solutions. Moreover, we assess the importance of matching between resource provisioning algorithms and architectural assumptions related to 5G network slices and a proper problem modeling. © 2020 The Authors","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","1-19","","","157","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; 5G mobile communication systems; Cost-efficiency; Multi-objectives optimization; Multiobjective optimization; Energy-aware provisioning; Queueing networks; Distributed computing; VNF placement; Latency-aware; Multi-objective optimization; 5g network slicing; 5G network slicing; Bandwidth efficiency; Cloud networks; Network slicing; Networks services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"263JZ63Y","journalArticle","2020","Sharma, S.K.; Woungang, I.; Anpalagan, A.; Chatzinotas, S.","Toward Tactile Internet in beyond 5G Era: Recent Advances, Current Issues, and Future Directions","IEEE Access","","","10.1109/ACCESS.2020.2980369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082972187&doi=10.1109%2fACCESS.2020.2980369&partnerID=40&md5=6181453932878af09e444a90f5914aac","Tactile Internet (TI) is envisioned to create a paradigm shift from the content-oriented communications to steer/control-based communications by enabling real-time transmission of haptic information (i.e., touch, actuation, motion, vibration, surface texture) over Internet in addition to the conventional audiovisual and data traffics. This emerging TI technology, also considered as the next evolution phase of Internet of Things (IoT), is expected to create numerous opportunities for technology markets in a wide variety of applications ranging from teleoperation systems and Augmented/Virtual Reality (AR/VR) to automotive safety and eHealthcare towards addressing the complex problems of human society. However, the realization of TI over wireless media in the upcoming Fifth Generation (5G) and beyond networks creates various non-conventional communication challenges and stringent requirements in terms of ultra-low latency, ultra-high reliability, high data-rate connectivity, resource allocation, multiple access and quality-latency-rate tradeoff. To this end, this paper aims to provide a holistic view on wireless TI along with a thorough review of the existing state-of-the-art, to identify and analyze the involved technical issues, to highlight potential solutions and to propose future research directions. First, starting with the vision of TI and recent advances and a review of related survey/overview articles, we present a generalized framework for wireless TI in the Beyond 5G Era including a TI architecture, the main technical requirements, the key application areas and potential enabling technologies. Subsequently, we provide a comprehensive review of the existing TI works by broadly categorizing them into three main paradigms; namely, haptic communications, wireless AR/VR, and autonomous, intelligent and cooperative mobility systems. Next, potential enabling technologies across physical/Medium Access Control (MAC) and network layers are identified and discussed in detail. Also, security and privacy issues of TI applications are discussed along with some promising enablers. Finally, we present some open research challenges and recommend promising future research directions. © 2013 IEEE.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","56948-56991","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Internet of Things (IOT); 5G mobile communication systems; Augmented reality; Network layers; IoT; Access control; 5G; Future research directions; Haptic communications; augmented reality (AR); Augmented/virtual reality; beyond 5G; Cooperative communication; haptic communications; Low-latency communication; Real-time transmissions; Security and privacy issues; Tactile internet; Textures; ultra-reliable and low-latency communications (URLLC); virtual reality (VR); Visual servoing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDFG8HNI","journalArticle","2020","Le Duc, T.; Leiva, R.G.; Casari, P.; Östberg, P.-O.","Machine learning methods for reliable resource provisioning in edge-cloud computing: A survey","ACM Computing Surveys","","","10.1145/3341145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072380854&doi=10.1145%2f3341145&partnerID=40&md5=47076a686bc04cca9a6254ea60f18b51","Large-scale software systems are currently designed as distributed entities and deployed in cloud data centers. To overcome the limitations inherent to this type of deployment, applications are increasingly being supplemented with components instantiated closer to the edges of networks—a paradigm known as edge computing. The problem of how to efficiently orchestrate combined edge-cloud applications is, however, incompletely understood, and a wide range of techniques for resource and application management are currently in use. This article investigates the problem of reliable resource provisioning in joint edge-cloud environments, and surveys technologies, mechanisms, and methods that can be used to improve the reliability of distributed applications in diverse and heterogeneous network environments. Due to the complexity of the problem, special emphasis is placed on solutions to the characterization, management, and control of complex distributed applications using machine learning approaches. The survey is structured around a decomposition of the reliable resource provisioning problem into three categories of techniques: workload characterization and prediction, component placement and system consolidation, and application elasticity and remediation. Survey results are presented along with a problem-oriented discussion of the state-of-the-art. A summary of identified challenges and an outline of future research directions are presented to conclude the article. © 2019 Association for Computing Machinery.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","5","52","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Cloud computing; Cloud-computing; Distributed systems; Edge computing; Surveys; Edge clouds; Machine learning; Distributed applications; Autoscaling; Complex networks; Optimisations; Machine-learning; Reliability; Placement; Consolidation; Heterogeneous networks; Machine learning methods; Remediation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q6LPDECE","journalArticle","2021","Harkous, H.; Jarschel, M.; He, M.; Pries, R.; Kellerer, W.","P8: P4 with Predictable Packet Processing Performance","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.3030102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108207879&doi=10.1109%2fTNSM.2020.3030102&partnerID=40&md5=fae627779ca282486737b020c7e5f22a","Data plane programmability brings network flexibility to a new level. However, it introduces the complexity of the data path's program as a new factor that influences packet forwarding latency and thus devices' performance. Accurate identification of the relation between data path complexity and packet forwarding latency enables the design and management of networks with predictable performance. In this article, we leverage the characteristics of P4 programming language to provide a method for estimating the packet forwarding latency as a function of the data path program. We analyze the impact of different P4 constructs on packet processing latency for three state-of-the-art P4 devices: Netronome SmartNIC, NetFPGA-SUME, and T4P4S DPDK-based software switch. Besides comparing the performance of these three targets, we use the derived results to propose a method for estimating the average packet latency, at compilation time, of arbitrary P4-based network functions implemented using the surveyed P4 constructs. The proposed method is finally validated using a set of realistic network functions, which shows that our method estimates the average packet latency with sub-microsecond precision.  © 2004-2012 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","2846-2859","","3","18","","","","","","","","","","","","","Scopus","","","","","","","","State of the art; Network functions; Transfer functions; Performance evaluation; Complex networks; software-defined networking; modeling; Packet forwarding; Packet processing; Programmability; P4; Average packet latencies; device benchmarking; Network flexibility; programmable data plane; Software switches","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYA4PE4A","journalArticle","2014","Bolla, R.; Bruschi, R.; Carrega, A.; Davoli, F.","Green networking with packet processing engines: Modeling and optimization","IEEE/ACM Transactions on Networking","","","10.1109/TNET.2013.2242485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873962195&doi=10.1109%2fTNET.2013.2242485&partnerID=40&md5=efbc5bbd40b15aab9a628993d298d263","With the aim of controlling power consumption in metro/transport and core networks, we consider energy-aware devices able to reduce their energy requirements by adapting their performance. In particular, we focus on state-of-the-art packet processing engines, which generally represent the most energy-consuming components of network devices, and which are often composed of a number of parallel pipelines to 'divide and conquer' the incoming traffic load. Our goal is to control both the power configuration of pipelines and the way to distribute traffic flows among them. We propose an analytical model to accurately represent the impact of green network technologies (i.e., low power idle and adaptive rate) on network- and energy-aware performance indexes. The model has been validated with experimental results, performed by using energy-aware software routers loaded by real-world traffic traces. The achieved results demonstrate how the proposed model can effectively represent energy- and network-aware performance indexes. On this basis, we propose a constrained optimization policy, which seeks the best tradeoff between power consumption and packet latency times. The procedure aims at dynamically adapting the energy-aware device configuration to minimize energy consumption while coping with incoming traffic volumes and meeting network performance constraints. In order to deeply understand the impact of such policy, a number of tests have been performed by using experimental data from software router architectures and real-world traffic traces. © 2013 IEEE.","2014","2025-10-22 19:07:36","2025-10-22 19:07:36","","110-123","","1","22","","","","","","","","","","","","","Scopus","","","","","","","","Adaptive rate; Forwarding engine; Green networking; Low power idle; Multipipeline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BF32GH2H","journalArticle","2017","Willis, K.; Walsh, T.","","PowerEdge Servers and 2nd Generation Intel_ Xeon_ Scalable Processors Naming Convention and Special Use Case Offerings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132030908&partnerID=40&md5=151d29a8a5d16dbe689416a2c534413f","","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWSR94LK","journalArticle","2018","Pandit, K.","","Modeling the Impact of CPU Properties to Optimize and Predict Packet-Processing Performance","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132017493&partnerID=40&md5=03524ff37d8af60c7819386ad5dc7981","","2018","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMS8JU3W","journalArticle","2018","","","Cloud-native network functions (CNFs)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132038112&partnerID=40&md5=cdeef27a31fac998235b74cdda147ba4","","2018","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHU9R3CW","conferencePaper","2019","Li, W.; Lemieux, Y.; Gao, J.; Zhao, Z.; Han, Y.","Service Mesh: Challenges, state of the art, and future research opportunities","","","","10.1109/SOSE.2019.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065961725&doi=10.1109%2fSOSE.2019.00026&partnerID=40&md5=84fdf0c8ecda35cac57f5d6bfd63a5b8","While the technology development towards microservices can significantly improve the speed and agility of software service delivery, it also raises the operational complexity associated with modern applications. This has led to the emergence of Service Mesh, a promising approach to mitigate this situation by introducing a dedicated infrastructure layer over microservices without imposing modification on the service implementations. Aiming to inspire more practical research work in this exploited area, we in this paper present a comprehensive review on the state of the art of Service Mesh and discuss the related challenges and its adoption. Finally, we highlight the opportunities for future research in this subject. © 2019 IEEE.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","122-127","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Microservices; Cloud computing; DevOps; Edge computing; Systems engineering; Information services; Mesh generation; Engineering research; Service oriented architecture (SOA); Edge Computing; Service Mesh; Challenges; Opportunities; Robotics; Service delivery; Service Delivery; Service Oriented Architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 13th IEEE International Conference on Service-Oriented System Engineering, SOSE 2019, 10th International Workshop on Joint Cloud Computing, JCC 2019 and 2019 IEEE International Workshop on Cloud Computing in Robotic Systems, CCRS 2019","","","","","","","","","","","","","","",""
"74PLSLQW","journalArticle","2019","Zhang, T.; Linguaglossa, L.; Gallo, M.; Giaccone, P.; Rossi, D.","Flowatcher-DPDK: Lightweight line-rate flow-level monitoring in software","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2019.2913710","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080533219&doi=10.1109%2fTNSM.2019.2913710&partnerID=40&md5=6b6f76f1533d5331eb49ae32e1f43c5b","In the last few years, several software-based solutions have been proved to be very efficient for high-speed packet processing, traffic generation, and monitoring, and can be considered valid alternatives to expensive and non-flexible hardware-based solutions. In this paper, we first benchmark heterogeneous design choices for software-based packet monitoring systems in terms of achievable performance and required resources (i.e., the number of CPU cores). Building on this extensive analysis we design FloWatcher-DPDK, a DPDK-based high-speed software traffic monitor we provide to the community as an open source project. In a nutshell, FloWatcher-DPDK provides tunable fine-grained statistics at packet and flow levels. Experimental results demonstrate that FloWatcher-DPDK sustains per-flow statistics with 5-nines precision at high-speed (e.g., 14.88 Mpps) using a limited amount of resources. Finally, we showcase the usage of FloWatcher-DPDK by configuring it to analyze the performance of two open source prototypes for stateful flow-level end-host and in-network packet processing. © 2019 IEEE.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","1143-1156","","3","16","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Open systems; Benchmarking; Traffic generation; Achievable performance; Flow statistics; High-speed packet processing; Intel DPDK; Monitoring system; Network traffic monitoring; Open source projects; Per-flow packet measurement; Software-based solutions; Traffic monitor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5TUNH7G2","journalArticle","2020","","","Sample Virtualized Network Fuction (SampleVNF)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132042614&partnerID=40&md5=5d9e08432ff92a46d4326fcd4d40e5c7","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DFZHMPSP","conferencePaper","2017","Cao, L.; Sharma, P.; Fahmy, S.; Saxena, V.","ENVI: Elastic resource flexing for network function virtualization","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084163207&partnerID=40&md5=2d5d87131b9ee1535b7f746bf9657c76","Dynamic and elastic resource allocation to Virtual Network Functions (VNFs) in accordance with varying workloads is a must for realizing promised reductions in capital and operational expenses in Network Functions Virtualization (NFV). However, workload heterogeneity and complex relationships between resources allocated to a VNF and the resulting capacity makes elastic resource flexing a challenging task. We propose an NFV resource flexing system, ENVI, that uses a combination of VNF-level features and infrastructure-level features to construct a machine-learning-based decision engine for detecting resource flexing events. ENVI also extracts the dependence relationship among VNFs in deployed Service Function Chains (SFCs) to carefully plan the sequence of resource flexing steps upon scaling detection. We present preliminary results for the accuracy of ENVI’s resource flexing decision engine with two different VNFs, namely, the caching proxy Squid and the intrusion detection system Suricata. Our preliminary results show that using a combination of features to train a neural network model is a promising approach for scaling detection. © 2017 USENIX Association. All rights reserved.","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Virtual reality; Decision engines; Virtual networks; Transfer functions; Network function virtualization; Operational expense; Intrusion detection; Intrusion Detection Systems; Feature extraction; Complex relationships; Engines; Dependence relationships; Deployed services; Neural network model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","9th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2017, co-located with USENIX ATC 2017","","","","","","","","","","","","","","",""
"FDRV82YK","journalArticle","2020","Carrascal, D.; Rojas, E.; Alvarez-Horcajo, J.; Lopez-Pajares, D.; Martínez-Yelmo, I.","Analysis of P4 and XDP for IoT Programmability in 6G and Beyond","IoT","","","10.3390/iot1020031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111225752&doi=10.3390%2fiot1020031&partnerID=40&md5=a6cacee7fce0e09efd71e345d2ead448","Recently, two technologies have emerged to provide advanced programmability in Software-Defined Networking (SDN) environments, namely P4 and XDP. At the same time, the Internet of Things (IoT) represents a pillar of future 6G networks, which will be also sustained by SDN. In this regard, there is a need to analyze the suitability of P4 and XDP for IoT. In this article, we aim to compare both technologies to help future research efforts in the field. For this purpose, we evaluate both technologies by implementing diverse use cases, assessing their performance and providing a quick qualitative overview. All tests and design scenarios are publicly available in GitHub to guarantee replication and serve as initial steps for researchers that want to initiate in the field. Results illustrate that currently XDP is the best option for constrained IoT devices, showing lower latency times, half the CPU usage, and reduced memory in comparison with P4. However, development of P4 programs is more straightforward and the amount of code lines is more similar regardless of the scenario. Additionally, P4 has a lot of potential in IoT if a special effort is made to improve the most common software target, BMv2. © 2020 by the authors.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","605-622","","2","1","","","","","","","","","","","","","Scopus","","","","","","","","edge computing; IoT; 6G; SDN; 5G; P4; programmability; XDP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KCWSYLRE","journalArticle","2019","Iqbal, M.F.; Zahid, M.; Habib, D.; John, L.K.","Efficient Prediction of Network Traffic for Real-Time Applications","Journal of Computer Networks and Communications","","","10.1155/2019/4067135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062350113&doi=10.1155%2f2019%2f4067135&partnerID=40&md5=2fb896ba6258eec7cb5c2f29469b648e","Accurate real-time traffic prediction is required in many networking applications like dynamic resource allocation and power management. This paper explores a number of predictors and searches for a predictor which has high accuracy and low computation complexity and power consumption. Many predictors from three different classes, including classic time series, artificial neural networks, and wavelet transform-based predictors, are compared. These predictors are evaluated using real network traces. Comparison of accuracy and cost, both in terms of computation complexity and power consumption, is presented. It is observed that a double exponential smoothing predictor provides a reasonable tradeoff between performance and cost overhead. © 2019 Muhammad Faisal Iqbal et al.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","2019","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Dynamic resource allocations; Real-time application; Complex networks; Neural networks; Traffic control; Computation complexity; Different class; Double exponential; Efficient predictions; Networking applications; Real time traffics; Wavelet transforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5JGQKXY","journalArticle","2021","Promwongsa, N.; Ebrahimzadeh, A.; Naboulsi, D.; Kianpisheh, S.; Belqasmi, F.; Glitho, R.; Crespi, N.; Alfandi, O.","A Comprehensive Survey of the Tactile Internet: State-of-the-Art and Research Directions","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2020.3025995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101801592&doi=10.1109%2fCOMST.2020.3025995&partnerID=40&md5=858188f084575fec72e04bd532b6bb3a","The Internet has made several giant leaps over the years, from a fixed to a mobile Internet, then to the Internet of Things, and now to a Tactile Internet. The Tactile Internet goes far beyond data, audio and video delivery over fixed and mobile networks, and even beyond allowing communication and collaboration among things. It is expected to enable haptic communications and allow skill set delivery over networks. Some examples of potential applications are tele-surgery, vehicle fleets, augmented reality and industrial process automation. Several papers already cover many of the Tactile Internet-related concepts and technologies, such as haptic codecs, applications, and supporting technologies. However, none of them offers a comprehensive survey of the Tactile Internet, including its architectures and algorithms. Furthermore, none of them provides a systematic and critical review of the existing solutions. To address these lacunae, we provide a comprehensive survey of the architectures and algorithms proposed to date for the Tactile Internet. In addition, we critically review them using a well-defined set of requirements and discuss some of the lessons learned as well as the most promising research directions.  © 1998-2012 IEEE.","2021","2025-10-22 19:07:36","2025-10-22 19:07:36","","472-523","","1","23","","","","","","","","","","","","","Scopus","","","","","","","","Network architecture; Surveys; State of the art; edge computing; Augmented reality; machine learning; artificial intelligence; tactile Internet; 5G/6G; Communication and collaborations; Critical review; Haptic communications; Industrial processs; ITS architecture; Mobile Internet; Supporting technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TG8J8JK3","journalArticle","2020","Jiang, C.; Fan, T.; Gao, H.; Shi, W.; Liu, L.; Cérin, C.; Wan, J.","Energy aware edge computing: A survey","Computer Communications","","","10.1016/j.comcom.2020.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078566025&doi=10.1016%2fj.comcom.2020.01.004&partnerID=40&md5=f1a80e4069ca1fa2606fc0756dcebe32","Edge computing is an emerging paradigm for the increasing computing and networking demands from end devices to smart things. Edge computing allows the computation to be offloaded from the cloud data centers to the network edge and edge nodes for lower latency, security and privacy preservation. Although energy efficiency in cloud data centers has been broadly investigated, energy efficiency in edge computing is largely left uninvestigated due to the complicated interactions between edge devices, edge servers, and cloud data centers. In order to achieve energy efficiency in edge computing, a systematic review on energy efficiency of edge devices, edge servers, and cloud data centers is required. In this paper, we survey the state-of-the-art research work on energy-aware edge computing, and identify related research challenges and directions, including architecture, operating system, middleware, applications services, and computation offloading. © 2020 Elsevier B.V.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","556-580","","","151","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Cloud data centers; Edge computing; Surveys; Middleware; Benchmarking; Computation offloading; State of the art; Green computing; Research challenges; Systematic Review; Network edges; Security and privacy; Computation partitioning; Computing offloading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLN6YUMB","journalArticle","2020","","","Linux Kernel User's and Administrator's Guide Power Management","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132019946&partnerID=40&md5=96f1ea3793863aa11d4dedafe70e4cf9","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7H57AXS","journalArticle","2019","Diekmann, C.; Naab, J.; Korsten, A.; Carle, G.","Agile Network Access Control in the Container Age","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2018.2889009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058876640&doi=10.1109%2fTNSM.2018.2889009&partnerID=40&md5=1a172299c0ca96670d0b476a50d39b83","Linux containers, such as those managed by Docker, are an increasingly popular way to package and deploy complex applications. However, the fundamental security primitive of network access control for a distributed microservice deployment is often ignored or left to the network operations team. High-level application-specific security requirements are not appropriately enforced by low-level network access control lists. Apart from coarse-grained separation of virtual networks, Docker neither supports the application developer to specify nor the network operators to enforce fine-grained network access control between containers. In a fictional story, we follow DevOp engineer Alice through the lifecycle of a Web application. From the initial design and software engineering through network operations and automation, we show the task expected of Alice and propose tool-support to help. As a full-stack DevOp, Alice is involved in high-level design decisions as well as low-level network troubleshooting. Focusing on network access control, we demonstrate shortcomings in today's policy management and sketch a tool-supported solution. We survey related academic work and show that many existing tools fail to bridge between the different levels of abstractions a full-stack engineer is operating on. Our toolset is formally verified using Isabell/HOL and is available as an open source. © 2018 IEEE.","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","41-55","","1","16","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Containers; Docker; Computer operating systems; Network security; Access control; Tools; policy; container; docker; formal methods; Formal methods; access control; centralized management; Centralized management; firewall; Firewall; Isabelle/HOl; Isabelle/HOL; operations & administration; Public policy; Security management; tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JR67TBKM","conferencePaper","2018","Bachiega, N.G.; Souza, P.S.L.; Bruschi, S.M.; De Souza, S.D.R.S.","Container-based performance evaluation: A survey and challenges","","","","10.1109/IC2E.2018.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048345603&doi=10.1109%2fIC2E.2018.00075&partnerID=40&md5=948531448ee4ea48f0e8b06a8ed48fb4","Virtualization is an expanding technology in all areas of research and development. It has been widely accepted because of characteristics such as elasticity and flexibility in delivering on-demand resources. Nowadays, containers are a new form of virtualization and they have been highlighted as large technology companies are giving more support to them. Containers are a type of OS-level virtualization, in which the kernel allows the existence of multiple isolated instances. This paper presents a survey of recent research and challenges involving containers, focusing on performance evaluation. To achieve this goal, we performed a systematic mapping considering the main databases (Springer, IEEE, ACM, and Scopus), raising the challenges of the area and prospects of future work, considering the recent use of containers. We have observed that there is still little research related to performance evaluation of containers and we consider this topic very important since performance is fundamental to the design and adoption of projects. © 2018 IEEE.","2018","2025-10-22 19:07:36","2025-10-22 19:07:36","","398-403","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Virtual reality; Virtualization; Surveys; Systematic mapping; On demands; Performance evaluation; Performance evaluations; New forms; Recent researches; Research and development; Technology companies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2018 IEEE International Conference on Cloud Engineering, IC2E 2018","","","","","","","","","","","","","","",""
"7D4TF2A5","journalArticle","2020","","","Data Plane Development Kit (DPKD), Version 20.11.1, Sample Applications User Guides, Section 23. L3 Forwarding with Power Management Sample Application","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132037031&partnerID=40&md5=e12c44c15b15dfaf3ff664e1e510db5c","","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUEK3TPL","journalArticle","2017","Liu, Y.","","Optimizing PAPI for Low-Overhead Counter Measurement","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080514388&partnerID=40&md5=e33fd7f1f7ec5d3937c87d209bfc1253","","2017","2025-10-22 19:07:36","2025-10-22 19:07:36","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YN8FICQ","journalArticle","2019","Wahab, O.A.; Kara, N.; Edstrom, C.; Lemieux, Y.","MAPLE: A Machine Learning Approach for Efficient Placement and Adjustment of Virtual Network Functions","Journal of Network and Computer Applications","","","10.1016/j.jnca.2019.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067443855&doi=10.1016%2fj.jnca.2019.06.003&partnerID=40&md5=a265fafa6da3450fa5aa1bc1fa2ea336","As one of the many advantages of cloud computing, Network Function Virtualization (NFV) has revolutionized the network and telecommunication industry through enabling the migration of network functions from expensive dedicated hardware to software-defined components that run in the form of Virtual Network Functions (VNFs). However, with NFV comes numerous challenges related mainly to the complexity of deploying and adjusting VNFs in the physical networks, owing to the huge number of nodes and links in today's datacenters, and the inter-dependency among VNFs forming a certain network service. Several contributions have been made in an attempt to answer these challenges, where most of the existing solutions focus on the static placement of VNFs and overlook the dynamic aspect of the problem, which arises mainly due to the ever-changing resource availability in the cloud datacenters and the continuous mobility of the users. Few attempts have been lately made to incorporate the dynamic aspect to the VNF deployment solutions. The main problem of these approaches lies in their reactive readjustment scheme which determines the placement/migration strategy upon the receipt of a new request or the happening of a certain event, thus resulting in high setup latencies. In this paper, we take advantage of machine learning to reduce the complexity of the placement and readjustment processes through designing a cluster-based proactive solution. The solution consists of (1) an Integer Linear Programming (ILP) model that considers a tradeoff between the minimization of the latency, Service-Level Objective (SLO) violation cost, hardware utilization, and VNF readjustment cost, (2) an optimized k-medoids clustering approach which proactively partitions the substrate network into a set of disjoint on-demand clusters and (3) data-driven cluster-based placement and readjustment algorithms that capitalize on machine learning to intelligently eliminate some cost functions from the optimization problem to boost its feasibility in large-scale networks. Simulation results show that the proposed solution considerably reduces the readjustment time and decrease the hardware utilization compared to the K-means, original k-medoids and migration without clustering approaches. © 2019 Elsevier Ltd","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","37-50","","","142","","","","","","","","","","","","","Scopus","","","","","","","","Resource availability; Cloud computing; Virtual reality; Transfer functions; Integer programming; Network function virtualization; Learning algorithms; Learning systems; Machine learning; Service level objective; Complex networks; Machine learning approaches; Optimization problems; Telecommunication industry; Cost functions; E-learning; Integer linear programming models; Data-driven optimization; Hardware utilization; Inductive logic programming (ILP); K-means clustering; Semi- supervised learning; Semi-supervised learning; Supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YM27N9NE","conferencePaper","2019","Niccolini, L.; Iannaccone, G.; Ratnasamy, S.; Chandrashekar, J.; Rizzo, L.","Building a power-proportional software router","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077121508&partnerID=40&md5=13f43034d31a92be8730c0bd63298ffd","We aim at improving the power efficiency of network routers without compromising their performance. Using server-based software routers as our prototyping vehicle, we investigate the design of a router that consumes power in proportion to the rate of incoming traffic. We start with an empirical study of power consumption in current software routers, decomposing the total power consumption into its component causes. Informed by this analysis, we develop software mechanisms that exploit the underlying hardware's power management features for more energy-efficient packet processing. We incorporate these mechanisms into Click and demonstrate a router that matches the peak performance of the original (unmodified) router while consuming up to half the power at low loads, with negligible impact on the packet forwarding latency. © 2012 by The USENIX Association. All Rights Reserved","2019","2025-10-22 19:07:36","2025-10-22 19:07:36","","89-100","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Empirical studies; Software mechanisms; Routers; Software prototyping; Total power consumption; Incoming traffic; Packet forwarding; Packet processing; Peak performance; Software routers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2012 USENIX Annual Technical Conference, USENIX ATC 2012","","","","","","","","","","","","","","",""
"T4BKMM72","journalArticle","2020","Ghai, K.S.; Choudhury, S.; Yassine, A.","Efficient algorithms to minimize the end-to-end latency of edge network function virtualization","Journal of Ambient Intelligence and Humanized Computing","","","10.1007/s12652-019-01630-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078343096&doi=10.1007%2fs12652-019-01630-6&partnerID=40&md5=8f899fc4e5c881d11cbf1182b8060763","In future wireless networks, network function virtualization will lay the foundation for establishing a new dynamic resource management framework to efficiently utilize network resources. The main problem discussed in this paper is the minimization of total latency for an edge network and how to solve it efficiently. A model of users, virtual network functions and hosting devices has been taken, and is used to find the minimum latency using integer linear programming. The problem is NP-hard and takes exponential time to return the optimal solution. We apply the stable matching based algorithm to solve the problem in polynomial time and then utilize local search to improve its efficiency further. From extensive performance evaluation, it is found that our proposed algorithm is very close to the optimal scheme in terms of latency and better in terms of time complexity. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","2020","2025-10-22 19:07:36","2025-10-22 19:07:36","","3963-3974","","10","11","","","","","","","","","","","","","Scopus","","","","","","","","Virtual reality; Transfer functions; Integer programming; Network function virtualization; Dynamic resource management; Polynomial approximation; Integer Linear Programming; Local search; Latency; End to end latencies; Future wireless networks; Hosting device; Local search (optimization); Stable matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUWVKPK8","conferencePaper","2014","Wamhoff, J.-T.; Marlier, P.; Dice, D.; Diestelhorst, S.; Felber, P.; Fetzer, C.","The turbo diaries: Application-controlled frequency scaling explained","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077433760&partnerID=40&md5=84be2f94ce36fa2a7dbed2626b459ec3","Most multi-core architectures nowadays support dynamic voltage and frequency scaling (DVFS) to adapt their speed to the system's load and save energy. Some recent architectures additionally allow cores to operate at boosted speeds exceeding the nominal base frequency but within their thermal design power. In this paper, we propose a general-purpose library that allows selective control of DVFS from user space to accelerate multi-threaded applications and expose the potential of heterogeneous frequencies. We analyze the performance and energy trade-offs using different DVFS configuration strategies on several benchmarks and real-world workloads. With the focus on performance, we compare the latency of traditional strategies that halt or busy-wait on contended locks and show the power implications of boosting of the lock owner. We propose new strategies that assign heterogeneous and possibly boosted frequencies while all cores remain fully operational. This allows us to leverage performance gains at the application level while all threads continuously execute at different speeds. We also derive a model to help developers decide on the optimal DVFS configuration strategy, e.g, for lock implementations. Our in-depth analysis and experimental evaluation of current hardware provides insightful guidelines for the design of future hardware power management and its operating system interface. © Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014. All rights reserved.","2014","2025-10-22 19:07:36","2025-10-22 19:07:36","","193-204","","","","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Power; Performance; Economic and social effects; Computer architecture; Benchmarking; Dynamic frequency scaling; Dynamic voltage and frequency scaling; Frequency-scaling; Save energy; Multicore architectures; Base frequencies; Controlled frequency; Locks (fasteners); System loads; Thermal designs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014","","","","","","","","","","","","","","",""
"Q3Z4R5N3","journalArticle","2019","Al-Tarazi, M.; Chang, J.M.","Performance-Aware Energy Saving for Data Center Networks","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2019.2891826","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062999304&doi=10.1109%2fTNSM.2019.2891826&partnerID=40&md5=cab31ef37ed02ce2dc89a5f62476eb21","Today's data center networks (DCNs) tend to have tens to hundreds of thousands of servers that provide massive and sophisticated services. The architectural design of DCNs are usually over-provisioned for peak workloads and fault tolerance. Statistically, DCNs remain highly under-utilized, with typical utilization of around 30%. Network over-provisioning and under-utilization can be exploited for energy-saving. Most research efforts on DCN energy saving focus on how to save maximum energy but have little or no consideration to the performance of the residual network. Thus, the DCN performance can become degraded and the network left vulnerable to sudden traffic surges. In this paper, we have studied the energy-saving problem in DCNs while preserving network performance. The problem was formulated as mixed integer linear problem (MILP) solvable by CPLEX in order to minimize the energy consumed by DCN; meanwhile, safety threshold constraints for links utilization are met. To overcome CPLEX high computational time, a heuristic algorithm to provide practical and efficient solution for the MILP is introduced. The heuristic algorithm uses switches grouping and links consolidation to switch the traffic to a small number of network devices and turn off unused switches and links. Valiant load balancing is used to distribute the loads over active links. Simulation experiments using synthetic and real packet traces were conducted to validate the heuristic in terms of energy consumption and network performance. The results show that the heuristic can save up to 45% of the network energy and improve the average imbalance scores for links and switches by more than 50% with minimal effect on network performance. © 2018 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","206-219","","1","16","","","","","","","","","","","","","Scopus","","","","","","","","Network performance; Energy utilization; Computational efficiency; Resource allocation; Energy conservation; Integer programming; Heuristic algorithms; Over provisioning; Data center networks; Data center networks (DCNs); energy saving; Fault tolerance; load balancing; Computational time; Energy-saving problems; Mixed integer linear; Research efforts; Valiant Load-balancing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APMEQGDI","journalArticle","2017","Wu, Q.; Li, G.Y.; Chen, W.; Ng, D.W.K.; Schober, R.","An Overview of Sustainable Green 5G Networks","IEEE Wireless Communications","","","10.1109/MWC.2017.1600343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028762867&doi=10.1109%2fMWC.2017.1600343&partnerID=40&md5=89d73fb2589aaf250e9c77fffda9413a","The stringent requirements of a 1000x increase in data traffic and 1 ms round-trip latency have made limiting the potentially tremendous ensuing energy consumption one of the most challenging problems for the design of the upcoming 5G networks. To enable sustainable 5G networks, new technologies have been proposed to improve the system energy efficiency, and alternative energy sources are introduced to reduce our dependence on traditional fossil fuels. In particular, various 5G techniques target the reduction of the energy consumption without sacrificing the quality of service. Meanwhile, energy harvesting technologies, which enable communication transceivers to harvest energy from various renewable resources and ambient radio frequency signals for communication, have drawn significant interest from both academia and industry. In this article, we provide an overview of the latest research on both green 5G techniques and energy harvesting for communication. In addition, some technical challenges and potential research topics for realizing sustainable green 5G networks are also identified. © 2017 IEEE.","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","72-80","","4","24","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Energy utilization; 5G mobile communication systems; Technical challenges; Queueing networks; Potential researches; Energy harvesting; Alternative energy source; Communication transceivers; Fossil fuels; New technologies; Radio transceivers; Radiofrequency signals; Renewable resource; Stringent requirement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RHICK386","journalArticle","2017","Liu, J.; Lu, W.; Zhou, F.; Lu, P.; Zhu, Z.","On Dynamic service function chain deployment and readjustment","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2017.2711610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028930403&doi=10.1109%2fTNSM.2017.2711610&partnerID=40&md5=4038ee32a096d49608a1956a4597f4b8","Network function virtualization (NFV) is a promising technology to decouple the network functions from dedicated hardware elements, leading to the significant cost reduction in network service provisioning. As more and more users are trying to access their services wherever and whenever, we expect the NFV-related service function chains (SFCs) to be dynamic and adaptive, i.e., they can be readjusted to adapt to the service requests' dynamics for better user experience. In this paper, we study how to optimize SFC deployment and readjustment in the dynamic situation. Specifically, we try to jointly optimize the deployment of new users' SFCs and the readjustment of in-service users' SFCs while considering the trade-off between resource consumption and operational overhead. We first formulate an integer linear programming (ILP) model to solve the problem exactly. Then, to reduce the time complexity, we design a column generation (CG) model for the optimization. Simulation results show that the proposed CGbased algorithm can approximate the performance of the ILP and outperform an existing benchmark in terms of the profit from service provisioning. © 2017 IEEE.","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","543-553","","3","14","","","","","","","","","","","","","Scopus","","","","","","","","Virtual reality; Virtualization; Economic and social effects; Benchmarking; Transfer functions; Integer programming; Network function virtualization; Chains; Resource consumption; Cost reduction; Service provisioning; Service functions; Column generation; Dynamic support; Dynamic supports; Function virtualization (NFV); In-network services; Integer linear programming models; Operational Overheads; Service function chain (SFC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6CXCP23E","journalArticle","2019","Xiang, Z.; Gabriel, F.; Urbano, E.; Nguyen, G.T.; Reisslein, M.; Fitzek, F.H.P.","Reducing Latency in Virtual Machines: Enabling Tactile Internet for Human-Machine Co-Working","IEEE Journal on Selected Areas in Communications","","","10.1109/JSAC.2019.2906788","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063097866&doi=10.1109%2fJSAC.2019.2906788&partnerID=40&md5=c6f601aac8dbfd6ca768e42bcb1e314b","Software-defined networking (SDN) and network function virtualization (NFV) processed in multi-access edge computing (MEC) cloud systems have been proposed as critical paradigms for achieving the low latency requirements of the tactile Internet. While virtual network functions (VNFs) allow greater flexibility compared to hardware-based solutions, the VNF abstraction also introduces additional packet processing delays. In this paper, we investigate the practical feasibility of NFV with respect to the tactile Internet latency requirements. We develop, implement, and evaluate Chain-based Low latency VNF ImplemeNtation (CALVIN), a low-latency management framework for distributed Service Function Chains (SFCs). CALVIN classifies VNFs into elementary, basic, and advanced VNFs; moreover, CALVIN implements elementary and basic VNFs in the kernel space, while the advanced VNFs are implemented in the user space. Throughout, CALVIN employs a distributed mapping with one VNF per Virtual Machine (VM) in a MEC system. Furthermore, CALVIN avoids the metadata structure processing and batch processing of packets in the conventional Linux networking stack so as to achieve short per-packet latencies. Our rigorous measurements on off-the-shelf conventional networking and computing hardware demonstrate that CALVIN achieves round-trip times from a MEC ingress point via two elementary forwarding VNFs (one in kernel space and one in user space) and a MEC server to a MEC egress point on the order of 0.32 ms. Our measurements also indicate that MEC network coding and encryption are feasible for small 256 byte packets with an MEC latency budget of 0.35 ms; whereas, large 1400 byte packets can complete the network coding, but not the encryption within the 0.35 ms. © 1983-2012 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","1098-1116","","5","37","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Cloud computing; Virtual reality; Servers; Linux; Cryptography; Transfer functions; Network function virtualization; Virtual machine; Budget control; Network security; Telecommunication networks; Batch data processing; Management frameworks; Delays; Packet processing; Network coding; service function chain (SFC); virtualized network function (VNF); Bridges; Computing hardware; Distributed service; Internet latencies; kernel space; Low-latency network softwarization; Packet latencies; Software defined networking (SDN); tactile Internet; user space","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FQ3AB3B","journalArticle","2020","Ren, Q.; Zhou, L.; Xu, Z.; Zhang, Y.; Zhang, L.","PacketUsher: Exploiting DPDK to accelerate compute-intensive packet processing","Computer Communications","","","10.1016/j.comcom.2020.07.040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089230815&doi=10.1016%2fj.comcom.2020.07.040&partnerID=40&md5=70f29d9dac32dc213c115392678755d4","Many compute-intensive network applications such as application-layer traffic generator, Deep Packet Inspection(DPI) and web servers are widely deployed on commodity PC for the reason of flexibility and cheap price. However, how to improve their performance on general purpose OS is challenging due to the high packet I/O related overheads. This paper presents PacketUsher, a high-performance packets processing framework to remove these performance bottlenecks. In building PacketUsher, we constructed a DPDK wrapper as the underlying packet I/O engine to accelerate packet transmission, and utilized the strategies of zero copy, batch processing and parallelism to improve packet processing. Through RFC2544 benchmark, we demonstrate that DPDK wrapper has excellent packets transmission capability. As a case study of PacketUsher, we design and implement a commercial application-layer traffic generator. The experiment results show that the FPS (Flow Per Second) value of our traffic generator over PacketUsher is more than 4 times of that over standard Linux platform. By comparison, the FPS value over PacketUsher is about 3 times of that over existing methods (Netmap and PF_RING). © 2020 Elsevier B.V.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","324-333","","","161","","","","","","","","","","","","","Scopus","","","","","","","","Computer operating systems; Design and implements; Batch data processing; Commercial applications; DPDK; Packet processing; Application Layer; Commodity PC; Deep packet inspection (DPI); Network applications; Packet transmissions; Performance bottlenecks; Performance improvement; Personal computers; Traffic generation; Traffic generators; Transmission capability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5VA99ZUC","journalArticle","2021","Pei, J.; Hong, P.; Xue, K.; Li, D.","Resource Aware Routing for Service Function Chains in SDN and NFV-Enabled Network","IEEE Transactions on Services Computing","","","10.1109/TSC.2018.2849712","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049062637&doi=10.1109%2fTSC.2018.2849712&partnerID=40&md5=5e6fda603b602fd7403730e7f61bd829","Owing to the Network Function Virtualization (NFV) and Software-Defined Networks (SDN), Service Function Chain (SFC) has become a popular service in SDN and NFV-enabled network. However, as the Virtual Network Function (VNF) of each type is generally multi-instance and flows with SFC requests must traverse a series of specified VNFs in predefined orders, it is a challenge for dynamic SFC formation to optimally select VNF instances and construct paths. Moreover, the load balancing and end-to-end delay need to be paid attention to, when routing flows with SFC requests. Additionally, fine-grained scheduling for traffic at flow level needs differentiated routing which should take flow features into consideration. Unfortunately, traditional algorithms cannot fulfill all these requirements. In this paper, we study the Differentiated Routing Problem considering SFC (DRP-SFC) in SDN and NFV-enabled network. We formulate the DRP-SFC as a Binary Integer Programming (BIP) model aiming to minimize the resource consumption costs of flows with SFC requests. Then a novel routing algorithm, Resource Aware Routing Algorithm (RA-RA), is proposed to solve the DRP-SFC. Performance evaluation shows that RA-RA can efficiently solve the DRP-SFC and surpass the performance of other existing algorithms in acceptance rate, throughput, hop count and load balancing.  © 2008-2012 IEEE.","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","985-997","","4","14","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Bandwidth; Transfer functions; Integer programming; Network function virtualization; Delays; Routing; Software defined networking; Service functions; Linear programming; Routing algorithms; Service function chain; network function virtualization; differentiated routing; Differentiated Routing; Electric load management; flow feature; Flow features; software-defined networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GHHPJREM","journalArticle","","","","Intel Streaming SIMD Extension","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949971730&partnerID=40&md5=0ce17c9e7bd498d2c311eebf3b3419f8","","","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5PHSZYF","journalArticle","2019","Wang, Z.; Zhang, J.; Huang, T.; Liu, Y.","Service Function Chain Composition, Placement, and Assignment in Data Centers","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2019.2933872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076701045&doi=10.1109%2fTNSM.2019.2933872&partnerID=40&md5=63970726335a5ce7c483886a20447349","With the development of network function virtualization (NFV), service function chains (SFCs) are deployed via virtual network functions (VNFs). In general, the SFCs are served via composition and then deployed into data center infrastructures. However, most of the existing works neglect SFC composition. Furthermore, they consider that VNF instances are independently deployed for each SFC, which may underutilize the computational power of servers. We consider, for each required VNF in the chain, the operator can either place it on a new instance or assign it to an established instance if the residual resource of that instance is sufficient. Such a deployment scheme can leverage resources more efficiently and we define it as SFC placement and assignment. In this paper, we first combine SFC composition, placement and assignment together to enhance resource allocation. We present the system model and formulate the problem as 0-1 integer programming. We aim to improve the VNF instance utilization as well as reduce the link consumption. A heuristic approach called Jcap is developed to solve the problem in two stages. The simulations show that Jcap achieves competitive performance with the optimal results obtained from mathematical model. © 2004-2012 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","1638-1650","","4","16","","","","","","","","","","","","","Scopus","","","","","","","","Virtual reality; Computational power; Virtual networks; Transfer functions; Integer programming; Network function virtualization; Heuristic methods; Service functions; 0-1-Integer Programming; Chain composition; Competitive performance; Heuristic approach; Residual resource; SFC composition; virtual network function assignment; virtual network function placement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZR8NPFG","journalArticle","2021","","","Data plane development kit power optimization on advantech*network appliance platform","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132017273&partnerID=40&md5=934669300c2ff13e3d58b928c5e753e3","","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FIMV7FKK","journalArticle","2020","Li, X.; Cheng, W.; Zhang, T.; Ren, F.; Yang, B.","Towards Power Efficient High Performance Packet I/O","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2019.2957746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078235600&doi=10.1109%2fTPDS.2019.2957746&partnerID=40&md5=78d36338bb0cde61ddc552f5aea3c420","Recently, high performance packet I/O frameworks continue to flourish for their ability to process packets from high-speed links. To achieve high throughput and low latency, high performance packet I/O frameworks usually employ busy polling. As busy polling will burn all CPU cycles even if there's no packet to process, these frameworks are quite power inefficient. However, exploiting power management techniques such as DVFS and LPI in the frameworks is challenging, because neither the OS nor the frameworks can provide information (e.g., actual CPU utilization, available idle period, or the target frequency) required by these techniques. In this article, we establish a model that can formulate the packet processing flow of high performance packet I/O to help and address the above challenges. From the model, we can deduce the information needed for power management techniques, and gain the insights to balance the power and latency. After suggesting to use pause instruction to reduce CPU power within short idle period, we propose two approaches to conduct power conservation for high performance packet I/O: one with the aid of traffic information and the other without. Experiments with Intel DPDK show that both approaches can achieve significant power reduction with little latency increase. © 1990-2012 IEEE.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","981-996","","4","31","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Electric power utilization; power consumption; latency; DVFS; busy polling; High performance packet I/O; Industrial management; pause instruction; Speed control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAZ2KU89","journalArticle","2021","","","ARMv8-A Power Management","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132022544&partnerID=40&md5=f1712db0ea6541aee8d7821a8b44810a","","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TDR5EAQA","journalArticle","2015","Hwang, J.; Ramakrishnan, K.K.; Wood, T.","NetVM: High performance and flexible networking using virtualization on commodity platforms","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2015.2401568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926028205&doi=10.1109%2fTNSM.2015.2401568&partnerID=40&md5=c619fddc8f4e379a6e692e7fe9cc5e16","NetVM brings virtualization to the Network by enabling high bandwidth network functions to operate at near line speed, while taking advantage of the flexibility and customization of low cost commodity servers. NetVM allows customizable data plane processing capabilities such as firewalls, proxies, and routers to be embedded within virtual machines, complementing the control plane capabilities of Software Defined Networking. NetVM makes it easy to dynamically scale, deploy, and reprogram network functions. This provides far greater flexibility than existing purpose-built, sometimes proprietary hardware, while still allowing complex policies and full packet inspection to determine subsequent processing. It does so with dramatically higher throughput than existing software router platforms. NetVM is built on top of the KVM platform and Intel DPDK library. We detail many of the challenges we have solved such as adding support for high-speed inter-VM communication through shared huge pages and enhancing the CPU scheduler to prevent overheads caused by inter-core communication and context switching. NetVM allows true zero-copy delivery of data to VMs both for packet processing and messaging among VMs within a trust boundary. Our evaluation shows how NetVM can compose complex network functionality from multiple pipelined VMs and still obtain throughputs up to 10 Gbps, an improvement of more than 250% compared to existing techniques that use SR-IOV for virtualized networking. © 2004-2012 IEEE.","2015","2025-10-22 19:07:37","2025-10-22 19:07:37","","34-47","","1","12","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Program processors; Virtual reality; Distributed computer systems; Virtualizations; Network functions; Network function virtualization; Data handling; Packet networks; Routers; Complex networks; Software-defined networkings; Software-defined networks; Computer system firewalls; Broadband networks; Data-plane processing; High-bandwidth networks; Inter-core communications; Network functionality; Software defined network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVFMAC3N","conferencePaper","2015","Hackenberg, D.; Schöne, R.; Ilsche, T.; Molka, D.; Schuchart, J.; Geyer, R.","An Energy Efficiency Feature Survey of the Intel Haswell Processor","","","","10.1109/IPDPSW.2015.70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962251153&doi=10.1109%2fIPDPSW.2015.70&partnerID=40&md5=582112a827fa8312102cfe118f3b0dba","The recently introduced Intel Xeon E5-1600 v3 and E5-2600 v3 series processors - codenamed Haswell-EP - implement major changes compared to their predecessors. Among these changes are integrated voltage regulators that enable individual voltages and frequencies for every core. In this paper we analyze a number of consequences of this development that are of utmost importance for energy efficiency optimization strategies such as dynamic voltage and frequency scaling (DVFS) and dynamic concurrency throttling (DCT). This includes the enhanced RAPL implementation and its improved accuracy as it moves from modeling to actual measurement. Another fundamental change is that every clock speed above AVX frequency - including nominal frequency - is opportunistic and unreliable, which vastly decreases performance predictability with potential effects on scalability. Moreover, we characterize significantly changed p-state transition behavior, and determine crucial memory performance data. © 2015 IEEE.","2015","2025-10-22 19:07:37","2025-10-22 19:07:37","","896-904","","","","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Parallel processing systems; Dynamic frequency scaling; Electric power measurement; Power demands; Dynamic voltage and frequency scaling; Energy measurement; Random access storage; Power demand; Benchmark testing; Random access memory; Actual measurements; Electric current regulators; Energy efficiency optimizations; Frequency measurement; Frequency measurements; Fundamental changes; Regulators; Voltage control; Voltage regulators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 IEEE 29th International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2015","","","","","","","","","","","","","","",""
"BKSA6TEF","journalArticle","2021","","","Packetbeat Documentation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132007624&partnerID=40&md5=23964327af4c0255958d698be2a14253","","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLVZRZMU","conferencePaper","2016","Panda, A.; Han, S.; Jang, K.; Walls, M.; Ratnasamy, S.; Shenker, S.","NetBricks: Taking the V out of NFV","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077011241&partnerID=40&md5=092d2020118409b814bf52a92711d1c9","The move from hardware middleboxes to software network functions, as advocated by NFV, has proven more challenging than expected. Developing new NFs remains a tedious process, requiring that developers repeatedly rediscover and reapply the same set of optimizations, while current techniques for providing isolation between NFs (using VMs or containers) incur high performance overheads. In this paper we describe NetBricks, a new NFV framework that tackles both these problems. For building NFs we take inspiration from modern data analytics frameworks (e.g., Spark and Dryad) and build a small set of customizable network processing elements. We also embrace type checking and safe runtimes to provide isolation in software, rather than rely on hardware isolation. NetBricks provides the same memory isolation as containers and VMs, without incurring the same performance penalties. To improve I/O efficiency, we introduce a novel technique called zero-copy software isolation. © 2016 by The USENIX Association All Rights Reserved.","2016","2025-10-22 19:07:37","2025-10-22 19:07:37","","203-216","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Systems analysis; Data Analytics; Network function virtualization; Customizable; Memory isolation; Middleboxes; Network-processing elements; Novel techniques; Performance penalties; Software network; Typechecking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016","","","","","","","","","","","","","","",""
"ZJTQATAX","conferencePaper","2003","Klemm, A.; Lindemann, C.; Lohmann, M.","Modeling IP traffic using the batch Markovian arrival process","","","","10.1016/S0166-5316(03)00067-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042328345&doi=10.1016%2fS0166-5316%2803%2900067-1&partnerID=40&md5=903c5b09c8e6ad84cb69f3a34947cbc9","In this paper, we show how to utilize the expectation-maximization (EM) algorithm for efficient and numerical stable parameter estimation of the batch Markovian arrival process (BMAP). In fact, effective computational formulas for the E-step of the EM algorithm are presented, which utilize the well-known randomization technique and a stable calculation of Poisson jump probabilities. Moreover, we identify the BMAP as an analytically tractable model of choice for aggregated traffic modeling of IP networks. The key idea of this aggregated traffic model lies in customizing the BMAP such that different lengths of IP packets are represented by rewards of the BMAP. Using measured traffic data, a comparative study with the MMPP and the Poisson process illustrates the effectiveness of the customized BMAP for IP traffic modeling by visual inspection of sample paths over several time scales, by presenting important statistical properties as well as by investigations of queuing behavior. © 2003 Elsevier Science B.V. All rights reserved.","2003","2025-10-22 19:07:37","2025-10-22 19:07:37","","149-173","","","54","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Markov processes; Telecommunication networks; Telecommunication traffic; Analytical/numerical models of aggregated IP traffic; EM algorithm; Expectation-maximization (EM) algorithms; Numerical transient analysis of Markov chains; Parameter estimation; Probability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Performance Evaluation","","","","","","","","","","","","","","",""
"DE54KGAA","journalArticle","2020","Shantharama, P.; Thyagaturu, A.S.; Reisslein, M.","Hardware-Accelerated Platforms and Infrastructures for Network Functions: A Survey of Enabling Technologies and Research Studies","IEEE Access","","","10.1109/ACCESS.2020.3008250","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089502667&doi=10.1109%2fACCESS.2020.3008250&partnerID=40&md5=5c5d820f5731abd41387747e740a65a4","In order to facilitate flexible network service virtualization and migration, network functions (NFs) are increasingly executed by software modules as so-called 'softwarized NFs' on General-Purpose Computing (GPC) platforms and infrastructures. GPC platforms are not specifically designed to efficiently execute NFs with their typically intense Input/Output (I/O) demands. Recently, numerous hardware-based accelerations have been developed to augment GPC platforms and infrastructures, e.g., the central processing unit (CPU) and memory, to efficiently execute NFs. This article comprehensively surveys hardware-accelerated platforms and infrastructures for executing softwarized NFs. This survey covers both commercial products, which we consider to be enabling technologies, as well as relevant research studies. We have organized the survey into the main categories of enabling technologies and research studies on hardware accelerations for the CPU, the memory, and the interconnects (e.g., between CPU and memory), as well as custom and dedicated hardware accelerators (that are embedded on the platforms); furthermore, we survey hardware-accelerated infrastructures that connect GPC platforms to networks (e.g., smart network interface cards). We find that the CPU hardware accelerations have mainly focused on extended instruction sets and CPU clock adjustments, as well as cache coherency. Hardware accelerated interconnects have been developed for on-chip and chip-to-chip connections. Our comprehensive up-to-date survey identifies the main trade-offs and limitations of the existing hardware-accelerated platforms and infrastructures for NFs and outlines directions for future research. © 2013 IEEE.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","132021-132085","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Dedicated hardware; Program processors; Infrastructure as a service (IaaS); Economic and social effects; Surveys; Hardware-accelerated; Transfer functions; memory; Integrated circuit interconnects; Central processing unit (CPU); Chip-to-chip connections; Commercial products; Enabling technologies; Flexible network services; General-purpose computing; Hardware acceleration; hardware accelerator; interconnect; software defined networking (SDN); virtualized network function (VNF)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5HPI5ED","journalArticle","2020","Salhab, N.; Rahim, R.; Langar, R.","Optimization of Virtualization Cost, Processing Power and Network Load of 5G Software-Defined Data Centers","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2020.2990664","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085129294&doi=10.1109%2fTNSM.2020.2990664&partnerID=40&md5=146993b049ffa8217325b4cab73744ba","Virtualization is getting unprecedented attention from Mobile Network Operators (MNOs) as it provides agility in deployment, especially when coupled with the Cloud that offers inherent elasticity and load-balancing of resources. MNOs have to ensure operational excellence by meeting several objectives. In this context, we propose in this paper, a framework for optimizing the mapping of next Generation Node-Bs (gNBs) to Software-Defined 5G Core (5GC) delay tolerant Network Functions (NFs). These NFs are considered to be deployed as a Virtual Machine (VM) pool, or containers, in order to minimize cloud computing cost, processing power and at the same time maximize network load. First, we formulate this problem as an integer linear program, while taking into account multiple constraints including Virtual Central Processing Unit (vCPU) capacity, central processing load limits and integrality of mapping relations between gNBs and 5GC NFs. Then, we propose an algorithm to solve large problem instances based on Branch, Cut and Price (BCP) combining all of 'Branch and Price', 'Branch and Cut' and 'Branch and Bound' frameworks. We present several schemes reflecting different optimization goals that the MNO can foster: virtualization cost, power minimization, network load or all. Simulation results demonstrate the good performance of our proposed algorithm to solve the gNBs-VM pool mapping for all evaluated schemes, while also emphasizing the advantages of a particular one (EWoS-333 for Equal Weight optimization Scheme) that can decrease virtualization cost by almost one order of magnitude compared to a static selection scheme, while considering the other two objectives.  © 2004-2012 IEEE.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","1542-1553","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","Program processors; Virtualization; Mapping; 5G mobile communication systems; Integer programming; Virtual machine; Wireless networks; Balancing; 5G; Delay tolerant networks; Integer linear programs; Multi-objective optimization; branch; Cloud computing costs; cut and price (BCP); mobile network operator (MNO); Mobile network operators; Multiple constraint; Operational excellence; Optimization goals; Power minimization; virtualized network functions; Weight optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RHBK7NKP","conferencePaper","2020","Dab, B.; Fajjari, I.; Rohon, M.; Auboin, C.; Diquelou, A.","Cloud-native Service Function Chaining for 5G based on Network Service Mesh","","","","10.1109/ICC40277.2020.9149045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089411572&doi=10.1109%2fICC40277.2020.9149045&partnerID=40&md5=991065d62ed128673406bb673f31442c","5G will provide a flexible and programmable infrastructure, allowing different networks to share the same access network. A way to respond to the diverse service requirements of 5G while reducing both CAPEX and OPEX is to adopt cloud-native architectures. In this context, micro-services software design, the corner stone of cloud-native architecture, seems to be ideal for 5G. However, despite its several advantages, micro-services raise new challenges which slow its adoption down in the NFV ecosystem. Indeed, steering the expected 5G traffic between cloud-native network function is extremely challenging and is still under-investigated. In this paper, we address the service function chaining (SFC) in micro-service based network function virtualization (NFV) ecosystem from the view of the traffic steering. Specifically, we design and implement a cloud-native SFC framework offering efficient traffic steering mechanisms while considering the network state of the underlying NFV infrastructure. In this context, an optimized network-aware load balancing strategy is proposed. Based on extensive experiments, the results obtained show that our strategy achieved good results in terms of i) end-to-end latency and ii) deployment time. © 2020 IEEE.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","2020-June","","","","","","","","","","","","","Scopus","","","","","","","","Computer architecture; Software design; Network functions; 5G mobile communication systems; Network services; Transfer functions; Network function virtualization; Design and implements; Load balancing strategy; Ecosystems; kubernetes; Service requirements; Service functions; service function chaining; Cloud-native functions; End to end latencies; network service mesh; Steering mechanisms; traffic steering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Communications","","","","","","","","","","","","","","",""
"G4UYFKV8","journalArticle","2020","Pham, C.; Tran, N.H.; Ren, S.; Saad, W.; Hong, C.S.","Traffic-Aware and Energy-Efficient vNF Placement for Service Chaining: Joint Sampling and Matching Approach","IEEE Transactions on Services Computing","","","10.1109/TSC.2017.2671867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079575000&doi=10.1109%2fTSC.2017.2671867&partnerID=40&md5=2843a9cb9b4f3d22fd720f93b20cc9f0","Although network function virtualization (NFV) is a promising approach for providing elastic network functions, it faces several challenges in terms of adaptation to diverse network appliances and reduction of the capital and operational expenses of the service providers. In particular, to deploy service chains, providers must consider different objectives, such as minimizing the network latency or the operational cost, which are coupled objectives that have traditionally been addressed separately. In this paper, the problem of virtual network function (vNF) placement for service chains is studied for the purpose of energy and traffic-aware cost minimization. This problem is formulated as an optimization problem named the joint operational and network traffic cost (OPNETOPNET) problem. First, a sampling-based Markov approximation (MA) approach is proposed to solve the combinatorial NP-hard problem, OPNETOPNET. Even though the MA approach can yield a near-optimal solution, it requires a long convergence time that can hinder its practical deployment. To overcome this issue, a novel approach that combines the MA with matching theory, named as SAMASAMA, is proposed to find an efficient solution for the original problem OPNETOPNET. Simulation results show that the proposed framework can reduce the total incurred cost by up to 19 percent compared to the existing non-coordinated approach. © 2008-2012 IEEE.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","172-185","","1","13","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Network traffic; Virtual reality; Virtual networks; Resource allocation; Transfer functions; Network function virtualization; Data centers; Datacenters; Operational expense; Optimization problems; Near-optimal solutions; resource allocation; NP-hard; Markov approximation; Network appliances; network function virtualization; network traffic; virtual network function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ELIGNEXR","conferencePaper","2019","Gupta, H.; Sharma, A.; Zelezniak, A.; Jang, M.; Ramachandran, U.","A black-box approach for estimating utilization of polled Io network functions","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084160867&partnerID=40&md5=1fa40eccf47ac5e71cca2524536bb2f1","Cloud management tasks such as performance diagnosis, workload placement, and power management depend critically on estimating the utilization of an application. But, it is challenging to measure actual utilization for polled IO network functions (NFs) without code instrumentation. We ask if CPU events (e.g., data cache misses) measured using hardware performance counters are good at estimating utilization for polled-IO NFs. We find a strong correlation between several CPU events and NF utilization for three representative types of network functions. Inspired by this finding, we explore the possibility of computing a universal estimation function that maps selected CPU events to NF utilization estimates for a wide-range of NFs, traffic profiles and traffic loads. Our NF-specific estimators and universal estimators achieve absolute estimation errors below 6% and 10% respectively. © 2019 USENIX Association. All rights reserved.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Transfer functions; Cloud managements; Performance diagnosis; Black box approach; Code instrumentation; Estimation errors; Hardware performance counters; Strong correlation; Universal estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019, co-located with USENIX ATC 2019","","","","","","","","","","","","","","",""
"CE54PX9R","journalArticle","2017","Trifonov, H.G.","","Traffic-Aware Adaptive Polling Mechanism for High Performance Packet Processing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080587284&partnerID=40&md5=a75704d121678886dc454603b6f48409","","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PH95RFAI","journalArticle","2021","","","Open vSwitch With DPDK","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132024182&partnerID=40&md5=35e7db0440d79dfe4c65fc950708c9a0","","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y8FNIZP9","conferencePaper","2021","Bouridah, A.; Fajjari, I.; Aitsaadi, N.; Belhadef, H.","Optimized scalable SFC traffic steering scheme for cloud native based applications","","","","10.1109/CCNC49032.2021.9369583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102979951&doi=10.1109%2fCCNC49032.2021.9369583&partnerID=40&md5=5283bc172f013d195f516ad251f4de31","Network Function Virtualization (NFV) has already proven its efficiency to deploy networking services in large-scale. Recent advances of cloud-native applications may bring new advantage by deploying and implementing Virtual Network Function (VNFs) as cloud-native Containers rather than virtual machines. Beside remarkable advantages such as lower overhead and faster running, microservices (cloud-native containers) intend to save costs while increasing the service agility. To this end, in this paper we extend consolidated state-of-the-art tools and technologies developed in two domains cloud-native applications and Network Function Virtualization (NFV). The proposed framework chains services provisioned across Kubernetes and Contiv/VPP domains and using containers. Our orchestration framework chain services across distributed CNFs. Furthermore, we propose K -TS scheme to load balance the traffic over services replicas. K -TS is based on Ketama Consistent hashing algorithm. Experimental simulations show very good results for both the service chaining framework in term of QoS satisfaction such as: packet error rate, throughput satisfaction and jitter. © 2021 IEEE.","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Kubernetes; Microservices; QoS; State of the art; Virtual networks; Transfer functions; Network function virtualization; NFV; Consistent Hashing algorithms; Experimental simulations; Its efficiencies; Ketama algorithm; Networking services; Packet error rates; Service Function Chain; Tools and technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021 IEEE 18th Annual Consumer Communications and Networking Conference, CCNC 2021","","","","","","","","","","","","","","",""
"4UY6HS3B","conferencePaper","2018","Moreira Zorello, L.M.; Torres Vieira, M.G.; Girani Tejos, R.A.; Torres Rojas, M.A.; Meirosu, C.; Melo De Brito Carvalho, T.C.","Improving Energy Efficiency in NFV Clouds with Machine Learning","","","","10.1109/CLOUD.2018.00097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057462359&doi=10.1109%2fCLOUD.2018.00097&partnerID=40&md5=6df104dfaaf267738458d631b4c32ee0","Widespread deployments of Network Function Virtualization (NFV) technology will replace many physical appliances in telecommunication networks with software executed on cloud platforms. Setting compute servers continuously to high-performance operating modes is a common NFV approach for achieving predictable operations. However, this has the effect that large amounts of energy are consumed even when little traffic needs to be forwarded. The Dynamic Voltage-Frequency Scaling (DVFS) technology available in Intel processors is a known option for adapting the power consumption to the workload, but it is not optimized for network traffic processing workloads. We developed a novel control method for DVFS, based observing the ongoing traffic and online predictions using machine learning. Our results show that we can save up to 27% compared to commodity DVFS, even when including the computational overhead of machine learning. © 2018 IEEE.","2018","2025-10-22 19:07:37","2025-10-22 19:07:37","","710-717","","","2018-July","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Cloud computing; Network traffic; Dynamic frequency scaling; Network function virtualization; NFV; Cloud platforms; Artificial intelligence; Learning systems; Machine learning; Dynamic voltage and frequency scaling; Dynamic voltage frequency scaling; Computational overheads; Control methods; Dynamic Voltage and Frequency Scaling; Intel processors; Online prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"SKTIGS9S","journalArticle","2019","DiGiglio, J.; Hunt, D.; Lim, A.; MacNamara, C.; Miskell, T.","","Intel speed select technology-Base frequency-Enhancing performance","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132031546&partnerID=40&md5=353d036f063cde5b587d54003283e858","","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IIB8886Y","journalArticle","2020","","","Power Management","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109580175&partnerID=40&md5=a2b355f1202d5102191bc3fc05ccd80f","","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APDKXRDS","bookSection","2013","Ignaciuk, P.; Bartoszewicz, A.","Congestion control in data transmission networks: Historical perspective","Communications and Control Engineering","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904723765&doi=10.1007%2f978-1-4471-4147-1_2&partnerID=40&md5=b496d88967f13ee48878c2e7d67e0eec","The congestion occurs when the traffic generated by the network users exceeds the available bandwidth in the communication system. In such circumstances, not all the packets sent by the sources can be immediately relayed on the route towards their destination. Instead, they accumulate in the buffers at the intermediate nodes and wait for the bandwidth increase. If the incoming rate is not reduced (or stopped) before the queue of awaiting packets reaches its limit, typically defined by the amount of the reserved memory at the node, the new data pieces must be discarded. The lost fragments are retransmitted, which further deepens the congestion at the bottleneck point. At certain stage, the network becomes clogged with retransmissions and stops providing its services – this state is referred to as a deadlock or congestion collapse. In fact, the early communication networks frequently suffered from congestion collapse, until the development of the Jacobson’s scheme [73] for the Internet flow control. © Springer-Verlag London 2013.","2013","2025-10-22 19:07:37","2025-10-22 19:07:37","","9-44","","","","9781447141464","","","","","","","","","","","","Scopus","","","","","","","","Data communication systems; Bandwidth; Traffic congestion; Available bandwidth; Bide; Congestion collapse; Expense; Historical perspective; Intermediate node; Nash; Settling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BR8TWA3E","journalArticle","2019","Linguaglossa, L.; Lange, S.; Pontarelli, S.; Retvari, G.; Rossi, D.; Zinner, T.; Bifulco, R.; Jarschel, M.; Bianchi, G.","Survey of Performance Acceleration Techniques for Network Function Virtualization","Proceedings of the IEEE","","","10.1109/JPROC.2019.2896848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062998800&doi=10.1109%2fJPROC.2019.2896848&partnerID=40&md5=574fa440541d99475a04f004f0b02f8e","The ongoing network softwarization trend holds the promise to revolutionize network infrastructures by making them more flexible, reconfigurable, portable, and more adaptive than ever. Still, the migration from hard-coded/hard-wired network functions toward their software-programmable counterparts comes along with the need for tailored optimizations and acceleration techniques so as to avoid or at least mitigate the throughput/latency performance degradation with respect to fixed function network elements. The contribution of this paper is twofold. First, we provide a comprehensive overview of the host-based network function virtualization (NFV) ecosystem, covering a broad range of techniques, from low-level hardware acceleration and bump-in-the-wire offloading approaches to high-level software acceleration solutions, including the virtualization technique itself. Second, we derive guidelines regarding the design, development, and operation of NFV-based deployments that meet the flexibility and scalability requirements of modern communication networks. © 1963-2012 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","746-764","","4","107","","","","","","","","","","","","","Scopus","","","","","","","","Performance degradation; Virtual reality; Virtualization; offloading; Transfer functions; Network function virtualization; Network infrastructure; Virtualization Techniques; virtualization; Acceleration; Packet processing; network function virtualization (NFV); Acceleration technique; Fast packet processing; performance acceleration; Performance acceleration; Software acceleration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGVLQTCX","journalArticle","2011","Olaniyi, S.A.S.; Adewole, K.S.; Jimoh, R.G.","Stock trend prediction using regression analysis-A data mining approach","ARPN Journal of Systems and Software","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894277180&partnerID=40&md5=3ea2f3e00d6581ef49700fb2227626e0","","2011","2025-10-22 19:07:37","2025-10-22 19:07:37","","154-157","","4","1","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7YFYL94T","journalArticle","1997","Mathis, M.; Semke, J.; Mahdavi, J.; Ott, T.","The macroscopic behavior of the TCP congestion avoidance algorithm","Computer Communication Review","","","10.1145/263932.264023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031175629&doi=10.1145%2f263932.264023&partnerID=40&md5=7b1e50888e37117a9d88b0459bdf55ff","In this paper, we analyze a performance model for the TCP Congestion Avoidance algorithm. The model predicts the bandwidth of a sustained TCP connection subjected to light to moderate packet losses, such as loss caused by network congestion. It assumes that TCP avoids retransmission timeouts and always has sufficient receiver window and sender data. The model predicts the Congestion Avoidance performance of nearly all TCP implementations under restricted conditions and of TCP with Selective Acknowledgements over a much wider range of Internet conditions. We verify the model through both simulation and live Internet measurements. The simulations test several TCP implementations under a range of loss conditions and in environments with both drop-tail and RED queuing. The model is also compared to live Internet measurements using the TReno diagnostic and real TCP implementations. We also present several applications of the model to problems of bandwidth allocation in the Internet. We use the model to analyze networks with multiple congested gateways; this analysis shows strong agreement with prior work in this area. Finally, we present several important implications about the behavior of the Internet in the presence of high load from diverse user communities.","1997","2025-10-22 19:07:37","2025-10-22 19:07:37","","67-82","","3","27","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Algorithms; Internet; Bandwidth; Network protocols; Mathematical models; Computer simulation; Congestion control (communication); Telecommunication systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IAVMAFNC","journalArticle","2017","King, C.I.","Stress-ng","Stress-ng","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941333121&partnerID=40&md5=c8b18e04b1c518cbeab5593003cf6529","","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCG8YJHQ","journalArticle","2020","","","XDP-Tools Utilities and Example Programs for Use With XDP","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132036047&partnerID=40&md5=12f668dfef36513483be8955e6dfa295","","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62ZUXCGN","conferencePaper","2012","Weaver, V.M.; Johnson, M.; Kasichayanula, K.; Ralph, J.; Luszczek, P.; Terpstra, D.; Moore, S.","Measuring energy and power with PAPI","","","","10.1109/ICPPW.2012.39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871142592&doi=10.1109%2fICPPW.2012.39&partnerID=40&md5=93d5b655b96279eac7fd539d711b2468","Energy and power consumption are becoming critical metrics in the design and usage of high performance systems. We have extended the Performance API (PAPI) analysis library to measure and report energy and power values. These values are reported using the existing PAPI API, allowing code previously instrumented for performance counters to also measure power and energy. Higher level tools that build on PAPI will automatically gain support for power and energy readings when used with the newest version of PAPI. We describe in detail the types of energy and power readings available through PAPI. We support external power meters, as well as values provided internally by recent CPUs and GPUs. Measurements are provided directly to the instrumented process, allowing immediate code analysis in real time. We provide examples showing results that can be obtained with our infrastructure. © 2012 IEEE.","2012","2025-10-22 19:07:37","2025-10-22 19:07:37","","262-268","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Program processors; Power meters; Electric power measurement; performance analysis; Real time; High performance systems; Code analysis; Critical metrics; energy measurement; Energy readings; Performance counters; power measurement; Technical presentations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel Processing Workshops","","","","","","","","","","","","","","",""
"QXKQCMVS","journalArticle","2013","Morton, A.","IMIX Genome Specification of variable packet sizes for additional testing","IETF, Internet-Draft draft-morton-bmwg-imixgenome- 02","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132011240&partnerID=40&md5=5de571abfba26763b2ab756c0ed0fd8c","","2013","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DYLYDDFD","journalArticle","1999","Allman, M.; Paxson, V.; Stevens, W.","TCP congestion control","TCP Congestion Control","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003599162&partnerID=40&md5=3f10ecb9c3fa5e8ed5c28fd1b9a96e85","","1999","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3S7BMWH","journalArticle","2020","","","TRex Realistic Traffic Generator","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132027355&partnerID=40&md5=51e399ffbaaf2b01fed265c5e3a25c3e","","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7XXK3WVB","journalArticle","2020","","","Turbostat-Report Processor Frequency and Idle Statistics","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132027542&partnerID=40&md5=9da5f0466389c5ef8282e98492591da5","","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K35BLP7Z","conferencePaper","2019","Gan, Y.; Zhang, Y.; Cheng, D.; Shetty, A.; Rathi, P.; Katarki, N.; Bruno, A.; Hu, J.; Ritchken, B.; Jackson, B.; Hu, K.; Pancholi, M.; He, Y.; Clancy, B.; Colen, C.; Wen, F.; Leung, C.; Wang, S.; Zaruvinsky, L.; Espinosa, M.; Lin, R.; Liu, Z.; Padilla, J.; Delimitrou, C.","An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems","","","","10.1145/3297858.3304013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064688619&doi=10.1145%2f3297858.3304013&partnerID=40&md5=b9f662fba2a35d83eb40d32009cf7676","Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","3-18","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Open source software; Datacenter; Microservice; cloud computing; Cloud-computing; microservices; QoS; acceleration; Benchmark suites; Cloud systems; Cluster computing; cluster management; Cluster management; datacenters; Economic and social effects; Field programmable gate arrays (FPGA); fpga; Fpgum; Open systems; Open-source; Quality-of-service; serverless; Serverless","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"QIMKACM9","journalArticle","2023","Sallo, D.H.; Kecskemeti, G.","Enriching computing simulators by generating realistic serverless traces","Journal of Cloud Computing","","","10.1186/s13677-023-00397-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150208452&doi=10.1186%2fs13677-023-00397-8&partnerID=40&md5=68c93581a3135014027d6b9fa9d8b39f","Serverless computing is stepping forward to provide a cloud environment that mainly focuses on managing infrastructure, resources and configurations on the behalf of a user. Research in this field can’t rely on commercial providers such as AWS and Azure, as their inflexibility and cost often limits the required levels of reproducibility and scalability. Therefore, simulators have been opted as an alternative solution by the research community. They offer a reduced-cost and easy-setup environment. To get respectable precision, simulators use real traces collected and offered by commercial providers. These traces represent comprehensive information of executed tasks that reflect user behaviour. Due to serverless computing’s recency, typical workload traces employed by IaaS simulators are not well adoptable to the new computing model. In this paper, we propose an approach for generating realistic serverless traces. We enhance our previous generator approach that was based on the Azure Functions dataset. Our new, genetic algorithm based approach improves the statistical properties of the generated traces. We also enabled arbitrary scaling of the workload, while maintaining real users’ behaviour. These advances further support reproducibility in the serverless research community. We validated the results of our generator approach using the coefficient of determination (R2), which shows that our generated workload closely matches the original dataset’s characteristics in terms of execution time, memory utilisation as well as user participation percentage. To demonstrate the benefits of the reusability of the generated traces, we applied them with a diverse set of simulators and shown that they offer reproducible results independently of the simulator used. © 2023, The Author(s).","2023","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","1","12","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Cloud environments; FaaS; Faas; Alternative solutions; Genetic Algorithm; Genetic algorithms; Infrastructure resources; Reduced cost; Reproducibilities; Research communities; Reusability; Serverless trace; Serverless workload; User behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QCX9AHR8","conferencePaper","2017","Gupta, H.; Vahid Dastjerdi, A.; Ghosh, S.K.; Buyya, R.","iFogSim: A toolkit for modeling and simulation of resource management techniques in the Internet of Things, Edge and Fog computing environments","","","","10.1002/spe.2509","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021248358&doi=10.1002%2fspe.2509&partnerID=40&md5=f5351d8461158bc62bf3f14acd916f12","Internet of Things (IoT) aims to bring every object (eg, smart cameras, wearable, environmental sensors, home appliances, and vehicles) online, hence generating massive volume of data that can overwhelm storage systems and data analytics applications. Cloud computing offers services at the infrastructure level that can scale to IoT storage and processing requirements. However, there are applications such as health monitoring and emergency response that require low latency, and delay that is caused by transferring data to the cloud and then back to the application can seriously impact their performances. To overcome this limitation, Fog computing paradigm has been proposed, where cloud services are extended to the edge of the network to decrease the latency and network congestion. To realize the full potential of Fog and IoT paradigms for real-time analytics, several challenges need to be addressed. The first and most critical problem is designing resource management techniques that determine which modules of analytics applications are pushed to each edge device to minimize the latency and maximize the throughput. To this end, we need an evaluation platform that enables the quantification of performance of resource management policies on an IoT or Fog computing infrastructure in a repeatable manner. In this paper we propose a simulator, called iFogSim, to model IoT and Fog environments and measure the impact of resource management techniques in latency, network congestion, energy consumption, and cost. We describe two case studies to demonstrate modeling of an IoT environment and comparison of resource management policies. Moreover, scalability of the simulation toolkit of RAM consumption and execution time is verified under different circumstances. Copyright © 2017 John Wiley & Sons, Ltd.","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","1275-1296","","","47","","","","","","","","","","","","","Scopus","","","","","","","","Online systems; Distributed computer systems; Energy utilization; Internet of things; Edge computing; Internet of Things (IOT); Natural resources management; Resource allocation; Digital storage; Fog computing; Computing environments; Resource management policy; Environmental management; Internet of Things (IoT); Model and simulation; Computing infrastructures; Random access storage; Fog; Resource management techniques; Industrial management; modeling and simulation; Domestic appliances; Evaluation platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Software - Practice and Experience","","","","","","","","","","","","","","",""
"LC2XJ7L7","journalArticle","2023","","","Google Data Center PUE performance","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209222184&partnerID=40&md5=b83f8cd2c9a3e2139d8459c113315a68","","2023","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5QFJDN8","journalArticle","2021","Koot, M.; Wijnhoven, F.","Usage impact on data center electricity needs: A system dynamic forecasting model","Applied Energy","","","10.1016/j.apenergy.2021.116798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103102639&doi=10.1016%2fj.apenergy.2021.116798&partnerID=40&md5=e0af53444a66b5513927b52834a297ac","This article presents a forecasting model of data center electricity needs based on understanding usage growth and we conclude that this growth is not fully compensated by efficiency gains of data center technological innovations. We predict a combined growth of data center electricity needs of 286 TWh in 2016 until about 321 TWh in 2030, if all currently known growth factors remain the same. We next run simulations for the end of Moore's law and the growth of industrial Internet of Things (IoT). The end of Moore's law results in about 658 TWh for 2030 and an increase of the share of global data center electricity consumption from about 1.15% in 2016 to 1.86% in 2030. A rise of the Industrial IoT may result into total energy consumption of about 364 TWh (about 1.03%) in 2030. Moore's law and IoT combined cause data center energy needs going up to 752 TWh in 2030, and about 2.13% of global electricity available. Our sensitivity analysis reveals that the future impact of the data centers’ electricity consumption is vulnerable to behavioral usage trends, since the 95% confidence interval of [343, 1031] TWh is relatively wide. Our forecasts, however, exclude the energy needs of mobile devices, edge and fog computing. We offer a system dynamic model and simulation input data selected from the existing literature for replicating this study and applying alternative parameters to it. We further suggest multiple research directions on usage impact on data center energy consumption. © 2021 The Authors","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","291","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Forecasting; Internet; Internet of things; Energy-consumption; Green computing; Fog computing; Data centers; Sensitivity analysis; Internet of Things; energy efficiency; forecasting method; System Dynamics; vulnerability; innovation; confidence interval; Data center electricity need; Data center electricity needs; Dynamic forecasting; Electricity-consumption; Energy needs; Forecasting modeling; fuel consumption; Moore Law; Moore's law; parameterization; research work; sensitivity analysis; System dynamic forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TR9PEDX8","bookSection","2010","Varga, A.","OMNeT++","Modeling and Tools for Network Simulation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960763273&doi=10.1007%2f978-3-642-12331-3_3&partnerID=40&md5=8bcb612c0aeff5cfc5b6583fe18ce30d","OMNeT++ (www.omnetpp.org) is an extensible, modular, component-based C++ simulation library and framework which also includes an integrated development and a graphical runtime environment. Domain-specific functionality (support for simulation of communication networks, queuing networks, performance evaluation, etc.) is provided by model frameworks, developed as independent projects. There are extensions for real-time simulation, network emulation, support for alternative programming languages (Java, C#), database integration, SystemC integration, HLA and several other functions. © 2010 Springer-Verlag Berlin Heidelberg.","2010","2025-10-22 19:07:37","2025-10-22 19:07:37","","35-59","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84QDSP2K","bookSection","2010","Riley, G.F.; Henderson, T.R.","The ns-3 network simulator","Modeling and Tools for Network Simulation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876045426&doi=10.1007%2f978-3-642-12331-3_2&partnerID=40&md5=6a1bc8cf49e3f049dbe1337559ff44cf","As networks of computing devices grow larger and more complex, the need for highly accurate and scalable network simulation technologies becomes critical. Despite the emergence of large-scale testbeds for network research, simulation still plays a vital role in terms of scalability (both in size and in experimental speed), reproducibility, rapid prototyping, and education. With simulation based studies, the approach can be studied in detail at varying scales, with varying data applications, varying field conditions, and will result in reproducible and analyzable results. © 2010 Springer-Verlag Berlin Heidelberg.","2010","2025-10-22 19:07:37","2025-10-22 19:07:37","","15-34","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S68QN75V","journalArticle","2015","Kecskemeti, G.","DISSECT-CF: A simulator to foster energy-aware scheduling in infrastructure clouds","Simulation Modelling Practice and Theory","","","10.1016/j.simpat.2015.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947023292&doi=10.1016%2fj.simpat.2015.05.009&partnerID=40&md5=0bfb3658bac3c2137f2f246f7914374f","Infrastructure as a Service (IaaS) systems offer on demand virtual infrastructures so reliably and flexibly that users expect a high service level. Therefore, even with regards to internal IaaS behaviour, production clouds only adopt novel ideas that are proven not to hinder established service levels. To analyse their expected behaviour, new ideas are often evaluated with simulators in production IaaS system-like scenarios. For instance, new research could enable collaboration amongst several layers of schedulers or could consider new optimisation objectives such as energy consumption. Unfortunately, current cloud simulators are hard to employ and they often have performance issues when several layers of schedulers interact in them. To target these issues, a new IaaS simulation framework (called DISSECT-CF) was designed. The new simulator's foundation has the following goals: easy extensibility, support energy evaluation of IaaSs and to enable fast evaluation of many scheduling and IaaS internal behaviour related scenarios. In response to the requirements of such scenarios, the new simulator introduces concepts such as: a unified model for resource sharing and a new energy metering framework with hierarchical and indirect metering options. Then, the comparison of several simulated situations to real-life IaaS behaviour is used to validate the simulator's functionality. Finally, a performance comparison is presented between DISSECT-CF and some currently available simulators. © 2015 Elsevier B.V.","2015","2025-10-22 19:07:37","2025-10-22 19:07:37","","188-218","","","58","","","","","","","","","","","","","Scopus","","","","","","","","Energy-aware scheduling; Power management; Scheduling; Cloud computing; Resource management; Energy utilization; Infrastructure as a service (IaaS); Performance issues; Simulation; Simulators; Simulation framework; Performance comparison; Energy awareness; Energy-awareness; Infrastructure as a Service; Virtual infrastructures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCNZD9TI","journalArticle","2022","Mahmud, R.; Pallewatta, S.; Goudarzi, M.; Buyya, R.","iFogSim2: An extended iFogSim simulator for mobility, clustering, and microservice management in edge and fog computing environments","Journal of Systems and Software","","","10.1016/j.jss.2022.111351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130094579&doi=10.1016%2fj.jss.2022.111351&partnerID=40&md5=b650072584d3ec15cdfca92a7638dd74","Internet of Things (IoT) has already proven to be the building block for next-generation Cyber–Physical Systems (CPSs). The considerable amount of data generated by the IoT devices needs latency-sensitive processing, which is not feasible by deploying the respective applications in remote Cloud datacentres. Edge/Fog computing, a promising extension of Cloud at the IoT-proximate network, can meet such requirements for smart CPSs. However, the structural and operational differences of Edge/Fog infrastructure resist employing Cloud-based service regulations directly to these environments. As a result, many research works have been recently conducted, focusing on efficient application and resource management in Edge/Fog computing environments. Scalable Edge/Fog infrastructure is a must to validate these policies, which is also challenging to accommodate in the real-world due to high cost and implementation time. Considering simulation as a key to this constraint, various software have been developed that can imitate the physical behavior of Edge/Fog computing environments. Nevertheless, the existing simulators often fail to support advanced service management features because of their monolithic architecture, lack of actual dataset, and limited scope for a periodic update. To overcome these issues, we have developed modular simulation models for service migration, dynamic distributed cluster formation, and microservice orchestration for Edge/Fog computing based on real datasets and extended the basic components of iFogSim, a widely used Edge/Fog computing simulator for their ease of adoption as iFogSim2. The performance of iFogSim2 and its built-in service management policies are evaluated using three use case scenarios and compared with the contemporary simulators and benchmark policies under different settings. Results indicate that our simulator consumes less memory and minimizes simulation time by an average of 28% when compared to other simulators. © 2022 Elsevier Inc.","2022","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","190","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Microservice; Microservices; Internet of things; Cluster computing; Benchmarking; Computer software; Fog computing; Computing environments; Building blockes; Environmental management; Internet of Things; Simulation; Cyber-physical systems; Edge/fog computing; Simulators; Clustering; Clusterings; Cybe-physical systems; Edge/Fog computing; Mobility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U2GJB2RS","journalArticle","2010","Velho, P.; Legrand, A.","Accuracy study and improvement of network simulation in the SimGrid framework","Int. Conf. on Simulation Tools and Techniques","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209228922&partnerID=40&md5=77739bc8b4beb622e0a961c6803fec92","","2010","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSHHRWRE","conferencePaper","2013","Balouek, D.; Amarie, A.C.; Charrier, G.; Desprez, F.; Jeannot, E.; Jeanvoine, E.; Lèbre, A.; Margery, D.; Niclausse, N.; Nussbaum, L.; Richard, O.; Perez, C.; Quesnel, F.; Rohr, C.; Sarzyniec, L.","Adding Virtualization Capabilities to the Grid'5000 Testbed","","","","10.1007/978-3-319-04519-1_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904646472&doi=10.1007%2f978-3-319-04519-1_1&partnerID=40&md5=27f9d0816df9aea694bb5a6b7f629bd3","Almost ten years after its premises, the Grid'5000 testbed has become one of the most complete testbed for designing or evaluating large-scale distributed systems. Initially dedicated to the study of High Performance Computing, the infrastructure has evolved to address wider concerns related to Desktop Computing, the Internet of Services and more recently the Cloud Computing paradigm. This paper present recent improvements of the Grid'5000 software and services stack to support large-scale experiments using virtualization technologies as building blocks. Such contributions include the deployment of customized software environments, the reservation of dedicated network domain and the possibility to isolate them from the others, and the automation of experiments with a REST API. We illustrate the interest of these contributions by describing three different use-cases of large-scale experiments on the Grid'5000 testbed. The first one leverages virtual machines to conduct larger experiments spread over 4000 peers. The second one describes the deployment of 10000 KVM instances over 4 Grid'5000 sites. Finally, the last use case introduces a one-click deployment tool to easily deploy major IaaS solutions. The conclusion highlights some important challenges of Grid'5000 related to the use of OpenFlow and to the management of applications dealing with tremendous amount of data. © Springer International Publishing Switzerland 2013.","2013","2025-10-22 19:07:37","2025-10-22 19:07:37","","3-20","","","367 CCIS","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Virtual reality; Virtualization; Distributed systems; Cloud Computing; Virtualizations; High performance computing; Testbeds; Experiments; Virtualization technologies; Customized software; Distributed Systems; Internet of Services; Large scale experiments; Large-scale distributed system; Large-Scale Testbed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Communications in Computer and Information Science","","","","","","","","","","","","","","",""
"LVDQP529","journalArticle","2016","Shehabi, A.","United States data center energy usage report","United States Data Center Energy Usage Report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010198598&partnerID=40&md5=ee3c20b0bf14d795f7df360fb342d3ad","","2016","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZJLTBY6","journalArticle","2022","","","Electricite : combien consomment les appareils de la maison ?, report","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209213020&partnerID=40&md5=d5830d557b580912ce614f0ab6cfdd2d","","2022","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJA4ZMV8","journalArticle","2023","","","Bilan electrique 2022","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209206938&partnerID=40&md5=3f923a68cba38e9daab641bdf3f544ec","","2023","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZPE37RU","journalArticle","2023","","How much carbon dioxide is produced per kilowatthour of U.S. electricity generation?","How much carbon dioxide is produced per kilowatthour of U.S. electricity generation?","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181673550&partnerID=40&md5=160ac3475f2e11d328477f8f71d09286","","2023","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BQGSTKEV","conferencePaper","2017","Heinrich, F.C.; Cornebize, T.; Degomme, A.; Legrand, A.; Carpen-Amarie, A.; Hunold, S.; Orgerie, A.-C.; Quinson, M.","Predicting the Energy-Consumption of MPI Applications at Scale Using only a Single Node","","","","10.1109/CLUSTER.2017.66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032620594&doi=10.1109%2fCLUSTER.2017.66&partnerID=40&md5=03eb8e05d82c1e29fe374761dbbfc782","Monitoring and assessing the energy efficiency of supercomputers and data centers is crucial in order to limit and reduce their energy consumption. Applications from the domain of High Performance Computing (HPC), such as MPI applications, account for a significant fraction of the overall energy consumed by HPC centers. Simulation is a popular approach for studying the behavior of these applications in a variety of scenarios, and it is therefore advantageous to be able to study their energy consumption in a cost-efficient, controllable, and also reproducible simulation environment. Alas, simulators supporting HPC applications commonly lack the capability of predicting the energy consumption, particularly when target platforms consist of multi-core nodes. In this work, we aim to accurately predict the energy consumption of MPI applications via simulation. Firstly, we introduce the models required for meaningful simulations: The computation model, the communication model, and the energy model of the target platform. Secondly, we demonstrate that by carefully calibrating these models on a single node, the predicted energy consumption of HPC applications at a larger scale is very close (within a few percents) to real experiments. We further show how to integrate such models into the SimGrid simulation toolkit. In order to obtain good execution time predictions on multi-core architectures, we also establish that it is vital to correctly account for memory effects in simulation. The proposed simulator is validated through an extensive set of experiments with wellknown HPC benchmarks. Lastly, we show the simulator can be used to study applications at scale, which allows researchers to save both time and resources compared to real experiments. © 2017 IEEE.","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","92-102","","","2017-September","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Forecasting; Energy utilization; Cluster computing; Computer architecture; Energy; Green computing; Supercomputers; High performance computing (HPC); Simulation environment; Simulation; HPC; Simulators; Multicore architectures; MPI; Communication modeling; Execution time predictions; Message passing; Platform modeling; Platform models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE International Conference on Cluster Computing, ICCC","","","","","","","","","","","","","","",""
"8ADTJBB7","conferencePaper","2017","Filho, M.C.S.; Oliveira, R.L.; Monteiro, C.C.; Inácio, P.R.M.; Freire, M.M.","CloudSim Plus: A cloud computing simulation framework pursuing software engineering principles for improved modularity, extensibility and correctness","","","","10.23919/INM.2017.7987304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029414646&doi=10.23919%2fINM.2017.7987304&partnerID=40&md5=bd419e1cfb51a75d065dde01882ce218","Cloud computing is an established technology to provide computing resources on demand that currently faces several challenges. Main challenges include management of shared resources, energy consumption, load balancing, resource provisioning and allocation, and fulfilment of service level agreements (SLAs). Due to its inherent complexity, cloud simulation is largely used to experiment new models and algorithms. This work presents CloudSim Plus, an open source simulation framework that pursues conformance to software engineering principles and object-oriented design in order to provide an extensible, modular and accurate tool. Based on the CloudSim framework, it aims to improve several engineering aspects, such as maintainability, reusability and extensibility. This work shows the benefits of CloudSim Plus, its particular features, how it ensures more accuracy, extension facility and usage simplicity. © 2017 IFIP.","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","400-406","","","","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Cloud computing; Energy utilization; Open systems; Software engineering; Computer software; Network function virtualization; Computing resource; Reusability; Service level agreement (SLAs); Simulation framework; Engineering aspects; Inherent complexity; Models and algorithms; Object oriented design; Object oriented programming; Software engineering principles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the IM 2017 - 2017 IFIP/IEEE International Symposium on Integrated Network and Service Management","","","","","","","","","","","","","","",""
"G2HRGMDE","journalArticle","2023","Kanso, H.; Noureddine, A.; Exposito, E.","Automated power modeling of computing devices: Implementation and use case for Raspberry Pis","Sustainable Computing: Informatics and Systems","","","10.1016/j.suscom.2022.100837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145646703&doi=10.1016%2fj.suscom.2022.100837&partnerID=40&md5=55ca46d0737b822c65d90f26278c2792","Monitoring the power consumption of smart and connected devices is a challenging task with heterogeneous devices and a variety of hardware and software configurations. In order to accurately monitor these devices and follow the speedy changes in their configuration, a new approach is needed. In this paper, we present an automated architecture and approach to empirically generate power models for a large set of devices. Our approach allows conducting automated benchmarks to collect power data and metrics, generating or updating accurate power models, and allowing software tools to query and retrieve the most accurate and up-to-date power model of a specific device configuration. We also present a proof-of-concept implementation for modeling the power consumption of Raspberry Pi devices. Finally, we conduct a comprehensive experiment, modeling the entire current lineup of Raspberry Pi devices with error margins as low as 0.3%, and then we discuss the impact of multiple device configurations on power consumption. © 2022 Elsevier Inc.","2023","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","37","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Power modeling; Performance; Automation; Computing power; Hardware and software; Measurement; Power consumption; Automated software architecture; Computing devices; Device configurations; Empirical experimentation; Hardware configurations; Heterogeneous devices; Software configuration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMFLL34F","journalArticle","2021","Alwasel, K.; Jha, D.N.; Habeeb, F.; Demirbaga, U.; Rana, O.; Baker, T.; Dustdar, S.; Villari, M.; James, P.; Solaiman, E.; Ranjan, R.","IoTSim-Osmosis: A framework for modeling and simulating IoT applications over an edge-cloud continuum","Journal of Systems Architecture","","","10.1016/j.sysarc.2020.101956","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097058270&doi=10.1016%2fj.sysarc.2020.101956&partnerID=40&md5=80b7425eee6f7a423f86b35b187435d6","The osmotic computing paradigm sets out the principles and algorithms for simplifying the deployment of Internet of Things (IoT) applications in integrated edge-cloud environments. Various existing simulation frameworks can be used to support integration of cloud and edge computing environments. However, none of these can directly support an osmotic computing environment due to the complexity of IoT applications and heterogeneity of integrated edge-cloud environments. Osmotic computing suggests the migration of workload to/from a cloud data center to edge devices, based on performance and security trigger events. We propose ‘IoTSim-Osmosis– a simulation framework to support the testing and validation of osmotic computing applications. In particular, our detailed related work analysis demonstrates that IoTSim-Osmosis is the first simulation framework to enable unified modeling and simulation of complex IoT applications over heterogeneous edge-cloud environments. IoTSim-Osmosis is demonstrated using an electricity management and billing application case study, for benchmarking various run-time QoS parameters, such as IoT battery use, execution time, network transmission time and consumed energy. © 2020 Elsevier B.V.","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","116","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud data centers; Internet of things; Edge computing; Internet of Things (IOT); Benchmarking; Computing environments; Complex networks; Internet of Things (IoT); Computing paradigm; Computing applications; Simulation framework; Network transmission; Modeling and simulating; Osmosis; Osmosis computing; Simulation.; Software-Defined Network (SDN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZUBUCEH","journalArticle","2002","","","IEEE 802.3 ae-2002 IEEE standard for information technology","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209196011&partnerID=40&md5=15ffa366efc4f1bd657299185a253a42","","2002","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XUP2R8YN","conferencePaper","2011","Wu, H.; Nabar, S.; Poovendran, R.","An energy framework for the network simulator 3 (ns-3)","","","","10.4108/icst.simutools.2011.245584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922764314&doi=10.4108%2ficst.simutools.2011.245584&partnerID=40&md5=1103577d31dcf3a8d9d847d0f39a0a9c","The Network Simulator-3 (ns-3) is rapidly developing into a flexible and easy-to-use tool suitable for wireless network simulation. Since energy consumption is a key issue for wireless devices, wireless network researchers often need to investigate the energy consumption at a battery powered node or in the overall network, while running network simulations. This requires the underlying simulator to support energy consumption and energy source modeling. Currently however, ns-3 does not provide any support for modeling energy consumption or energy sources. In this paper, we introduce an integrated energy framework for ns-3, with models for energy source as well as energy consumption. We present the design and implementation of the overall framework and the specific models therein. Further, we show how the proposed framework can be used in ns-3 to simulate energy-aware protocols in a wireless network. Copyright © 2011 ICST.","2011","2025-10-22 19:07:37","2025-10-22 19:07:37","","222-230","","","","","","","","","","","","","","","","Scopus","","","","","","","","Design and implementations; Energy utilization; Energy consumption; Power management (telecommunication); Wireless networks; Network simulation; Network simulators; Simulators; Battery management systems; Battery models; Energy-aware protocol simulation; Energy-aware protocols; Network simulations; Ns-3; Overall networks; Wireless network simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SIMUTools 2011 - 4th International ICST Conference on Simulation Tools and Techniques","","","","","","","","","","","","","","",""
"FASSDJEF","journalArticle","1999","Tirumala, A.","","Iperf: The TCP/UDP Bandwidth Measurement Tool","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169467871&partnerID=40&md5=6503187c98ca58285e8946d13ea10588","","1999","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MTF29JX","conferencePaper","2020","Guegan, L.; Amersho, B.L.; Orgerie, A.-C.; Quinson, M.","A Large-Scale Wired Network Energy Model for Flow-Level Simulations","","","","10.1007/978-3-030-15032-7_88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063995808&doi=10.1007%2f978-3-030-15032-7_88&partnerID=40&md5=ecebd0379739e51297b52c2e0da22a46","The use of simulators to predict network energy consumption is a good way for scientists to improve and develop new algorithms and also to assess them. However, the average size of a network platforms is continuously increasing with the emergence of new technologies like the Internet Of Things and Fog Computing. Packet-level simulators start to reach their limits in terms of performance and this calls for newer solutions in the domain of large-scale platform energy models. In this paper, we propose two energy models for wired networks adapted to flow level simulators in order to estimate the energy consumption of large platforms. An evaluation of these models is proposed and it demonstrates their applicability in practice and their accuracy. Indeed, we obtain simulation results with a relative error lower than 4% compared to an ns-3-based solution, and our flow-based simulation is 120 times faster. © 2020, Springer Nature Switzerland AG.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","1047-1058","","","926","","","","","","","","","","","","","Scopus","","","","","","","","Relative errors; Energy utilization; Network energy consumption; Fog computing; Simulators; Flow-level simulation; Flow-level simulators; Large scale platforms; Network platforms; Packet level; Wired networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Advances in Intelligent Systems and Computing","","","","","","","","","","","","","","",""
"EVDI8MB9","journalArticle","2022","Cherrueau, R.-A.; Delavergne, M.; van Kempen, A.; Lebre, A.; Pertin, D.; Balderrama, J.R.; Simonet, A.; Simonin, M.","EnosLib: A Library for Experiment-Driven Research in Distributed Computing","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2021.3111159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114742756&doi=10.1109%2fTPDS.2021.3111159&partnerID=40&md5=be6ea4f33bc372f075fb3c171ab0cf5a","Despite the importance of experiment-driven research in the distributed computing community, there has been little progress in helping researchers conduct their experiments. In most cases, they have to achieve tedious and time-consuming development and instrumentation activities to deal with the specifics of testbeds and the system under study. In order to relieve researchers of the burden of those efforts, we have developed ENOSLIB: a Python library that takes into account best experimentation practices and leverages modern toolkits on automatic deployment and configuration systems. ENOSLIB helps researchers not only in the process of developing their experimental artifacts, but also in running them over different infrastructures. To demonstrate the relevance of our library, we discuss three experimental engines built on top of ENOSLIB, and used to conduct empirical studies on complex software stacks between 2016 and 2019 (database systems, communication buses and OpenStack). By introducing ENOSLIB, our goal is to gather academic and industrial actors of our community around a library that aggregates everyday experiment-driven research operations. A library that has been already adopted by open-source projects and members of the scientific community thanks to its ease of use and extension. © 2021 IEEE.","2022","2025-10-22 19:07:37","2025-10-22 19:07:37","","1464-1477","","6","33","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Distributed computer systems; Industrial research; Software testing; Job analysis; Task analysis; Software; Libraries; performance evaluation; Performances evaluation; Benchmark testing; Automatic configuration; Automatic deployments; Code; Computing community; distributed computing experimentation library; Distributed computing experimentation library; Experiment-driven research","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6AT3WFAJ","conferencePaper","2021","Courageux-Sudan, C.; Orgerie, A.-C.; Quinson, M.","Automated performance prediction of microservice applications using simulation","","","","10.1109/MASCOTS53633.2021.9614260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123177041&doi=10.1109%2fMASCOTS53633.2021.9614260&partnerID=40&md5=3de9b299e6d2200bff10b42d806e3af2","Microservices transform monolithic applications into simple, scalable, and interacting services. It allows for faster development and fine-grained deployments. However, the cooperation of several services leads to intricate dependencies, hindering the detection of performance bottlenecks. Current microservice performance analysis methods require real deployments, a costly process both in time and resources, while performance prediction through simulation relies on models that are complex to develop and instantiate. In this paper, we propose a microservice performance analysis approach based on simulation. Our contribution first introduces a microservice performance model requiring few instantiation parameters. We then propose a methodology to automatically derive model instantiation values from a single execution trace. We evaluate this methodology on two benchmarks from the literature. Our approach accurately predicts the deployment performance of large-scale microservice applications in various configurations from a single execution trace. This provides valuable insights on the performance of an application prior to its deployment on real platform.  © 2021 IEEE.","2021","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Performance; Fine grained; Web services; Performance evaluation; Model and simulation; Modeling and simulation; Performances evaluation; Monolithics; Performance bottlenecks; Execution trace; Performance prediction; Simple++","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS","","","","","","","","","","","","","","",""
"BIVYAH99","journalArticle","2020","Isa, I.S.B.M.; El-Gorashi, T.E.H.; Musa, M.O.I.; Elmirghani, J.M.H.","Energy efficient fog-based healthcare monitoring infrastructure","IEEE Access","","","10.1109/ACCESS.2020.3033555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099259654&doi=10.1109%2fACCESS.2020.3033555&partnerID=40&md5=ae195e882e0fb8e42fc329dfeaf966c3","Recent advances in mobile technologies and cloud computing services have inspired the development of cloud-based real-time health monitoring systems. However, the transfer of health-related data to the cloud contributes to the burden on the networking infrastructures, leading to high latency and increased power consumption. Fog computing is introduced to relieve this burden by bringing services to the users’ proximity. This study proposes a new fog computing architecture for health monitoring applications based on a Gigabit Passive Optical Network (GPON) access network. An Energy-Efficient Fog Computing (EEFC) model is developed using Mixed Integer Linear Programming (MILP) to optimize the number and location of fog devices at the network edge to process and analyze the health data for energy-efficient fog computing. The performance of the EEFC model at low data rates and high data rates health applications is studied. The outcome of the study reveals that a total energy saving of 36% and 52% are attained via processing and analysis the health data at the fog in comparison to conventional processing and analysis at the central cloud for low data rate application and high data rate application, respectively. We also developed a real-time heuristic; Energy Optimized Fog Computing (EOFC) heuristic, with energy consumption performance approaching the EEFC model. Furthermore, we examined the energy efficiency improvements under different scenarios of devices idle power consumption and traffic volume. © 2020 Lippincott Williams and Wilkins. All rights reserved.","2020","2025-10-22 19:07:37","2025-10-22 19:07:37","","197828-197852","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Cloud computing; Energy utilization; Real time systems; Green computing; Energy consumption; Integer programming; Fog computing; Internet of Things; Cloud computing services; Fog; ECG signal; Energy efficiency improvements; Ethernet; Gigabit passive optical network; GPON; Health; Health monitoring; High data rate applications; Low-data-rate applications; Machine-to-machine (M2M); Mixed-integer linear programming; Networking infrastructure; Passive optical networks; Real-time health monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6CY9T588","conferencePaper","2019","Guegan, L.; Orgerie, A.-C.","Estimating the end-to-end energy consumption of low-bandwidth IoT applications for WiFi devices","","","","10.1109/CloudCom.2019.00049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079074638&doi=10.1109%2fCloudCom.2019.00049&partnerID=40&md5=cf6d488b221d750df919602f3e17f854","Information and Communication Technology takes a growing part in the worldwide energy consumption. One of the root causes of this increase lies in the multiplication of connected devices. Each object of the Internet-of-Things often does not consume much energy by itself. Yet, their number and the infrastructures they require to properly work have leverage. In this paper, we combine simulations and real measurements to study the energy impact of IoT devices. In particular, we analyze the energy consumption of Cloud and telecommunication infrastructures induced by the utilization of connected devices, and we propose an end-to-end energy consumption model for these devices. © 2019 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","287-294","","","2019-December","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Energy utilization; Internet of things; Wireless local area networks (WLAN); Clouds; Green computing; Energy consumption; Information and Communication Technologies; Blockchain; Energy consumption model; IOT applications; End-to-end model; End-to-end models; Energy impact; IoT devices; Real measurements; Telecommunication infrastructures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom","","","","","","","","","","","","","","",""
"835MMZEX","journalArticle","2018","Li, Y.; Orgerie, A.-C.; Rodero, I.; Amersho, B.L.; Parashar, M.; Menaud, J.-M.","End-to-end energy models for Edge Cloud-based IoT platforms: Application to data stream analysis in IoT","Future Generation Computer Systems","","","10.1016/j.future.2017.12.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039909917&doi=10.1016%2fj.future.2017.12.048&partnerID=40&md5=8d7d371ce4f2a169a5a837029454720a","Internet of Things (IoT) is bringing an increasing number of connected devices that have a direct impact on the growth of data and energy-hungry services. These services are relying on Cloud infrastructures for storage and computing capabilities, transforming their architecture into more a distributed one based on edge facilities provided by Internet Service Providers (ISP). Yet, between the IoT device, communication network and Cloud infrastructure, it is unclear which part is the largest in terms of energy consumption. In this paper, we provide end-to-end energy models for Edge Cloud-based IoT platforms. These models are applied to a concrete scenario: data stream analysis produced by cameras embedded on vehicles. The validation combines measurements on real test-beds running the targeted application and simulations on well-known simulators for studying the scaling-up with an increasing number of IoT devices. Our results show that, for our scenario, the edge Cloud part embedding the computing resources consumes 3 times more than the IoT part comprising the IoT devices and the wireless access point. © 2017 Elsevier B.V.","2018","2025-10-22 19:07:37","2025-10-22 19:07:37","","667-678","","","87","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Internet of things; Internet of Things (IOT); Edge clouds; Green computing; Digital storage; Computing capability; Cloud infrastructures; Data stream; Energy-efficiency; IoT; Energy model; Data stream analysis; Edge Cloud computing; End-to-end energy model; Internet service providers; Internet service providers (ISP); Wireless access points","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W44LXBH3","journalArticle","2022","Islam, Mohammad Mainul; Ramezani, Fahimeh; Lu, Hai Yan; Naderpour, Mohsen","Optimal Placement of Applications in the Fog Environment: A Systematic Literature Review","J. Parallel and Distrib. Comput","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150009781&partnerID=40&md5=e56bba9bccbb8c877c3942ff59b3d1f6","","2022","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXACGTEI","conferencePaper","2019","Zhang, Y.; Gan, Y.; Delimitrou, C.","μqSim: Enabling Accurate and Scalable Simulation for Interactive Microservices","","","","10.1109/ISPASS.2019.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065406209&doi=10.1109%2fISPASS.2019.00034&partnerID=40&md5=6d6d2dddbd199083af596f9b032e8407","Current cloud services are moving away from monolithic designs and towards graphs of many loosely-coupled, single-concerned microservices. Microservices have several advantages, including speeding up development and deployment, allowing specialization of the software infrastructure, and helping with debugging and error isolation. At the same time they introduce several hardware and software challenges. Given that most of the performance and efficiency implications of microservices happen at scales larger than what is available outside production deployments, studying such effects requires designing the right simulation infrastructures. We present j);qSim, a scalable and validated queueing network simulator designed specifically for interactive microser-vices. μqSim provides detailed intra- and inter-microservice models that allow it to faithfully reproduce the behavior of complex, many-tier applications. μqSim is also modular, allowing reuse of individual models across microservices and end-to-end applications. We have validated μqSim both against simple and more complex microservices graphs, and have shown that it accurately captures performance in terms of throughput and tail latency. Finally, we use μqSim to model the tail at scale effects of request fanout, and the performance impact of power management in latency -sensitive microservices. © 2019 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","212-222","","","","","","","","","","","","","","","","Scopus","","","","","","","","Program debugging; Performance impact; Hardware and software; End-to-end application; Complex networks; Network simulators; Loosely coupled; Software infrastructure; Individual models; Monolithic design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2019 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2019","","","","","","","","","","","","","","",""
"PAZTIBWD","conferencePaper","2022","Courageux-Sudan, C.; Guegan, L.; Orgerie, A.-C.; Quinson, M.","A Flow-Level Wi-Fi Model for Large Scale Network Simulation","","","","10.1145/3551659.3559022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141711765&doi=10.1145%2f3551659.3559022&partnerID=40&md5=f2ab212a07e7cb574de31b0aff3d05b6","Wi-Fi networks are extensively used to provide Internet access to end-users and to deploy applications at the edge. By playing a major role in modern networking, Wi-Fi networks are getting bigger and denser. However, studying their performance at large-scale and in a reproducible manner remains a challenging task. Current solutions include real experiments and simulations. While the size of experiments is limited by their financial cost and potential disturbance of commercial networks, the simulations also lack scalability due to their models' granularity and computational runtime. In this paper, we introduce a new Wi-Fi model for large-scale simulations. This model, based on flow-level simulation, requires fewer computations than state-of-the-art models to estimate bandwidth sharing over a wireless medium, leading to better scalability. Comparing our model to the already existing Wi-Fi implementation of ns-3, we show that our approach yields to close performance evaluations while improving the runtime of simulations by several orders of magnitude. Using this kind of model could allow researchers to obtain reproducible results for networks composed of thousands of nodes much faster than previously.  © 2022 ACM.","2022","2025-10-22 19:07:37","2025-10-22 19:07:37","","111-119","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Large-scales; Wi-Fi; Wireless local area networks (WLAN); Runtimes; End-users; Scalability; performance evaluation; Model and simulation; Performances evaluation; Internet access; Flow-level; Large-scale network simulation; modeling and simulation; Wi-fi network; Wi-Fi networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","MSWiM 2022 - Proceedings of the International Conference on Modeling Analysis and Simulation of Wireless and Mobile Systems","","","","","","","","","","","","","","",""
"7ZMWPXIU","journalArticle","2013","Velho, P.; Schnorr, L.M.; Casanova, H.; Legrand, A.","On the Validity of Flow-level TCP Network Models for Grid and Cloud Simulations","ACM Transactions on Modeling and Computer Simulation","","","10.1145/2517448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002716104&doi=10.1145%2f2517448&partnerID=40&md5=ac18458d87cdb90eaf754aad0005ae59","Researchers in the area of grid/cloud computing perform many of their experiments using simulations that must capture network behavior. In this context, packet-level simulations, which are widely used to study network protocols, are too costly given the typical large scales of simulated systems and applications. An alternative is to implement network simulations with less costly flow-level models. Several flow-level models have been proposed and implemented in grid/cloud simulators. Surprisingly, published validations of these models, if any, consist of verifications for only a few simple cases. Consequently, even when they have been used to obtain published results, the ability of these simulators to produce scientifically meaningful results is in doubt. This work evaluates these state-of-the-art flow-level network models of TCP communication via comparison to packet-level simulation. While it is straightforward to show cases in which previously proposed models lead to good results, instead we follow the critical method, which places model refutation at the center of the scientific activity, and we systematically seek cases that lead to invalid results. Careful analysis of these cases reveals fundamental flaws and also suggests improvements. One contribution of this work is that these improvements lead to a new model that, while far from being perfect, improves upon all previously proposed models in the context of simulation of grids or clouds. A more important contribution, perhaps, is provided by the pitfalls and unexpected behaviors encountered in this work, leading to a number of enlightening lessons. In particular, this work shows that model validation cannot be achieved solely by exhibiting (possibly many) “good cases.” Confidence in the quality of a model can only be strengthened through an invalidation approach that attempts to prove the model wrong. © 2013, ACM. All rights reserved.","2013","2025-10-22 19:07:37","2025-10-22 19:07:37","","1-26","","4","23","","","","","","","","","","","","","Scopus","","","","","","","","scalability; validation; Experimentation; Grid and cloud computing simulation; SimGrid","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XG6XTAB","journalArticle","2019","Lera, I.; Guerrero, C.; Juiz, C.","YAFS: A Simulator for IoT Scenarios in Fog Computing","IEEE Access","","","10.1109/ACCESS.2019.2927895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073893852&doi=10.1109%2fACCESS.2019.2927895&partnerID=40&md5=3a2fae3d226d69e4d3a1a6f4d75e397e","Fog computing is a paradigm that extends the cloud to intermediate network devices with computational and storage capacities. This allows the execution of applications closer to edge devices and end-users by allocating services in those intermediate devices. The placement of those services has an influence on the performance of the fog architecture. We propose a fog computing simulator for analyzing the design and deployment of applications through customized and dynamical strategies. We model the relationships among deployed applications, network connections, and infrastructure characteristics through complex network theory, enabling the integration of topological measures in dynamic and customizable strategies, such as the placement of application modules, workload location, and path routing and scheduling of services. We present a comparative analysis of the efficiency and the convergence of results of our simulator with the most referenced one, iFogSim. To highlight the YAFS functionalities, we model three scenarios that, to the best of our knowledge, cannot be implemented with current fog simulators: dynamic allocation of new application modules, dynamic failures of network nodes, and user mobility along with the topology. © 2013 IEEE.","2019","2025-10-22 19:07:37","2025-10-22 19:07:37","","91745-91758","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Computation theory; fog computing; Fog computing; Complex networks; Internet of Things; Topology; Fog; simulator; Simulators; Application module; Dynamic allocations; Comparative analysis; Deployed applications; Dynamic failures; Intermediate networks; Network connection; New applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9S624AP3","conferencePaper","2022","Gougeon, A.; Lemercier, F.; Blavette, A.; Orgerie, A.-C.","Modeling the End-to-End Energy Consumption of a Nation-Wide Smart Metering Infrastructure","","","","10.1109/ISCC55528.2022.9912949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141128304&doi=10.1109%2fISCC55528.2022.9912949&partnerID=40&md5=4af824b291f8cb5b8d0102496bf3f964","Several countries have deployed, or have started the deployment of a smart metering infrastructure in order to enable the Smart Grid. This infrastructure aims to provide new services to grid users and grid operators relying on several communication technologies. One of the goals of this infrastructure is to improve energy consumption, for instance by increasing the awareness of the users, or by enforcing energy management policies. Yet, this infrastructure also consumes energy. The objective of this work is to accurately characterize the energy consumption of each part of the smart metering infrastructure, at a nation-wide scale. We also explore several consumption scenarios highlighting the impact of legacy technologies on the energy consumption of the smart metering infrastructure.  © 2022 IEEE.","2022","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","2022-June","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Energy; Energy management; Energy-consumption; Management policy; End to end; Smart grid; Communicationtechnology; Electric measuring instruments; Grid operators; Grid users; New services; Smart metering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Symposium on Computers and Communications","","","","","","","","","","","","","","",""
"YJHJ892V","conferencePaper","2012","Uhrmacher, A.M.","Seven pitfalls in modeling and simulation research","","","","10.1109/WSC.2012.6465321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874748463&doi=10.1109%2fWSC.2012.6465321&partnerID=40&md5=7f826674d76c5e6f39b9d9f446936214","Modeling and simulation is applied in many disciplines. While its multidisciplinarity is part of its fascination, its ubiquity also holds some dangers. Being not aware about these dangers might imply that resources are wasted, (PhD-) projects fail, and the overall progress of modeling and simulation is needlessly slowed down. Seven of these pitfalls are identified and tentative recommendations are made on how these pitfalls can be avoided. © 2012 IEEE.","2012","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Software engineering; Computer simulation; Modeling and simulation; Circuit simulation; Multidisciplinarity; Projects fail","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - Winter Simulation Conference","","","","","","","","","","","","","","",""
"INBIP67B","conferencePaper","2005","Sierra, M.R.; Coello Coello, C.A.","Improving PSO-based Multi-Objective optimization using crowding, mutation and ε-dominance","","","","10.1007/978-3-540-31880-4_35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-24344480582&doi=10.1007%2f978-3-540-31880-4_35&partnerID=40&md5=cde7f58a922047af031d2f9e8ef27d1d","In this paper, we propose a new Multi-Objective Particle Swarm Optimizer, which is based on Pareto dominance and the use of a crowding factor to filter out the list of available leaders. We also propose the use of different mutation (or turbulence) operators which act on different subdivisions of the swarm. Finally, the proposed approach also incorporates the ε-dominance concept to fix the size of the set of final solutions produced by the algorithm. Our approach is compared against five state-of-the-art algorithms, including three PSO-based approaches recently proposed. The results indicate that the proposed approach is highly competitive, being able to approximate the front even in cases where all the other PSO-based approaches fail. © Springer-Verlag Berlin Heidelberg 2005.","2005","2025-10-22 19:07:37","2025-10-22 19:07:37","","505-519","","","3410","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Algorithms; Multiobjective optimization; Approximation theory; Pareto principle; Crowding factors; Optimizers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science","","","","","","","","","","","","","","",""
"SJQ4YIRW","journalArticle","2018","Smet, P.; Dhoedt, B.; Simoens, P.","Docker Layer Placement for On-Demand Provisioning of Services on Edge Clouds","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2018.2844187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048151684&doi=10.1109%2fTNSM.2018.2844187&partnerID=40&md5=c4e7bdb07766e3ce1e3794ca7058a7b4","Driven by the increasing popularity of the microservice architecture, we see an increase in services with unknown demand pattern located in the edge network. Pre-deployed instances of such services would be idle most of the time, which is economically infeasible. Also, the finite storage capacity limits the amount of deployed instances we can offer. Instead, we present an on-demand deployment scheme using the Docker platform. In Docker, service images consist of layers, each layer adding specific functionality. This allows different services to reuse layers, avoiding cluttering the storages with redundant replicas. We propose a layer placement method which allows users to connect to a server, retrieve all necessary layers -possibly from multiple locations- and deploy an instance of the requested service within the desired response time. We search for the best layer placement which maximizes the satisfied demand given the storage and delay constraints. We developed an iterative optimization heuristic which is less exhaustive by dividing the global problem in smaller subproblems. Our simulation results show that our heuristic is able to solve the problem with less system resources. Last, we present interesting use-cases to use this approach in real-life scenarios. © 2004-2012 IEEE.","2018","2025-10-22 19:07:37","2025-10-22 19:07:37","","1161-1174","","3","15","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud computing; Computer architecture; Network architecture; Edge computing; Servers; Iterative methods; On demands; Placement algorithm; Time factors; services; docker; Long tail; long-tail; on-demand; placement algorithm; service-centric; Service-centric","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VMYC5IT","conferencePaper","2012","Dawoud, W.; Takouna, I.; Meinel, C.","Elastic virtual machine for fine-grained cloud resource provisioning","","","","10.1007/978-3-642-29219-4_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865700853&doi=10.1007%2f978-3-642-29219-4_2&partnerID=40&md5=0a9ed8478d935e9cf164b85de141c4a8","Elasticity is one of the distinguishing characteristics associated with Cloud computing emergence. It enables cloud resources to auto-scale to cope with workload demand. Multi-instances horizontal scaling is the common scalability architecture in Cloud; however, its current implementation is coarse-grained, while it considers Virtual Machine (VM) as a scaling unit, this implies additional scaling-out overhead and limits it to specific applications. To overcome these limitations, we propose Elastic VM as a fine-grained vertical scaling architecture. Our results proved that Elastic VM architecture implies less consumption of resources, mitigates Service Level Objectives (SLOs) violation, and avoids scaling-up overhead. Furthermore, it scales broader range of applications including databases. © 2012 Springer-Verlag.","2012","2025-10-22 19:07:37","2025-10-22 19:07:37","","11-25","","","269 CCIS","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; Virtualizations; Architecture; Elasticity; Virtual machines; Coarse-grained; Service level objective; Resource provisioning; Computer simulation; virtualization; Vertical scaling; elasticity; auto-scaling; Auto-scale; Communication systems; Heterojunction bipolar transistors; Horizontal scaling; Scaling-up","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Communications in Computer and Information Science","","","","","","","","","","","","","","",""
"2FRSVCLR","journalArticle","2018","Guerrero, C.; Lera, I.; Juiz, C.","Resource optimization of container orchestration: a case study in multi-cloud microservices-based applications","Journal of Supercomputing","","","10.1007/s11227-018-2345-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044624170&doi=10.1007%2fs11227-018-2345-2&partnerID=40&md5=dd476bbb76f87c0ea30760bdc4b66184","An approach to optimize the deployment of microservices-based applications using containers in multi-cloud architectures is presented. The optimization objectives are three: cloud service cost, network latency among microservices, and time to start a new microservice when a provider becomes unavailable. The decision variables are: the scale level of the microservices; their allocation in the virtual machines; the provider and virtual machine type selection; and the number of virtual machines. The experiments compare the optimization results between a Greedy First-Fit and a Non-dominated Sorting Genetic Algorithm II (NSGA-II). NSGA-II with a two-point crossover operator and three mutation operators obtained an overall improvement of 300% in regard to the greedy algorithm. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","2018","2025-10-22 19:07:37","2025-10-22 19:07:37","","2956-2983","","7","74","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Microservices; Cloud computing; Virtual machine; Multiobjective optimization; Network security; Container orchestration; Genetic algorithms; Genetic algorithm; Greedy algorithms; Network latencies; Multi-objective optimization; Crossover operator; Decision variables; Mutation operators; Non dominated sorting genetic algorithm ii (NSGA II); Resource optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXVKC2HB","journalArticle","2015","Jennings, B.; Stadler, R.","Resource Management in Clouds: Survey and Research Challenges","Journal of Network and Systems Management","","","10.1007/s10922-014-9307-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931011055&doi=10.1007%2fs10922-014-9307-7&partnerID=40&md5=cf605477e364b9c4bbe4faa4a35f370c","Resource management in a cloud environment is a hard problem, due to: the scale of modern data centers; the heterogeneity of resource types and their interdependencies; the variability and unpredictability of the load; as well as the range of objectives of the different actors in a cloud ecosystem. Consequently, both academia and industry began significant research efforts in this area. In this paper, we survey the recent literature, covering 250+ publications, and highlighting key results. We outline a conceptual framework for cloud resource management and use it to structure the state-of-the-art review. Based on our analysis, we identify five challenges for future investigation. These relate to: providing predictable performance for cloud-hosted applications; achieving global manageability for cloud systems; engineering scalable resource management systems; understanding economic behavior and cloud pricing; and developing solutions for the mobile cloud paradigm. © 2014, Springer Science+Business Media New York.","2015","2025-10-22 19:07:37","2025-10-22 19:07:37","","567-619","","3","23","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Information management; Resource management; Virtualization; Cloud environments; Virtualizations; Surveys; Natural resources management; Resource allocation; Research challenges; Economics; Survey; Conceptual frameworks; Developing solutions; Resource management systems; State-of-the art reviews; Surveying","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCKB73TJ","journalArticle","2005","Pacifici, G.; Spreitzer, M.; Tantawi, A.N.; Youssef, A.","Performance management for cluster-based web services","IEEE Journal on Selected Areas in Communications","","","10.1109/JSAC.2005.857208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-29144473731&doi=10.1109%2fJSAC.2005.857208&partnerID=40&md5=c529802e51103ae7b22b5f29aed8a004","We present an architecture and prototype implementation of a performance management system for cluster-based web services. The system supports multiple classes of web services traffic and allocates server resources dynamically so to maximize the expected value of a given cluster utility function in the face of fluctuating loads. The cluster utility is a function of the performance delivered to the various classes, and this leads to differentiated service. In this paper, we will use the average response time as the performance metric. The management system is transparent: it requires no changes in the client code, the server code, or the network interface between them. The system performs three performance management tasks: resource allocation, load balancing, and server overload protection. We use two nested levels of management. The inner level centers on queuing and scheduling of request messages. The outer level is a feedback control loop that periodically adjusts the scheduling weights and server allocations of the inner level. The feedback controller is based on an approximate first-principles model of the system, with parameters derived from continuous monitoring. We focus on SOAP-based web services. We report experimental results that show the dynamic behavior of the system. © 2005 IEEE.","2005","2025-10-22 19:07:37","2025-10-22 19:07:37","","2333-2343","","12","23","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Web services; Servers; Resource allocation; World Wide Web; Queueing theory; Telecommunication traffic; Clustered computing; Performance management; Quality-of-service (QoS); Service differentiation; Utility functions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5FQ55P9V","journalArticle","2001","Chen, B.P.K.; Henderson, S.G.","Two Issues in Setting Call Centre Staffing Levels","Annals of Operations Research","","","10.1023/A:1016015213287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035742615&doi=10.1023%2fA%3a1016015213287&partnerID=40&md5=03ce261824a313f04e69b3055782ff50","Motivated by a problem facing the Police Communication Centre in Auckland, New Zealand, we consider the setting of staffing levels in a call centre with priority customers. The choice of staffing level over any particular time period (e.g., Monday from 8 am-9 am) relies on accurate arrival rate information. The usual method for identifying the arrival rate based on historical data can, in some cases, lead to considerable errors in performance estimates for a given staffing level. We explain why, identify three potential causes of the difficulty, and describe a method for detecting and addressing such a problem.","2001","2025-10-22 19:07:37","2025-10-22 19:07:37","","175-192","","1-4","108","","","","","","","","","","","","","Scopus","","","","","","","","Conditional poisson process; Convexity; Forecast error; Nonstationarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4GHA7QE","journalArticle","2017","Chen, T.; Bahsoon, R.","Self-Adaptive Trade-off Decision Making for Autoscaling Cloud-Based Services","IEEE Transactions on Services Computing","","","10.1109/TSC.2015.2499770","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029351128&doi=10.1109%2fTSC.2015.2499770&partnerID=40&md5=0da55c2422403d112b7efdc918b9ab49","Elasticity in the cloud is often achieved by on-demand autoscaling. In such context, the goal is to optimize the Quality of Service (QoS) and cost objectives for the cloud-based services. However, the difficulty lies in the facts that these objectives, e.g., throughput and cost, can be naturally conflicted; and the QoS of cloud-based services often interfere due to the shared infrastructure in cloud. Consequently, dynamic and effective trade-off decision making of autoscaling in the cloud is necessary, yet challenging. In particular, it is even harder to achieve well-compromised trade-offs, where the decision largely improves the majority of the objectives; while causing relatively small degradations to others. In this paper, we present a self-adaptive decision making approach for autoscaling in the cloud. It is capable to adaptively produce autoscaling decisions that lead to well-compromised trade-offs without heavy human intervention. We leverage on ant colony inspired multi-objective optimization for searching and optimizing the trade-offs decisions, the result is then filtered by compromise-dominance, a mechanism that extracts the decisions with balanced improvements in the trade-offs. We experimentally compare our approach to four state-of-the-arts autoscaling approaches: rule, heuristic, randomized and multi-objective genetic algorithm based solutions. The results reveal the effectiveness of our approach over the others, including better quality of trade-offs and significantly smaller violation of the requirements. © 2015 IEEE.","2017","2025-10-22 19:07:37","2025-10-22 19:07:37","","618-632","","4","10","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; cloud computing; Cloud computing; Economic and social effects; Decision making; State of the art; Trade off; Multiobjective optimization; Genetic algorithms; Ant colony optimization; Search based optimizations; Ant colonies; Shared infrastructure; Adaptive decision making; Human intervention; Multi-objective genetic algorithm; multi-objective trade-offs; QoS interference; Search-based optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P4R7SYZD","journalArticle","1983","Grassmann, W.","CONVEXITY OF THE MEAN QUEUE SIZE OF THE M/M/c QUEUE WITH RESPECT TO THE TRAFFIC INTENSITY.","Journal of Applied Probability","","","10.1017/S0021900200024244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0020887727&doi=10.1017%2fS0021900200024244&partnerID=40&md5=87a6779b9a04878607ed482bb023c679","It is shown that the expected number in an M/M/c queue is convex with respect to the traffic intensity. The proof is conducted by expressing the second derivative of the expected queue size as the sum of non-negative terms.","1983","2025-10-22 19:07:37","2025-10-22 19:07:37","","916-919","","4","20","","","","","","","","","","","","","Scopus","","","","","","","","Probability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZKEG4F5","journalArticle","1982","Karmarkar, N.; Karp, R.M.","The differencing method of set partitioning","The Differencing Method of Set Partitioning","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003590131&partnerID=40&md5=5341bca0eee85b3d764e5afbbc6cb864","","1982","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LRL5E7W","journalArticle","2008","Narayanan, D.; Donnelly, A.; Rowstron, A.","Write off-loading: Practical power management for enterprise storage","ACM Transactions on Storage","","","10.1145/1416944.1416949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-59449092139&doi=10.1145%2f1416944.1416949&partnerID=40&md5=fdf472ddb79d2aebeacd76b3f69e69b9","In enterprise data centers power usage is a problem impacting server density and the total cost of ownership. Storage uses a significant fraction of the power budget and there are no widely deployed power-saving solutions for enterprise storage systems. The traditional view is that enterprise workloads make spinning disks down ineffective because idle periods are too short. We analyzed block-level traces from 36 volumes in an enterprise data center for one week and concluded that significant idle periods exist, and that they can be further increased by modifying the read/write patterns using write off-loading. Write off-loading allows write requests on spun-down disks to be temporarily redirected to persistent storage elsewhere in the data center. The key challenge is doing this transparently and efficiently at the block level, without sacrificing consistency or failure resilience. We describe our write off-loading design and implementation that achieves these goals. We evaluate it by replaying portions of our traces on a rack-based testbed. Results show that just spinning disks down when idle saves 28 - 36% of energy, and write off-loading further increases the savings to 45 - 60%. © 2008 ACM.","2008","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","3","4","","","","","","","","","","","","","Scopus","","","","","","","","Power; Energy; Energy management; Satellite communication systems; Disk spin-down; DiskEnergy; Disks (machine components); Disks (structural components); Enterprise storage; Loading; Spin dynamics; Write off-loading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YBU55PF","conferencePaper","2011","Xiong, P.; Wang, Z.; Malkowski, S.; Wang, Q.; Jayasinghe, D.; Pu, C.","Economical and robust provisioning of N-tier cloud workloads: A Multi-level control approach","","","","10.1109/ICDCS.2011.88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051864287&doi=10.1109%2fICDCS.2011.88&partnerID=40&md5=e471e1498fd23792af21885b2e739cdc","Resource provisioning for N-tier web applications in Clouds is non-trivial due to at least two reasons. First, there is an inherent optimization conflict between cost of resources and Service Level Agreement (SLA) compliance. Second, the resource demands of the multiple tiers can be different from each other, and varying along with the time. Resources have to be allocated to multiple (virtual) containers to minimize the total amount of resources while meeting the end-to-end performance requirements for the application. In this paper we address these two challenges through the combination of the resource controllers on both application and container levels. On the application level, a decision maker (i.e., an adaptive feedback controller) determines the total budget of the resources that are required for the application to meet SLA requirements as the workload varies. On the container level, a second controller partitions the total resource budget among the components of the applications to optimize the application performance (i.e., to minimize the round trip time). We evaluated our method with three different workload models-open, closed, and semiopen- that were implemented in the RUBiS web application benchmark. Our evaluation indicates two major advantages of our method in comparison to previous approaches. First, fewer resources are provisioned to the applications to achieve the same performance. Second, our approach is robust enough to address various types of workloads with time-varying resource demand without reconfiguration. © 2011 IEEE.","2011","2025-10-22 19:07:37","2025-10-22 19:07:37","","571-580","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Non-trivial; Containers; Optimization; Cloud computing; Service Level Agreements; User interfaces; Decision makers; Benchmarking; Budget control; Application performance; Resource demands; Application level; Adaptive feedback; Adaptive control; Controllers; Resource provisioning; World Wide Web; WEB application; Adaptive Control; End-to-end performance; Control approach; Multi-level; N-tier web application; Resource budget; Resource controllers; Round-trip time; Service level agreement; Time varying; Total budget","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Distributed Computing Systems","","","","","","","","","","","","","","",""
"D33MDQFJ","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072523733&partnerID=40&md5=a4d9d0ca5c4e0a81742bd1b5fd06c9dc","","","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TN3SVIXQ","journalArticle","2004","Reed, W.J.; Jorgensen, M.","The double Pareto-lognormal distribution - A new parametric model for size distributions","Communications in Statistics - Theory and Methods","","","10.1081/STA-120037438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042550642&doi=10.1081%2fSTA-120037438&partnerID=40&md5=55a15aff7686aeb902a3de8923187c2f","A family of probability densities, which has proved useful in modelling the size distributions of various phenomens, including incomes and earnings, human settlement sizes, oil-field volumes and particle sizes, is introduced. The distribution, named herein as the double Pareto-lognormal or dPlN distribution, arises as that of the state of a geometric Brownian motion (GBM), with lognormally distributed initial state, after an exponentially distributed length of time (or equivalently as the distribution of the killed state of such a GBM with constant killing rate). A number of phenomena can be viewed as resulting from such a process (e.g., incomes, settlement sizes), which explains the good fit. Properties of the distribution are derived and estimation methods discussed. The distribution exhibits Paretian (power-law) behaviour in both tails, and when plotted on logarithmic axes, its density exhibits hyperbolic-type behaviour.","2004","2025-10-22 19:07:37","2025-10-22 19:07:37","","1733-1753","","8","33","","","","","","","","","","","","","Scopus","","","","","","","","Computer simulation; Pareto principle; EM algorithm; Parameter estimation; Probability; Brownian movement; Fat tails; Financial returns; Laplace transforms; Pareto law; Particle size analysis; Power-law distribution; Size distribution; WWW file size","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFGTVPMD","journalArticle","2011","Vaquero, L.M.; Rodero-Merino, L.; Buyya, R.","Dynamically scaling applications in the cloud","Computer Communication Review","","","10.1145/1925861.1925869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551491370&doi=10.1145%2f1925861.1925869&partnerID=40&md5=985086bc116694cc75bc6bfbfbace65b","Scalability is said to be one of the major advantages brought by the cloud paradigm and, more specifically, the one that makes it different to an advanced outsourcing solution. However, there are some important pending issues before making the dreamed automated scaling for applications come true. In this paper, the most notable initiatives towards whole application scalability in cloud environments are presented. We present relevant efforts at the edge of state of the art technology, providing an encompassing overview of the trends they each follow. We also highlight pending challenges that will likely be addressed in new research efforts and present an ideal scalable cloud system.","2011","2025-10-22 19:07:37","2025-10-22 19:07:37","","45-52","","1","41","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud systems; Computer systems; Scalability; Application scalability; Research efforts; Outsourcing; Outsourcing solution; State-of-the-art technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EABIPLLV","journalArticle","2010","Stillwell, M.; Schanzenbach, D.; Vivien, F.; Casanova, H.","Resource allocation algorithms for virtualized service hosting platforms","Journal of Parallel and Distributed Computing","","","10.1016/j.jpdc.2010.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955515011&doi=10.1016%2fj.jpdc.2010.05.006&partnerID=40&md5=e2e2dd608677beaf7de2a190b3781bff","Commodity clusters are used routinely for deploying service hosting platforms. Due to hardware and operation costs, clusters need to be shared among multiple services. Crucial for enabling such shared hosting platforms is virtual machine (VM) technology, which allows consolidation of hardware resources. A key challenge, however, is to make appropriate decisions when allocating hardware resources to service instances. In this work we propose a formulation of the resource allocation problem in shared hosting platforms for static workloads with servers that provide multiple types of resources. Our formulation supports a mix of best-effort and QoS scenarios, and, via a precisely defined objective function, promotes performance, fairness, and cluster utilization. Further, this formulation makes it possible to compute a bound on the optimal resource allocation. We propose several classes of resource allocation algorithms, which we evaluate in simulation. We are able to identify an algorithm that achieves average performance close to the optimal across many experimental scenarios. Furthermore, this algorithm runs in only a few seconds for large platforms and thus is usable in practice. © 2010 Elsevier Inc. All rights reserved.","2010","2025-10-22 19:07:37","2025-10-22 19:07:37","","962-974","","9","70","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Optimization; Algorithms; Virtual machines; Resource allocation; Virtual machine; Optimal resource allocation; Computer simulation; Best-effort; Cluster; Hardware resources; Resource allocation algorithms; Resource allocation problem; Multiple services; Cluster utilization; Commodity clusters; Objective functions; Operation cost; Service hosting; Service instances; Virtual machine technology; Virtualized services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T24QRMMV","journalArticle","2007","Wood, T.; Shenoy, P.; Venkataramani, A.; Yousif, M.","Black-box and gray-box strategies for virtual machine migration","Proc. NSDI","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-53349127069&partnerID=40&md5=fa5dcf25b8c23206d5b3b030ea72fac4","","2007","2025-10-22 19:07:37","2025-10-22 19:07:37","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TV7VWD7T","journalArticle","2015","Aroca, J.A.; Chatzipapas, A.; Anta, A.F.; Mancuso, V.","A Measurement-Based Characterization of the Energy Consumption in Data Center Servers","IEEE Journal on Selected Areas in Communications","","","10.1109/JSAC.2015.2481198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960129677&doi=10.1109%2fJSAC.2015.2481198&partnerID=40&md5=cfcd23421d1e295909acbaf7de6079f2","In this work, we present an exhaustive empirical characterization of the power requirements of multiple components of data center servers. To do so, we devise different experiments to stress these components, taking into account the multiple available frequencies and the fact that we are working with multicore servers. In these experiments, we measure energy consumption of server components and identify their optimal operational points. Our study proves that the curve defining the minimal CPU power utilization, as a function of the load in active cycles per second, is neither concave nor purely convex. Instead, it definitively shows a super-linear dependence on the load. Similarly, we present results on how to improve the efficiency of network cards and disks. Finally, we validate the accuracy of the model derived from our characterization by comparing the real energy consumed by two Hadoop applications-PageRank and WordCount-with the estimation from our model, obtaining errors below 4.1% on average. © 2015 IEEE.","2015","2025-10-22 19:07:37","2025-10-22 19:07:37","","2863-2877","","12","33","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Program processors; Distributed computer systems; Cloud Computing; Energy utilization; Networks (circuits); Electric power measurement; Data centers; CPU; energy efficiency; Characterization; Power requirement; DVFS; network; data centers; disk; energy measurements; Linear dependence; Measurement-based; Multi-core servers; Multiple components","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DXTL3QUD","conferencePaper","2007","Fan, X.; Weber, W.-D.; Barroso, L.A.","Power provisioning for a warehouse-sized computer","","","","10.1145/1250662.1250665","https://www.scopus.com/inward/record.uri?eid=2-s2.0-35348835964&doi=10.1145%2f1250662.1250665&partnerID=40&md5=0ba10bc53962f2321e9062dec64e3177","Large-scale Internet services require a computing infrastructure that can beappropriately described as a warehouse-sized computing system. The cost ofbuilding datacenter facilities capable of delivering a given power capacity tosuch a computer can rival the recurring energy consumption costs themselves.Therefore, there are strong economic incentives to operate facilities as closeas possible to maximum capacity, so that the non-recurring facility costs canbe best amortized. That is difficult to achieve in practice because ofuncertainties in equipment power ratings and because power consumption tends tovary significantly with the actual computing activity. Effective powerprovisioning strategies are needed to determine how much computing equipmentcan be safely and efficiently hosted within a given power budget. In this paper we present the aggregate power usage characteristics of largecollections of servers (up to 15 thousand) for different classes ofapplications over a period of approximately six months. Those observationsallow us to evaluate opportunities for maximizing the use of the deployed powercapacity of datacenters, and assess the risks of over-subscribing it. We findthat even in well-tuned applications there is a noticeable gap (7 - 16%)between achieved and theoretical aggregate peak power usage at the clusterlevel (thousands of servers). The gap grows to almost 40% in wholedatacenters. This headroom can be used to deploy additional compute equipmentwithin the same power budget with minimal risk of exceeding it. We use ourmodeling framework to estimate the potential of power management schemes toreduce peak power and energy usage. We find that the opportunities for powerand energy savings are significant, but greater at the cluster-level (thousandsof servers) than at the rack-level (tens). Finally we argue that systems needto be power efficient across the activity range, and not only at peakperformance levels. Copyright 2007 ACM.","2007","2025-10-22 19:07:37","2025-10-22 19:07:37","","13-23","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Power modeling; Internet; Telecommunication services; Mathematical models; Warehouses; Power provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"FTYQ4NP7","journalArticle","2009","Li, H.; Zhang, Q.","Multiobjective optimization problems with complicated pareto sets, MOEA/ D and NSGA-II","IEEE Transactions on Evolutionary Computation","","","10.1109/TEVC.2008.925798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349108023&doi=10.1109%2fTEVC.2008.925798&partnerID=40&md5=13559bf89e121c518aa6b21723f19a3a","Partly due to lack of test problems, the impact of the Pareto set (PS) shapes on the performance of evolutionary algorithms has not yet attracted much attention. This paper introduces a general class of continuous multiobjective optimization test instances with arbitrary prescribed PS shapes, which could be used for studying the ability of multiobjective evolutionary algorithms for dealing with complicated PS shapes. It also proposes a new version of MOEA/D based on differential evolution (DE), i.e., MOEA/D-DE, and compares the proposed algorithm with NSGA-II with the same reproduction operators on the test instances introduced in this paper. The experimental results indicate that MOEA/D could significantly outperform NSGA-II on these test instances. It suggests that decomposition based multiobjective evolutionary algorithms are very promising in dealing with complicated PS shapes. © 2008 IEEE.","2009","2025-10-22 19:07:38","2025-10-22 19:07:38","","284-302","","2","13","","","","","","","","","","","","","Scopus","","","","","","","","Multiobjective optimization; Evolutionary algorithms; Testing; Differential evolution; Pareto principle; Aggregation; Decomposition; General class; Multi-objective evolutionary algorithms; Multi-objective optimization problems; Nsga-ii; Pareto optimality; Pareto sets; Reproduction operators; Shape optimization; Test instances; Test problems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MAJTZGCY","journalArticle","1999","Zitzler, E.; Thiele, L.","Multiobjective evolutionary algorithms: A comparative case study and the strength Pareto approach","IEEE Transactions on Evolutionary Computation","","","10.1109/4235.797969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033318858&doi=10.1109%2f4235.797969&partnerID=40&md5=beb167a6fd2d1daf7c4f1c7565a77000","Evolutionary algorithms (EA's) are often well-suited for optimization problems involving several, often conflicting objectives. Since 1985, various evolutionary approaches to multiobjective optimization have been developed that are capable of searching for multiple solutions concurrently in a single run. However, the few comparative studies of different methods presented up to now remain mostly qualitative and arc often restricted to a few approaches. In this paper, four multiobjective EA's are compared quantitatively where an extended 0/1 knapsack problem is taken as a basis. Furthermore, we introduce a new evolutionary approach to multicriteria optimization, the Strength Pareto EA (SPEA), that combines several features of previous multiobjective EA's in a unique manner. It is characterized by a) storing nondominated solutions externally in a second, continuously updated population, b) evaluating an individual's fitness dependent on the number of external nondominated points that dominate it, c) preserving population diversity using the Pareto dominance relationship, and d) incorporating a clustering procedure in order to reduce the nondominated set without destroying its characteristics. The proof-of-principle results obtained on two artificial problems as well as a larger problem, the synthesis of a digital hardware-software multiprocessor system, suggest that SPEA can be very effective in sampling from along the entire Pareto-optimal front and distributing the generated solutions over the tradeoff surface. Moreover, SPEA clearly outperforms the other four multiobjective EA's on the 0/1 knapsack problem. © 1999 IEEE.","1999","2025-10-22 19:07:38","2025-10-22 19:07:38","","257-271","","4","3","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Problem solving; Multiobjective optimization; Computer simulation; Genetic algorithms; Clustering; Sampling; Pareto optimality; Evolutionary algorithm; Interfaces (computer); Knapsack problem; Multiprocessing systems; Niching; Strength Pareto evolutionary algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRMVBBJS","journalArticle","2018","Liu, X.-F.; Zhan, Z.-H.; Deng, J.D.; Li, Y.; Gu, T.; Zhang, J.","An Energy Efficient Ant Colony System for Virtual Machine Placement in Cloud Computing","IEEE Transactions on Evolutionary Computation","","","10.1109/TEVC.2016.2623803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041323218&doi=10.1109%2fTEVC.2016.2623803&partnerID=40&md5=0bc23775671f54d3ee44222d97082fcd","Virtual machine placement (VMP) and energy efficiency are significant topics in cloud computing research. In this paper, evolutionary computing is applied to VMP to minimize the number of active physical servers, so as to schedule underutilized servers to save energy. Inspired by the promising performance of the ant colony system (ACS) algorithm for combinatorial problems, an ACS-based approach is developed to achieve the VMP goal. Coupled with order exchange and migration (OEM) local search techniques, the resultant algorithm is termed an OEMACS. It effectively minimizes the number of active servers used for the assignment of virtual machines (VMs) from a global optimization perspective through a novel strategy for pheromone deposition which guides the artificial ants toward promising solutions that group candidate VMs together. The OEMACS is applied to a variety of VMP problems with differing VM sizes in cloud environments of homogenous and heterogeneous servers. The results show that the OEMACS generally outperforms conventional heuristic and other evolutionary-based approaches, especially on VMP with bottleneck resource characteristics, and offers significant savings of energy and more efficient use of different resources. © 1997-2012 IEEE.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","113-128","","1","22","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Program compilers; cloud computing; Cloud computing; Distributed computer systems; Green computing; Virtual machine; Network security; Evolutionary algorithms; Virtual machine placements; Ant colony optimization; Ant colony system (ACS); Ant colony system algorithms; Ant colony systems; Bottleneck resources; Combinatorial problem; Evolutionary computing; Global optimization; Heterogeneous servers; Local search techniques; virtual machine placement (VMP)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BT98DWVR","journalArticle","1979","Garey, M.R.; Johnson, D.S.","","Computers and Intractability","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0004127488&partnerID=40&md5=7acaf2208249ba347c4a2ae88ddf1e3d","","1979","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KV9EYNKU","journalArticle","2012","Beloglazov, A.; Abawajy, J.; Buyya, R.","Energy-aware resource allocation heuristics for efficient management of data centers for Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2011.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370722&doi=10.1016%2fj.future.2011.04.017&partnerID=40&md5=404d8a6f96e7208ce49f7fb3ffc699cd","Cloud computing offers utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of electrical energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only minimize operational costs but also reduce the environmental impact. In this paper, we define an architectural framework and principles for energy-efficient Cloud computing. Based on this architecture, we present our vision, open research challenges, and resource provisioning and allocation algorithms for energy-efficient management of Cloud computing environments. The proposed energy-aware allocation heuristics provision data center resources to client applications in a way that improves energy efficiency of the data center, while delivering the negotiated Quality of Service (QoS). In particular, in this paper we conduct a survey of research in energy-efficient computing and propose: (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering QoS expectations and power usage characteristics of the devices; and (c) a number of open research challenges, addressing which can bring substantial benefits to both resource providers and consumers. We have validated our approach by conducting a performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant cost savings and demonstrates high potential for the improvement of energy efficiency under dynamic workload scenarios. © 2011 Elsevier B.V. All rights reserved.","2012","2025-10-22 19:07:38","2025-10-22 19:07:38","","755-768","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Energy efficient; Virtualizations; Energy aware; Resource allocation; Energy-efficient resource allocation; Computing environments; Research challenges; Data centers; Client applications; Computer systems; Performance evaluation; Cost saving; Dynamic consolidation; Allocation algorithm; Architectural frameworks; Architectural principles; Business domain; Carbon footprint; Computing solutions; Electrical energy; Environmental impact; Green IT; High potential; IT services; Operational costs; Pay-as-you-go; Pervasive applications; Power usage; Research; Resource providers; Resource provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XNNMGV76","conferencePaper","2010","Durillo, J.J.; García-Nieto, J.; Nebro, A.J.; Coello Coello, C.A.; Luna, F.; Alba, E.","Multi-objective particle swarm optimizers: An experimental comparison","","","","10.1007/978-3-642-01020-0_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650741651&doi=10.1007%2f978-3-642-01020-0_39&partnerID=40&md5=3eab3740d8b3622d9fc85b598a96864a","Particle Swarm Optimization (PSO) has received increasing attention in the optimization research community since its first appearance in the mid-1990s. Regarding multi-objective optimization, a considerable number of algorithms based on Multi-Objective Particle Swarm Optimizers (MOPSOs) can be found in the specialized literature. Unfortunately, no experimental comparisons have been made in order to clarify which MOPSO version shows the best performance. In this paper, we use a benchmark composed of three well-known problem families (ZDT, DTLZ, and WFG) with the aim of analyzing the search capabilities of six representative state-of-the-art MOPSOs, namely, NSPSO, SigmaMOPSO, OMOPSO, AMOPSO, MOPSOpd, and CLMOPSO. We additionally propose a new MOPSO algorithm, called SMPSO, characterized by including a velocity constraint mechanism, obtaining promising results where the rest perform inadequately. © Springer-Verlag 2009.","2010","2025-10-22 19:07:38","2025-10-22 19:07:38","","495-509","","","5467 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Multiobjective optimization; Experimental comparison; Research communities; Particle swarm optimization (PSO); Multi objective; Particle swarm optimization; Multi-objective optimization; Comparative studies; Particle swarm; Comparative study; Particle swarm optimizers; Search capabilities; Velocity constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"FHYHGNMS","journalArticle","2003","Elnozahy, M.; Kistler, M.; Rajamony, R.","Energy conservation policies for web servers","Energy Conservation Policies for Web Servers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-1142307038&partnerID=40&md5=66b186478711087a76c76266458c3b17","","2003","2025-10-22 19:07:38","2025-10-22 19:07:38","","99-112","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNN2BZ79","journalArticle","2002","Deb, K.; Pratap, A.; Agarwal, S.; Meyarivan, T.","A fast and elitist multiobjective genetic algorithm: NSGA-II","IEEE Transactions on Evolutionary Computation","","","10.1109/4235.996017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036530772&doi=10.1109%2f4235.996017&partnerID=40&md5=76831106ec37df04361f38a96f7c2508","Multiobjective evolutionary algorithms (EAs) that use nondominated sorting and sharing have been criticized mainly for their: 1) O(MN3) computational complexity (where M is the number of objectives and N is the population size); 2) nonelitism approach; and 3) the need for specifying a sharing parameter. In this paper, we suggest a nondominated sorting-based multiobjective EA (MOEA), called nondominated sorting genetic algorithm II (NSGA-II), which alleviates all the above three difficulties. Specifically, a fast nondominated sorting approach with O(MN2) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to Pareto-archived evolution strategy and strength-Pareto EA - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multiobjective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective seven-constraint nonlinear problem, are compared with another constrained multiobjective optimizer and much better performance of NSGA-II is observed.","2002","2025-10-22 19:07:38","2025-10-22 19:07:38","","182-197","","2","6","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Decision making; Computational complexity; Multiobjective optimization; Computer simulation; Genetic algorithms; Sorting; Constraint handling; Convergence of numerical methods; Elitism; Multicriterion decision making; Pareto-optimal solutions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"648QW6X5","journalArticle","1995","Beaulieu, N.C.; McLane, P.J.; Abu-Dayya, A.A.","Estimating the Distribution of a Sum of Independent Lognormal Random Variables","IEEE Transactions on Communications","","","10.1109/26.477480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029488390&doi=10.1109%2f26.477480&partnerID=40&md5=5a18e034feb2cc251075310bdf8a3208","Four methods that can be used to approximate the distribution function (DF) of a sum of independent lognormal random variables (RV's) are compared. The aim is to determine the best method to compute the DF considering both accuracy and computational effort. The investigation focuses on values of the dB spread, σ, valid for practical problems in wireless transmission (6 dB ≤ σ ≤ 12 dB). Contrary to some previous reports, our results show that the simpler Wilkinson's approach gives a more accurate estimate, in some cases of interest, than Schwartz and Yeh's approach. © 1995 IEEE","1995","2025-10-22 19:07:38","2025-10-22 19:07:38","","2869-2873","","12","43","","","","","","","","","","","","","Scopus","","","","","","","","Approximation theory; Computer simulation; Random processes; Estimation; Complementary density function; Computational methods; Farley approximation; Fourier transforms; Integration; Inverse Fourier transform; Mobile radio systems; Probability density function; Random variables","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G98R8TIH","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072518051&partnerID=40&md5=e46be198863af3cf8f4b61bb5b220d49","","","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2YNJQXM","journalArticle","2006","Reyes-Sierra, M.; Coello, C.A.C.","Multi-objective particle swarm optimizers: A survey of the state-of-the-art","International Journal of Computational Intelligence Research","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750267220&partnerID=40&md5=1a0128ddf932b774736624118a50213e","","2006","2025-10-22 19:07:38","2025-10-22 19:07:38","","287-308","","3","2","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7UKE6K7H","journalArticle","2015","Zhan, Z.-H.; Liu, X.-F.; Gong, Y.-J.; Zhang, J.; Chung, H.S.-H.; Li, Y.","Cloud computing resource scheduling and a survey of its evolutionary approaches","ACM Computing Surveys","","","10.1145/2788397","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939803867&doi=10.1145%2f2788397&partnerID=40&md5=51dd07826ce6c544fd26df28f90068de","A disruptive technology fundamentally transforming the way that computing services are delivered, cloud computing offers information and communication technology users a new dimension of convenience of resources, as services via the Internet. Because cloud provides a finite pool of virtualized on-demand resources, optimally scheduling them has become an essential and rewarding topic, where a trend of using Evolutionary Computation (EC) algorithms is emerging rapidly. Through analyzing the cloud computing architecture, this survey first presents taxonomy at two levels of scheduling cloud resources. It then paints a landscape of the scheduling problem and solutions. According to the taxonomy, a comprehensive survey of state-of-the-art approaches is presented systematically. Looking forward, challenges and potential future research directions are investigated and invited, including real-time scheduling, adaptive dynamic scheduling, large-scale scheduling, multiobjective scheduling, and distributed and parallel scheduling. At the dawn of Industry 4.0, cloud computing scheduling for cyber-physical integration with the presence of big data is also discussed. Research in this area is only in its infancy, but with the rapid fusion of information and data technology, more exciting and agenda-setting topics are likely to emerge on the horizon.","2015","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","4","47","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Big data; Cloud computing; Cloud-computing; Computer architecture; Surveys; Information and Communication Technologies; Computing resource; Genetic algorithms; Computing services; Genetic algorithm; Resource scheduling; Resource-scheduling; Ant colony optimization; Particle swarm optimization (PSO); Particle swarm optimization; Disruptive technology; Evolutionary approach; Evolutionary Computation; Particle swarm; Swarm optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SFUM6REF","journalArticle","2004","Marler, R.T.; Arora, J.S.","Survey of multi-objective optimization methods for engineering","Structural and Multidisciplinary Optimization","","","10.1007/s00158-003-0368-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-2442535151&doi=10.1007%2fs00158-003-0368-6&partnerID=40&md5=4139f4adec0a24676ea2d2762299e751","A survey of current continuous nonlinear multi-objective optimization (MOO) concepts and methods is presented. It consolidates and relates seemingly different terminology and methods. The methods are divided into three major categories: methods with a priori articulation of preferences, methods with a posteriori articulation of preferences, and methods with no articulation of preferences. Genetic algorithms are surveyed as well. Commentary is provided on three fronts, concerning the advantages and pitfalls of individual methods, the different classes of methods, and the field of MOO as a whole. The Characteristics of the most significant methods are summarized. Conclusions are drawn that reflect often-neglected ideas and applicability to engineering problems. It is found that no single approach is superior. Rather, the selection of a specific method depends on the type of information that is provided in the problem, the user's preferences, the solution requirements, and the availability of software.","2004","2025-10-22 19:07:38","2025-10-22 19:07:38","","369-395","","6","26","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Computer software; Problem solving; Vectors; Genetic algorithms; Engineering; Design variables; Functions; Multi-criteria; Multi-objective; Nonlinear systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRNIINKK","journalArticle","2016","Fazio, M.; Celesti, A.; Ranjan, R.; Liu, C.; Chen, L.; Villari, M.","Open Issues in Scheduling Microservices in the Cloud","IEEE Cloud Computing","","","10.1109/MCC.2016.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996569901&doi=10.1109%2fMCC.2016.112&partnerID=40&md5=d52198bb1cc22e10b6f9e5e3d6df7c95","The adoption of container-based microservices architectures is revolutionizing application design. By adopting a microservices architecture, developers can engineer applications that are composed of multiple lightweight, self-contained, and portable runtime components deployed across a large number of geodistributed servers. © 2016 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","81-88","","5","3","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Cloud computing; microservices; Internet of things; Cloud systems; Runtimes; Software developer; Distributed applications; Application architecture; Application design; Cloud computing architecture; Federated clouds; Independent components; Service deployment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNP9VA6J","conferencePaper","2019","Samanta, A.; Jiao, L.; Muhlhauser, M.; Wang, L.","Incentivizing microservices for online resource sharing in edge clouds","","","","10.1109/ICDCS.2019.00049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072527786&doi=10.1109%2fICDCS.2019.00049&partnerID=40&md5=e42ef8d1c52446da52f38488cb2fb389","The microservice architecture provides high agility, making it a suitable choice for implementing edge cloud services. Provisioning microservices at the network edge requires the dynamic allocation of resources. However, due to the resource limitation in the edge cloud environment, there is no guarantee that enough resources are always available upon a microservice's requests. In this paper, we design an online auction-based mechanism to incentivize microservices to spare their occupied resources so that the edge cloud platform can reclaim them and reallocate them to other microservices that need resources. We firstly design a single-stage auction that determines the winning bids to satisfy the resource demands in polynomial time, while calculating the payments. Then, we design an online framework to tie a series of such single-stage auctions into a multi-stage online mechanism without requiring the knowledge of future bids and demands. Via rigorous analysis, we exhibit that our mechanism design achieves truthful bidding and individual rationality, with a constant competitive ratio regarding the social cost of the system in the long run. Finally, we verify the practical performance of our mechanism through extensive simulations. © 2019 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","420-430","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Distributed computer systems; Edge computing; Extensive simulations; Resource sharing; On-line algorithms; Polynomial approximation; Resource limitations; Competitive ratio; Dynamic allocations; Individual rationality; Machine design; Online algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Distributed Computing Systems","","","","","","","","","","","","","","",""
"YSWE6JSA","journalArticle","2003","Zitzler, E.; Thiele, L.; Laumanns, M.; Fonseca, C.M.; Da Fonseca, V.G.","Performance assessment of multiobjective optimizers: An analysis and review","IEEE Transactions on Evolutionary Computation","","","10.1109/TEVC.2003.810758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037936618&doi=10.1109%2fTEVC.2003.810758&partnerID=40&md5=16bb83388676a0ce9d36a3e3455cc5e1","An important issue in multiobjective optimization is the quantitative comparison of the performance of different algorithms. In the case of multiobjective evolutionary algorithms, the outcome is usually an approximation of the Pareto-optimal set, which is denoted as an approximation set, and therefore the question arises of how to evaluate the quality of approximation sets. Most popular are methods that assign each approximation set a vector of real numbers that reflect different aspects of the quality. Sometimes, pairs of approximation sets are considered too. In this study, we provide a rigorous analysis of the limitations underlying this type of quality assessment. To this end, a mathematical frame-work is developed which allows to classify and discuss existing techniques.","2003","2025-10-22 19:07:38","2025-10-22 19:07:38","","117-132","","2","7","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Vectors; Multiobjective optimization; Approximation theory; Evolutionary algorithms; Pareto principle; Multiobjective optimizers; Performance assessment; Quality indicator","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDGP6KZE","conferencePaper","2017","Panda, A.; Sagiv, M.; Shenker, S.","Verification in the Age of Microservices","","","","10.1145/3102980.3102986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028014958&doi=10.1145%2f3102980.3102986&partnerID=40&md5=2c48a4d4ee3c6bb7b997ad2cf5632346","Many large applications are now built using collections of microservices, each of which is deployed in isolated containers and which interact with each other through the use of remote procedure calls (RPCs). The use of microservices improves scalability - each component of an application can be scaled independently - and deployability. However, such applications are inherently distributed and current tools do not provide mechanisms to reason about and ensure their global behavior. In this paper we argue that recent advances in formal methods and software packet processing pave the path towards building mechanisms that can ensure correctness for such systems, both when they are being built and at runtime. These techniques impose minimal runtime overheads and are amenable to production deployments. © 2017 ACM.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","30-36","","","Part F129307","","","","","","","","","","","","","Scopus","","","","","","","","Runtimes; Formal verification; Packet processing; Formal methods; Deployability; Global behaviors; Remote Procedure Call; Runtime overheads","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Workshop on Hot Topics in Operating Systems - HOTOS","","","","","","","","","","","","","","",""
"UQYQTTRD","journalArticle","1956","Burke, P.J.","The output of a queueing system","Operations Research","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001104312&partnerID=40&md5=2791e2c21cdc2e9d0a46397d0b298e2b","","1956","2025-10-22 19:07:38","2025-10-22 19:07:38","","699-704","","6","4","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UB83AMNY","journalArticle","2012","Khazaei, H.; Misic, J.; Misic, V.B.","Performance analysis of cloud computing centers using M/G/m/m+r queuing systems","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2011.199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859728505&doi=10.1109%2fTPDS.2011.199&partnerID=40&md5=ee9314987ea6955752696748ee0a917b","Successful development of cloud computing paradigm necessitates accurate performance evaluation of cloud data centers. As exact modeling of cloud centers is not feasible due to the nature of cloud centers and diversity of user requests, we describe a novel approximate analytical model for performance evaluation of cloud server farms and solve it to obtain accurate estimation of the complete probability distribution of the request response time and other important performance indicators. The model allows cloud operators to determine the relationship between the number of servers and input buffer size, on one side, and the performance indicators such as mean number of tasks in the system, blocking probability, and probability that a task will obtain immediate service, on the other. © 1990-2012 IEEE.","2012","2025-10-22 19:07:38","2025-10-22 19:07:38","","936-943","","5","23","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Cloud computing; Benchmarking; Performance evaluation; Markov processes; Computing paradigm; Response time (computer systems); response time; performance analysis; Queueing theory; queuing theory; Queuing theory; Computing center; Accurate estimation; Accurate performance; Blocking probability; Cloud data; Embedded Markov chain; embedded Markov chain.; Input buffers; Performance indicators; Probability distributions; Queuing systems; Semi markov process; semi-Markov process; Server farms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQ7MFXMD","conferencePaper","2018","Niu, Y.; Liu, F.; Li, Z.","Load Balancing Across Microservices","","","","10.1109/INFOCOM.2018.8486300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056174602&doi=10.1109%2fINFOCOM.2018.8486300&partnerID=40&md5=e6e54404d28ef87f04bcb09227fe99d0","With the advent of cloud container technology, enterprises develop applications through microservices, breaking monolithic software into a suite of small services whose instances run independently in containers. User requests are served by a series of microservices forming a chain, and the chains often share microservices. Existing load balancing strategies either incur significant networking overhead or ignore the competition for shared microservices across chains. Furthermore, typical load balancing solutions leverage a hybrid technique by combining HTTP with message queue to support microservice communications, bringing additional operational complexity. To address these challenges, we propose a chain-oriented load balancing algorithm (COLBA) based solely on message queues, which balances load based on microservice requirements of chains to minimize response time. We model the load balancing problem as a non-cooperative game, and leverage Nash bargaining to coordinate microservice allocation across chains. Employing convex optimization with rounding, we efficiently solve the problem that is proven NP-hard. Extensive trace-driven simulations demonstrate that COLBA reduces the overall average response time at least by 13% compared with existing load balancing strategies. © 2018 IEEE.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","198-206","","","2018-April","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Distributed computer systems; Game theory; Chains; Convex optimization; Hybrid techniques; Load balancing algorithms; Load balancing problem; Load balancing strategy; Nash bargaining; Noncooperative game; Operational complexity; Trace driven simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"XJYNQ36E","journalArticle","2017","Kulkarni, S.G.; Zhang, W.; Hwang, J.; Rajagopalan, S.; Ramakrishnan, K.; Wood, T.; Arumaithurai, M.; Fu, X.","NFVnice: Dynamic backpressure and scheduling for NFV service chains","ACM SIGCOMM","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060312991&partnerID=40&md5=192802b7d0fa098b515d2e1b88250d0b","","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","71-84","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DYMY68QU","journalArticle","1991","Medhi, J.","","Stochastic Models in Queueing Theory","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003686773&partnerID=40&md5=cc06e1d1814c07bf039459403e4e678e","","1991","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GGRTZCSX","journalArticle","2015","Akamai, A.","Online holiday shopping trends and traffic report for Europe and North America","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072519220&partnerID=40&md5=3583a8c0a72d2784008b08e5507794af","","2015","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2EXEKIW","conferencePaper","2015","Morabito, R.","Power Consumption of Virtualization Technologies: An Empirical Investigation","","","","10.1109/UCC.2015.93","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965029470&doi=10.1109%2fUCC.2015.93&partnerID=40&md5=8ec180bb7aeb56b6224c763c30a61187","Virtualization is growing rapidly as a result of the increasing number of alternative solutions in this area, and of the wide range of application field. Until now, hypervisor-based virtualization has been the de facto solution to perform server virtualization. Recently, container-based virtualization - an alternative to hypervisors - has gained more attention because of lightweight characteristics, attracting cloud providers that have already made use of it to deliver their services. However, a gap in the existing research on containers exists in the area of power consumption. This paper presents the results of a performance comparison in terms of power consumption of four different virtualization technologies: KVM and Xen, which are based on hypervisor virtualization, Docker and LXC which are based on container virtualization. The aim of this empirical investigation, carried out by means of a testbed, is to understand how these technologies react to particular workloads. Our initial results show how, despite of the number of virtual entities running, both kinds of virtualization alternatives behave similarly in idle state and in CPU/Memory stress test. Contrarily, the results on network performance show differences between the two technologies. © 2015 IEEE.","2015","2025-10-22 19:07:38","2025-10-22 19:07:38","","522-527","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Hypervisor; Containers; Docker; Cloud computing; Performance; Virtual reality; Cloud Computing; Virtualizations; Alternative solutions; virtualization; power consumption; Virtualization technologies; container; hypervisor; Empirical investigation; KVM; LXC; Performance comparison; Xen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing, UCC 2015","","","","","","","","","","","","","","",""
"4597JNVU","conferencePaper","2019","Yu, R.; Kilari, V.T.; Xue, G.; Yang, D.","Load Balancing for Interdependent IoT Microservices","","","","10.1109/INFOCOM.2019.8737450","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068225941&doi=10.1109%2fINFOCOM.2019.8737450&partnerID=40&md5=a2e0c52954d55f6b18b76371219b3245","Advances in virtualization technologies and edge computing have inspired a new paradigm for Internet-of-Things (IoT) application development. By breaking a monolithic application into loosely coupled microservices, great gain can be achieved in performance, flexibility and robustness. In this paper, we study the important problem of load balancing across IoT microservice instances. A key difficulty in this problem is the interdependencies among microservices: the load on a successor microservice instance directly depends on the load distributed from its predecessor microservice instances. We propose a graph-based model for describing the load dependencies among microservices. Based on the model, we first propose a basic formulation for load balancing, which can be solved optimally in polynomial time. The basic model neglects the quality-of-service (QoS) of the IoT application. We then propose a QoS-aware load balancing model, based on a novel abstraction that captures a realization of the application's internal logic. The QoS-aware load balancing problem is NP-hard. We propose a fully polynomial-time approximation scheme for the QoS-aware problem. We show through simulation experiments that our proposed algorithm achieves enhanced QoS compared to heuristic solutions. © 2019 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","298-306","","","2019-April","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Internet of things; Internet of Things (IOT); Computation theory; Resource allocation; Graphic methods; Load balancing problem; IoT; Virtualization technologies; microservice; Polynomial approximation; load balancing; Application development; application graph; Fully polynomial time approximation schemes; fully polynomial-time approximation scheme; Graph-based modeling; Load balancing models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"Y3ESJJV2","journalArticle","2005","Barabási, A.-L.","The origin of bursts and heavy tails in human dynamics","Nature","","","10.1038/nature03459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-18744406314&doi=10.1038%2fnature03459&partnerID=40&md5=ea851126856920836209855834ef27ff","The dynamics of many social, technological and economic phenomena are driven by individual human actions, turning the quantitative understanding of human behaviour into a central question of modern science. Current models of human dynamics, used from risk assessment to communications, assume that human actions are randomly distributed in time and thus well approximated by Poisson processes. In contrast, there is increasing evidence that the timing of many human activities, ranging from communication to entertainment and work patterns, follow non-Poisson statistics, characterized by bursts of rapidly occurring events separated by long periods of inactivity. Here I show that the bursty nature of human behaviour is a consequence of a decision-based queuing process: when individuals execute tasks based on some perceived priority, the timing of the tasks will be heavy tailed, with most tasks being rapidly executed, whereas a few experience very long waiting times. In contrast, random or priority blind execution is well approximated by uniform inter-event statistics. These finding have important implications, ranging from resource management to service allocation, in both communications and retail.","2005","2025-10-22 19:07:38","2025-10-22 19:07:38","","207-211","","7039","435","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; resource management; Internet; Economic and social effects; Communication; Commerce; article; biological model; physiology; time; Time Factors; Approximation theory; Risk assessment; human; priority journal; resource allocation; model; Statistics; Humans; Resource Allocation; statistics; Technology; behavior; Behavior; commercial phenomena; daily life activity; decision making; Decision Making; dynamics; human activities; Human Activities; Human behavior; Human dynamics; Human engineering; innovation; interpersonal communication; Models, Biological; Models, Statistical; Modern science; Poisson distribution; Poisson Distribution; psychological aspect; Random Allocation; randomization; risk assessment; Risk Assessment; science; science and technology; statistical model; task performance; Work patterns","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SRKPMM5W","conferencePaper","2009","Nebro, A.J.; Durillo, J.J.; Nieto, G.; Coello, C.A.C.; Luna, F.; Alba, E.","SMPSO: A new pso-based metaheuristic for multi-objective optimization","","","","10.1109/MCDM.2009.4938830","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650565595&doi=10.1109%2fMCDM.2009.4938830&partnerID=40&md5=d4ae1703c5ac2dd82a52e83189cec23c","In this work, we present a new multi-objective particle swarm optimization algorithm (PSO) characterized by the use of a strategy to limit the velocity of the particles. The proposed approach, called Speed-constrained Multi-objective PSO (SMPSO) allows to produce new effective particle positions in those cases in which the velocity becomes too high. Other features of SMPSO include the use of polynomial mutation as a turbulence factor and an external archive to store the nondominated solutions found during the search. Our proposed approach is compared with respect to five multi-objective metaheuristics representative of the state-of-the-art in the area. For the comparison, two different criteria are adopted: the quality of the resulting approximation sets and the convergence speed to the Pareto front. The experiments carried out indicate that SMPSO obtains remarkable results in terms of both, accuracy and speed. ©2009 IEEE.","2009","2025-10-22 19:07:38","2025-10-22 19:07:38","","66-73","","","","","","","","","","","","","","","","Scopus","","","","","","","","Decision making; Artificial intelligence; Multiobjective optimization; Metaheuristic; Particle swarm optimization (PSO); Multi objective; Approximation set; Convergence speed; Multi objective particle swarm optimization; Multi-objective metaheuristics; Nondominated solutions; Pareto front; Particle position; Polynomial mutation; Turbulence factor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2009 IEEE Symposium on Computational Intelligence in Multi-Criteria Decision-Making, MCDM 2009 - Proceedings","","","","","","","","","","","","","","",""
"D56Q5Z8Y","conferencePaper","2017","Li, S.; Guo, Z.; Shou, G.; Hu, Y.; Li, H.","QoE analysis of NFV-based mobile edge computing video application","","","","10.1109/ICNIDC.2016.7974607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027520812&doi=10.1109%2fICNIDC.2016.7974607&partnerID=40&md5=271821a67276b14597ba2d481d78cade","Mobile Edge Computing (MEC) provides mobile and cloud computing capabilities within the access network. Network Functions Virtualization (NFV) leverages standard IT Virtualization technology to decouple the network functions from the underlying physical infrastructure. Basing on the ICT demand, MEC can be consolidated into NFV, as a network element within access network. This paper presents an architecture of NFV-based MEC platform and analyzes its Quality of Service (QoS) compared with the remote servers (Shenzhen and Qingdao). Then, this paper measures the Quality of Experience (QoE) of HTTP videos deployed in the servers. The result shows MEC can offer a service environment with higher bandwidth, which supports 10-fold gains, and ultra-low latency, jitter and packet loss rate. Moreover, along with the higher resolution and bitrates, the range of the video QoE improvement on this platform rises compared with the remote servers. In a word, the NFV-based MEC can achieve better performance than the remote servers. © 2016 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","411-415","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Virtual reality; Virtualization; Distributed computer systems; Network functions; Transfer functions; Network function virtualization; NFV; Virtualization technologies; Quality of experience (QoE); MEC; 5G and future network; Digital integrated circuits; Future networks; Higher resolution; Packet loss rates; QoE; Service environment; Video applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of 2016 5th International Conference on Network Infrastructure and Digital Content, IEEE IC-NIDC 2016","","","","","","","","","","","","","","",""
"X66WDY94","conferencePaper","2018","Yala, L.; Frangoudis, P.A.; Ksentini, A.","Latency and Availability Driven VNF Placement in a MEC-NFV Environment","","","","10.1109/GLOCOM.2018.8647858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063445904&doi=10.1109%2fGLOCOM.2018.8647858&partnerID=40&md5=1a2fd5c229e4fd75bb1bb15a4bbcd7d9","Multi-access Edge Computing (MEC) is gaining momentum as it is considered as one of the enablers of 5G ultra-Reliable Low-Latency Communications (uRLLC) services. MEC deploys computation resources close to the end user, enabling to reduce drastically the end-to-end latency. ETSI has recently leveraged the MEC architecture to run all MEC entities, including MEC applications, as Virtual Network Functions (VNF) in a Network Functions Virtualization (NFV) environment. This evolution allows taking advantage of the mature architecture and the enabling tools of NFV, including the potential to apply a variety of service-tailored function placement algorithms. However, the latter need to be carefully designed in case of MEC applications such as uRLLC, where service access latency is critical. In this paper, we propose a novel placement scheme applicable to a MEC in NFV environment. In particular, we propose a formulation of the problem of VNF placement tailored to uRLLC as an optimization problem of two conflicting objectives, namely minimizing access latency and maximizing service availability. To deal with the complexity of the problem, we propose a Genetic Algorithm to solve it, which we compare with a CPLEX implementation of our model. Our numerical results show that our heuristic algorithm runs efficiently and produces solutions that approximate well the optimal, reducing latency and providing a highly-available service. © 2018 IEEE.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Virtual networks; Network functions; 5G mobile communication systems; Transfer functions; Heuristic algorithms; Multiaccess; Network function virtualization; Computing applications; Genetic algorithms; Availability; Computation resources; Low-latency communication; Communication service; Access latency; Gaining momentum","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Global Communications Conference, GLOBECOM","","","","","","","","","","","","","","",""
"IQBYIHSD","conferencePaper","2016","Zhang, W.; Liu, G.; Zhang, W.; Shah, N.; Lopreiato, P.; Todeschi, G.; Ramakrishnan, K.K.; Wood, T.","OpenNetVM: Flexible, high performance NFV (Demo)","","","","10.1109/LANMAN.2016.7548875","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987771001&doi=10.1109%2fLANMAN.2016.7548875&partnerID=40&md5=871b8347af77397fd4bae929fb87c014","Network Function Virtualization promises to enable dynamic management of software-based network functions. We envision a dynamic and flexible network that can support a smarter data plane than just simple switches that forward packets. This network architecture supports complex stateful rourtng of flows where processing by network functions (NFs) can transform packet data, customized on a per-flow basis, as it moves between end points. This demo will present OpenNetVM, a highly efficient packet processing framework that greatly simplifies the development of network functions, as well as their management and optimization. OpenNetVM runs network functions in lightweight Docker containers that start in less than a second. The OpenNetVM platform manager provides load balancing, flexible flow management, and service name abstractions. OpenNetVM uses DPDK for high performance I/O, and efficiently routes packets through dynamically created service chains. We will demonstrate how the research community can easily build new network functions and rapidly deploy them to see their effectiveness in high performance network environments. © 2016 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","2016-August","","","","","","","","","","","","","Scopus","","","","","","","","Virtualizations; Network architecture; Network functions; Transfer functions; Packet networks; Complex networks; Research communities; Network management; Dynamic management; Packet processing; Flexible networks; Forward packets; High performance networks; Metropolitan area networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE Workshop on Local and Metropolitan Area Networks","","","","","","","","","","","","","","",""
"XQ4RYGGF","journalArticle","2018","Cattaneo, G.; Giust, F.; Meani, C.; Munaretto, D.; Paglierani, P.","Deploying CPU-intensive applications on MEC in NFV systems: The immersive video use case","Computers","","","10.3390/computers7040055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059256376&doi=10.3390%2fcomputers7040055&partnerID=40&md5=8c47d4cc30ba044b2744a9139ae336d9","Multi-access Edge Computing (MEC) will be a technology pillar of forthcoming 5G networks. Nonetheless, there is a great interest in also deploying MEC solutions in current 4G infrastructures. MEC enables data processing in proximity to end users. Thus, latency can be minimized, high data rates locally achieved, and real-time information about radio link status or consumer geographical position exploited to develop high-value services. To consolidate network elements and edge applications on the same virtualization infrastructure, network operators aim to combine MEC with Network Function Virtualization (NFV). However, MEC in NFV integration is not fully established yet: in fact, various architectural issues are currently open, even at standardization level. This paper describes a novel MEC in an NFV system which successfully combines, at management level, MEC functional blocks with an NFV Orchestrator, and can neutrally support any “over the top” Mobile Edge application with minimal integration effort. A specific ME app combined with an end-user app for the provision of immersive video services is presented. To provide low latency, CPU-intensive services to end users, the proposed architecture exploits High-Performance Computing resources embedded in the edge infrastructure. Experimental results showing the effectiveness of the proposed architecture are reported and discussed. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","4","7","","","","","","","","","","","","","Scopus","","","","","","","","Virtualization; Video processing; Network function virtualization; Orchestration; Multi-access edge computing; Immersive video","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSJUZVP5","journalArticle","2019","Li, L.; Ota, K.; Dong, M.","DeepNFV: A Lightweight Framework for Intelligent Edge Network Functions Virtualization","IEEE Network","","","10.1109/MNET.2018.1700394","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045631978&doi=10.1109%2fMNET.2018.1700394&partnerID=40&md5=23023759988cd6f7f02e921bcc8b16b1","Traditional Network Functions Virtualization (NFV) implementations are somehow too heavy and do not have enough functionality to conduct complex tasks. In this work, we propose a lightweight NFV framework named DeepNFV, which is based on the Docker container running on the network edge, and integrates state-of-the-art deep learning models with NFV containers to address some complicated problems, such as traffic classification, link analysis, and so on. We compare the DeepNFV framework with several existing works, and detail its structures and functions. The most significant advantage of DeepNFV is its lightweight design, resulting from the virtualization and low-cost nature of the container technology. Also, we design this framework to be compatible with edge devices, in order to decrease the computational overhead of the central servers. Another merit is its strong analysis ability brought by deep learning models, which make it suitable for many more scenarios than traditional NFV approaches. In addition, we also describe some typical application scenarios, regarding how the NFV container works and how to utilize its learning ability. Simulations demonstrate its high efficiency, as well as the outstanding recognition performance in a typical use case. © 1986-2012 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","136-141","","1","33","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Containers; Deep learning; Virtual reality; Virtualization; Edge computing; Docker containers; Servers; Network functions; Transfer functions; Network function virtualization; Learning systems; Telecommunication traffic; Computational model; Computational overheads; Learning abilities; Lightweight design; Traffic classification; Typical application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PV2SZZ8","journalArticle","2017","Mehmood, Y.; Ahmad, F.; Yaqoob, I.; Adnane, A.; Imran, M.; Guizani, S.","Internet-of-Things-Based Smart Cities: Recent Advances and Challenges","IEEE Communications Magazine","","","10.1109/MCOM.2017.1600514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029576329&doi=10.1109%2fMCOM.2017.1600514&partnerID=40&md5=1cfda6ec9fa8b431bba04b5b29883f1d","The Internet of Things is a novel cutting edge technology that proffers to connect a plethora of digital devices endowed with several sensing, actuation, and computing capabilities with the Internet, thus offering manifold new services in the context of a smart city. The appealing IoT services and big data analytics are enabling smart city initiatives all over the world. These services are transforming cities by improving infrastructure and transportation systems, reducing traffic congestion, providing waste management, and improving the quality of human life. In this article, we devise a taxonomy to best bring forth a generic overview of the IoT paradigm for smart cities, integrated ICT, network types, possible opportunities and major requirements. Moreover, an overview of the up-to-date efforts from standard bodies is presented. Later, we give an overview of existing open source IoT platforms for realizing smart city applications followed by several exemplary case studies. In addition, we summarize the latest synergies and initiatives worldwide taken to promote IoT in the context of smart cities. Finally, we highlight several challenges in order to give future research directions. © 1979-2012 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","16-24","","9","55","","","","","","","","","","","","","Scopus","","","","","","","","Big data; Internet of things; Smart city; Computing capability; Transportation system; Traffic congestion; Open sources; Digital devices; Cutting edge technology; Future research directions; Data analytics; Network types; Standard bodies; Waste management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAYMH4DN","journalArticle","2019","","","OpenNebula: Open Source Vcloud","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092693991&partnerID=40&md5=b9a0e50dc3ed8048bd13cdd55b6ec6e4","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDD2XVA9","conferencePaper","2007","Bogdanov, A.; Knudsen, L.R.; Leander, G.; Paar, C.; Poschmann, A.; Robshaw, M.J.B.; Seurin, Y.; Vikkelsoe, C.","PRESENT: An ultra-lightweight block cipher","","","","10.1007/978-3-540-74735-2_31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37149045263&doi=10.1007%2f978-3-540-74735-2_31&partnerID=40&md5=1df6f4bab163b6946899acf504a32822","With the establishment of the AES the need for new block ciphers has been greatly diminished; for almost all block cipher applications the AES is an excellent and preferred choice. However, despite recent implementation advances, the AES is not suitable for extremely constrained environments such as RFID tags and sensor networks. In this paper we describe an ultra-lightweight block cipher, PRESENT. Both security and hardware efficiency have been equally important during the design of the cipher and at 1570 GE, the hardware requirements for PRESENT are competitive with today's leading compact stream ciphers. © Springer-Verlag Berlin Heidelberg 2007.","2007","2025-10-22 19:07:38","2025-10-22 19:07:38","","450-466","","","4727 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Systems analysis; Security systems; Cryptography; Sensor networks; Cipher applications; Lightweight block cipher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"WZ47QT4J","journalArticle","2017","Blanco, B.; Fajardo, J.O.; Giannoulakis, I.; Kafetzakis, E.; Peng, S.; Pérez-Romero, J.; Trajkovska, I.; Khodashenas, P.S.; Goratti, L.; Paolino, M.; Sfakianakis, E.; Liberal, F.; Xilouris, G.","Technology pillars in the architecture of future 5G mobile networks: NFV, MEC and SDN","Computer Standards and Interfaces","","","10.1016/j.csi.2016.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009468168&doi=10.1016%2fj.csi.2016.12.007&partnerID=40&md5=0e437a6434c1ae84d9b0203d5b64250d","This paper analyzes current standardization situation of 5G and the role network softwarization plays in order to address the challenges the new generation of mobile networks must face. This paper surveys recent documentation from the main stakeholders to pick out the use cases, scenarios and emerging vertical sectors that will be enabled by 5G technologies, and to identify future high-level service requirements. Driven by those service requirements 5G systems will support diverse radio access technology scenarios, meet end-to-end user experienced requirements and provide capability of flexible network deployment and efficient operations. Then, based on the identified requirements, the paper overviews the main 5G technology trends and design principles to address them. In particular, the paper emphasizes the role played by three main technologies, namely SDN, NFV and MEC, and analyzes the main open issues of these technologies in relation to 5G. © 2017 Elsevier B.V.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","216-228","","","54","","","","","","","","","","","","","Scopus","","","","","","","","Mobile telecommunication systems; Standardization; Wireless networks; NFV; End to end; SDN; 5G; Design Principles; MEC; Technology trends; Service requirements; Flexible networks; High-level services; Paper surveys; Radio access technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJ8RWEAM","journalArticle","2012","","","NetFPGA-10G Specifications","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092727897&partnerID=40&md5=40bcf615c411a3c9a8296384c2ba9643","","2012","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDUYEFF9","conferencePaper","2017","Adzic, G.; Chatley, R.","Serverless computing: economic and architectural impact","","","","10.1145/3106237.3117767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133872008&doi=10.1145%2f3106237.3117767&partnerID=40&md5=798a97d62635bfdaba6437601b4fa867","Amazon Web Services unveiled their ""Lambda""platform in late 2014. Since then, each of the major cloud computing infrastructure providers has released services supporting a similar style of deployment and operation, where rather than deploying and running monolithic services, or dedicated virtual machines, users are able to deploy individual functions, and pay only for the time that their code is actually executing. These technologies are gathered together under the marketing term ""serverless""and the providers suggest that they have the potential to significantly change how client/server applications are designed, developed and operated. This paper presents two case industrial studies of early adopters, showing how migrating an application to the Lambda deployment architecture reduced hosting costs-by between 66% and 95%-and discusses how further adoption of this trend might influence common software architecture design practices.  © 2017 ACM.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","884-889","","","2017-January","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Cloud computing; Cloud-computing; Cloud Computing; Serverless; Web services; Amazon web services; Economics; Lambda's; Monolithics; Infrastructure providers; Client/server application; Cloud computing infrastructures; Deployment architecture; Service supporting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering","","","","","","","","","","","","","","",""
"DSRYGIUY","journalArticle","2021","Xu, Z.; Gong, W.; Xia, Q.; Liang, W.; Rana, O.F.; Wu, G.","NFV-Enabled IoT Service Provisioning in Mobile Edge Clouds","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2020.2972530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103960860&doi=10.1109%2fTMC.2020.2972530&partnerID=40&md5=d26f8f4d8b924c9ae27b8400824dc8f1","Conventional Internet of Things (IoT) applications involve data capture from various sensors in environments, and the captured data then is processed in remote clouds. However, some critical IoT applications (e.g., autonomous vehicles) require a much lower response latency and more secure guarantees than those offered by remote clouds today. Mobile edge clouds (MEC) supported by the network function virtualization (NFV) technique have been envisioned as an ideal platform for supporting such IoT applications. Specifically, MECs enable to handle IoT applications in edge networks to shorten network latency, and NFV enables agile and low-cost network functions to run in low-cost commodity servers as virtual machines (VMs). One fundamental problem for the provisioning of IoT applications in an NFV-enabled MEC is where to place virtualized network functions (VNFs) for IoT applications in the MEC, such that the operational cost of provisioning IoT applications is minimized. In this paper, we first address this fundamental problem, by considering a special case of the IoT application placement problem, where the IoT application and VNFs of each service request are consolidated into a single location (gateway or cloudlet), for which we propose an exact solution and an approximation algorithm with a provable approximation ratio. We then develop a heuristic algorithm that controls the resource violation ratios of edge clouds in the network. For the IoT application placement problem for IoT applications where their VNFs can be placed to multiple locations, we propose an efficient heuristic that jointly places the IoT application and its VNFs. We finally study the performance of the proposed algorithms by simulations and implementations in a real test-bed, Experimental results show that the performance of the proposed algorithms outperform their counterparts by at least 10 percent.  © 2002-2012 IEEE.","2021","2025-10-22 19:07:38","2025-10-22 19:07:38","","1892-1906","","5","20","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Gateways (computer networks); Internet of Things (IOT); Network functions; Transfer functions; Heuristic algorithms; Network function virtualization; Costs; Approximation algorithms; Service requests; Network latencies; VNF placement; Approximation ratios; IOT applications; network function virtualization; algorithm design; approximation algorithms; Exact solution; Internet of Things (IoT) application; Mobile edge clouds; Single location","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W86CIZBJ","conferencePaper","2019","Dhakal, A.; Ramakrishnan, K.K.","Netml: An nfv platform with efficient support for machine learning applications","","","","10.1109/NETSOFT.2019.8806698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072010834&doi=10.1109%2fNETSOFT.2019.8806698&partnerID=40&md5=31489cc3433a2ac8f4adbcb19fa30a75","Real-Time applications such as autonomous and connected cars, surveillance, and online learning applications have to train on streaming data. They require low-latency, high throughput machine learning (ML) functions resident in the network and in the cloud to perform learning and inference. NFV on edge cloud platforms can provide support for these applications by having heterogeneous computing including GPUs and other accelerators to offload ML-related computation. GPUs provide the necessary speedup for performing learning and inference to meet the needs of these latency sensitive real-Time applications. Supporting ML inference and learning efficiently for streaming data in NFV platforms has several challenges. In this paper, we present a framework, NetML, that runs existing ML applications on an heterogeneous NFV platform that includes both CPUs and GPUs. NetML efficiently transfers the appropriate packet payload to the GPU, minimizing overheads, avoiding locks, and avoiding CPU-based data copies. Additionally, NetML minimizes latency by maximizing overlap between the data movement and GPU computation. We evaluate the efficiency of our approach for training and inference using popular object detection algorithms on our platform. NetML reduces the latency for inferring images by more than 20% and increases the training throughput by 30% while reducing CPU utilization compared to other state-of-The-Art alternatives. © 2019 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","396-404","","","","","","","","","","","","","","","","Scopus","","","","","","","","Program processors; State of the art; Heterogeneous computing; Network function virtualization; Real-time application; Machine learning; Inference engines; Machine learning applications; Object detection; CPU utilization; Object detection algorithms; Online learning; Training throughputs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2019 IEEE Conference on Network Softwarization: Unleashing the Power of Network Softwarization, NetSoft 2019","","","","","","","","","","","","","","",""
"C44ZS8N6","journalArticle","2013","Dinh, H.T.; Lee, C.; Niyato, D.; Wang, P.","A survey of mobile cloud computing: Architecture, applications, and approaches","Wireless Communications and Mobile Computing","","","10.1002/wcm.1203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888322916&doi=10.1002%2fwcm.1203&partnerID=40&md5=3c02ac47b24e8c9bfd9126167d40c94b","Together with an explosive growth of the mobile applications and emerging of cloud computing concept, mobile cloud computing (MCC) has been introduced to be a potential technology for mobile services. MCC integrates the cloud computing into the mobile environment and overcomes obstacles related to the performance (e.g., battery life, storage, and bandwidth), environment (e.g., heterogeneity, scalability, and availability), and security (e.g., reliability and privacy) discussed in mobile computing. This paper gives a survey of MCC, which helps general readers have an overview of the MCC including the definition, architecture, and applications. The issues, existing solutions, and approaches are presented. In addition, the future research directions of MCC are discussed. Copyright © 2011 John Wiley & Sons, Ltd.","2013","2025-10-22 19:07:38","2025-10-22 19:07:38","","1587-1611","","18","13","","","","","","","","","","","","","Scopus","","","","","","","","Surveys; Mobile applications; Mobile computing; Mobile cloud computing; Offloading; Mobile environments; Battery life; Future research directions; Explosive growth; Mobile service; Mobile services; Potential technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTA7JU8Z","journalArticle","2015","Hu, Y.C.; Patel, M.; Sabella, D.; Sprecher, N.; Young, V.","Mobile edge computing: A key technology towards 5G","Mobile Edge Computing-A Key Technology Towards 5G","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963757817&partnerID=40&md5=333635cdcabb534a28c501ea6b0e8ae9","","2015","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","11","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAZDQ65C","journalArticle","2019","","","Ring","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092712343&partnerID=40&md5=29e48261dfa16ff6ddda7221da5e13b0","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5DJCA9PE","journalArticle","2017","Nastic, S.; Rausch, T.; Scekic, O.; Dustdar, S.; Gusev, M.; Koteska, B.; Kostoska, M.; Jakimovski, B.; Ristov, S.; Prodan, R.","A serverless real-time data analytics platform for edge computing","IEEE Internet Computing","","","10.1109/MIC.2017.2911430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029365106&doi=10.1109%2fMIC.2017.2911430&partnerID=40&md5=9ec5bd564e219d20be5f7f495a7bf388","A novel approach implements cloud-supported, real-time data analytics in edge computing applications. The authors introduce their serverless edgedata analytics platform and application model and discuss their main design requirements and challenges, based on real-life healthcare use case scenarios. © 2017 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","64-71","","4","21","","","","","","","","","","","","","Scopus","","","","","","","","Internet; Edge computing; Application modeling; Real-time data; Use case scenario","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNN7V7Y9","journalArticle","2017","Ananthanarayanan, G.; Bahl, P.; Bodik, P.; Chintalapudi, K.; Philipose, M.; Ravindranath, L.; Sinha, S.","Real-Time Video Analytics: The Killer App for Edge Computing","Computer","","","10.1109/MC.2017.3641638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031670207&doi=10.1109%2fMC.2017.3641638&partnerID=40&md5=395ca02fefe64b7c91fd4acb62d9b615","Video analytics will drive a wide range of applications with great potential to impact society. A geographically distributed architecture of public clouds and edges that extend down to the cameras is the only feasible approach to meeting the strict real-time requirements of large-scale live video analytics. © 2017 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","58-67","","10","50","","","","","","","","","","","","","Scopus","","","","","","","","Computer science; Computers; Edge computing; Bandwidth; Real time videos; edge computing; bandwidth; latency; Real time; Camera network; camera networks; cameras; Cameras; intelligent edge; provisioning; real time; real-time video analytics; smart cameras; Smart cameras; video analytics; Video analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9QXL5G7","conferencePaper","2016","Yang, B.; Chai, W.K.; Pavlou, G.; Katsaros, K.V.","Seamless Support of Low Latency Mobile Applications with NFV-Enabled Mobile Edge-Cloud","","","","10.1109/CloudNet.2016.21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010685422&doi=10.1109%2fCloudNet.2016.21&partnerID=40&md5=fc8d1c0e614543d42b2fa4773f51d8d8","Emerging mobile multimedia applications, such as augmented reality, have stringent latency requirements and high computational cost. To address this, mobile edge-cloud (MEC) has been proposed as an approach to bring resources closer to users. Recently, in contrast to conventional fixed cloud locations, the advent of network function virtualization (NFV) has, with some added cost due to the necessary decentralization, enhanced MEC with new flexibility in placing MEC services to any nodes capable of virtualizing their resources. In this work, we address the question on how to optimally place resources among NFV-enabled nodes to support mobile multimedia applications with low latency requirement and when to adapt the current resource placements to address workload changes. We first show that the placement optimization problem is NP-hard and propose an online dynamic resource allocation scheme that consists of an adaptive greedy heuristic algorithm and a detection mechanism to identify the time when the system will no longer be able to satisfy the applications' delay requirement. Our scheme takes into account the effect of current existing techniques (i.e., auto-scaling and load balancing). We design and implement a realistic NFV-enabled MEC simulated framework and show through extensive simulations that our proposal always manages to allocate sufficient resources on time to guarantee continuous satisfaction of the application latency requirements under changing workload while incurring up to 40% less cost in comparison to existing overprovisioning approaches. © 2016 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","136-141","","","","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Mobile applications; Dynamic resource allocations; Heuristic algorithms; Augmented reality; Computational costs; Costs; Design and implements; Detection mechanism; Extensive simulations; Mobile multimedia applications; Multimedia systems; Placement optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 5th IEEE International Conference on Cloud Networking, CloudNet 2016","","","","","","","","","","","","","","",""
"S44K8VRK","journalArticle","2020","","","Mec in 5G Networks","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739808&partnerID=40&md5=7a6a10bc40ad8a1bddfcf88e0c642a98","","2020","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4R88NQC7","journalArticle","2019","Aditya, P.; Akkus, I.E.; Beck, A.; Chen, R.; Hilt, V.; Rimac, I.; Satzke, K.; Stein, M.","Will Serverless Computing Revolutionize NFV?","Proceedings of the IEEE","","","10.1109/JPROC.2019.2898101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062408182&doi=10.1109%2fJPROC.2019.2898101&partnerID=40&md5=b536f61c170aa2ebd4371230e158c4ea","Communication networks need to be both adaptive and scalable. The last few years have seen an explosive growth of software-defined networking (SDN) and network function virtualization (NFV) to address this need. Both technologies help enable networking software to be decoupled from the hardware so that software functionality is no longer constrained by the underlying hardware and can evolve independently. Both SDN and NFV aim to advance a software-based approach to networking, where networking functionality is implemented in software modules and executed on a suitable cloud computing platform. Achieving this goal requires the virtualization paradigm used in these services that play an important role in the transition to software-based networks. Consequently, the corresponding computing platforms accompanying the virtualization technologies need to provide the required agility, robustness, and scalability for the services executed. Serverless computing has recently emerged as a new paradigm in virtualization and has already significantly changed the economics of offloading computations to the cloud. It is considered as a low-latency, resource-efficient, and rapidly deployable alternative to traditional virtualization approaches, such as those based on virtual machines and containers. Serverless computing provides scalability and cost reduction, without requiring any additional configuration overhead on the part of the developer. In this paper, we explore and survey how serverless computing technology can help building adaptive and scalable networks and show the potential pitfalls of doing so. © 1963-2012 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","667-678","","4","107","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Application programs; cloud computing; Cloud computing; Virtual reality; Edge computing; Transfer functions; Network function virtualization; edge computing; serverless computing; Scalability; Virtualization technologies; Cost reduction; Computing technology; Software defined networking; network function virtualization (NFV); Software defined networking (SDN); Application virtualization; Cloud computing platforms; Offloading computations; Software functionality; software-defined networking (SDN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZP67CET3","journalArticle","2019","","","Apache Storm","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067659812&partnerID=40&md5=484c381b548d10a7295b00471baa67ca","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UFW9YFR3","journalArticle","2017","Mach, P.; Becvar, Z.","Mobile Edge Computing: A Survey on Architecture and Computation Offloading","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2017.2682318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028360031&doi=10.1109%2fCOMST.2017.2682318&partnerID=40&md5=f8175210396621bb960b65c83bb5e929","Technological evolution of mobile user equipment (UEs), such as smartphones or laptops, goes hand-in-hand with evolution of new mobile applications. However, running computationally demanding applications at the UEs is constrained by limited battery capacity and energy consumption of the UEs. A suitable solution extending the battery life-time of the UEs is to offload the applications demanding huge processing to a conventional centralized cloud. Nevertheless, this option introduces significant execution delay consisting of delivery of the offloaded applications to the cloud and back plus time of the computation at the cloud. Such a delay is inconvenient and makes the offloading unsuitable for real-time applications. To cope with the delay problem, a new emerging concept, known as mobile edge computing (MEC), has been introduced. The MEC brings computation and storage resources to the edge of mobile network enabling it to run the highly demanding applications at the UE while meeting strict delay requirements. The MEC computing resources can be exploited also by operators and third parties for specific purposes. In this paper, we first describe major use cases and reference scenarios where the MEC is applicable. After that we survey existing concepts integrating MEC functionalities to the mobile networks and discuss current advancement in standardization of the MEC. The core of this survey is, then, focused on user-oriented use case in the MEC, i.e., computation offloading. In this regard, we divide the research on computation offloading to three key areas: 1) decision on computation offloading; 2) allocation of computing resource within the MEC; and 3) mobility management. Finally, we highlight lessons learned in area of the MEC and we discuss open research challenges yet to be addressed in order to fully enjoy potentials offered by the MEC. © 1998-2012 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","1628-1656","","3","19","","","","","","","","","","","","","Scopus","","","","","","","","Electric batteries; Energy utilization; Computer architecture; Network architecture; Edge computing; Surveys; Mobile applications; Computation offloading; Mobile telecommunication systems; Mobile edge computing; computation offloading; allocation of computing resources; Allocation of computing resources; mobile network architecture; mobility management; Mobility management; Real-time application; Research challenges; standardization; Standardization; Technological evolution; use-cases; Wireless networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HB5V7ZMZ","conferencePaper","2019","Hall, A.; Ramachandran, U.","An execution model for serverless functions at the edge","","","","10.1145/3302505.3310084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066038506&doi=10.1145%2f3302505.3310084&partnerID=40&md5=b5ea5977feb5c87dfc390668905e62cc","Serverless computing platforms allow developers to host single-purpose applications that automatically scale with demand. In contrast to traditional long-running applications on dedicated, virtualized, or container-based platforms, serverless applications are intended to be instantiated when called, execute a single function, and shut down when finished. State-of-the-art serverless platforms achieve these goals by creating a new container instance to host a function when it is called and destroying the container when it completes. This design allows for cost and resource savings when hosting simple applications, such as those supporting IoT devices at the edge of the network. However, the use of containers introduces some overhead which may be unsuitable for applications requiring low-latency response or hardware platforms with limited resources, such as those served by edge computing environments. In this paper, we present a nomenclature for characterizing server-less function access patterns which allows us to derive the basic requirements of a serverless computing runtime. We then propose the use of WebAssembly as an alternative method for running serverless applications while meeting these requirements. Finally, we demonstrate how a WebAssembly-based serverless platform provides many of the same isolation and performance guarantees of container-based platforms while reducing average application start times and the resources needed to host them. © 2019 ACM.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","225-236","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Internet of things; serverless; Edge computing; fog computing; FaaS; Fog computing; Performance guarantees; Computing environments; Computing platform; edge computing; function-as-a-service; Hardware platform; Long-running applications; webassembly","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IoTDI 2019 - Proceedings of the 2019 Internet of Things Design and Implementation","","","","","","","","","","","","","","",""
"T48QBQF6","conferencePaper","2018","Jahromi, N.T.; Glitho, R.H.; Larabi, A.; Brunner, R.","An NFV and microservice based architecture for on-the-fly component provisioning in content delivery networks","","","","10.1109/CCNC.2018.8319227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046953095&doi=10.1109%2fCCNC.2018.8319227&partnerID=40&md5=ea4d830208d22e05baa00b82699ca110","Content Delivery Networks (CDNs) deliver content (e.g. Web pages, videos) to geographically distributed end-users over the Internet. Some contents do sometimes attract the attention of a large group of end-users. This often leads to flash crowds which can cause major issues such as outage in the CDN. Microservice architectural style aims at decomposing monolithic systems into smaller components which can be independently deployed, upgraded and disposed. Network Function Virtualization (NFV) is an emerging technology that aims to reduce costs and bring agility by decoupling network functions from the underlying hardware. This paper leverages the NFV and microservice architectural style to propose an architecture for on-the-fly CDN component provisioning to tackle issues such as flash crowds. In the proposed architecture, CDN components are designed as sets of microservices which interact via RESTFul Web services and are provisioned as Virtual Network Functions (VNFs), which are deployed and orchestrated on-the-fly. We have built a prototype in which a CDN surrogate server, designed as a set of microservices, is deployed on-the-fly. The prototype is deployed on SAVI, a Canadian distributed test bed for future Internet applications. The performance is also evaluated. © 2018 IEEE.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","1-7","","","2018-January","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Virtual reality; Architecture; Emerging technologies; Memory architecture; Web services; Transfer functions; Network function virtualization; Architectural style; CDN; Content delivery network; Content Delivery Network; Monolithic systems; Network Function Virtualization; NFV; On the flies; on-the-fly component provisioning; Proposed architectures; RESTful Web services; Websites","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CCNC 2018 - 2018 15th IEEE Annual Consumer Communications and Networking Conference","","","","","","","","","","","","","","",""
"2E9948T3","journalArticle","2019","","","Cities with the Most Surveillance Cameras in the World Mass Serveillance","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092720038&partnerID=40&md5=260725fb7bdf156577c8745745b5f957","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M8DJ2EH3","journalArticle","2018","","Mobile edge computing (MEC); deployment of mobile edge computing in an NFV environment v.1.1.1","Mobile Edge Computing (MEC); Deployment of Mobile Edge Computing in An NFV Environment","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050886380&partnerID=40&md5=482634895820ecacec335dcc883dc84d","","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3A77BI6","journalArticle","2019","Bentaleb, A.; Taani, B.; Begen, A.C.; Timmerer, C.; Zimmermann, R.","A survey on bitrate adaptation schemes for streaming media over HTTP","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2018.2862938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051035075&doi=10.1109%2fCOMST.2018.2862938&partnerID=40&md5=b0d56e7ced58fa2dedc3199f3c243412","In this survey, we present state-of-the-art bitrate adaptation algorithms for HTTP adaptive streaming (HAS). As a key distinction from other streaming approaches, the bitrate adaptation algorithms in HAS are chiefly executed at each client, i.e., in a distributed manner. The objective of these algorithms is to ensure a high quality of experience (QoE) for viewers in the presence of bandwidth fluctuations due to factors like signal strength, network congestion, network recon-vergence events, etc. While such fluctuations are common in public Internet, they can also occur in home networksor even managed networks where there is often admission control and QoS tools. Bitrate adaptation algorithms may take factors like bandwidth estimations, playback buffer fullness, device features, viewer preferences, and content features into account, albeit with different weights. Since the viewer’s QoE needs to be determined in real-time during playback, objective metrics are generally used including number of buffer stalls, duration of startup delay, frequency and amount of quality oscillations, and video instability. By design, the standards for HAS do not mandate any particular adaptation algorithm, leaving it to system builders to innovate and implement their own method. This survey provides an overview of the different methods proposed over the last several years. © 2018 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","562-585","","1","21","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Standards; HTTP; Surveys; Bandwidth; Servers; Image coding; Video signal processing; ABR schemes; Adaptive video streaming; Bit rates; Bitrate adaptation; Communication channels (information theory); DASH; HAS; Home networks; Media; Media streaming; Network protocols; Streaming media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEEILIEA","journalArticle","2019","","","Apache JMeter","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071968259&partnerID=40&md5=0da8c29c3fc2fa6e7a2bc39496d5b351","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"58785KJT","journalArticle","2009","Hauptmann, A.","","Video Content Analysis","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092744121&partnerID=40&md5=59cfc39a558f3f71bde86a20aa110e95","","2009","2025-10-22 19:07:38","2025-10-22 19:07:38","","3271-3276","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2CLIUIQ","journalArticle","2019","Liu, P.; Chaudhry, S.R.; Huang, T.; Wang, X.; Collier, M.","Multi-Factorial Energy Aware Resource Management in Edge Networks","IEEE Transactions on Green Communications and Networking","","","10.1109/TGCN.2018.2874397","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067529896&doi=10.1109%2fTGCN.2018.2874397&partnerID=40&md5=e5dfab09ec839bf3710c43b758dd4b2e","Edge networks deliver computing services close to the user, unlike centralized clouds. This improves service scalability and delay-sensitive functions can be offloaded to the edge, when the latency incurred by cloud services is too high. Since services in edge networks, by their nature, are not centralized, careful design is required to achieve efficient resource utilization and low power consumption. These issues are addressed in this paper. A network device power model is formulated to explore the power dissipation characteristics of frequency scalable CMOS devices (as measured using a NetFPGA testbed). An on-demand energy-efficient resource allocation model (OERA) is designed based on this model. OERA features acceptance ratios that are 11%-17% higher than existing solutions and 9% lower power consumption. A novel algorithm is presented for resource placement in edge networks, which can accommodate higher traffic flow demands and distribution distance than existing solutions. This uses mixed integer linear programming to simultaneously maximize the aggregate flow demands and to minimize the network energy consumption. An iterative algorithm and a heuristic greedy edge network device placement algorithm are implemented that not only solve this NP-Hard problem but also significantly reduce the network energy consumption. © 2017 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","45-56","","1","3","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Embedded systems; Energy efficiency; Cloud computing; resource management; Resource management; Distributed computer systems; Energy utilization; Computer resource management; Green computing; Energy dissipation; Natural resources management; Resource allocation; Computational complexity; computer network performance; Computer networks; Dynamic frequency scaling; Electric losses; Electric power measurement; Energy conservation; Energy-efficient resource allocation; Integer programming; Iterative methods; Low power electronics; Low-power consumption; Lower-power consumption; Mixed integer linear programming; Network energy consumption; Power demands; Power management (telecommunication); Resource utilisation; Semiconductor device models; Semiconductor devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H4IT3EHG","journalArticle","2017","Cziva, R.; Pezaros, D.P.","Container Network Functions: Bringing NFV to the Network Edge","IEEE Communications Magazine","","","10.1109/MCOM.2017.1601039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020940399&doi=10.1109%2fMCOM.2017.1601039&partnerID=40&md5=e925375f7ec224aba683e1b2e7cca12f","In order to cope with the increasing network utilization driven by new mobile clients, and to satisfy demand for new network services and performance guarantees, telecommunication service providers are exploiting virtualization over their network by implementing network services in virtual machines, decoupled from legacy hardware accelerated appliances. This effort, known as NFV, reduces OPEX and provides new business opportunities. At the same time, next generation mobile, enterprise, and IoT networks are introducing the concept of computing capabilities being pushed at the network edge, in close proximity of the users. However, the heavy footprint of today's NFV platforms prevents them from operating at the network edge. In this article, we identify the opportunities of virtualization at the network edge and present Glasgow Network Functions (GNF), a container-based NFV platform that runs and orchestrates lightweight container VNFs, saving core network utilization and providing lower latency. Finally, we demonstrate three useful examples of the platform: IoT DDoS remediation, on-demand troubleshooting for telco networks, and supporting roaming of network functions. © 1979-2012 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","24-31","","6","55","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Virtual reality; Virtualization; Internet of things; Network functions; Hardware-accelerated; Network services; Transfer functions; Business opportunities; Computing capability; Net work utilization; Network function virtualization; Performance guarantees; Telecommunication service provider; Telecommunication services; Virtual machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CL7STSTJ","journalArticle","2019","","","Nest","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092729135&partnerID=40&md5=c0410c1350c3d72c5fdb61febc15a106","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EN7DWGDC","journalArticle","2019","","Multi-Access Edge Computing (MEC); Framework and Reference Architecture","Multi-access Edge Computing (MEC); Framework and Reference Architecture","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072052535&partnerID=40&md5=06f6d3fd16207c63b5ccdd0035f7a54f","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RAUI68A","journalArticle","2016","Razzaque, M.A.; Milojevic-Jevric, M.; Palade, A.; Cla, S.","Middleware for internet of things: A survey","IEEE Internet of Things Journal","","","10.1109/JIOT.2015.2498900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959420432&doi=10.1109%2fJIOT.2015.2498900&partnerID=40&md5=b004a6d236543ca3bc7b1f7ec7fe5c43","The Internet of Things (IoT) envisages a future in which digital and physical things or objects (e.g., smartphones, TVs, cars) can be connected by means of suitable information and communication technologies, to enable a range of applications and services. The IoT's characteristics, including an ultra-largescale network of things, device and network level heterogeneity, and large numbers of events generated spontaneously by these things, will make development of the diverse applications and services a very challenging task. In general, middleware can ease a development process by integrating heterogeneous computing and communications devices, and supporting interoperability within the diverse applications and services. Recently, there have been a number of proposals for IoT middleware. These proposals mostly addressed wireless sensor networks (WSNs), a key component of IoT, but do not consider RF identification (RFID), machine-tomachine (M2M) communications, and supervisory control and data acquisition (SCADA), other three core elements in the IoT vision. In this paper, we outline a set of requirements for IoT middleware, and present a comprehensive review of the existing middleware solutions against those requirements. In addition, open research issues, challenges, and future research directions are highlighted. © 2015 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","70-95","","1","3","","","","","","","","","","","","","Scopus","","","","","","","","Internet; Internet of things; Internet of Things (IOT); Middleware; Data acquisition; Internet of Things (IoT) characteristics; Interoperability; Machine-to-machine (M2M) communication; Machine-to-machine communications; Middleware requirements; Radio frequency identification (RFID); RF identification (RFID); Rf identifications; Supervisory control and data acquisition; Supervisory control and data acquisition (SCADA); Wireless sensor network (WSNs); Wireless sensor networks; Wireless sensor networks (WSNs)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAMF6UL7","journalArticle","2018","Bouet, M.; Conan, V.","Mobile Edge Computing Resources Optimization: A Geo-Clustering Approach","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2018.2816263","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044070269&doi=10.1109%2fTNSM.2018.2816263&partnerID=40&md5=1193c3a0032b88b914cebe6561d05f2e","Mobile edge computing (MEC) is an emerging technology that aims at pushing applications and content close to the users (e.g., at base stations, access points, and aggregation networks) to reduce latency, improve quality of experience, and ensure highly efficient network operation and service delivery. It principally relies on virtualization-enabled MEC servers with limited capacity at the edge of the network. One key issue is to dimension such systems in terms of server size, server number, and server operation area to meet MEC goals. In this paper, we formulate this problem as a mixed integer linear program. We then propose a graph-based algorithm that, taking into account a maximum MEC server capacity, provides a partition of MEC clusters, which consolidates as many communications as possible at the edge. We use a dataset of mobile communications to extensively evaluate them with real world spatiooral human dynamics. In addition to quantifying macroscopic MEC benefits, the evaluation shows that our algorithm provides MEC area partitions that largely offload the core, thus pushing the load at the edge (e.g., with 10 small MEC servers between 55% and 64% of the traffic stay at the edge), and that are well balanced through time. © 2004-2012 IEEE.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","787-796","","2","15","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Virtual reality; Virtualization; Edge computing; Mobile telecommunication systems; Servers; Mobile edge computing; fog computing; Mobile communications; Integer programming; Base stations; clustering; Clustering algorithms; dimensioning; Fog computing; Graphic methods; Heuristic algorithms; Mobile Edge Computing; multi-access edge computing; Multiaccess; network virtualization; Network virtualization; Partitioning algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNKZGPWA","journalArticle","2017","Buchanan, W.J.; Li, S.; Asif, R.","Lightweight cryptography methods","Journal of Cyber Security Technology","","","10.1080/23742917.2017.1384917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206596672&doi=10.1080%2f23742917.2017.1384917&partnerID=40&md5=22d0af4d890811dc5b012e0cf03625d7","While our conventional cryptography methods, such for AES (encryption), SHA-256 (hashing) and RSA/Elliptic Curve (signing), work well on systems which have reasonable processing power and memory capabilities, these do not scale well into a world with embedded systems and sensor networks. Thus, lightweight cryptography methods are proposed to overcome many of the problems of conventional cryptography. This includes constraints related to physical size, processing requirements, memory limitation and energy drain. This paper outlines many of the techniques that are defined as replacements for conventional cryptography within an Internet of things space and discuss some trends in the design of lightweight algorithms. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","187-201","","3-4","1","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Cryptography; AES encryption; CLEFIA; encryption; Enocoro; hashing functions; Hashing functions; Lesamanta-LW; Lesamantum-LW; Light-weight cryptography; Lightweight cryptography; PHOTONSPONGENT; PRESENT; resource-limited devices; Resource-limited devices; Sensor networks; Trivium","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V7G2TDWP","journalArticle","2022","Palade, A.; Clarke, S.","Collaborative Agent Communities for Resilient Service Composition in Mobile Environments","IEEE Transactions on Services Computing","","","10.1109/TSC.2020.2964753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083743454&doi=10.1109%2fTSC.2020.2964753&partnerID=40&md5=f5c84da3826bcd512277c7d10719596b","Automatic planning, with dynamic binding and adaptive composition recovery, has been used to tackle complex service provisioning in mobile environments, but given frequent network topology changes, and services with time-dependent QoS, finding composites that can functionally and non-functionally satisfy a user's request remains difficult. Many service composition mechanisms either require a centralised perspective of the environment, or use optimisation mechanisms that trade off computational efficiency for optimality. Stigmergy-based approaches have been used to model decentralised service interactions between service providers, using a community of mobile software agents that share the same goal to approximate the set of QoS-optimal service compositions. Inspired by this model, this article addresses computational efficiency concerns using a collaborative approach to engage multiple communities of agents for provisioning QoS-optimal service compositions in mobile environments. New compositions can emerge from local decisions and interactions with agents from diverse communities. We assess whether having multiple communities improves the diversity and optimality of solutions. We also measure the proposed approach' efficiency in dealing with incomplete information. The results show that the proposed approach trades optimality for a more diverse set of solutions, at a cost of higher overhead. © 2008-2012 IEEE.","2022","2025-10-22 19:07:38","2025-10-22 19:07:38","","876-890","","2","15","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Economic and social effects; Computational efficiency; Collaborative agents; Collaborative approach; Communication overheads; decentralised; Efficiency; flexible; Incomplete information; Mobile agents; Mobile environments; Mobile software agents; QoS-aware service composition; Service compositions; Service interaction; Stigmergic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQ8VI6EY","conferencePaper","2016","Comi, P.; Secondo Crosta, P.; Beccari, M.; Paglierani, P.; Grossi, G.; Pedersini, F.; Petrini, A.","Hardware-accelerated high-resolution video coding in Virtual Network Functions","","","","10.1109/EuCNC.2016.7560999","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988936199&doi=10.1109%2fEuCNC.2016.7560999&partnerID=40&md5=e4755e04c082aa1f8511639697dd8af8","Network Function Virtualization (NFV) has become a widely acclaimed approach to facilitate the management and orchestration of network services. However, after rapidly achieving a widespread success, NFV is now challenged by the overwhelming demand of computing power originated by the never-ending growth of innovative applications coming from the Internet world. To overcome this problem, the use of h/w acceleration combined with NFV has been proposed. This way, the computing performance of commodity servers can be greatly enhanced, without losing the advantages offered by NFV in service management. In this paper, to demonstrate the potentialities of NFV and h/w acceleration, a Virtual Network Function for video coding (video Transcoding Unit-vTU) is presented. The vTU is accelerated by a General Purpose GPU, and is based on Open Source software packages for media processing. The vTU architecture is firstly described in details. A thorough characterization of its computing performance is then reported, and the obtained results are compared to those achieved with non-accelerated and/or non-virtualized versions of the vTU itself. Also, the performance provided by an original, GPU accelerated version of the VP8 encoder is presented. The activities described in this paper have been carried out within the EU FP7 T-NOVA project. © 2016 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","32-36","","","","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Program processors; Open systems; Software engineering; Video signal processing; Video-transcoding; Network functions; Computing performance; General purpose gpu; Hardware-accelerated; In-service management; Media processing; Network services; Transfer functions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EUCNC 2016 - European Conference on Networks and Communications","","","","","","","","","","","","","","",""
"GCVNGDM2","conferencePaper","2019","Palade, A.; Kazmi, A.; Clarke, S.","An evaluation of open source serverless computing frameworks support at the Edge","","","","10.1109/SERVICES.2019.00057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072771398&doi=10.1109%2fSERVICES.2019.00057&partnerID=40&md5=921ad78e9a7561588b837529881b53b9","The proliferation of Internet of Things (IoT) and the success of resource-rich cloud services have pushed the data processing horizon towards the edge of the network. This has the potential to address bandwidth costs, and latency, availability and data privacy concerns. Serverless computing, a cloud computing model for stateless and event-driven applications, promises to further improve Quality of Service (QoS) by eliminating the burden of always-on infrastructure through ephemeral containers. Open source serverless frameworks have been introduced to avoid the vendor lock-in and computation restrictions of public cloud platforms and to bring the power of serverless computing to on-premises deployments. In an IoT environment, these frameworks can leverage the computational capabilities of devices in the local network to further improve QoS of applications delivered to the user. However, these frameworks have not been evaluated in a resource-constrained, edge computing environment. In this work we evaluate four open source serverless frameworks, namely, Kubeless, Apache OpenWhisk, OpenFaaS, Knative. Each framework is installed on a bare-metal, single master, Kubernetes cluster. We use the JMeter framework to evaluate the response time, throughput and success rate of functions deployed using these frameworks under different workloads. The evaluation results are presented and open research opportunities are discussed. © 2019 IEEE.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","206-211","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Containers; Docker; Kubernetes; QoS; Internet of things; Open systems; Apache Openwhisk; Computing frameworks; Data privacy; FaaS; Function as a Service; Function composition; Function evaluation; JMeter; Knative; Kubeless; OpenFaaS; Opensource serverless computing frameworks; Quantitative evaluation; Serverless computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2019 IEEE World Congress on Services, SERVICES 2019","","","","","","","","","","","","","","",""
"5KWK2RDS","journalArticle","2020","","Multi-access Edge Computing (MEC); Framework and Reference Architecture: Tech. Rep. GS MEC 003","Multi-Access Edge Computing (MEC)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101137764&partnerID=40&md5=69c98f52ad8c938df8d5a44fd2f4dfba","","2020","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IWMLRR6","conferencePaper","2017","Liu, Y.; Briones, J.; Zhou, R.; Magotra, N.","Study of secure boot with a FPGA-based IoT device","","","","10.1109/MWSCAS.2017.8053108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034084065&doi=10.1109%2fMWSCAS.2017.8053108&partnerID=40&md5=9cba3d9340f4b2807acc0ab560f9da3f","Internet of Things (loT) is network connected 'Things' such as vehicles, buildings, embedded systems, sensors, as well as people. IoT enables these objects to collect and exchange data of interest to complete various tasks including patient health monitoring, environmental monitoring, system condition prognostics and prediction, smart grid, smart buildings, smart cities, and do on. Due to the large scale of and the limited host processor computation power in an IoT system, effective security provisioning is shifting from software-based security implementation to hardware-based security implementation in terms of efficiency and effectiveness. Moreover, FPGA can take over the work of infrastructure components to preserve and protect critical components and minimize the negative impacts on these components. In this paper, we employ Xilinx Zynq-7000 Series System-on-Chip (SoC) ZC706 prototype board to design an IoT device. To defend against threats to FPGA design, we have studied Zynq-ZC706 to (1) encrypt FPGA bitstream to protect the IoT device from bitstream decoding; (2) encrypt system boot image to enhance system security; and (3) ensure the FPGA operates correctly as intended via authentication to avoid spoofing and Trojan Horse attacks. © 2017 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","1053-1056","","","2017-August","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Critical component; Internet of things; Field programmable gate arrays (FPGA); Binary sequences; Computation power; Cryptography; Environmental Monitoring; Hardware security; Image enhancement; Integrated circuit design; Malware; Programmable logic controllers; Prototype boards; Security implementations; Security Provisioning; Smart city; System conditions; System-on-chip; Trojan Horse attacks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Midwest Symposium on Circuits and Systems","","","","","","","","","","","","","","",""
"ZZBZQHCS","journalArticle","2017","Mao, Y.; You, C.; Zhang, J.; Huang, K.; Letaief, K.B.","A Survey on Mobile Edge Computing: The Communication Perspective","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2017.2745201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028734877&doi=10.1109%2fCOMST.2017.2745201&partnerID=40&md5=6d1262992dcf95ea5c521e168f340065","Driven by the visions of Internet of Things and 5G communications, recent years have seen a paradigm shift in mobile computing, from the centralized mobile cloud computing toward mobile edge computing (MEC). The main feature of MEC is to push mobile computing, network control and storage to the network edges (e.g., base stations and access points) so as to enable computation-intensive and latency-critical applications at the resource-limited mobile devices. MEC promises dramatic reduction in latency and mobile energy consumption, tackling the key challenges for materializing 5G vision. The promised gains of MEC have motivated extensive efforts in both academia and industry on developing the technology. A main thrust of MEC research is to seamlessly merge the two disciplines of wireless communications and mobile computing, resulting in a wide-range of new designs ranging from techniques for computation offloading to network architectures. This paper provides a comprehensive survey of the state-of-the-art MEC research with a focus on joint radio-and-computational resource management. We also discuss a set of issues, challenges, and future research directions for MEC research, including MEC system deployment, cache-enabled MEC, mobility management for MEC, green MEC, as well as privacy-aware MEC. Advancements in these directions will facilitate the transformation of MEC from theory to practice. Finally, we introduce recent standardization efforts on MEC as well as some typical MEC application scenarios. © 1998-2012 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","2322-2358","","4","19","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; resource management; Resource management; Energy utilization; Network architecture; Edge computing; Surveys; Mobile computing; Computation offloading; Mobile cloud computing; Mobile telecommunication systems; Computation theory; Green computing; Mobile edge computing; 5G mobile communication systems; computation offloading; fog computing; green computing; mobile cloud computing; Mobile communications; Natural resources management; Resource allocation; Wireless communications; Wireless telecommunication systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MN2M52L9","conferencePaper","2016","Dutta, S.; Taleb, T.; Frangoudis, P.A.; Ksentini, A.","On-the-fly QoE-aware transcoding in the mobile edge","","","","10.1109/GLOCOM.2016.7842074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015411480&doi=10.1109%2fGLOCOM.2016.7842074&partnerID=40&md5=8a4b4fe6c630af4c774e112017dab37d","To enhance video streaming experience for mobile users, we propose an approach towards Quality-of-Experience (QoE) aware on-the-fly transcoding. The proposed approach relies on the concept of Mobile Edge Computing (MEC) as a key enabler in enhancing service quality. Our scheme involves an autonomic creation of a transcoding service as a Virtual Network Function (VNF) and ensures dynamic rate switching of the streamed video to maintain the desirable quality. This edge-assistive transcoding and adaptive streaming results in reduced computational loads and reduced core network traffic. The proposed solution represents a complete miniature content delivery network infrastructure on the edge, ensuring reduced latency and better quality of experience. © 2016 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Virtual networks; Video streaming; Autonomics; Dynamic rates; Mobile edge computing; Mobile users; Network functions; Rate switching; Service Quality; Streamed video; Transcoding; Video-streaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Global Communications Conference, GLOBECOM","","","","","","","","","","","","","","",""
"5KV8H5QD","journalArticle","2019","Doyle, S.; Tkachuk, G.","Accelerating IPSec NFVs with arrive technologies on the Intel FPGA programmable acceleration card N3000","Netw. Function Virtual. (NFV) Workloads","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092720024&partnerID=40&md5=1e87d4816069a1b3d5b0ef047c65189d","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VEQL85QH","conferencePaper","2017","Koller, R.; Williams, D.","Will Serverless End the Dominance of Linux in the Cloud?","","","","10.1145/3102980.3103008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027993116&doi=10.1145%2f3102980.3103008&partnerID=40&md5=94d77241c36530e85f9ecea7d744d3ce","From the inception of the cloud, running multi-tenant workloads has put strain on the Linux kernel's abstractions. After years of having its abstractions bypassed via virtualization, the kernel has responded with a native container abstraction that is eagerly being applied in the cloud. In this paper, we point out that history is repeating itself: with the introduction of serverless computing, even the native container abstraction is ill-suited. We show that bypassing the kernel with unikernels can yield at least a factor of 6 better latency and throughput. Facing a more complex kernel than ever and a relatively undemanding computing model, we must revisit the question of whether the kernel should try to adapt, we should continue bypassing the kernel, or if it is finally time to try a new native OS for this important future cloud workload. © 2017 ACM.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","169-173","","","Part F129307","","","","","","","","","","","","","Scopus","","","","","","","","Multi tenants; Containers; Computer operating systems; Abstracting; Computing model; Linux; Linux kernel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Workshop on Hot Topics in Operating Systems - HOTOS","","","","","","","","","","","","","","",""
"I9ARQWIV","journalArticle","2019","Subudhi, B.N.; Rout, D.K.; Ghosh, A.","Big data analytics for video surveillance","Multimedia Tools and Applications","","","10.1007/s11042-019-07793-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067242076&doi=10.1007%2fs11042-019-07793-w&partnerID=40&md5=0bf9819047111b4bb8059083e8aa85ea","This article addresses the usage and scope of Big Data Analytics in video surveillance and its potential application areas. The current age of technology provides the users, ample opportunity to generate data at every instant of time. Thus in general, a tremendous amount of data is generated every instant throughout the world. Among them, amount of video data generated is having a major share. Education, healthcare, tours and travels, food and culture, geographical exploration, agriculture, safety and security, entertainment etc., are the key areas where a tremendous amount of video data is generated every day. A major share among it are taken by the daily used surveillance data captured from the security purpose camera and are recorded everyday. Storage, retrieval, processing, and analysis of such gigantic data require some specific platform. Big Data Analytics is such a platform, which eases this analysis task. The aim of this article is to investigate the current trends in video surveillance and its applications using Big Data Analytics. It also aims to focus on the research opportunities for visual surveillance in Big Data frameworks. We have reported here the state-of-the-art surveillance schemes for four different imaging modalities: conventional video scene, remotely sensed video, medical diagnostics, and underwater surveillance. Several works were reported in this research field over recent years and are categorized based on the challenges solved by the researchers. A list of tools used for video surveillance using Big Data framework is presented. Finally, research gaps in this domain are discussed. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","26129-26162","","18","78","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Big data; Advanced Analytics; Big Data; Big Data Analytics for video; Data Analytics; Data Science; Diagnosis; Digital storage; Imaging modality; Medical diagnostics; Medical imaging; Research opportunities; Safety and securities; Security systems; Surveillance data; Underwater imaging; Underwater surveillance; Video recording; Video surveillance; Visual surveillance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJY3UJPH","journalArticle","2016","Mohanty, S.P.; Choppali, U.; Kougianos, E.","Everything you wanted to know about smart cities","IEEE Consumer Electronics Magazine","","","10.1109/MCE.2016.2556879","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983385301&doi=10.1109%2fMCE.2016.2556879&partnerID=40&md5=0c92228489190124f0bb1a6ef185bb8f","","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","60-70","","3","5","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VU77HMNP","journalArticle","2019","","","Present-vhdl","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092694404&partnerID=40&md5=de10e60f72f0282575a9e38e043799d9","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APDWL969","journalArticle","2020","ETSI, E.","Network functions virtualisation (NFV)","Network Functions Virtualisation (NFV)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089134546&partnerID=40&md5=fbbd1cedb284c9785ff6bbb46474f298","","2020","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VE4GFZLJ","journalArticle","2019","Kubernetes, T.","Kubernetes","Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063890881&partnerID=40&md5=192a9cea6a3b7ce32adc05133ff9ddd7","","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4S5NUUU3","conferencePaper","2017","Chang, Z.H.; Jong, B.F.; Wong, W.J.; Wong, M.L.D.","Distributed video transcoding on a heterogeneous computing platform","","","","10.1109/APCCAS.2016.7803998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011103309&doi=10.1109%2fAPCCAS.2016.7803998&partnerID=40&md5=05f0a2d6f6e17ff89055fbcdd34f5910","The requirement for real-time video transcoding systems has significantly increased due to the easy and widely available access to high resolution video streams and large-scale applications in recent years. In this paper, we propose a real-time distributed video transcoding system working on heterogeneous environment to tackle the high requirement of such applications. It allows multiple computers to be networked together to execute the same transcoding task so that the system can process more video streams in real time. Most importantly, the proposed method emphasizes on the velocity of the video data which involves the continuous input video stream and outcomes of transcoded video output stream that is accessible on-the-fly in contrast to the batch-oriented approach such as the MapReduce framework, where output latency can be significant. The performance of the proposed system can be further improved by using a more intelligent scheduler for video frames distribution. © 2016 IEEE.","2017","2025-10-22 19:07:38","2025-10-22 19:07:38","","444-447","","","","","","","","","","","","","","","","Scopus","","","","","","","","Real time systems; Heterogeneous computing; Continuous input; Heterogeneous environments; Image coding; Large-scale applications; Mapreduce frameworks; Multiple computers; Real time videos; Video signal processing; Video streaming; Video-transcoding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 IEEE Asia Pacific Conference on Circuits and Systems, APCCAS 2016","","","","","","","","","","","","","","",""
"UZ2MVERE","journalArticle","2018","Khomh, F.; Abtahizadeh, S.A.","Understanding the impact of cloud patterns on performance and energy consumption","Journal of Systems and Software","","","10.1016/j.jss.2018.03.063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045462134&doi=10.1016%2fj.jss.2018.03.063&partnerID=40&md5=0d07058d3d463220ec67779d9373bb32","Cloud patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. In this work, we conduct an empirical study on two multi-processing and multi-threaded applications deployed in the cloud, to investigate the individual and the combined impact of six cloud patterns (Local Database Proxy, Local Sharding Based Router, Priority Queue, Competing Consumers, Gatekeeper and Pipes and Filters) on the energy consumption. We measure the energy consumption using Power-API; an application programming interface (API) written in Java to monitor the energy consumed at the process-level. Results show that cloud patterns can effectively reduce the energy consumption of a cloud-based application, but not in all cases. In general, there appear to be a trade-off between an improved response time of the application and the energy consumption. Moreover, our findings show that migrating an application to a microservices architecture can improve the performance of the application, while significantly reducing its energy consumption. We summarize our contributions in the form of guidelines that developers and software architects can follow during the implementation of a cloud-based application. © 2018 Elsevier Inc.","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","151-170","","","141","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Application programs; Energy efficiency; Cloud computing; Software architecture; Cloud applications; Energy utilization; Economic and social effects; Multi- threaded applications; Green computing; Energy consumption; Application programming interfaces (API); Cloud pattern; Cloud patterns; Cloud-based applications; Empirical studies; Multi-processing; Performance optimization; Performance optimizations; Software architects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXB8EIUL","journalArticle","2022","Cortellessa, V.; Di Pompeo, D.; Eramo, R.; Tucci, M.","A model-driven approach for continuous performance engineering in microservice-based systems","Journal of Systems and Software","","","10.1016/j.jss.2021.111084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117098236&doi=10.1016%2fj.jss.2021.111084&partnerID=40&md5=47e70199c168eed6e6f288b9b64e7894","Microservices are quite widely impacting on the software industry in recent years. Rapid evolution and continuous deployment represent specific benefits of microservice-based systems, but they may have a significant impact on non-functional properties like performance. Despite the obvious relevance of this property, there is still a lack of systematic approaches that explicitly take into account performance issues in the lifecycle of microservice-based systems. In such a context of evolution and re-deployment, Model-Driven Engineering techniques can provide major support to various software engineering activities, and in particular they can allow managing the relationships between a running system and its architectural model. In this paper, we propose a model-driven integrated approach that exploits traceability relationships between the monitored data of a microservice-based running system and its architectural model to derive recommended refactoring actions that lead to performance improvement. The approach has been applied and validated on two microservice-based systems, in the domain of e-commerce and ticket reservation, respectively, whose architectural models have been designed in UML profiled with MARTE. © 2021 The Author(s)","2022","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","183","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Performance; Software engineering; Architectural modeling; Continuous deployment; Life cycle; Model driven approach; Model-driven engineering; Model-driven Engineering; Performance engineering; Running systems; Software evolution; Software Evolution; Software refactoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJR3DIJ3","journalArticle","2018","Zhou, X.","Benchmarking microservice systems for software engineering research","40Th ACM/IEEE International Conference on Software Engineering (ICSE)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178238757&partnerID=40&md5=eb38025223cf5577fffa47a2a516480b","","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R2EFESK4","journalArticle","2006","Romano, J.; Kromrey, J.D.; Coraggio, J.; Skowronek, J.","Appropriate statistics for ordinal level data: Should we really be using t-test and Cohen's d for evaluating group differences on the NSSE and other surveys?","Annual Meeting of the Florida Association of Institutional Research","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960837892&partnerID=40&md5=97f4aa2643d0ecbcd14a9aad2f79763a","","2006","2025-10-22 19:07:38","2025-10-22 19:07:38","","1-33","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKELE7JC","journalArticle","2004","Pierce, C.A.; Block, R.A.; Aguinis, H.","Cautionary note on reporting eta-squared values from multifactor anova designs","Educational and Psychological Measurement","","","10.1177/0013164404264848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-10044284358&doi=10.1177%2f0013164404264848&partnerID=40&md5=005c2d60a207aab3a21166aee76f966e","The authors provide a cautionary note on reporting accurate eta-squared values from multifactor analysis of variance (ANOVA) designs. They reinforce the distinction between classical and partial eta-squared as measures of strength of association. They provide examples from articles published in premier psychology journals in which the authors erroneously reported partial eta-squared values as representing classical eta-squared values. Finally, they discuss broader impacts of inaccurately reported eta-squared values for theory development, meta-analytic reviews, and intervention programs.","2004","2025-10-22 19:07:38","2025-10-22 19:07:38","","916-924","","6","64","","","","","","","","","","","","","Scopus","","","","","","","","Analysis of variance; Effect size; Eta-squared; Partial eta-squared","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BJZ846EE","journalArticle","2019","Fahad, M.; Shahid, A.; Manumachu, R.R.; Lastovetsky, A.","A comparative study of methods for measurement of energy of computing","Energies","","","10.3390/en12112204","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067106808&doi=10.3390%2fen12112204&partnerID=40&md5=1b7b5b544c44153b6b62a7d40ef60e20","Energy of computing is a serious environmental concern and mitigating it is an important technological challenge. Accurate measurement of energy consumption during an application execution is key to application-level energy minimization techniques. There are three popular approaches to providing it: (a) System-level physical measurements using external power meters; (b) Measurements using on-chip power sensors and (c) Energy predictive models. In this work, we present a comprehensive study comparing the accuracy of state-of-the-art on-chip power sensors and energy predictive models against system-level physical measurements using external power meters, which we consider to be the ground truth. We show that the average error of the dynamic energy profiles obtained using on-chip power sensors can be as high as 73% and the maximum reaches 300% for two scientific applications, matrix-matrix multiplication and 2D fast Fourier transform for a wide range of problem sizes. The applications are executed on three modern Intel multicore CPUs, two Nvidia GPUs and an Intel Xeon Phi accelerator. The average error of the energy predictive models employing performance monitoring counters (PMCs) as predictor variables can be as high as 32% and the maximum reaches 100% for a diverse set of seventeen benchmarks executed on two Intel multicore CPUs (one Haswell and the other Skylake). We also demonstrate that using inaccurate energy measurements provided by on-chip sensors for dynamic energy optimization can result in significant energy losses up to 84%. We show that, owing to the nature of the deviations of the energy measurements provided by on-chip sensors from the ground truth, calibration can not improve the accuracy of the on-chip sensors to an extent that can allow them to be used in optimization of applications for dynamic energy. Finally, we present the lessons learned, our recommendations for the use of on-chip sensors and energy predictive models and future directions. © 2019 by the authors.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","11","12","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Power; Program processors; Energy utilization; Dynamics; Benchmarking; Energy; Green computing; Computing power; Energy dissipation; Energy predictive model; Energy predictive models; Fast Fourier transforms; GPU; Graphics processing unit; Multi-cores; Multicore CPU; NVML; Performance monitoring counter; Performance monitoring counters; Performance-monitoring; Power aensor; Power aensors; Power meters; Powermeter; Predictive models; RAPL; Xeon phi; Xeon Phi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPU2TWN3","journalArticle","2016","Vegas, S.; Apa, C.; Juristo, N.","Crossover Designs in Software Engineering Experiments: Benefits and Perils","IEEE Transactions on Software Engineering","","","10.1109/TSE.2015.2467378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962866799&doi=10.1109%2fTSE.2015.2467378&partnerID=40&md5=235974c8d613ff75a08f5ca437a1ba1b","In experiments with crossover design subjects apply more than one treatment. Crossover designs are widespread in software engineering experimentation: they require fewer subjects and control the variability among subjects. However, some researchers disapprove of crossover designs. The main criticisms are: the carryover threat and its troublesome analysis. Carryover is the persistence of the effect of one treatment when another treatment is applied later. It may invalidate the results of an experiment. Additionally, crossover designs are often not properly designed and/or analysed, limiting the validity of the results. In this paper, we aim to make SE researchers aware of the perils of crossover experiments and provide risk avoidance good practices. We study how another discipline (medicine) runs crossover experiments. We review the SE literature and discuss which good practices tend not to be adhered to, giving advice on how they should be applied in SE experiments. We illustrate the concepts discussed analysing a crossover experiment that we have run. We conclude that crossover experiments can yield valid results, provided they are properly designed and analysed, and that, if correctly addressed, carryover is no worse than other validity threats. © 2015 IEEE.","2016","2025-10-22 19:07:38","2025-10-22 19:07:38","","120-135","","2","42","","","","","","","","","","","","","Scopus","","","","","","","","Design; Software engineering; carryover; controlled experiment; Controlled experiment; crossover design; Crossover design; Crossover experiments; data analysis; Data reduction; Experimental software engineering; Good practices; Risk avoidance; Software engineering experiments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQ6YVRN7","journalArticle","2018","Santos, E.A.; McLean, C.; Solinas, C.; Hindle, A.","How does docker affect energy consumption? Evaluating workloads in and out of Docker containers","Journal of Systems and Software","","","10.1016/j.jss.2018.07.077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053352568&doi=10.1016%2fj.jss.2018.07.077&partnerID=40&md5=a866674254e6fe1a8729a6ef3fd1a1fc","Context: Virtual machines provide isolation of services at the cost of hypervisors and more resource usage. This spurred the growth of systems like Docker that enable single hosts to isolate several applications, similar to VMs, within a low-overhead abstraction called containers. Motivation: Although containers tout low overhead performance, how much do they increase energy use? Methodology: This work statistically compares the energy consumption of three application workloads in Docker and on bare-metal Linux. Results: In all cases, there was a statistically significant (t-test and Wilcoxon p <.05) increase in energy consumption when running tests in Docker, mostly due to the performance of I/O system calls. Developers worried about I/O overhead could consider baremetal deployments over Docker container deployments. © 2018","2018","2025-10-22 19:07:38","2025-10-22 19:07:38","","14-25","","","146","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Docker; Microservice; Cloud computing; Virtualization; Computer operating systems; Energy utilization; Green computing; Bare metal linux; Containerization; Docker containers; Energy consumption; Resource usage; Running tests; System calls","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WVUTAWQ8","journalArticle","2021","Verdecchia, R.; Lago, P.; Ebert, C.; De Vries, C.","Green IT and Green Software","IEEE Software","","","10.1109/MS.2021.3102254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118591280&doi=10.1109%2fMS.2021.3102254&partnerID=40&md5=755c4fe29383d9c14162132cd01c9457","Software and IT usage are continuously growing to keep our society active and manage our individual lives. But as they grow, their energy demand is exploding. By 2030, data centers alone will already consume some 10% of the global electricity.1 Including the Internet, telecommunications, and embedded devices, the energy consumption will be one-third of the global demand. Understanding that end users only consume what we offer, it is the community of software developers who must become active in ecologic behaviors. Green IT is the call of today. Each single line of code that we develop today may still be running years from now on zillions of processors, eating energy and contributing to global climate change. © 1984-2012 IEEE.","2021","2025-10-22 19:07:38","2025-10-22 19:07:38","","7-15","","6","38","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Energy utilization; Climate change; Embedded device; End-users; Energy demands; Energy-consumption; Global demand; Green computing; Internet devices; Line of codes; Software developer; Telecommunication devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSW3TKB5","journalArticle","2013","Hirst, J.M.; Miller, J.R.; Kaplan, B.A.; Reed, D.D.","Watts up? Pro AC power meter for automated energy recording","Behavior Analysis in Practice","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889803805&partnerID=40&md5=a40fa7422f155c37bc1d5e5fc75b13bf","","2013","2025-10-22 19:07:38","2025-10-22 19:07:38","","82-95","","1","6","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXS559TD","conferencePaper","2020","Ergasheva, S.; Khomyakov, I.; Kruglov, A.; Succil, G.","Metrics of energy consumption in software systems: A systematic literature review","","","","10.1088/1755-1315/431/1/012051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080894336&doi=10.1088%2f1755-1315%2f431%2f1%2f012051&partnerID=40&md5=30df7296a80987f34df5dc24e03f247c","The current situation when using tight time frames and frequently changing requirements when creating software dictates the need to create a system for monitoring energy consumption at any stage of production of a software product. At the first stage, we need to evaluate the state-of-the-art on this topic. To this goal, we conducted a systematic literature review. During the review more than 500 studies were observed and 124 of them were selected for detailed analysis. Among these papers, 169 metrics were derived and assessed from the point of their applicability within invasive software development process analysis. The study demonstrates the relevance of the questions posed and shows the immaturity of the area. There is no evolutionary study and the possibility of assessment at any stage of the development of a software product. The data show the importance and relevance of technical work and the importance of its further development. © 2020 IOP Publishing Ltd. All rights reserved.","2020","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","431","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Software design; State of the art; Current situation; Invasive software; Software products; Software systems; Systematic literature review; Technical work; Time frame","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IOP Conference Series: Earth and Environmental Science","","","","","","","","","","","","","","",""
"7XAV8TKW","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178229172&partnerID=40&md5=517c77504ebd4ed6df0e1af428066f78","","","2025-10-22 19:07:38","2025-10-22 19:07:38","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7XMLRLP","conferencePaper","2019","Liu, M.; Peter, S.; Krishnamurthy, A.; Phothilimthana, P.M.","E3: Energy-efficient microservices on smartnic-accelerated servers","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074451146&partnerID=40&md5=2fc9b5be570d88098c87c71ce4f4a3b6","We investigate the use of SmartNIC-accelerated servers to execute microservice-based applications in the data center. By offloading suitable microservices to the SmartNIC’s low-power processor, we can improve server energy-efficiency without latency loss. However, as a heterogeneous computing substrate in the data path of the host, SmartNICs bring several challenges to a microservice platform: network traffic routing and load balancing, microservice placement on heterogeneous hardware, and contention on shared SmartNIC resources. We present E3, a microservice execution platform for SmartNIC-accelerated servers. E3 follows the design philosophies of the Azure Service Fabric microservice platform and extends key system components to a SmartNIC to address the above-mentioned challenges. E3 employs three key techniques: ECMP-based load balancing via SmartNICs to the host, network topology-aware microservice placement, and a data-plane orchestrator that can detect SmartNIC overload. Our E3 prototype using Cavium LiquidIO SmartNICs shows that SmartNIC offload can improve cluster energy-efficiency up to 3× and cost efficiency up to 1.9× at up to 4% latency cost for common microservices, including real-time analytics, an IoT hub, and virtual network functions. © Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019. All rights reserved.","2019","2025-10-22 19:07:38","2025-10-22 19:07:38","","363-378","","","","","","","","","","","","","","","","Scopus","","","","","","","","Real-time analytics; Energy efficiency; Execution platforms; Green computing; Design philosophy; Heterogeneous computing; Heterogeneous hardware; Key system components; Low power processors; Philosophical aspects; Servers; Virtual networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019","","","","","","","","","","","","","","",""
"WH3KGLYV","journalArticle","1992","Basili, V.R.","Software modeling and measurement: The goal/question/metric paradigm","Software Modeling and Measurement: The Goal/Question/Metric Paradigm","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0005382508&partnerID=40&md5=3853a47ef5cf11bbbe765454cf429ebf","","1992","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T39T5ZSF","conferencePaper","2010","Heward, G.; Müller, I.; Han, J.; Schneider, J.-G.; Versteeg, S.","Assessing the performance impact of service monitoring","","","","10.1109/ASWEC.2010.28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954345094&doi=10.1109%2fASWEC.2010.28&partnerID=40&md5=c113ed9e093c2cba6090e1d5fbae6d4f","Service monitoring is an essential part of service-oriented software systems and is required for meeting regulatory requirements, verifying compliance to service-level agreements, optimising system performance, and minimising the cost of hosting Web services. However, service monitoring comes with a cost, including a performance impact on the monitored services and systems. Therefore, it is important to deploy the right level of monitoring at the appropriate time and location in order to achieve the objectives of monitoring whilst minimising its impact on services and systems. Although there have been many efforts to create Web services monitoring techniques and frameworks, there has been limited work in quantifying the impact of Web service monitoring. In this paper, we report on experiments assessing the performance impact of service monitoring under typical system monitoring settings. The performance impact of monitoring method, monitor location, monitor processing capability, and monitoring mode are taken into consideration. Based on the experimental results, we advise on the most appropriate ways to deploy service monitoring. © 2010 IEEE.","2010","2025-10-22 19:07:39","2025-10-22 19:07:39","","192-201","","","","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Service Level Agreements; Software systems; Computer software; Monitor location; Monitoring methods; Monitoring mode; Monitoring techniques; Performance impact; Processing capability; Regulatory requirements; Service interceptors; Service monitoring; Service Oriented; System monitoring; Web service monitoring; Web services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Australian Software Engineering Conference, ASWEC","","","","","","","","","","","","","","",""
"LWBHZKWB","journalArticle","2019","Di Francesco, P.; Lago, P.; Malavolta, I.","Architecting with microservices: A systematic mapping study","Journal of Systems and Software","","","10.1016/j.jss.2019.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060521992&doi=10.1016%2fj.jss.2019.01.001&partnerID=40&md5=95d7beacebfc79566f4a506b7a7180ba","Context: A microservice architecture is composed of a set of small services, each running in its own process and communicating with lightweight mechanisms. Many aspects on architecting with microservices are still unexplored and existing research is still far from being crispy clear. Objective: We aim at identifying, classifying, and evaluating the state of the art on architecting with microservices from the following perspectives: publication trends, focus of research, and potential for industrial adoption. Method: We apply the systematic mapping methodology. We rigorously selected 103 primary studies and we defined and applied a classification framework to them for extracting key information for subsequent analysis. We synthesized the obtained data and produced a clear overview of the state of the art. Results: This work contributes with (i) a classification framework for research studies on architecting with microservices, (ii) a systematic map of current research of the field, (iii) an evaluation of the potential for industrial adoption of research results, and (iv) a discussion of emerging findings and implications for future research. Conclusion: This study provides a solid, rigorous, and replicable picture of the state of the art on architecting with microservices. Its results can benefit both researchers and practitioners of the field. © 2019 Elsevier Inc.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","77-97","","","150","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Software architecture; Classification (of information); Classification framework; Focus of researches; Implications for futures; Industrial adoption; Industrial research; Mapping; State of the art; Systematic mapping; Systematic mapping studies; Systematic mapping study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94ZU9TQM","journalArticle","2014","Merkel, D.","Docker: Lightweight linux containers for consistent development and deployment","Linux Journal","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926444656&partnerID=40&md5=ffabb5619a892434a0212f02e9fd31f5","","2014","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","239","2014","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8DLQ8BT","journalArticle","2016","Chen, X.; Jiao, L.; Li, W.; Fu, X.","Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing","IEEE/ACM Transactions on Networking","","","10.1109/TNET.2015.2487344","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015384872&doi=10.1109%2fTNET.2015.2487344&partnerID=40&md5=2576cf988405bfd1006fe6eb101acf74","Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases. © 1993-2012 IEEE.","2016","2025-10-22 19:07:39","2025-10-22 19:07:39","","2795-2808","","5","24","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Mobile devices; Computation offloading; Mobile cloud computing; Mobile telecommunication systems; Computation theory; Computational efficiency; Computer games; Decision making; Decision-making problem; Distributed computations; Edge clouds; Efficient computation; game theory; Game theory; mobile-edge cloud computing; Nash equilibria; Nash equilibrium; Optimal systems; Radio access networks; Wireless interference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKX2ZZMJ","conferencePaper","2011","Chun, B.-G.; Ihm, S.; Maniatis, P.; Naik, M.; Patti, A.","CloneCloud: Elastic execution between mobile device and cloud","","","","10.1145/1966445.1966473","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955951954&doi=10.1145%2f1966445.1966473&partnerID=40&md5=10d63d8e01e56a340a75c8b6d7c61f02","Mobile applications are becoming increasingly ubiquitous and provide ever richer functionality on mobile devices. At the same time, such devices often enjoy strong connectivity with more powerful machines ranging from laptops and desktops to commercial clouds. This paper presents the design and implementation of CloneCloud, a system that automatically transforms mobile applications to benefit from the cloud. The system is a flexible application partitioner and execution runtime that enables unmodified mobile applications running in an application-level virtual machine to seamlessly off-load part of their execution from mobile devices onto device clones operating in a computational cloud. CloneCloud uses a combination of static analysis and dynamic profiling to partition applications automatically at a fine granularity while optimizing execution time and energy use for a target computation and communication environment. At runtime, the application partitioning is effected by migrating a thread from the mobile device at a chosen point to the clone in the cloud, executing there for the remainder of the partition, and re-integrating the migrated thread back to the mobile device. Our evaluation shows that CloneCloud can adapt application partitioning to different environments, and can help some applications achieve as much as a 20x execution speed-up and a 20-fold decrease of energy spent on the mobile device. Copyright © 2011 ACM.","2011","2025-10-22 19:07:39","2025-10-22 19:07:39","","301-314","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Mobile devices; Portable equipment; Smartphones; Partitioning; Cloning; Dynamic analysis; Laptop computers; Migration; Mobile cloud computing; Mobile telecommunication systems; Offloading; Static analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EuroSys'11 - Proceedings of the EuroSys 2011 Conference","","","","","","","","","","","","","","",""
"Y54G4VND","conferencePaper","2012","Gordon, M.S.; Anoushe Jamshidi, D.; Mahlke, S.; Morley Mao, Z.; Chen, X.","CoMET: Code offload by migrating execution transparently","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076923128&partnerID=40&md5=9a5060db8b9efcdfd44fe12dad2d251e","In this paper we introduce a runtime system to allow unmodified multi-threaded applications to use multiple machines. The system allows threads to migrate freely between machines depending on the workload. Our prototype, COMET (Code Offload by Migrating Execution Transparently), is a realization of this design built on top of the Dalvik Virtual Machine. COMET leverages the underlying memory model of our runtime to implement distributed shared memory (DSM) with as few interactions between machines as possible. Making use of a new VM-synchronization primitive, COMET imposes little restriction on when migration can occur. Additionally, enough information is maintained so one machine may resume computation after a network failure. We target our efforts towards augmenting smartphones or tablets with machines available in the network. We demonstrate the effectiveness of COMET on several real applications available on Google Play. These applications include image editors, turn-based games, a trip planner, and math tools. Utilizing a server-class machine, COMET can offer significant speed-ups on these real applications when run on a modern smartphone. With WiFi and 3G networks, we observe geometric mean speed-ups of 2.88X and 1.27X relative to the Dalvik interpreter across the set of applications with speed-ups as high as 15X on some applications. © 2012 by The USENIX Association. All Rights Reserved.","2012","2025-10-22 19:07:39","2025-10-22 19:07:39","","93-106","","","","","","","","","","","","","","","","Scopus","","","","","","","","Wi-Fi; Smartphones; Dalvik virtual machines; Distributed shared memory; Machine shops; Memory architecture; Multi- threaded applications; Multiple machine; Network failure; Real applications; Runtime systems; Synchronization primitive; Systems analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 10th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2012","","","","","","","","","","","","","","",""
"BAPQUDFI","journalArticle","2012","Verbelen, T.; Simoens, P.; De Turck, F.; Dhoedt, B.","AIOLOS: Middleware for improving mobile application performance through cyber foraging","Journal of Systems and Software","","","10.1016/j.jss.2012.06.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865204463&doi=10.1016%2fj.jss.2012.06.011&partnerID=40&md5=dee2b4b554997ad0987b734a2861603d","As the popularity of smartphones and tablets increases, the mobile platform is becoming a very important target for application developers. Despite recent advances in mobile hardware, most mobile devices fail to execute complex multimedia applications (such as image processing) with an acceptable level of user experience. Cyber foraging is a well-known computing technique to enhance the capabilities of mobile devices, where the mobile device offloads parts of the application to a nearby discovered server in the network. Although first introduced in 2001, cyber foraging is still not widely adopted in current smartphone platforms or applications. In this respect, two major challenges are to be tackled. First, a suitable adaptive decision engine is needed to determine the optimal offloading decision, that takes into account the potentially high and variable latency between the device and the server. Second, an integrated cyber foraging platform with sufficient support for application developers is not publicly available on popular mobile platforms such as Android. In this paper, we present AIOLOS, a mobile middleware framework for cyber foraging on the Android platform. AIOLOS uses an estimation model that takes into account server resources and network state to decide at runtime whether or not a method call should be offloaded. We also introduce developer tools to integrate the AIOLOS framework in the Android platform, enabling easy development of cyber foraging enabled applications. A prototype implementation is presented and evaluated in detail by means of both a chess application and a newly developed photo editor application. © 2012 Elsevier Inc. All rights reserved.","2012","2025-10-22 19:07:39","2025-10-22 19:07:39","","2629-2639","","11","85","","","","","","","","","","","","","Scopus","","","","","","","","Distributed systems; Mobile devices; Cyber foraging; Application developers; Computing techniques; Decision engines; Estimation models; Image processing; Middleware; Mobile applications; Mobile computing; Mobile hardware; Mobile middleware; Mobile phones; Mobile platform; Multimedia applications; Network state; Photo editors; Prototype implementations; Robots; Runtimes; Server resources; Smartphones; User experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H6R7L748","journalArticle","2018","Gedeon, J.; Heuschkel, J.; Wang, L.; Mühlhäuser, M.","Fog Computing: Current Research and Future Challenges","KuVS-Fachgespräch Fog Comput","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055787884&partnerID=40&md5=f3ed5d093c35fbb1e5f2369913f054ca","","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","1-4","","","1","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTHSUG28","conferencePaper","2010","Cuervoy, E.; Balasubramanian, A.; Cho, D.-K.; Wolman, A.; Saroiu, S.; Chandra, R.; Bahlx, P.","MAUI: Making smartphones last longer with code offload","","","","10.1145/1814433.1814441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954993714&doi=10.1145%2f1814433.1814441&partnerID=40&md5=c41bbe80921b5bbf2f63ed0803a1c662","This paper presents MAUI, a system that enables fine-grained energy-aware offload of mobile code to the infrastructure. Previous approaches to these problems either relied heavily on programmer support to partition an application, or they were coarse-grained requiring full process (or full VM) migration. MAUI uses the benefits of a managed code environment to offer the best of both worlds: it supports fine-grained code offload to maximize energy savings with minimal burden on the programmer. MAUI decides at runtime which methods should be remotely executed, driven by an optimization engine that achieves the best energy savings possible under the mobile device's current connectivity constrains. In our evaluation, we show that MAUI enables: 1) a resource-intensive face recognition application that consumes an order of magnitude less energy, 2) a latency-sensitive arcade game application that doubles its refresh rate, and 3) a voice-based language translation application that bypasses the limitations of the smartphone environment by executing unsupported components remotely. Copyright 2010 ACM.","2010","2025-10-22 19:07:39","2025-10-22 19:07:39","","49-62","","","","","","","","","","","","","","","","Scopus","","","","","","","","Smartphones; Mobile codes; Coarse-grained; Code offload; Energy; Energy  savings; Energy aware; Energy management; Energy-savings; Fine grained; Partitioning; Smart phones","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","MobiSys'10 - Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services","","","","","","","","","","","","","","",""
"ACVTY9R5","journalArticle","2014","Lewis, J.; Fowler, M.","Microservices: A definition of this new architectural term","Microservices: A Definition of This New Architectural Term","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964234114&partnerID=40&md5=fd3de0bd7b34545e47485cf075757737","","2014","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J98HTSWZ","conferencePaper","2012","Kosta, S.; Aucinas, A.; Hui, P.; Mortier, R.; Zhang, X.","ThinkAir: Dynamic resource allocation and parallel execution in the cloud for mobile code offloading","","","","10.1109/INFCOM.2012.6195845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861596582&doi=10.1109%2fINFCOM.2012.6195845&partnerID=40&md5=2f2ea3dde7f0b12d746a891601f06d9f","Smartphones have exploded in popularity in recent years, becoming ever more sophisticated and capable. As a result, developers worldwide are building increasingly complex applications that require ever increasing amounts of computational power and energy. In this paper we propose ThinkAir, a framework that makes it simple for developers to migrate their smartphone applications to the cloud. ThinkAir exploits the concept of smartphone virtualization in the cloud and provides method-level computation offloading. Advancing on previous work, it focuses on the elasticity and scalability of the cloud and enhances the power of mobile cloud computing by parallelizing method execution using multiple virtual machine (VM) images. We implement ThinkAir and evaluate it with a range of benchmarks starting from simple micro-benchmarks to more complex applications. First, we show that the execution time and energy consumption decrease two orders of magnitude for a N-queens puzzle application and one order of magnitude for a face detection and a virus scan application. We then show that a parallelizable application can invoke multiple VMs to execute in the cloud in a seamless and on-demand manner such as to achieve greater reduction on execution time and energy consumption. We finally use a memory-hungry image combiner tool to demonstrate that applications can dynamically request VMs with more computational power in order to meet their computational requirements. © 2012 IEEE.","2012","2025-10-22 19:07:39","2025-10-22 19:07:39","","945-953","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Virtualizations; Smartphones; Benchmarking; Complex applications; Computation offloading; Computational power; Computational requirements; Dynamic resource allocations; Elasticity; Execution time; Mobile codes; Orders of magnitude; Parallel executions; Parallelizing; Signal encoding; Virtual machines; Virus scan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"FDXY6FJ6","conferencePaper","2014","Chang, H.; Hari, A.; Mukherjee, S.; Lakshman, T.V.","Bringing the cloud to the edge","","","","10.1109/INFCOMW.2014.6849256","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904465488&doi=10.1109%2fINFCOMW.2014.6849256&partnerID=40&md5=6dd481d13ecb005f79ba94ceadcf19cd","Edge services become increasingly important as the Internet transforms into an Internet of Things (IoT). Edge services require bounded latency, bandwidth reduction between the edge and the core, service resiliency with graceful degradation, and access to resources visible only inside the NATed and secured edge networks. While the data center based cloud excels at providing general purpose computation/storage at scale, it is not suitable for edge services. We present a new model for cloud computing, which we call the Edge Cloud, that addresses edge computing specific issues by augmenting the traditional data center cloud model with service nodes placed at the network edges. We describe the architecture of the Edge Cloud and its implementation as an overlay hybrid cloud using the industry standard OpenStack cloud management framework. We demonstrate the advantages garnered by two new classes of applications enabled by the Edge Cloud - a highly accurate indoor localization that saves on latency, and a scalable and resilient video monitoring that saves on bandwidth. © 2014 IEEE.","2014","2025-10-22 19:07:39","2025-10-22 19:07:39","","346-351","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Internet of things; Access to resources; Bandwidth; Bandwidth reductions; General-purpose computations; Graceful degradation; Indoor localization; Industry standards; Internet of Things (IOT); Traditional data centers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"2D2JF46W","journalArticle","2012","Sharifi, M.; Kafaie, S.; Kashefi, O.","A survey and taxonomy of cyber foraging of mobile devices","IEEE Communications Surveys and Tutorials","","","10.1109/SURV.2011.111411.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897999903&doi=10.1109%2fSURV.2011.111411.00016&partnerID=40&md5=a4055a5a82325e2ee3d717288f5c8301","With the ever-increasing advancement of mobile device technology and their pervasive usage, users expect to run their applications on mobile devices and get the same performance as if they used to run their applications on powerful non-mobile computers. There is a challenge though in that mobile devices deliver lower performance than traditional less-constrained and non-mobile computers because they are constrained by weight, size, and mobility in spite of all their advancements in recent years. One of the most common solutions that has ameliorated this performance disparity is cyber foraging, wherein nearby non-mobile computers called surrogates are utilized to run the whole or parts of applications on behalf of mobile devices. In this paper, we present a survey of cyber foraging as a solution to resolve the challenges of computing on resource-constrained mobile devices. We also explain the most notable cyber foraging systems and present a categorization of existing cyber foraging approaches considering their type of dynamicity, granularity, metrics used, surrogate types and scale, location of their decision maker unit, remoteness of execution, migration support, and their overheads. © 2012 IEEE.","2012","2025-10-22 19:07:39","2025-10-22 19:07:39","","1232-1243","","4","14","","","","","","","","","","","","","Scopus","","","","","","","","Mobile devices; Cyber foraging; Cyber Foraging; Decision makers; Device technologies; Mobile Devices; Resource-Constrained Computing; Surveys; Taxonomies; Taxonomy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4WYYZPE","journalArticle","2016","Balalaie, A.; Heydarnoori, A.; Jamshidi, P.","Microservices Architecture Enables DevOps: Migration to a Cloud-Native Architecture","IEEE Software","","","10.1109/MS.2016.64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968796741&doi=10.1109%2fMS.2016.64&partnerID=40&md5=428311b5b8f1d1fed8654690c5a60fe0","When DevOps started gaining momentum in the software industry, one of the first service-based architectural styles to be introduced, be applied in practice, and become popular was microservices. Migrating monolithic architectures to cloud-native architectures such as microservices reaps many benefits, such as adaptability to technological changes and independent resource management for different system components. This article reports on experiences and lessons learned during incremental migration and architectural refactoring of a commercial MBaaS (mobile back end as a service) to microservices. It explains how adopting DevOps facilitated a smooth migration. Furthermore, the researchers transformed their experiences in different projects into reusable migration practices, resulting in microservices migration patterns. This article is part of a theme issue on DevOps. The Web extra at https://youtu.be/MF3-dKTCQ88 is an audio recording of Brian Brannon speaking with author Pooyan Jamshidi and James Lewis, principal engineer at ThoughtWorks, about DevOps and microservices architecture. © 2016 IEEE.","2016","2025-10-22 19:07:39","2025-10-22 19:07:39","","42-52","","3","33","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; microservices; Computer architecture; architectural refactoring; DevOps; HTTP; migration pattern; Migration patterns; mobile back end as a service; Refactorings; Software design; software development; software engineering; Software engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GDWQI3NJ","journalArticle","2016","Sill, A.","The Design and Architecture of Microservices","IEEE Cloud Computing","","","10.1109/MCC.2016.111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997402736&doi=10.1109%2fMCC.2016.111&partnerID=40&md5=f4a9d927dbbe0c63632bfb31c6c8a4d1","Microservices are sweeping through cloud design architectures, at once embodying new trends and making use of previous paradigms. This column explores the basis for these trends in both modern and historical standards, and sets out a direction for the future of microservices development. © 2016 IEEE.","2016","2025-10-22 19:07:39","2025-10-22 19:07:39","","76-80","","5","3","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Microservices; Automation; Computer architecture; Network architecture; architecture; Architecture; automation; cloud; Clouds; containers; data; design; Design; Design architecture; networks; Networks (circuits); standards; Standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XX7UESE3","journalArticle","2017","Satyanarayanan, M.","The emergence of edge computing","Computer","","","10.1109/MC.2017.9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009446769&doi=10.1109%2fMC.2017.9&partnerID=40&md5=cd3428df30a93363cd7e8db5cabdde75","Industry investment and research interest in edge computing, in which computing and storage nodes are placed at the Internet's edge in close proximity to mobile devices or sensors, have grown dramatically in recent years. This emerging technology promises to deliver highly responsive cloud services for mobile computing, scalability and privacy-policy enforcement for the Internet of Things, and the ability to mask transient cloud outages. The web extra at www.youtube.com/playlist?list=PLmrZVvFtthdP3fwHPy-4d61oDvQY-RBgS includes a five-video playlist demonstrating proof-of-concept implementations for three tasks: assembling 2D Lego models, freehand sketching, and playing Ping-Pong. © 1970-2012 IEEE.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","30-39","","1","50","","","","","","","","","","","","","Scopus","","","","","","","","Close proximity; Cloud services; Computer science; Computers; Edge computing; Emerging technologies; Freehand sketching; nocv1; Privacy policies; Proof of concept; Research interests","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGVHEAVN","conferencePaper","2016","Liu, P.; Willis, D.; Banerjee, S.","ParaDrop: Enabling lightweight multi-tenancy at the network's extreme edge","","","","10.1109/SEC.2016.39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010831253&doi=10.1109%2fSEC.2016.39&partnerID=40&md5=9f17c934cdc3359f5b704e175ca7ef65","We introduce ParaDrop, a specific edge computing platform that provides computing and storage resources at the 'extreme' edge of the network allowing third-party developers to flexibly create new types of services. This extreme edge of the network is the WiFi Access Point (AP) or the wireless gateway through which all end-device traffic (personal devices, sensors, etc.) passes through. ParaDrop's focus on WiFi APs also stems from the fact that the WiFi AP has unique contextual knowledge of its end-devices (e.g., proximity, channel characteristics) that are lost as we get deeper into the network. While different variations and implementations of edge computing platforms have been created over the last decade, ParaDrop focuses on specific design issues around how to structure an architecture, a programming interface, and orchestration framework through which such edge computing services can be dynamically created, installed, and revoked. ParaDrop consists of the following three main components: a flexible hosting substrate in the WiFi APs that supports multi-tenancy, a cloud-based backend through which such computations are orchestrated across many ParaDrop APs, and an API through which third-party developers can deploy and manage their computing functions across such different ParaDrop APs. We have implemented and deployed the entire ParaDrop framework and, in this paper, describe its overall architecture and our initial experiences using it as an edge computing platform. © 2016 IEEE.","2016","2025-10-22 19:07:39","2025-10-22 19:07:39","","1-13","","","","","","","","","","","","","","","","Scopus","","","","","","","","Channel characteristics; Computer architecture; Computing functions; Contextual knowledge; Gateways (computer networks); Network architecture; Personal devices; Programming interface; Storage resources; Wi-Fi; Wi-fi access points; Wireless gateways; Wireless local area networks (WLAN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 1st IEEE/ACM Symposium on Edge Computing, SEC 2016","","","","","","","","","","","","","","",""
"FZXAUN3B","journalArticle","2017","Balan, R.K.; Flinn, J.","Cyber Foraging: Fifteen Years Later","IEEE Pervasive Computing","","","10.1109/MPRV.2017.2940972","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029352267&doi=10.1109%2fMPRV.2017.2940972&partnerID=40&md5=ba1a595b8310c9a083ba8f9cf8cd2bc1","Revisiting Mahadev Satyanarayanan's original vision of cyber foraging and reflecting on the last 15 years of related research, the authors discuss the major accomplishments achieved as well as remaining challenges. They also look to current and future applications that could provide compelling application scenarios for making cyber foraging a widely deployed technology. This article is part of a special issue on pervasive computing revisited. © 2002-2012 IEEE.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","24-30","","3","16","","","","","","","","","","","","","Scopus","","","","","","","","Computer applications; Software engineering; Application scenario; communication; Communication; computer systems organization; Computer systems organization; Cyber foraging; Future applications; Information technology; Information Technology; mobile; networking; pervasive computing; special-purpose and application-based systems; ubiquitous computing; Ubiquitous computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSELFVI4","conferencePaper","2011","Ra, M.-R.; Sheth, A.; Mummert, L.; Pillai, P.; Wetherall, D.; Govindan, R.","Odessa: Enabling interactive perception applications on mobile devices","","","","10.1145/1999995.2000000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961048093&doi=10.1145%2f1999995.2000000&partnerID=40&md5=31c898117bb8d28e0bd9e3e02d38a1dd","Resource constrained mobile devices need to leverage computation on nearby servers to run responsive applications that recognize objects, people, or gestures from real-time video. The two key questions that impact performance are what computation to offload, and how to structure the parallelism across the mobile device and server. To answer these questions, we develop and evaluate three interactive perceptual applications. We find that offloading and parallelism choices should be dynamic, even for a given application, as performance depends on scene complexity as well as environmental factors such as the network and device capabilities. To this end we develop Odessa, a novel, lightweight, runtime that automatically and adaptively makes offloading and parallelism decisions for mobile interactive perception applications. Our evaluation shows that the incremental greedy strategy of Odessa converges to an operating point that is close to an ideal offline partitioning. It provides more than a 3x improvement in application performance over partitioning suggested by domain experts. Odessa works well across a variety of execution environments, and is agile to changes in the network, device and application inputs. © 2011 ACM.","2011","2025-10-22 19:07:39","2025-10-22 19:07:39","","43-56","","","","","","","","","","","","","","","","Scopus","","","","","","","","incremental partitioning; Incremental partitioning; Mobile devices; mobile perception application; offloading; parallel processing; Parallel processing; Portable equipment; Real time systems; User interfaces; video processing; Video processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","MobiSys'11 - Compilation Proceedings of the 9th International Conference on Mobile Systems, Applications and Services and Co-located Workshops","","","","","","","","","","","","","","",""
"B56B848V","journalArticle","2020","","","BPF Compiler Collection (BCC). Retrieved from","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097236527&partnerID=40&md5=a68ad0ae4f81617eb27c49b2c4c2e97e","","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQ4Q258M","conferencePaper","2017","Chang, C.-C.; Yang, S.-R.; Yeh, E.-H.; Lin, P.; Jeng, J.-Y.","A Kubernetes-Based Monitoring Platform for Dynamic Cloud Resource Provisioning","","","","10.1109/GLOCOM.2017.8254046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046372373&doi=10.1109%2fGLOCOM.2017.8254046&partnerID=40&md5=eccb2611e5a1df030d85f4a3a041d21a","Recently, more and more network operators have deployed cloud environment to implement network operations centers that monitor the status of their large-scale mobile or wireline networks. Typically, the cloud environment adopts container-based virtualization that uses Docker for container packaging with Kubernetes for multihost Docker container management. In such a container-based environment, it is important that the Kubernetes can dynamically monitor the resource requirements and/or usage of the running applications, and then adjust the resource provisioned to the managed containers accordingly. Currently, Kubernetes provides a naive dynamic resource-provisioning mechanism which only considers CPU utilization and thus is not effective. This paper aims at developing a generic platform to facilitate dynamic resource-provisioning based on Kubernetes. Our platform contains the following three features. First, our platform includes a comprehensive monitoring mechanism that integrates and provides the relatively complete system resource utilization and application QoS metrics to the resource-provisioning algorithm to make the better provisioning strategy. Second, our platform modularizes the operation of dynamic resource- provisioning operation so that the users can easily deploy a newly designed algorithm to replace an existing one in our platform. Third, the dynamic resource-provisioning operation in our platform is implemented as a control loop which can consequently be applied to all the running application following a user-defined time interval without other manual configuration. © 2017 IEEE.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","1-6","","","2018-January","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Containers; Docker; Kubernetes; monitoring; Container; Cloud environments; dynamic resource provisioning; Dynamic resource provisioning; Dynamics; Large-scales; Monitoring platform; Network operations centers; Network operator; Running applications; Wire line networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Global Communications Conference, GLOBECOM","","","","","","","","","","","","","","",""
"5HGLMEDX","conferencePaper","2019","Gan, Y.; Zhang, Y.; Cheng, D.; Shetty, A.; Rathi, P.; Katarki, N.; Bruno, A.; Hu, J.; Ritchken, B.; Jackson, B.; Hu, K.; Pancholi, M.; He, Y.; Clancy, B.; Colen, C.; Wen, F.; Leung, C.; Wang, S.; Zaruvinsky, L.; Espinosa, M.; Lin, R.; Liu, Z.; Padilla, J.; Delimitrou, C.","An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems","","","","10.1145/3297858.3304013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064688619&doi=10.1145%2f3297858.3304013&partnerID=40&md5=b9f662fba2a35d83eb40d32009cf7676","Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","3-18","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Open source software; Datacenter; Microservice; cloud computing; Cloud-computing; microservices; QoS; acceleration; Benchmark suites; Cloud systems; Cluster computing; cluster management; Cluster management; datacenters; Economic and social effects; Field programmable gate arrays (FPGA); fpga; Fpgum; Open systems; Open-source; Quality-of-service; serverless; Serverless","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"M5QAE9AS","journalArticle","1991","Bailey, D.H.; Barszcz, E.; Barton, J.T.; Browning, D.S.; Carter, R.L.; Dagum, L.; Fatoohi, R.A.; Frederickson, P.O.; Lasinski, T.A.; Schreiber, R.S.; Simon, H.D.; Venkatakrishnan, V.; Weeratunga, S.K.","The nas parallel benchmarks","International Journal of High Performance Computing Applications","","","10.1177/109434209100500306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973836157&doi=10.1177%2f109434209100500306&partnerID=40&md5=12f2b27c9f81379811534a509bccaa5c","A new set of benchmarks has been developed for the performance evaluation of highly parallel supercom puters. These consist of five “parallel kernel” bench marks and three “simulated application” benchmarks. Together they mimic the computation and data move ment characteristics of large-scale computational fluid dynamics applications. The principal distinguishing feature of these benchmarks is their “pencil and paper” specification—all details of these benchmarks are specified only algorithmically. In this way many of the difficulties associated with conventional bench- marking approaches on highly parallel systems are avoided. © 1991, Sage Publications. All rights reserved.","1991","2025-10-22 19:07:39","2025-10-22 19:07:39","","63-73","","3","5","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLT983TN","conferencePaper","2007","Imamagic, E.; Dobrenic, D.","Grid infrastructure monitoring system based on Nagios","","","","10.1145/1272680.1272685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548251405&doi=10.1145%2f1272680.1272685&partnerID=40&md5=a1e9003ac921d02cfacc5fa08fb58cd7","Monitoring in distributed environment such as a grid is crucial for normal operation of all subsystems. Constant gathering of information enables efficient security auditing, failure detection, maintenance, job scheduling, accounting, resource performance tuning, debugging, etc. In this paper we focus on monitoring of resources in the grid with the purpose of failure detection, notifications and automatic recovery. We introduce our system based on open source monitoring framework Nagios that achieves these functionalities. We describe grid specific features we implemented in order to achieve efficient grid monitoring system, namely sensors for various grid services, advanced sensor hierarchy and certificate-based authorization on web interface. Finally, we give overview of the implementation of our system for monitoring EGEE grid infrastructure. Copyright 2007 ACM.","2007","2025-10-22 19:07:39","2025-10-22 19:07:39","","23-28","","","","","","","","","","","","","","","","Scopus","","","","","","","","Condition monitoring; Automatic recovery; Computer resource management; Computer system recovery; Failure analysis; Failure detection; Grid computing; Grid monitoring architecture; Knowledge acquisition; Network monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2007 Workshop on Grid Monitoring, GMW'07","","","","","","","","","","","","","","",""
"A8GYVZP6","journalArticle","","","","Datadog","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097248158&partnerID=40&md5=26ee91c13c2aa399a9357087964a3a52","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9BGEAAQ","conferencePaper","2015","Piraghaj, S.F.; Dastjerdi, A.V.; Calheiros, R.N.; Buyya, R.","A Framework and Algorithm for Energy Efficient Container Consolidation in Cloud Data Centers","","","","10.1109/DSDIS.2015.67","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964497471&doi=10.1109%2fDSDIS.2015.67&partnerID=40&md5=27ae17192e919f9725e5b8b246ba5422","One of the major challenges that cloud providers face is minimizing power consumption of their data centers. To this point, majority of current research focuses on energy efficient management of resources in the Infrastructure as a Service model and through virtual machine consolidation. However, containers are increasingly gaining popularity and going to be major deployment model in cloud environment and specifically in Platform as a Service. This paper focuses on improving the energy efficiency of servers for this new deployment model by proposing a framework that consolidates containers on virtual machines. We first formally present the container consolidation problem and then we compare a number of algorithms and evaluate their performance against metrics such as energy consumption, Service Level Agreement violations, average container migrations rate, and average number of created virtual machines. Our proposed framework and algorithms can be utilized in a private cloud to minimize energy consumption, or alternatively in a public cloud to minimize the total number of hours the virtual machines leased. © 2015 IEEE.","2015","2025-10-22 19:07:39","2025-10-22 19:07:39","","368-375","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Platform as a Service (PaaS); Cloud computing; Virtualization; Algorithms; Cloud Computing; Cloud data centers; Cloud environments; Container as a Service; Deployment models; Energy Efficiency; Energy efficient; Energy utilization; Framework and algorithms; Infrastructure as a service (IaaS); Internet; Internet of things; Java programming language; Service Level Agreements; Virtual machine consolidations; Virtualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 IEEE International Conference on Data Science and Data Intensive Systems; 8th IEEE International Conference Cyber, Physical and Social Computing; 11th IEEE International Conference on Green Computing and Communications and 8th IEEE International Conference on Internet of Things, DSDIS/CPSCom/GreenCom/iThings 2015","","","","","","","","","","","","","","",""
"9V2U8MXG","journalArticle","","","","Docker","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097211828&partnerID=40&md5=6708e505656f42ef935adfac738f56ce","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7U3QJ3X","journalArticle","2008","Barak, N.","","JgraphT","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097213865&partnerID=40&md5=292c2031b1402d6d1660c4377aaf4bdf","","2008","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NAQ4VLGK","journalArticle","2004","Massie, M.L.; Chun, B.N.; Culler, D.E.","The ganglia distributed monitoring system: Design, implementation, and experience","Parallel Computing","","","10.1016/j.parco.2004.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-3342966061&doi=10.1016%2fj.parco.2004.04.001&partnerID=40&md5=bb124c87b75271923533a6a58693e765","Ganglia is a scalable distributed monitoring system for high performance computing systems such as clusters and Grids. It is based on a hierarchical design targeted at federations of clusters. It relies on a multicast-based listen/announce protocol to monitor state within clusters and uses a tree of point-to-point connections amongst representative cluster nodes to federate clusters and aggregate their state. It leverages widely used technologies such as XML for data representation, XDR for compact, portable data transport, and RRDtool for data storage and visualization. It uses carefully engineered data structures and algorithms to achieve very low per-node overheads and high concurrency. The implementation is robust, has been ported to an extensive set of operating systems and processor architectures, and is currently in use on over 500 clusters around the world. This paper presents the design, implementation, and evaluation of Ganglia along with experience gained through real world deployments on systems of widely varying scale, configurations, and target application domains over the last two and a half years. © 2004 Elsevier B.V. All rights reserved.","2004","2025-10-22 19:07:39","2025-10-22 19:07:39","","817-840","","7","30","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Algorithms; Clusters; Computer applications; Computer operating systems; Computing systems; Condition monitoring; Data structures; Distributed computer systems; Distributed systems; Grids; Hierarchical systems; Multicasting; Parallel processing systems; Structural design; Trees (mathematics); XML","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSST9NDL","conferencePaper","2018","Masson, C.; Rim, J.E.; Lee, H.K.","DDSketch: A fast and fully-mergeable quantile sketch with relative-error guarantees","","","","10.14778/3352063.3352135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074537736&doi=10.14778%2f3352063.3352135&partnerID=40&md5=1fb08193b7fd72eedcd3b307ecbbc834","Summary statistics such as the mean and variance are easily maintained for large, distributed data streams, but order statistics (i.e., sample quantiles) can only be approximately summarized. There is extensive literature on maintaining quantile sketches where the emphasis has been on bounding the rank error of the sketch while using little memory. Unfortunately, rank error guarantees do not preclude arbitrarily large relative errors, and this often occurs in practice when the data is heavily skewed. Given the distributed nature of contemporary large-scale systems, another crucial property for quantile sketches is mergeablility, i.e., several combined sketches must be as accurate as a single sketch of the same data. We present the first fully-mergeable, relative-error quantile sketching algorithm with formal guarantees. The sketch is extremely fast and accurate, and is currently being used by Datadog at a wide-scale. © 2019 VLDB Endowment.","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","2195-2205","","","12","","","","","","","","","","","","","Scopus","","","","","","","","Distributed data streams; Errors; Large scale systems; Order statistics; Relative errors; Summary statistic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the VLDB Endowment","","","","","","","","","","","","","","",""
"2ZQW3LKB","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097241211&partnerID=40&md5=b95368a35bc942ec457f838b0bb97a89","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9DIKNV4K","conferencePaper","2019","Noor, A.; Jha, D.N.; Mitra, K.; Jayaraman, P.P.; Souza, A.; Ranjan, R.; Dustdar, S.","A framework for monitoring microservice-oriented cloud applications in heterogeneous virtualization environments","","","","10.1109/CLOUD.2019.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067381634&doi=10.1109%2fCLOUD.2019.00035&partnerID=40&md5=e9fb328dc0f72a148e478f437ddfc1f3","Microservices have emerged as a new approach for developing and deploying cloud applications that require higher levels of agility, scale, and reliability. To this end, a microservice-based cloud application architecture advocates decomposition of monolithic application components into independent software components called 'microservices'. As the independent microservices can be developed, deployed, and updated independently of each other, it leads to complex run-time performance monitoring and management challenges. To solve this problem, we propose a generic monitoring framework, Multi-microservices Multi-virtualization Multi-cloud (M3) that monitors the performance of microservices deployed across heterogeneous virtualization platforms in a multi-cloud environment. We validated the efficacy and efficiency of M3 using a Book-Shop application executing across AWS and Azure. © 2019 IEEE.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","156-163","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Monitoring; Containers; Microservices; Cloud computing; Application components; Cloud applications; Container; Monitoring frameworks; Multi-clouds; New approaches; Run-time performance; Software component; Virtual reality; Virtualization; VM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"89ZSUI96","conferencePaper","2017","Mayer, B.; Weinreich, R.","A dashboard for microservice monitoring and management","","","","10.1109/ICSAW.2017.44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025678915&doi=10.1109%2fICSAW.2017.44&partnerID=40&md5=0cd137af2b581c3c6b0e0eca710982a5","We present an experimental dashboard for microservice monitoring and management. The dashboard can be adapted to different stakeholder needs and it supports the integration of different monitoring infrastructures for collecting microservice runtime data. Aside from runtime information, the dashboard also supports the integration of other information sources for providing static information about microservices and microservice development. We describe the main motivation for developing the dashboard, explain the basic concepts and present important usage scenarios and views currently supported in the dashboard. © 2017 IEEE.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","66-69","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Basic concepts; Information sources; Microservice dashboard; Microservice management; Microservice monitoring; Monitoring and management; Run-time information; Software architecture; Static information; Usage scenarios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE International Conference on Software Architecture Workshops, ICSAW 2017: Side Track Proceedings","","","","","","","","","","","","","","",""
"4L8DJXKM","conferencePaper","2017","Moradi, F.; Flinta, C.; Johnsson, A.; Meirosu, C.","ConMon: An automated container based network performance monitoring system","","","","10.23919/INM.2017.7987264","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029438453&doi=10.23919%2fINM.2017.7987264&partnerID=40&md5=7272fa543fabca82836d72e452f5b4d3","The popularity of container technologies and their widespread usage for building microservices demands solutions dedicated for efficient monitoring of containers and their interactions. In this paper we present ConMon, an automated system for monitoring the network performance of container-based applications. It automatically identifies newly instantiated application containers and observes passively their traffic. Based on these observations, it configures and executes monitoring functions inside adjacent monitoring containers. The system adapts the monitoring containers to changes driven by either the application or the execution platform. The evaluation results validate the feasibility of the ConMon approach and illustrate its scalability in terms of low overhead on compute resources, moderate impact on applications, and negligible impact on the background network traffic. © 2017 IFIP.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","54-62","","","","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Containers; Automated systems; Automation; Binary alloys; Compute resources; Efficient monitoring; Evaluation results; Execution platforms; Monitoring functions; Network performance; Network performance monitoring; Network traffic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the IM 2017 - 2017 IFIP/IEEE International Symposium on Integrated Network and Service Management","","","","","","","","","","","","","","",""
"BB5L89LK","journalArticle","","","","Prometheus","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097219831&partnerID=40&md5=73d5a12c929c7db7e75b077d3d52c8c4","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VGFL6IHI","journalArticle","2020","","","CNCF Cloud Native Landscape","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097217996&partnerID=40&md5=3566126478b39a6ec0f2ef94c8c60cb2","","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"873JI4Z8","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097239840&partnerID=40&md5=b10068408ce36dbb29ee5e0484f227f8","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LF5SMJNE","conferencePaper","1993","McCanne, S.; Jacobson, V.","The BSD packet filter: A new architecture for user-level packet capture","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077206746&partnerID=40&md5=bfe7b22125776923195480159edf78bc","Many versions of Unix provide facilities for user-level packet capture, making possible the use of general purpose workstations for network monitoring. Because network monitors run as user-level processes, packets must be copied across the kernel/user-space protection boundary. This copying can be minimized by deploying a kernel agent called a packet filter, which discards unwanted packets as early as possible. The original Unix packet filter was designed around a stack-based filter evaluator that performs sub-optimally on current RISC CPUs. The BSD Packet Filter (BPF) uses a new, register-based filter evaluator that is up to 20 times faster than the original design. BPF also uses a straightforward buffering strategy that makes its overall performance up to 100 times faster than Sun's NIT running on the same hardware. © 1993 USENIX.All right reserved.","1993","2025-10-22 19:07:39","2025-10-22 19:07:39","","259-269","","","","","","","","","","","","","","","","Scopus","","","","","","","","Packet filters; Buffering strategy; Computer workstations; Network Monitoring; Network monitors; On currents; Original design; Packet capture; Program processors; UNIX; Unwanted packets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Winter 1993 USENIX Conference","","","","","","","","","","","","","","",""
"QVQUQZ9A","journalArticle","","","","New Relic","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032364452&partnerID=40&md5=035c21ebc0c2e6e8722e8b235dd6756a","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WRTKKX3V","conferencePaper","2019","Gan, Y.; Zhang, Y.; Hu, K.; Cheng, D.; He, Y.; Pancholi, M.; Delimitrou, C.","Seer: Leveraging Big Data to Navigate the Complexity of Performance Debugging in Cloud Microservices","","","","10.1145/3297858.3304004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064659746&doi=10.1145%2f3297858.3304004&partnerID=40&md5=67a5e54db5ebf1ecee4bb2bc5f5c7790","Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether.We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91% of the time, and avoids the QoS violation to begin with in 84% of cases. Finally, we show that Seer can identify applicationlevel design bugs, and provide insights on how to better architect microservices to achieve predictable performance. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","19-33","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Datacenter; Microservice; Big data; Cloud adoptions; cloud computing; Cloud computing; Cloud-computing; data mining; Data mining; datacenter; deep learning; Deep learning; Information management; microservices; monitoring; Online systems; Performance; Performance costs; performance debugging; Performance debugging; Program debugging; QoS; resource management; Resource management; tracing; Tracing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"8P7NLAVW","conferencePaper","2021","Cinque, M.; Corte, R.D.; Pecchia, A.","Microservices Monitoring with Event Logs and Black Box Execution Tracing","","","","10.1109/SERVICES51467.2021.00023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123717085&doi=10.1109%2fSERVICES51467.2021.00023&partnerID=40&md5=b47f6212972444f8cbf91ea1484a88ae","Monitoring is a core practice in any software system, and entails gathering a variety of data sources that pertain the execution of a given system. Trends in microservices systems exacerbate the role of monitoring. Microservices put forth reduced size, independency, flexibility and modularity principles, which well cope with ever-changing business environments. However, as real-world applications are decomposed, they can easily reach hundreds of microservices. This inherent complexity determines an increasing difficulty in debugging, monitoring and forensics, and poses novel challenges to monitoring data sources, such as event logs.  © 2021 IEEE.","2021","2025-10-22 19:07:39","2025-10-22 19:07:39","","12","","","","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Black boxes; Clearwater; Data-source; Docker; Event logs; Execution tracing; Kubernetes; Log analysis; Microservice; Microservices; REST","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2021 IEEE World Congress on Services, SERVICES 2021","","","","","","","","","","","","","","",""
"VUFU7X8V","journalArticle","1999","Begel, A.; McCanne, S.; Graham, S.L.","BPF+: Exploiting global data-flow optimization in a generalized packet filter architecture","Computer Communication Review","","","10.1145/316194.316214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033204392&doi=10.1145%2f316194.316214&partnerID=40&md5=cf36885f99deda499012c5ad05b666d9","A packet filler is a programmable selection criterion for classifying or selecting packets from a packet stream in a generic, reusable fashion. Previous work on packet filters falls roughly into two categories, namely those efforts that investigate flexible and extensible filter abstractions but sacrifice performance, and those that focus on low-level, optimized filtering representations but sacrifice flexibility. Applications like network monitoring and intrusion detection, however, require both high-level expressiveness and raw performance. In this paper, we propose a fully general packet filter framework that affords both a high degree of flexibility and good performance. In our framework, a packet filter is expressed in a high-level language that is compiled into a highly efficient native implementation. The optimization phase of the compiler uses a flowgraph set relation called edge dominators and the novel application of an optimization technique that we call ""redundant predicate elimination,"" in which we interleave partial redundancy elimination, predicate assertion propagation, and flowgraph edge elimination to carry out the filter predicate optimization. Our resulting packet-filtering framework, which we call BPF+, derives from the BSD packet filter (BPF), and includes a filter program translator, a byte code optimizer, a byte code safety verifier to allow code to migrate across protection boundaries, and a just-in-time assembler to convert byte codes to efficient native code. Despite the high degree of flexibility afforded by our generalized framework, our performance measurements show that our system achieves performance comparable to state-of-the-art packet filter architectures and better than hand-coded filters written in C. © 1999 ACM.","1999","2025-10-22 19:07:39","2025-10-22 19:07:39","","123-134","","4","29","","","","","","","","","","","","","Scopus","","","","","","","","Codes (symbols); Data communication systems; Data flow analysis; High level languages; Optimization; Packet filters; Packet switching; Program compilers; Signal filtering and prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NUCCQC7K","journalArticle","2010","De Melo, A.C.","The new linux perf tools","Slides from Linux Kongress","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937476715&partnerID=40&md5=32d69aa6271f145acae831317024ae7b","","2010","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUCVL6KP","journalArticle","2014","Lewis, J.; Fowler, M.","Microservices: A definition of this new architectural term","Microservices: A Definition of This New Architectural Term","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964234114&partnerID=40&md5=fd3de0bd7b34545e47485cf075757737","","2014","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"34Y2DI87","journalArticle","2021","Masouros, D.; Xydis, S.; Soudris, D.","Rusty: Runtime Interference-Aware Predictive Monitoring for Modern Multi-Tenant Systems","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2020.3013948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090449884&doi=10.1109%2fTPDS.2020.3013948&partnerID=40&md5=ef543cd52dc6f2508a315444a314d165","Modern micro-service and container-based cloud-native applications have leveraged multi-tenancy as a first class system design concern. The increasing number of co-located services/workloads into server facilities stresses resource availability and system capability in an unconventional and unpredictable manner. To efficiently manage resources in such dynamic environments, run-time observability and forecasting are required to capture workload sensitivities under differing interference effects, according to applied co-location scenarios. While several research efforts have emerged on interference-aware performance modelling, they are usually applied at a very coarse-grained manner e.g., estimating the overall performance degradation of an application, thus failing to effectively quantify, predict or provide educated insights on the impact of continuous runtime interference on per-resource allocations. In this paper, we present Rusty, a predictive monitoring system that leverages the power of Long Short-Term Memory networks to enable fast and accurate runtime forecasting of key performance metrics and resource stresses of cloud-native applications under interference. We evaluate Rusty under a diverse set of interference scenarios for a plethora of representative cloud workloads, showing that Rusty i) achieves extremely high prediction accuracy, average $R^2$R2 value of 0.98, ii) enables very deep prediction horizons retaining high accuracy, e.g., $R^2$R2 of around 0.99 for a horizon of 1 sec ahead and around 0.94 for an horizon of 5 sec ahead, while iii) satisfying, at the same time, the strict latency constraints required to make Rusty practical for continuous predictive monitoring at runtime.  © 1990-2012 IEEE.","2021","2025-10-22 19:07:39","2025-10-22 19:07:39","","184-198","","1","32","","","","","","","","","","","","","Scopus","","","","","","","","Dynamic environments; Forecasting; interference aware; Interference effects; Latency constraints; LSTM networks; multi-tenant systems; Performance degradation; Performance metrics; Performance modelling; predictive monitoring; Predictive monitoring; Resource availability; Signal processing; system predictability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJRL7WPI","conferencePaper","2013","Shen, K.; Shriraman, A.; Dwarkadas, S.; Zhang, X.; Chen, Z.","Power containers: An OS facility for fine-grained power and energy management on multicore servers","","","","10.1145/2499368.2451124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880084057&doi=10.1145%2f2499368.2451124&partnerID=40&md5=112375f1784ddee3e8da2b03c015e68e","Energy efficiency and power capping are critical concerns in server and cloud computing systems. They face growing challenges due to dynamic power variations from new client-directed web applications, as well as complex behaviors due to multicore resource sharing and hardware heterogeneity. This paper presents a new operating system facility called ""power containers"" that accounts for and controls the power and energy usage of individual fine-grained requests in multicore servers. This facility relies on three key techniques-1) online model that attributes multicore power (including shared maintenance power) to concurrently running tasks, 2) alignment of actual power measurements and model estimates to enable online model recalibration, and 3) on-the-fly applicationtransparent request tracking in multi-stage servers to isolate the power and energy contributions and customize per-request control. Our mechanisms enable new multicore server management capabilities including fair power capping that only penalizes powerhungry requests, and energy-aware request distribution between heterogeneous servers. Our evaluation uses three multicore processors (Intel Woodcrest, Westmere, and SandyBridge) and a variety of server and cloud computing (Google App Engine) workloads. Our results demonstrate the high accuracy of our request power accounting (no more than 11% errors) and the effectiveness of container-enabled power virus isolation and throttling. Our request distribution case study shows up to 25% energy saving compared to an alternative approach that recognizes machine heterogeneity but not fine-grained workload affinity.","2013","2025-10-22 19:07:39","2025-10-22 19:07:39","","65-76","","","48","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Containers; Embedded systems; Energy efficiency; Hardware counters; Multi core; Multicore; Operating system; Platform as a Service (PaaS); Power modeling; Power virus; Server and cloud computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM SIGPLAN Notices","","","","","","","","","","","","","","",""
"9VTPQU87","conferencePaper","2014","Zhai, Y.; Zhang, X.; Eranian, S.; Tang, L.; Mars, J.","Happy: Hyperthread-aware power profiling dynamically","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077459426&partnerID=40&md5=2097f753ffcf901217994ca6b5f04c69","Quantifying the power consumption of individual applications co-running on a single server is a critical component for software-based power capping, scheduling, and provisioning techniques in modern datacenters. However, with the proliferation of hyperthreading in the last few generations of server-grade processor designs, the challenge of accurately and dynamically performing this power attribution to individual threads has been significantly exacerbated. Due to the sharing of core-level resources such as functional units, prior techniques are not suitable to attribute the power consumption between hyperthreads sharing a physical core. In this paper, we present a runtime mechanism that quantifies and attributes power consumption to individual jobs at fine granularity. Specifically, we introduce a hyperthread-aware power model that differentiates between the states when both hardware threads of a core are in use, and when only one thread is in use. By capturing these two different states, we are able to accurately attribute power to each logical CPU in modern servers. We conducted experiments with several Google production workloads on an Intel Sandy Bridge server. Compared to prior hyperthread-oblivious model, HaPPy is substantially more accurate, reducing the prediction error from 20.5% to 7.5% on average and from 31.5% to 9.4% in the worst case. © Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014. All rights reserved.","2014","2025-10-22 19:07:39","2025-10-22 19:07:39","","211-217","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Electric power utilization; Critical component; Datacenter; Functional units; Hyperthreading; Multitasking; Physical core; Power; Power capping; Power profiling; Processor design; Single server","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014","","","","","","","","","","","","","","",""
"XLRVABI2","journalArticle","1984","Lazowska, E.D.; Zahorjan, J.; Graham, G.S.; Sevcik, K.C.","","Quantitative System Performance: Computer System Analysis Using Queueing Network Models","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003834102&partnerID=40&md5=2510094fe765c8f8f6d6acde2842053a","","1984","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5LRPW3TX","journalArticle","2018","Ferroni, M.; Colmenares, J.A.; Hofmeyr, S.; Kubiatowicz, J.D.; Santambrogio, M.D.","Enabling power-awareness for the Xen hypervisor","ACM SIGBED Review","","","10.1145/3199610.3199615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089730588&doi=10.1145%2f3199610.3199615&partnerID=40&md5=ba0885caf8d819a4e0b46b4fc0e243e3","Virtualization allows simultaneous execution of multi-tenant workloads on the same platform, either a server or an embedded system. Unfortunately, it is non-trivial to attribute hardware events to multiple virtual tenants, as some system's metrics relate to the whole system (e.g., RAPL energy counters). Virtualized environments have then a rather incomplete picture of how tenants use the hardware, limiting their optimization capabilities. Thus, we propose XeM-Power, a lightweight monitoring solution for Xen that precisely accounts hardware events to guest workloads. It also enables attribution of CPU power consumption to individual tenants. We show that XeMPower introduces negligible overhead in power consumption, aiming to be a reference design for power-aware virtualized environments. © 2018 Authors.","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","36-42","","1","15","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Power management; Electric power utilization; Hypervisor; Multi tenants; Non-trivial; Optimization capabilities; Power awareness; Power-aware; Reference designs; Virtualized environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JWFVH6AP","journalArticle","","","","Weave Scope","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071420868&partnerID=40&md5=bb45823128e041f19b65cab560af010b","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTGCSK9A","conferencePaper","2014","Deri, L.; Martinelli, M.; Cardigliano, A.","Realtime high-speed network traffic monitoring using ntopng","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949487110&partnerID=40&md5=6dc0ba001f6a954b4b4e7d7fdc86575f","Monitoring network traffic has become increasingly challenging in terms of number of hosts, protocol proliferation and probe placement topologies. Virtualised environments and cloud services shifted the focus from dedicated hardware monitoring devices to virtual machine based, software traffic monitoring applications. This paper covers the design and implementation of ntopng, an open-source traffic monitoring application designed for high-speed networks. ntopng's key features are large networks real-time analytics and the ability to characterise application protocols and user traffic behaviour. ntopng was extensively validated in various monitoring environments ranging from small networks to.it ccTLD traffic analysis. © LISA 2014.All right reserved.","2014","2025-10-22 19:07:39","2025-10-22 19:07:39","","69-79","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Application protocols; Behavioral research; Dedicated hardware; Design and implementations; High speed network traffic; HIgh speed networks; Internet protocols; Monitoring; Monitoring environment; Open source software; Real-time analytics; Traffic monitoring; Virtualised environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","28th Large Installation System Administration Conference, LISA 2014","","","","","","","","","","","","","","",""
"DYBW4SMN","conferencePaper","2000","Bellosa, F.","The benefits of event-driven energy accounting in power-sensitive systems","","","","10.1145/566726.566736","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944384544&doi=10.1145%2f566726.566736&partnerID=40&md5=acdcf8e369e9024a3056aa6cdfc18124","A prerequisite of energy-aware scheduling is precise knowledge of any activity inside the computer system. Embedded hardware monitors (e.g., processor performance counters) have proved to offer valuable information in the field of performance analysis. The same approach can be applied to investigate the energy usage patterns of individual threads. We use information about active hardware units (e.g., integer/floating point unit, cache/memory interface) gathered by event counters to establish a thread-specific energy accounting. The evaluation shows that the correlation of events and energy values provides the necessary information for energy-aware scheduling policies. Our approach to OS-directed power management adds the energy usage pattern to the runtime context of a thread. Depending on the field of application we present two scenarios that benefit from applying energy usage patterns: Workstations with passive cooling on the one hand and battery-powered mobile systems on the other hand. Energy-aware scheduling evaluates the energy usage of each thread and throttles the system activity so that the scheduling goal is achieved. In workstations we throttle the system if the average energy use exceeds a predefined power-dissipation capacity. This makes a compact, noiseless and affordable system design possible that meets sporadic yet high demands in computing power. Nowadays, more and more mobile systems offer the features of reducible clock speed and dynamic voltage scaling. Energy-aware scheduling can employ these features to yield a longer battery life by slowing down low-priority threads while preserving a certain quality of service.","2000","2025-10-22 19:07:39","2025-10-22 19:07:39","","37-42","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Computer systems programming; Cooling systems; Electric batteries; Embedded hardware; Energy accounting; Energy-aware scheduling; Hardware; Passive cooling; Performance analysis; Power management; Power-sensitive systems; Processor performance; Quality of service; Scheduling; Specific energy; Voltage scaling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 9th Workshop on ACM SIGOPS European Workshop: Beyond the PC: New Challenges for the Operating System, EW 2000","","","","","","","","","","","","","","",""
"R9S9JJL9","journalArticle","2016","Burns, B.; Grant, B.; Oppenheimer, D.; Brewer, E.; Wilkes, J.","Borg, omega, and kubernetes","Queue","","","10.1145/2898442.2898444","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960969836&doi=10.1145%2f2898442.2898444&partnerID=40&md5=d0defa676806718c1a9b91c2e9c70de1","","2016","2025-10-22 19:07:39","2025-10-22 19:07:39","","70-93","","1","14","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDQP37ZJ","journalArticle","2019","Brondolin, R.; Ferroni, M.; Santambrogio, M.","Performance-aware load shedding for monitoring events in container based environments","ACM SIGBED Review","","","10.1145/3373400.3373404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075802823&doi=10.1145%2f3373400.3373404&partnerID=40&md5=cd5ff103db1c4e292adb5a6975238249","Runtime monitoring tools have become fundamental to assess the correct operation of complex systems and applications. Unfortunately, the more precise is the monitoring (sampling rate, information granularity, and so on), the higher is the overhead introduced in the system itself. In this paper, we propose a new load shedding framework that enables runtime adaptation of monitoring agents under heavy system load, exploiting an heuristic Load Manager to control the agent status and a runtime support for domain-specific policies. We implemented the proposed methodology on Sysdig, with an average control error improvement of 3.51x (12.25x at most), w.r.t. previous solutions. Copyright held by Owner/Author","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","27-32","","3","16","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Data-stream processing; Load Shedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IKZXIRHF","conferencePaper","2018","Pina, F.; Correia, J.; Filipe, R.; Araujo, F.; Cardroom, J.","Nonintrusive monitoring of microservice-based systems","","","","10.1109/NCA.2018.8548311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059972659&doi=10.1109%2fNCA.2018.8548311&partnerID=40&md5=a4c3f4f828fddb283ee6b003982d66a8","Breaking large software systems into smaller functionally interconnected components is a trend on the rise. This architectural style, known as 'microservices', simplifies development, deployment and management at the expense of complexity and observability. In fact, in large scale systems, it is particularly difficult to determine the set of microservices responsible for delaying a client's request, when one module impacts several other microservices in a cascading effect. Components cannot be analyzed in isolation, and without instrumenting their source code extensively, it is difficult to find the bottlenecks and trace their root causes. To mitigate this problem, we propose a much simpler approach: log gateway activity, to register all calls to and between microservices, as well as their responses, thus enabling the extraction of topology and performance metrics, without changing source code. For validation, we implemented the proposed platform, with a microservices-based application that we observe under load. Our results show that we can extract relevant performance information with a negligible effort, even in legacy systems, where instrumenting modules may be a very expensive task. © 2018 IEEE.","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance metrics; Black boxes; Microservices; Large scale systems; Gateways (computer networks); Architectural style; Black-box monitoring; Cascading effects; Gateway; Large software systems; Legacy systems; Non-intrusive monitoring; Source codes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NCA 2018 - 2018 IEEE 17th International Symposium on Network Computing and Applications","","","","","","","","","","","","","","",""
"ICVAYJRL","conferencePaper","2017","Asnaghi, A.; Ferroni, M.; Santambrogio, M.D.","DockerCap: A Software-Level Power Capping Orchestrator for Docker Containers","","","","10.1109/CSE-EUC-DCABES.2016.166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026642569&doi=10.1109%2fCSE-EUC-DCABES.2016.166&partnerID=40&md5=19be1729ebe7a99678ff8c78e63497c8","Internet of Things (IoT) is experiencing a huge hype these days, thanks to the increasing capabilities of embedded devices that enable their adoption in new fields of application (e.g. Wireless Sensor Networks, Connected Cars, Health Care, etc.). On the one hand, this is leading to an increasing adoption of multi-tenancy solutions for Cloud and Fog Computing, to analyze and store the data produced. On the other hand, power consumption has become a major concern for almost every digital system, from the smallest embedded circuits to the biggest computer clusters, with all the shades in between. Fine-grain control mechanisms are then needed to cap power consumption at each level of the stack, still guaranteeing Service Level Agreements (SLA) to the hosted applications. In this work, we propose DockerCap, a software-level power capping orchestrator for Docker containers that follows an Observe-Decide-Act loop structure: this allows to quickly react to changes that impact on the power consumption by managing resources of each container at run-time, to ensure the desired power cap. We show how we are able to obtain results comparable with the state of the art power capping solution provided by Intel RAPL, still being able to tune the performances of the containers and even guarantee SLA constraints. © 2016 IEEE.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","90-97","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Electric power utilization; Containers; Docker; Distributed computer systems; Internet of things; Service Level Agreements; Ubiquitous computing; Internet of Things (IOT); State of the art; Green computing; Wireless sensor networks; Computer clusters; Embedded circuits; Fine-grain controls; Fog Computing; Managing resources; Power Management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 19th IEEE International Conference on Computational Science and Engineering, 14th IEEE International Conference on Embedded and Ubiquitous Computing and 15th International Symposium on Distributed Computing and Applications to Business, Engineering and Science, CSE-EUC-DCABES 2016","","","","","","","","","","","","","","",""
"V85BTZ5N","conferencePaper","2018","Brondolin, R.; Sardelli, T.; Santambrogio, M.D.","DEEP-mon: Dynamic and energy efficient power monitoring for container-based infrastructures","","","","10.1109/IPDPSW.2018.00110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052236003&doi=10.1109%2fIPDPSW.2018.00110&partnerID=40&md5=b3fc988b43b9d7d4cf6b652e09435256","In the last few years energy efficiency of large scale infrastructures gained a lot of attention, as power consumption became one of the most impacting factors of the operative costs of a data-center and of its Total Cost of Ownership (TCO). Power consumption can be observed at different layers of the data-center, from the overall power grid, moving to each rack and arriving to each machine and system. Given the rise of application containers both in the cloud computing and High Performance Computing (HPC) scenarios, it becomes more and more important to measure power consumption also at the application level, where power-aware schedulers and orchestrators can optimize the execution of the workloads not only from a performance perspective, but also considering performance/power trade-offs. In this paper we propose DEEP-mon, a novel monitoring tool able to measure power consumption and attribute it for each thread and application container running in the system. Moreover, we show how the proposed approach has a negligible impact on the monitored system and on the running workloads, overcoming the limitations of the previous works in the field. © 2018 IEEE.","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","676-684","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Monitoring; Electric power utilization; Power awareness; Containers; Energy efficiency; Distributed computer systems; Economic and social effects; Green computing; Total cost of ownership; Application containers; Application level; Electric power transmission networks; High performance computing (HPC); Impacting factor; Large scale infrastructures; Monitored systems; Power attribution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2018 IEEE 32nd International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2018","","","","","","","","","","","","","","",""
"DJQKWC2W","journalArticle","2012","Rotem, E.; Naveh, A.; Ananthakrishnan, A.; Weissmann, E.; Rajwan, D.","Power-management architecture of the intel microarchitecture code-named Sandy Bridge","IEEE Micro","","","10.1109/MM.2012.12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859729360&doi=10.1109%2fMM.2012.12&partnerID=40&md5=ac411761c3d90741a5eebafa6fed9716","Modern microprocessors are evolving into system-on-a-chip designs with high integration levels, catering to ever-shrinking form factors. Portability without compromising performance is a driving market need. An architectural approach that's adaptive to and cognizant of workload behavior and platform physical constraints is indispensable to meeting these performance and efficiency goals. This article describes power-management innovations introduced on Intel's Sandy Bridge microprocessor. © 2012 IEEE.","2012","2025-10-22 19:07:39","2025-10-22 19:07:39","","20-27","","2","32","","","","","","","","","","","","","Scopus","","","","","","","","Program processors; Energy management; Application specific integrated circuits; Approximation theory; Architectural approach; energy management; Form factors; High integration level; Market needs; Micro architectures; Microprocessor chips; Modern microprocessor; Physical constraints; power management; Power managements; Sandy Bridge; System-on-a-chip designs; Turbo Boost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWM5TB4L","journalArticle","2019","Deri, L.; Sabella, S.; Mainardi, S.","Combining system visibility and security using eBPF","Italian Conference on Cybersecurity","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102386111&partnerID=40&md5=4c6391aeed60593ddea37f793f19591e","","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JILK9UY6","journalArticle","1999","Mucci, P.J.; Browne, S.; Deane, C.; Ho, G.","PAPI: A portable interface to hardware performance counters","Proceedings of the Department of Defense HPCMP Users Group Conference","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646222013&partnerID=40&md5=24440d72bf4d73c520b743720ddc1dae","","1999","2025-10-22 19:07:39","2025-10-22 19:07:39","","7-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KES7IVIY","conferencePaper","2023","Adeppady, M.; Conte, A.; Karl, H.; Giaccone, P.; Chiasserini, C.F.","Energy-aware Provisioning of Microservices for Serverless Edge Computing","","","","10.1109/GLOBECOM54140.2023.10437798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187344836&doi=10.1109%2fGLOBECOM54140.2023.10437798&partnerID=40&md5=3407e06752dd06c798af012e211b4933","Serverless edge computing allows for highly efficient resource utilization, reducing the energy footprint of edge data centers. Indeed, the containers can be dynamically created and destroyed, allowing to adapt the workload to the available resources. Creating containers upon arrivals of service requests entails, however, a high start-up latency, which may be unsuitable for time-critical services. As alternative solution, pre-started containers ('warm containers') are used to decrease start-up latency, but incurring in higher resource costs. In this work, we minimize the energy consumption of the active servers in the data center by optimally managing the various container states while meeting the target delay of the requested services. Further, in light of the problem complexity, we investigate how a simple threshold-based algorithm performs and show that it can closely match the optimum. © 2023 IEEE.","2023","2025-10-22 19:07:39","2025-10-22 19:07:39","","3070-3075","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Containers; Datacenter; Energy utilization; Edge computing; Energy; Green computing; Resources utilizations; Alternative solutions; Critical service; Edge data; Energy-aware provisioning; Service requests; Time-critical","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Global Communications Conference, GLOBECOM","","","","","","","","","","","","","","",""
"JAZM5ZW8","conferencePaper","2019","Kim, J.; Lee, K.","FunctionBench: A suite of workloads for serverless cloud function service","","","","10.1109/CLOUD.2019.00091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072317217&doi=10.1109%2fCLOUD.2019.00091&partnerID=40&md5=d0cba5a320a7466c6ad22981b03f0d34","Serverless computing is attracting considerable attention recently, but many published papers use micro-benchmarks for evaluation that might result in impracticality. To address this, we present FunctionBench, a suite of practical function workloads for public services. It contains realistic data-oriented applications that utilize various resources during execution. The source codes customized for various cloud service providers are publicly available. We are positive that it suggests opportunities for new function applications with lessen experiment setup overheads. © 2019 IEEE.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","502-504","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Serverless; Clouds; Computer science; Benchmarking; FaaS; Computer programming; Cloud; New functions; Benchmark; Cloud service providers; Experiment set-up; Micro-benchmark; Public services; Workload","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"WJ3MU98R","journalArticle","","","","Vmstat—Report virtual memory statistics","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003949265&partnerID=40&md5=18ba8b5b142f75196a2e82c9a1ff961e","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKSNFERJ","journalArticle","2020","Zhao, L.","Rhythm: Component-distinguishable workload deployment in datacenters","Proc. 15th Eur. Conf. Comput. Syst","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121740906&partnerID=40&md5=71a7f3c61786dd341a562b21bcf4a600","","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","1-17","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UJNNAZE","conferencePaper","2020","Cadden, J.; Unger, T.; Awad, Y.; Dong, H.; Krieger, O.; Appavoo, J.","SEUSS: Skip redundant paths to make serverless fast","","","","10.1145/3342195.3392698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087107959&doi=10.1145%2f3342195.3392698&partnerID=40&md5=7c393950590d0b7cd76c31891e4148d7","This paper presents a system-level method for achieving the rapid deployment and high-density caching of serverless functions in a FaaS environment. For reduced start times, functions are deployed from unikernel snapshots, bypassing expensive initialization steps. To reduce the memory footprint of snapshots we apply page-level sharing across the entire software stack that is required to run a function. We demonstrate the effects of our techniques by replacing Linux on the compute node of a FaaS platform architecture. With our prototype OS, the deployment time of a function drops from 100s of milliseconds to under 10 ms. Platform throughput improves by 51x on workload composed entirely of new functions. We are able to cache over 50,000 function instances in memory as opposed to 3,000 using standard OS techniques. In combination, these improvements give the FaaS platform a new ability to handle large-scale bursts of requests. © 2020 ACM.","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer operating systems; Memory footprint; Cache memory; Deployment time; Initialization step; New functions; Platform architecture; Rapid deployments; Redundant paths; Software stacks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 15th European Conference on Computer Systems, EuroSys 2020","","","","","","","","","","","","","","",""
"VNTF5DTE","journalArticle","","","","Apache OpenWhisk","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052391921&partnerID=40&md5=ab5ddcbe8d8cbd17177a5e410c26c70a","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXJ33RRT","journalArticle","","","","Cloud Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014238761&partnerID=40&md5=dc60b1e7e73ef6a1d4f3d133131e79cd","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XM2VJWGB","journalArticle","2019","Mohan, Anup; Sane, Harshad; Doshi, Kshitij; Edupuganti, Saikrishna; Nayak, Naren; Sukhomlinov, Vadim","Agile cold starts for scalable serverless","Proc. HotCloud","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181985770&partnerID=40&md5=b4f008f48c40d00af00858bb2ebb5c86","","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B9TQIWQT","journalArticle","","","","Memory and computing power at Amazon lambda","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003943978&partnerID=40&md5=9267b8050649fe4b7a0892c05281bab8","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CF3V5MNS","conferencePaper","2019","Kannan, R.S.; Subramanian, L.; Raju, A.; Ahn, J.; Mars, J.; Tang, L.","GrandSLAm: Guaranteeing SLAs for jobs in microservices execution frameworks","","","","10.1145/3302424.3303958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063902706&doi=10.1145%2f3302424.3303958&partnerID=40&md5=3421b52ef10bf2d471d82be441436ba2","The microservice architecture has dramatically reduced user effort in adopting and maintaining servers by providing a catalog of functions as services that can be used as building blocks to construct applications. This has enabled datacenter operators to look at managing datacenter hosting microservices quite differently from traditional infrastructures. Such a paradigm shift calls for a need to rethink resource management strategies employed in such execution environments. We observe that the visibility enabled by a microservices execution framework can be exploited to achieve high throughput and resource utilization while still meeting Service Level Agreements, especially in multi-tenant execution scenarios. In this study, we present GrandSLAm, a microservice execution framework that improves utilization of datacenters hosting microservices. GrandSLAm estimates time of completion of requests propagating through individual microservice stages within an application. It then leverages this estimate to drive a runtime system that dynamically batches and reorders requests at each microservice in a manner where individual jobs meet their respective target latency while achieving high throughput. GrandSLAm significantly increases throughput by up to 3× compared to the our baseline, without violating SLAs for a wide range of real-world AI and ML applications. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Resource management; Service Level Agreements; Learning systems; Building blockes; Computer systems; Execution environments; Execution framework; Execution scenario; Machine Learning; Resource utilizations; Systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 14th EuroSys Conference 2019","","","","","","","","","","","","","","",""
"HVF5QXTG","journalArticle","2018","Akkus, I.E.; Chen, R.; Rimac, I.; Stein, M.; Satzke, K.; Beck, A.; Aditya, P.; Hilt, V.","SAND: Towards High-Performance Serverless Computing","USENIX ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062596504&partnerID=40&md5=69803d1ae53e00a17efa1267107cd265","","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","923-935","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5UWD5WZ","journalArticle","2020","Gunasekaran, Jashwant Raj; Thinakaran, Prashanth; Nachiappan, Nachiappan C; Kandemir, Mahmut Taylan; Das, Chita R","Fifer: Tackling resource underutilization in the serverless era","Proceedings of the ACM/IFIP/USENIX International Middleware Conference (Middleware)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099724585&partnerID=40&md5=f426d3314eb0a2c92cd7bd633091a5b7","","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLKVR8Y5","conferencePaper","2022","Li, Z.; Guo, L.; Chen, Q.; Cheng, J.; Xu, C.; Zeng, D.; Song, Z.; Ma, T.; Yang, Y.; Li, C.; Guo, M.","Help Rather Than Recycle: Alleviating Cold Startup in Serverless Computing Through Inter-Function Container Sharing","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137787065&partnerID=40&md5=cae1d5bf3a230156bd84ee6d47324708","In serverless computing, each function invocation is executed in a container (or a Virtual Machine), and container cold startup results in long response latency. We observe that some functions suffer from cold container startup, while the warm containers of other functions are idle. Based on the observation, other than booting a new container for a function from scratch, we propose to alleviate the cold startup by re-purposing a warm but idle container from another function. We implement a container management scheme, named Pagurus, to achieve the purpose. Pagurus comprises an intra-function manager for replacing an idle warm container to be a container that other functions can use without introducing additional security issues, an inter-function scheduler for scheduling containers between functions, and a sharingaware function balancer at the cluster-level for balancing the workload across different nodes. Experiments using Azure serverless traces show that Pagurus alleviates 84.6% of the cold startup, and the cold startup latency is reduced from hundreds of milliseconds to 16 milliseconds if alleviated. © 2022 USENIX Annual Technical Conference, ATC 2022.All rights reserved.","2022","2025-10-22 19:07:39","2025-10-22 19:07:39","","69-84","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Containers; Balancing; Container management; Management scheme; Security issues","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2022 USENIX Annual Technical Conference, ATC 2022","","","","","","","","","","","","","","",""
"47YT9TV6","journalArticle","2023","Xie, R.; Gu, D.; Tang, Q.; Huang, T.; Yu, F.R.","Workflow Scheduling in Serverless Edge Computing for the Industrial Internet of Things: A Learning Approach","IEEE Transactions on Industrial Informatics","","","10.1109/TII.2022.3217477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141466873&doi=10.1109%2fTII.2022.3217477&partnerID=40&md5=66543484125a586a3e40a1558926b76a","Serverless edge computing is seen as a promising enabler to execute differentiated Industrial Internet of Things (IIoT) applications without managing the underlying servers and clusters. In IIoT serverless edge computing, IIoT workflow scheduling for cloud-edge collaborative processing is closely related to the service quality of users. However, serverless functions decomposed by IIoT applications are limited in their deployment at the edge due to the resource-constrained nature of edge infrastructures. In addition, the scheduling of complex IIoT applications supported by serverless computing is more challenging. Therefore, considering the limited function deployment and the complex dependencies of serverless workflows, we model the workflow application as directed acyclic graph and formulate the scheduling problem as a multiobjective optimization problem. A dueling double deep Q-network-based solution is proposed to make scheduling decisions under dynamically changing systems. Extensive simulation experiments are conducted to validate the superiority of the proposed scheme.  © 2005-2012 IEEE.","2023","2025-10-22 19:07:39","2025-10-22 19:07:39","","8242-8252","","7","19","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Deep learning; Internet of things; Edge computing; Wireless communications; Complex networks; Computational modelling; Deep reinforcement learning; Deep reinforcement learning (DRL); Directed graphs; Industrial internet of thing; Job analysis; Job shop scheduling; Job-Shop scheduling; Multi-objectives optimization; multiobjective optimization; Multiobjective optimization; Processor scheduling; Reinforcement learning; Reinforcement learnings; serverless edge computing; Serverless edge computing; Task analysis; workflow scheduling; Workflow scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2J29XMWD","journalArticle","2019","Jonas, E.","Cloud programming simplified: A Berkeley view on serverless computing","Cloud Programming Simplified: A Berkeley View on Serverless Computing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067433472&partnerID=40&md5=85287d7260661386b411bc1efadbde9b","","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUUK9GB5","conferencePaper","2021","Mampage, A.; Karunasekera, S.; Buyya, R.","Deadline-aware dynamic resource management in serverless computing environments","","","","10.1109/CCGrid51090.2021.00058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108510704&doi=10.1109%2fCCGrid51090.2021.00058&partnerID=40&md5=890ec416032c734fae061d3a62717af1","Serverless computing enables rapid application development and deployment by composing loosely coupled microservices at a scale. This emerging paradigm greatly unburdens the users of cloud environments, from the need to provision and manage the underlying cloud resources. With this shift in responsibility, the cloud provider faces the challenge of providing acceptable performance to the user without compromising on reliability, while having minimal knowledge of the application requirements. Sub-optimal resource allocations, specifically the CPU resources, could result in the violation of performance requirements of applications. Further, the fine-grained serverless billing model only charges for resource usage in terms of function execution time. At the same time, the provider has to maintain the underlying infrastructure in always-on mode to facilitate asynchronous function calls. Thus, achieving optimum utilization of cloud resources without compromising on application requirements is of high importance to the provider. Most of the current works only focus on minimizing function execution times caused by delays in infrastructure set up and reducing resource costs for the end-user. However, in this paper, we focus on both the provider and user's perspective and propose a function placement policy and a dynamic resource management policy for applications deployed in serverless computing environments. The policies minimize the resource consumption cost for the service provider while meeting the user's application requirement, i.e., deadline. The proposed solutions are sensitive to deadline and efficiently increase the resource utilization for the provider, while dynamically managing resources to improve function response times. We implement and evaluate our approach through simulation using ContainerCloudSim toolkit. The proposed function placement policy when compared with baseline scheduling techniques can reduce resource consumption by up to three times. The dynamic resource allocation policy when evaluated with a fixed resource allocation policy and a proportional CPU-shares policy shows improvements of up to 25% in meeting the required function deadlines. © 2021 IEEE.","2021","2025-10-22 19:07:39","2025-10-22 19:07:39","","483-492","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cluster computing; Dynamic resource allocations; Natural resources management; Resource allocation; Computing environments; Performance requirements; serverless computing; Application requirements; dy-namic resource management; Dynamic resource management; Environmental management; function placement; Optimal resource allocation; Rapid application development; Resource allocation policy; resource efficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2021","","","","","","","","","","","","","","",""
"C6FHASMQ","conferencePaper","2020","Oakes, E.; Yang, L.; Zhou, D.; Houck, K.; Harter, T.; Arpaci-Dusseau, A.C.; Arpaci-Dusseau, R.H.","SOCK: Rapid task provisioning with serverless-optimized containers","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077468687&partnerID=40&md5=4e3d486e4ba7e8e882f63bf763e28a81","Serverless computing promises to provide applications with cost savings and extreme elasticity. Unfortunately, slow application and container initialization can hurt common-case latency on serverless platforms. In this work, we analyze Linux container primitives, identifying scalability bottlenecks related to storage and network isolation. We also analyze Python applications from GitHub and show that importing many popular libraries adds about 100 ms to startup. Based on these findings, we implement SOCK, a container system optimized for serverless workloads. Careful avoidance of kernel scalability bottlenecks gives SOCK an 18× speedup over Docker. A generalized-Zygote provisioning strategy yields an additional 3× speedup. A more sophisticated three-tier caching strategy based on Zygotes provides a 45× speedup over SOCK without Zygotes. Relative to AWS Lambda and OpenWhisk, OpenLambda with SOCK reduces platform overheads by 2.8× and 5.3× respectively in an image processing case study. © Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018. All rights reserved.","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","57-69","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Computer operating systems; Image processing; Caching strategy; Cost saving; Network isolation; Scalability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018","","","","","","","","","","","","","","",""
"67D7KK4P","conferencePaper","2022","Pan, L.; Wang, L.; Chen, S.; Liu, F.","Retention-Aware Container Caching for Serverless Edge Computing","","","","10.1109/INFOCOM48880.2022.9796705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133285886&doi=10.1109%2fINFOCOM48880.2022.9796705&partnerID=40&md5=5d8c244a23c67dea264b5e9f05ee86de","Serverless edge computing adopts an event-based model where Internet-of-Things (IoT) services are executed in lightweight containers only when requested, leading to significantly improved edge resource utilization. Unfortunately, the startup latency of containers degrades the responsiveness of IoT services dramatically. Container caching, while masking this latency, requires retaining resources thus compromising resource efficiency. In this paper, we study the retention-aware container caching problem in serverless edge computing. We leverage the distributed and heterogeneous nature of edge platforms and propose to optimize container caching jointly with request distribution. We reveal step by step that this joint optimization problem can be mapped to the classic ski-rental problem. We first present an online competitive algorithm for a special case where request distribution and container caching are based on a set of carefully designed probability distribution functions. Based on this algorithm, we propose an online algorithm called O-RDC for the general case, which incorporates the resource capacity and network latency by opportunistically distributing requests. We conduct extensive experiments to examine the performance of the proposed algorithms with both synthetic and real-world serverless computing traces. Our results show that ORDC outperforms existing caching strategies of current serverless computing platforms by up to 94.5% in terms of the overall system cost. © 2022 IEEE.","2022","2025-10-22 19:07:39","2025-10-22 19:07:39","","1069-1078","","","2022-May","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Internet of things; Edge computing; Serverless computing; edge computing; Resource efficiencies; serverless computing; container caching; Container caching; Distribution functions; Edge resources; Event-based modeling; Joint optimization; Request distributions; Resources utilizations; ski-rental problem; Ski-rental problems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"H8NP52AA","journalArticle","","","","Perf: Linux Profiling with Performance Counters","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877683951&partnerID=40&md5=e8f2b976737a97fabea50bca634d8503","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEPMW2JP","conferencePaper","2020","Du, D.; Yu, T.; Xia, Y.; Zang, B.; Yan, G.; Qin, C.; Wu, Q.; Chen, H.","Catalyzer: Sub-millisecond startup for serverless computing with initialization-less booting","","","","10.1145/3373376.3378512","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082400852&doi=10.1145%2f3373376.3378512&partnerID=40&md5=7efa51b655f8910603f7a378b26b339f","Serverless computing promises cost-efficiency and elasticity for high-productive software development. To achieve this, the serverless sandbox system must address two challenges: strong isolation between function instances, and low startup latency to ensure user experience. While strong isolation can be provided by virtualization-based sandboxes, the initialization of sandbox and application causes non-negligible startup overhead. Conventional sandbox systems fall short in low-latency startup due to their application-agnostic nature: they can only reduce the latency of sandbox initialization through hypervisor and guest kernel customization, which is inadequate and does not mitigate the majority of startup overhead. This paper proposes Catalyzer, a serverless sandbox system design providing both strong isolation and extremely fast function startup. Instead of booting from scratch, Catalyzer restores a virtualization-based function instance from a well-formed checkpoint image and thereby skips the initialization on the critical path (init-less). Catalyzer boosts the restore performance by on-demand recovering both user-level memory state and system state. We also propose a new OS primitive, sfork (sandbox fork), to further reduce the startup latency by directly reusing the state of a running sandbox instance. Fundamentally, Catalyzer removes the initialization cost by reusing state, which enables general optimizations for diverse serverless functions. The evaluation shows that Catalyzer reduces startup latency by orders of magnitude, achieves <1ms latency in the best case, and significantly reduces the end-to-end latency for real-world workloads. Catalyzer has been adopted by Ant Financial, and we also present lessons learned from industrial development. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","467-481","","","","","","","","","","","","","","","","Scopus","","","","","","","","Operating system; Virtual reality; Virtualization; Virtualizations; Software design; Serverless computing; Low latency; Checkpoint and restore; Cost elasticities; Cost-efficiency; Restoration; Start-up overheads; Startup latency; Users' experiences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"HHEFZKE3","conferencePaper","2020","Shahrad, M.; Fonseca, R.; Goiri, Í.; Chaudhry, G.; Batum, P.; Cooke, J.; Laureano, E.; Tresness, C.; Russinovich, M.; Bianchini, R.","Serverless in the wild: Characterizing and optimizing the serverless workload at a large cloud provider","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091934381&partnerID=40&md5=16dd6343f7a2bb6ef374f99e1bb924da","Function as a Service (FaaS) has been gaining popularity as a way to deploy computations to serverless backends in the cloud. This paradigm shifts the complexity of allocating and provisioning resources to the cloud provider, which has to provide the illusion of always-available resources (i.e., fast function invocations without cold starts) at the lowest possible resource cost. Doing so requires the provider to deeply understand the characteristics of the FaaS workload. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we first characterize the entire production FaaS workload of Azure Functions. We show for example that most functions are invoked very infrequently, but there is an 8-order-of-magnitude range of invocation frequencies. Using observations from our characterization, we then propose a practical resource management policy that significantly reduces the number of function cold starts, while spending fewer resources than state-of-the-practice policies. Copyright © Proc. of the 2020 USENIX Annual Technical Conference, ATC 2020. All rights reserved.","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","205-218","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud providers; Resource costs; Cold start; Paradigm shifts; Public information; Resource management policy; State of the practice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2020 USENIX Annual Technical Conference, ATC 2020","","","","","","","","","","","","","","",""
"TQTHGMV4","journalArticle","2018","Liu, C.; Li, K.; Li, K.","Minimal Cost Server Configuration for Meeting Time-Varying Resource Demands in Cloud Centers","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2018.2836452","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047012237&doi=10.1109%2fTPDS.2018.2836452&partnerID=40&md5=fb9dc8f6a33375053bb3a7402c4e5d74","We consider the minimal cost server configuration for meeting resource demands over multiple time slots. Specifically, there are some heterogeneous servers. Each server is specified by a cost, certain amounts of several resources, and an active interval, i.e., the time interval that the server is planed to work. There are different overall demands for each type of resource over different time slots. A feasible solution is a set of servers such that at any time slot, the resources provided by the selected servers are at least their corresponding demands. Notice that, a selected server can not provide resources for the time slots out of its active interval. The total cost of the solution is the summation of the costs of all selected servers. The goal is to find a feasible solution with minimal total cost. This problem is proved to be NP-hard due to a reduction from the multidimensional knapsack problem (MKP), which is a well-known NP-hard combinational optimization problem. To solve our problem, we present a randomized approximation algorithm called partial rounding algorithm (PRA), which guarantees O (KT)-approximation, i.e., η (KT)-approximation, where K is the number of kinds of resources, T is the number of time slots, and η is a positive constant. Furthermore, to minimize η as much as possible, we propose a varied Chernoff bound and apply it in PRA. We perform extensive experiments with random inputs and a specific application input. The results show that PRA with our varied Chernoff conclusion can find solutions closing to the optimal one. © 1990-2012 IEEE.","2018","2025-10-22 19:07:39","2025-10-22 19:07:39","","2503-2513","","11","29","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Cloud computing; Resource management; Bandwidth; Servers; Costs; Approximation algorithms; Chernoff bounds; Cost minimization; meeting resource demands; Randomized approximation; randomized approximation algorithm; Resource demands; server configuration; varied Chernoff bound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TU4ZE325","conferencePaper","2020","Silva, P.; Fireman, D.; Pereira, T.E.","Prebaking functions to warm the serverless cold start","","","","10.1145/3423211.3425682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098482026&doi=10.1145%2f3423211.3425682&partnerID=40&md5=a504f228433628dd70e0d3a74365fdba","Function-as-service (FaaS) platforms promise a simpler programming model for cloud computing, in which the developers concentrate on writing its applications. In contrast, platform providers take care of resource management and administration. As FaaS users are billed based on the execution of the functions, platform providers have a natural incentive not to keep idle resources running at the platform's expense. However, this strategy may lead to the cold start issue, in which the execution of a function is delayed because there is no ready resource to host the execution. Cold starts can take hundreds of milliseconds to seconds and have been a prohibitive and painful disadvantage for some applications. This work describes and evaluates a technique to start functions, which restores snapshots from previously executed function processes. We developed a prototype of this technique based on the CRIU process checkpoint/restore Linux tool. We evaluate this prototype by running experiments that compare its start-up time against the standard Unix process creation/start-up procedure. We analyze the following three functions: i) a ""do-nothing"" function, ii) an Image Resizer function, and iii) a function that renders Markdown files. The results attained indicate that the technique can improve the start-up time of function replicas by 40% (in the worst case of a ""do-nothing"" function) and up to 71% for the Image Resizer one. Further analysis indicates that the runtime initialization is a key factor, and we confirmed it by performing a sensitivity analysis based on synthetically generated functions of different code sizes. These experiments demonstrate that it is critical to decide when to create a snapshot of a function. When one creates the snapshots of warm functions, the speed-up achieved by the prebaking technique is even higher: the speed-up increases from 127.45% to 403.96%, for a small, synthetic function; and for a bigger, synthetic function, this ratio increases from 121.07% to 1932.49%. © 2020 Association for Computing Machinery.","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","1-13","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource management; Computer operating systems; Serverless; Middleware; Image enhancement; Cold start; Startup time; Cloud; Faas; Generated function; ITS applications; Key factors; Performance evaluation; Process creation; Programming models; Sensitivity analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Middleware 2020 - Proceedings of the 2020 21st International Middleware Conference","","","","","","","","","","","","","","",""
"V6P9DDAR","journalArticle","","","","Amazon Lambda","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971535952&partnerID=40&md5=c81820cd628831a2fb7ca371091d198f","","","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBTC7P3V","conferencePaper","2020","Wang, L.; Li, M.; Zhang, Y.; Ristenpart, T.; Swift, M.","Peeking behind the curtains of serverless platforms","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077448177&partnerID=40&md5=4c9a798d44b920fec75b104bd8d7da8f","Serverless computing is an emerging paradigm in which an application's resource provisioning and scaling are managed by third-party services. Examples include AWS Lambda, Azure Functions, and Google Cloud Functions. Behind these services' easy-to-use APIs are opaque, complex infrastructure and management ecosystems. Taking on the viewpoint of a serverless customer, we conduct the largest measurement study to date, launching more than 50,000 function instances across these three services, in order to characterize their architectures, performance, and resource management efficiency. We explain how the platforms isolate the functions of different accounts, using either virtual machines or containers, which has important security implications. We characterize performance in terms of scalability, coldstart latency, and resource efficiency, with highlights including that AWS Lambda adopts a bin-packing-like strategy to maximize VM memory utilization, that severe contention between functions can arise in AWS and Azure, and that Google had bugs that allow customers to use resources for free. © Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018. All rights reserved.","2020","2025-10-22 19:07:39","2025-10-22 19:07:39","","133-145","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource management; Memory architecture; Efficiency; Resource efficiencies; Bin packing; Complex infrastructures; Measurement study; Memory utilization; Security implications; Third party services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018","","","","","","","","","","","","","","",""
"KACBYAE6","journalArticle","2015","Hu, Y.C.; Patel, M.; Sabella, D.; Sprecher, N.; Young, V.","Mobile edge computing: A key technology towards 5G","Mobile Edge Computing-A Key Technology Towards 5G","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963757817&partnerID=40&md5=333635cdcabb534a28c501ea6b0e8ae9","","2015","2025-10-22 19:07:39","2025-10-22 19:07:39","","","","11","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32VW76TK","journalArticle","2023","Saxena, D.; Ji, T.; Singhvi, A.; Khalid, J.; Akella, A.","Navigating Performance-Efficiency Tradeoffs in Serverless Computing: Deduplication to the Rescue!","Operating Systems Review (ACM)","","","10.1145/3606557.3606564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164254628&doi=10.1145%2f3606557.3606564&partnerID=40&md5=39e9c8f5f6fbb95bc0a523163a00380b","Navigating the performance and efficiency trade-offs is critical for serverless platforms, where the providers ideally want to give the illusion of warm function startups while maintaining low resource costs. Limited controls, provided via toggling sandboxes between warm and cold states and keepalives, force operators to sacrifice significant resources to achieve good performance.  © 2023 Copyright is held by the owner/author(s).","2023","2025-10-22 19:07:39","2025-10-22 19:07:39","","47-53","","1","57","","","","","","","","","","","","","Scopus","","","","","","","","Cloud-computing; Performance; Virtualization; Cloud Computing; Virtualizations; Economic and social effects; Serverless; Efficiency; Commerce; Resource costs; Cold state; Deduplication; Memory deduplication; Memory Deduplication; Performance efficiency; Trade off","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IULXHL6G","conferencePaper","2019","Shahrad, M.; Balkind, J.; Wentzlaff, D.","Architectural implications of function-as-a-service computing","","","","10.1145/3352460.3358296","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074454583&doi=10.1145%2f3352460.3358296&partnerID=40&md5=a1c5e1ae40346c4b02458962a3f50a50","Serverless computing is a rapidly growing cloud application model, popularized by Amazon's Lambda platform. Serverless cloud services provide fine-grained provisioning of resources, which scale automatically with user demand. Function-as-a-Service (FaaS) applications follow this serverless model, with the developer providing their application as a set of functions which are executed in response to a user- or system-generated event. Functions are designed to be short-lived and execute inside containers or virtual machines, introducing a range of system-level overheads. This paper studies the architectural implications of this emerging paradigm. Using the commercial-grade Apache OpenWhisk FaaS platform on real servers, this work investigates and identifies the architectural implications of FaaS serverless computing. The workloads, along with the way that FaaS inherently interleaves short functions from many tenants frustrates many of the locality-preserving architectural structures common in modern processors. In particular, we find that: FaaS containerization brings up to 20x slowdown compared to native execution, cold-start can be over 10x a short function's execution time, branch mispredictions per kilo-instruction are 20x higher for short functions, memory bandwidth increases by 6x due to the invocation pattern, and IPC decreases by as much as 35% due to inter-function interference. We open-source FaaSProfiler, the FaaS testing and profiling platform that we developed for this work. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:39","2025-10-22 19:07:39","","1063-1075","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud applications; Serverless; Computer architecture; Architecture; Clouds; Architectural structure; Branch mispredictions; Cloud; Faas; Function-as-a-service; Locality-preserving; Modern processors; Open whisk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"PFWPRBLL","conferencePaper","2017","McGrath, G.; Brenner, P.R.","Serverless Computing: Design, Implementation, and Performance","","","","10.1109/ICDCSW.2017.36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027531918&doi=10.1109%2fICDCSW.2017.36&partnerID=40&md5=7922eccabb0c16d5ecf2a4aba6079cf0","We present the design of a novel performance-oriented serverless computing platform implemented in. NET, deployed in Microsoft Azure, and utilizing Windows containers as function execution environments. Implementation challenges such as function scaling and container discovery, lifecycle, and reuse are discussed in detail. We propose metrics to evaluate the execution performance of serverless platforms and conduct tests on our prototype as well as AWS Lambda, Azure Functions, Google Cloud Functions, and IBM's deployment of Apache OpenWhisk. Our measurements show the prototype achieving greater throughput than other platforms at most concurrency levels, and we examine the scaling and instance expiration trends in the implementations. Additionally, we discuss the gaps and limitations in our current design, propose possible solutions, and highlight future research. © 2017 IEEE.","2017","2025-10-22 19:07:39","2025-10-22 19:07:39","","405-410","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Distributed computer systems; Web services; FaaS; Apache OpenWhisk; AWS Lambda; Azure Functions; Function-as-a-Service; Google Cloud Functions; IBM OpenWhisk; serverless computing; serverless performance; Windows operating system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE 37th International Conference on Distributed Computing Systems Workshops, ICDCSW 2017","","","","","","","","","","","","","","",""
"4JXZFA6E","journalArticle","2020","Mahmoudi, N.; Khazaei, H.","Performance modeling of serverless computing platforms","IEEE Transactions on Cloud Computing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108777806&partnerID=40&md5=5a99e5f8d064071dd6c17aeb8dee1182","","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","2834-2847","","4","10","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUQKGVMG","journalArticle","","","","Energy saving strategy","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003935101&partnerID=40&md5=b793f4c6d2a34ba2807b73603c50d9bc","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LAYEP75S","journalArticle","2012","Patt-Shamir, B.; Rawitz, D.","Vector bin packing with multiple-choice","Discrete Applied Mathematics","","","10.1016/j.dam.2012.02.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859922814&doi=10.1016%2fj.dam.2012.02.020&partnerID=40&md5=d42743c934e12933297b86bcf7932576","We consider a variant of bin packing called multiple-choice vector bin packing. In this problem, we are given a set of n items, where each item can be selected in one of several D-dimensional incarnations. We are also given T bin types, each with its own cost andD-dimensional size. Our goal is to pack the items in a set of bins of minimum overall cost. The problem is motivated by scheduling in networks with guaranteed quality of service (QoS), but due to its general formulation it has many other applications as well. We present an approximation algorithm that is guaranteed to produce a solution whose cost is about lnD times the optimum. For the running time to be polynomial we require D=O(1) and T=O(logn). This extends previous results for vector bin packing, in which each item has a single incarnation and there is only one bin type. To obtain our result we also present a PTAS for the multiple-choice version of multidimensional knapsack, where we are given only one bin and the goal is to pack a maximum weight set of (incarnations of) items in that bin. © 2012 Elsevier Ltd. All rights reserved.","2012","2025-10-22 19:07:40","2025-10-22 19:07:40","","1591-1600","","10-11","160","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Costs; Approximation algorithms; Bin packing; Bins; Guaranteed quality; Multidimensional knapsack; Multiple-choice multidimensional knapsack; Multiple-choice vector bin packing; Other applications; Overall costs; Running time; Vectors; Weight set","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6IPMD57","journalArticle","","","","Azure Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041179679&partnerID=40&md5=4b7dcbec72e81f7c2321f9ba9504130e","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MR6EC3KJ","journalArticle","2017","Ruiu, P.; Fiandrino, C.; Giaccone, P.; Bianco, A.; Kliazovich, D.; Bouvry, P.","On the energy-proportionality of data center networks","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2017.2711967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061511614&doi=10.1109%2fTSUSC.2017.2711967&partnerID=40&md5=3c022d9a61ff6d9c6cf847627cdfca62","Data centers provision industry and end users with the necessary computing and communication resources to access the vast majority of services online and on a pay-as-you-go basis. In this paper, we study the problem of energy proportionality in data center networks (DCNs). Devices are energy proportional when any increase of the load corresponds to a proportional increase of energy consumption. In data centers, energy consumption is concern as it considerably impacts on the operational expenses (OPEX) of the operators. In our analysis, we investigate the impact of three different allocation policies on the energy proportionality of computing and networking equipment for different DCNs, including 2-Tier, 3-Tier, and Jupiter topologies. For evaluation, the size of the DCNs varies to accommodate up to several thousands of computing servers. Validation of the analysis is conducted through simulations. We propose new metrics with the objective to characterize in a holistic manner the energy proportionality in data centers. The experiments unveil that, when consolidation policies are in place and regardless of the type of architecture, the size of the DCN plays a key role, i.e., larger DCNs containing thousands of servers are more energy proportional than small DCNs. © 2016 IEEE.","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","197-210","","2","2","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Green computing; Allocation policies; Communication resources; data center networking; Data center networkings; Data center networks; Data center networks (DCNs); Energy proportionalities; Energy-efficiency; energy-proportionality; Networking equipment; Operational expense","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UN89G6E","journalArticle","2019","Tao, Z.; Xia, Q.; Hao, Z.; Li, C.; Ma, L.; Yi, S.; Li, Q.","A survey of virtual machine management in edge computing","Proc. IEEE","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082883374&partnerID=40&md5=4e72932e2486eef6c7c69ed2ee0ff079","","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","1482-1499","","8","107","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98CHMKIR","journalArticle","2020","Agache, A.","Firecracker: Lightweight virtualization for serverless applications","USENIX NSDI","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100498805&partnerID=40&md5=c2c620de699387405713dd03d0904cde","","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GMUMRL3S","conferencePaper","2019","Gan, Y.; Zhang, Y.; Cheng, D.; Shetty, A.; Rathi, P.; Katarki, N.; Bruno, A.; Hu, J.; Ritchken, B.; Jackson, B.; Hu, K.; Pancholi, M.; He, Y.; Clancy, B.; Colen, C.; Wen, F.; Leung, C.; Wang, S.; Zaruvinsky, L.; Espinosa, M.; Lin, R.; Liu, Z.; Padilla, J.; Delimitrou, C.","An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems","","","","10.1145/3297858.3304013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064688619&doi=10.1145%2f3297858.3304013&partnerID=40&md5=b9f662fba2a35d83eb40d32009cf7676","Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","3-18","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Open source software; Datacenter; Microservice; cloud computing; Cloud-computing; microservices; QoS; acceleration; Benchmark suites; Cloud systems; Cluster computing; cluster management; Cluster management; datacenters; Economic and social effects; Field programmable gate arrays (FPGA); fpga; Fpgum; Open systems; Open-source; Quality-of-service; serverless; Serverless","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"KPRUKHQQ","conferencePaper","2013","Ousterhout, K.; Wendell, P.; Zaharia, M.; Stoica, I.","Sparrow: Distributed, low latency scheduling","","","","10.1145/2517349.2522716","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889640333&doi=10.1145%2f2517349.2522716&partnerID=40&md5=3453ba1344af99cae7b8501554703616","Large-scale data analytics frameworks are shifting towards shorter task durations and larger degrees of parallelism to provide low latency. Scheduling highly parallel jobs that complete in hundreds of milliseconds poses a major challenge for task schedulers, which will need to schedule millions of tasks per second on appropriate machines while offering millisecond-level latency and high availability. We demonstrate that a decentralized, randomized sampling approach provides near-optimal performance while avoiding the throughput and availability limitations of a centralized design. We implement and deploy our scheduler, Sparrow, on a 110-machine cluster and demonstrate that Sparrow performs within 12% of an ideal scheduler. © 2013 ACM.","2013","2025-10-22 19:07:40","2025-10-22 19:07:40","","69-84","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; High availability; Highly parallels; Large-scale datum; Low latency; Near-optimal performance; Randomized sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SOSP 2013 - Proceedings of the 24th ACM Symposium on Operating Systems Principles","","","","","","","","","","","","","","",""
"DN5EBF7E","journalArticle","2016","","","Apache OpenWhisk","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071948507&partnerID=40&md5=cae79e308d1a4a884fbd05575f40dcfd","","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5WN8ZG7K","journalArticle","","Simon, Eismann; Joel, Scheuner","","A Review of Serverless Use Cases and their Characteristics","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098402238&partnerID=40&md5=1ef65986f58542e24905bb400e205491","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"88V295PZ","conferencePaper","2019","Mohan, A.; Sane, H.; Doshi, K.; Edupuganti, S.; Nayak, N.; Sukhomlinov, V.","Agile cold starts for scalable serverless","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084160535&partnerID=40&md5=78d805902ca3dc9483d26084f74a76cf","The Serverless or Function-as-a-Service (FaaS) model capitalizes on lightweight execution by packaging code and dependencies together for just-in-time dispatch. Often a container environment has to be set up afresh– a condition called “cold start"", and in such cases, performance suffers and overheads mount, both deteriorating rapidly under high concurrency. Caching and reusing previously employed containers ties up memory and risks information leakage. Latency for cold starts is frequently due to work and wait-times in setting up various dependencies – such as in initializing networking elements. This paper proposes a solution that pre-crafts such resources and then dynamically reassociates them with baseline containers. Applied to networking, this approach demonstrates an order of magnitude gain in cold starts, negligible memory consumption, and flat startup time under rising concurrency. © 2019 USENIX Association. All rights reserved.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud computing; Wait time; Cold start; High concurrencies; Information leakage; Just in time; Memory consumption; Startup time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019, co-located with USENIX ATC 2019","","","","","","","","","","","","","","",""
"Y2XJP28Y","journalArticle","","","","Brigade-workflows","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098406206&partnerID=40&md5=a6596e197849ea4e104d741f94a2badb","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2BFJW73","conferencePaper","2017","Harlap, A.; Tumanov, A.; Chung, A.; Ganger, G.R.; Gibbons, P.B.","Proteus: Agile ML elasticity through tiered reliability in dynamic resource markets","","","","10.1145/3064176.3064182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019230467&doi=10.1145%2f3064176.3064182&partnerID=40&md5=ae793a495f02a4472e2a897874109dc2","Many shared computing clusters allow users to utilize excess idle resources at lower cost or priority, with the proviso that some or all may be taken away at any time. But, exploiting such dynamic resource availability and the often fluctuating markets for them requires agile elasticity and effective acquisition strategies. Proteus aggressively exploits such transient revocable resources to do machine learning (ML) cheaper and/or faster. Its parameter server framework, AgileML, efficiently adapts to bulk additions and revocations of transient machines, through a novel 3-stage active-backup approach, with minimal use of more costly non-transient resources. Its BidBrain component adaptively allocates resources from multiple EC2 spot markets to minimize average cost per work as transient resource availability and cost change over time. Our evaluations show that Proteus reduces cost by 85% relative to non-transient pricing, and by 43% relative to previous approaches, while simultaneously reducing runtimes by up to 37%. © 2017 Copyright held by the owner/author(s).","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","589-604","","","","","","","","","","","","","","","","Scopus","","","","","","","","Elasticity; Costs; Commerce; Spot market; Learning systems; Acquisition strategies; Agile manufacturing systems; Average cost; Computing clusters; Cost changes; Dynamic resource availabilities; Dynamic resources; Transient resources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 12th European Conference on Computer Systems, EuroSys 2017","","","","","","","","","","","","","","",""
"DLXSBVQX","conferencePaper","2019","Suresh, A.; Gandhi, A.","FNSched: An efficient scheduler for serverless functions","","","","10.1145/3366623.3368136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078922442&doi=10.1145%2f3366623.3368136&partnerID=40&md5=68847dba229c4bab2960be8b3fe1f625","An imminent challenge in the serverless computing landscape is the escalating cost of infrastructure needed to handle the growing traffic at scale. This work presents FnSched, a function-level scheduler designed to minimize provider resource costs while meeting customer performance requirements. FnSched works by carefully regulating the resource usage of colocated functions on each invoker, and autoscaling capacity by concentrating load on few invokers in response to varying traffic. We implement a prototype of FnSched and show that, compared to existing baselines, FnSched significantly improves resource efficiency, by as much as 36%–55%, while providing acceptable application latency. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","19-24","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Middleware; Resource usage; Autoscaling; Co-located; Escalating costs; Function levels; Performance requirements; Resource costs; Resource efficiencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WOSC 2019 - Proceedings of the 2019 5th International Workshop on Serverless Computing, Part of Middleware 2019","","","","","","","","","","","","","","",""
"NQETTQW5","journalArticle","","","","Serverless Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098525877&partnerID=40&md5=cb5dd68616db3c7763503fa350dfbdc5","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RQKURUZA","journalArticle","2000","Hoxmeier, J.A.; DiCesare, C.","System response time and user satisfaction: An experimental study of browser-based applications","AMCIS 2000 Proceedings","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242530345&partnerID=40&md5=133e2518e2900702e5a142408a03bb44","","2000","2025-10-22 19:07:40","2025-10-22 19:07:40","","140-145","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJARY2P5","journalArticle","2017","Elyasi, N.; Arjomand, M.; Sivasubramaniam, A.; Kandemir, M.T.; Das, C.R.; Jung, M.","Exploiting intra-request slack to improve SSD performance","ACM SIGPLAN Notices","","","10.1145/3037697.3037728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066424914&doi=10.1145%2f3037697.3037728&partnerID=40&md5=c998df4eaeae91a0d7036dd13eded94c","With Solid State Disks (SSDs) offering high degrees of parallelism, SSD controllers place data and direct requests to exploit the maximum offered hardware parallelism. In the quest to maximize parallelism and utilization, sub-requests of a request that are directed to different flash chips by the scheduler can experience differential wait times since their individual queues are not coordinated and load balanced at all times. Since the macro request is considered complete only when its last sub-request completes, some of its sub-requests that complete earlier have to necessarily wait for this last sub-request. This paper opens the door to a new class of schedulers to leverage such slack between sub-requests in order to improve response times. Specifically, the paper presents the design and implementation of a slack-enabled re-ordering scheduler, called Slacker, for sub-requests issued to each flash chip. Layered under a modern SSD request scheduler, Slacker estimates the slack of each incoming sub-request to a flash chip and allows them to jump ahead of existing sub-requests with sufficient slack so as to not detrimentally impact their response times. Slacker is simple to implement and imposes only marginal additions to the hardware. Using a spectrum of 21 workloads with diverse read-write characteristics, we show that Slacker provides as much as 19.5%, 13% and 14.5% improvement in response times, with average improvements of 12%, 6.5% and 8.5%, for write-intensive, read-intensive and read-write balanced workloads, respectively. © 2017 ACM.","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","375-388","","4","52","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Design and implementations; Computer science; Balanced work-load; Computer programming; Flash chips; Hardware parallelisms; Intra-request slack; Load-balanced; Re orderings; Solid state disks; Ssd; Wait time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K9YC8WUZ","conferencePaper","2019","Zhang, C.; Yu, M.; Wang, W.; Yan, F.","Mark: Exploiting cloud services for cost-effective, slo-aware machine learning inference serving","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076183718&partnerID=40&md5=de8d4f1dca43c789793276270808d25f","The advances of Machine Learning (ML) have sparked a growing demand of ML-as-a-Service: developers train ML models and publish them in the cloud as online services to provide low-latency inference at scale. The key challenge of ML model serving is to meet the response-time Service-Level Objectives (SLOs) of inference workloads while minimizing the serving cost. In this paper, we tackle the dual challenge of SLO compliance and cost effectiveness with MArk (Model Ark), a general-purpose inference serving system built in Amazon Web Services (AWS). MArk employs three design choices tailor-made for inference workload. First, MArk dynamically batches requests and opportunistically serves them using expensive hardware accelerators (e.g., GPU) for improved performance-cost ratio. Second, instead of relying on feedback control scaling or over-provisioning to serve dynamic workload, which can be too slow or too expensive for inference serving, MArk employs predictive autoscaling to hide the provisioning latency at low cost. Third, given the stateless nature of inference serving, MArk exploits the flexible, yet costly serverless instances to cover the occasional load spikes that are hard to predict. We evaluated the performance of MArk using several state-of-the-art ML models trained in popular frameworks including TensorFlow, MXNet, and Keras. Compared with the premier industrial ML serving platform SageMaker, MArk reduces the serving cost up to 7.8× while achieving even better latency performance. © Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019. All rights reserved.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","1049-1062","","","","","","","","","","","","","","","","Scopus","","","","","","","","State of the art; Web services; Costs; Machine learning; Amazon web services; Cost effectiveness; Expensive hardware; Latency performance; On-line service; Over provisioning; Performance-cost ratio; Service level objective","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019","","","","","","","","","","","","","","",""
"KDVR9968","journalArticle","","","","Microsoft Azure Serverless Computing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072040842&partnerID=40&md5=0510241c379401e49ccb91a3f847e916","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WTUSXKN","conferencePaper","2015","Delgado, P.; Dinu, F.; Kermarrec, A.-M.; Zwaenepoel, W.","Hawk: Hybrid datacenter scheduling","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992029827&partnerID=40&md5=e541b7894adc128e8f152137264b2d38","This paper addresses the problem of efficient scheduling of large clusters under high load and heterogeneous workloads. A heterogeneousworkload typically consists of many short jobs and a small number of large jobs that consume the bulk of the cluster's resources. Recent work advocates distributed scheduling to overcome the limitations of centralized schedulers for large clusters with many competing jobs. Such distributed schedulers are inherently scalable, but may make poor scheduling decisions because of limited visibility into the overall resource usage in the cluster. In particular, we demonstrate that under high load, short jobs can fare poorly with such a distributed scheduler. We propose instead a new hybrid centralized/distributed scheduler, called Hawk. In Hawk, long jobs are scheduled using a centralized scheduler, while short ones are scheduled in a fully distributed way. Moreover, a small portion of the cluster is reserved for the use of short jobs. In order to compensate for the occasional poor decisions made by the distributed scheduler, we propose a novel and efficient randomized work-stealing algorithm. We evaluate Hawk using a trace-driven simulation and a prototype implementation in Spark. In particular, using a Google trace, we show that under high load, compared to the purely distributed Sparrow scheduler, Hawk improves the 50th and 90th percentile runtimes by 80% and 90% for short jobs and by 35% and 10% for long jobs, respectively. Measurements of a prototype implementation using Spark on a 100-node cluster confirm the results of the simulation. © 2015 USENIX Annual Technical Conference.","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","499-510","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Prototype implementations; Centralized schedulers; Distributed schedulers; Trace driven simulation; Distributed scheduling; Efficient scheduling; Heterogeneous workloads; Scheduling decisions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2015 USENIX Annual Technical Conference, USENIX ATC 2015","","","","","","","","","","","","","","",""
"EKREEQ7F","journalArticle","2016","Iandola, F.N.; Han, S.; Moskewicz, M.W.; Ashraf, K.; Dally, W.J.; Keutzer, K.","","SqueezeNet: AlexNet-level Accuracy with 50x Fewer Parameters and <1MB Model Size","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988340112&partnerID=40&md5=9ba329ae98ab30a684b6086fe17a2cb9","","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZER5DMG2","conferencePaper","2018","Niu, Y.; Liu, F.; Li, Z.","Load Balancing Across Microservices","","","","10.1109/INFOCOM.2018.8486300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056174602&doi=10.1109%2fINFOCOM.2018.8486300&partnerID=40&md5=e6e54404d28ef87f04bcb09227fe99d0","With the advent of cloud container technology, enterprises develop applications through microservices, breaking monolithic software into a suite of small services whose instances run independently in containers. User requests are served by a series of microservices forming a chain, and the chains often share microservices. Existing load balancing strategies either incur significant networking overhead or ignore the competition for shared microservices across chains. Furthermore, typical load balancing solutions leverage a hybrid technique by combining HTTP with message queue to support microservice communications, bringing additional operational complexity. To address these challenges, we propose a chain-oriented load balancing algorithm (COLBA) based solely on message queues, which balances load based on microservice requirements of chains to minimize response time. We model the load balancing problem as a non-cooperative game, and leverage Nash bargaining to coordinate microservice allocation across chains. Employing convex optimization with rounding, we efficiently solve the problem that is proven NP-hard. Extensive trace-driven simulations demonstrate that COLBA reduces the overall average response time at least by 13% compared with existing load balancing strategies. © 2018 IEEE.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","198-206","","","2018-April","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Distributed computer systems; Game theory; Chains; Convex optimization; Hybrid techniques; Load balancing algorithms; Load balancing problem; Load balancing strategy; Nash bargaining; Noncooperative game; Operational complexity; Trace driven simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"QJ97M76T","conferencePaper","2019","Hunt, P.; Konar, M.; Junqueira, F.P.; Reed, B.","ZooKeeper: Wait-free coordination for internet-scale systems","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077109271&partnerID=40&md5=54d7bb3044aaba79d144ebaeae2094ff","In this paper, we describe ZooKeeper, a service for coordinating processes of distributed applications. Since ZooKeeper is part of critical infrastructure, ZooKeeper aims to provide a simple and high performance kernel for building more complex coordination primitives at the client. It incorporates elements from group messaging, shared registers, and distributed lock services in a replicated, centralized service. The interface exposed by ZooKeeper has the wait-free aspects of shared registers with an event-driven mechanism similar to cache invalidations of distributed file systems to provide a simple, yet powerful coordination service. The ZooKeeper interface enables a high-performance service implementation. In addition to the wait-free property, ZooKeeper provides a per client guarantee of FIFO execution of requests and linearizability for all requests that change the ZooKeeper state. These design decisions enable the implementation of a high performance processing pipeline with read requests being satisfied by local servers. We show for the target workloads, 2:1 to 100:1 read to write ratio, that ZooKeeper can handle tens to hundreds of thousands of transactions per second. This performance allows ZooKeeper to be used extensively by client applications. © 2019 USENIX Annual Technical Conference. All rights reserved.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","145-158","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cache invalidation; Client applications; Coordination reactions; Distributed applications; Distributed file systems; Event driven mechanisms; File organization; High-performance processing; Internet-scale systems; Target workloads","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2010 USENIX Annual Technical Conference, USENIX ATC 2010","","","","","","","","","","","","","","",""
"QPWPCNNT","journalArticle","2020","Brooker, M.; Florescu, A.; Popa, D.-M.; Neugebauer, R.; Agache, A.; Iordache, A.; Liguori, A.; Piwonka, P.","Firecracker: Lightweight Virtualization for Serverless Applications","NSDI","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095497238&partnerID=40&md5=acdd7c262baa0e03669c6c09ec95784f","","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TBLF8TT9","conferencePaper","2018","Hazelwood, K.; Bird, S.; Brooks, D.; Chintala, S.; Diril, U.; Dzhulgakov, D.; Fawzy, M.; Jia, B.; Jia, Y.; Kalro, A.; Law, J.; Lee, K.; Lu, J.; Noordhuis, P.; Smelyanskiy, M.; Xiong, L.; Wang, X.","Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective","","","","10.1109/HPCA.2018.00059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046720962&doi=10.1109%2fHPCA.2018.00059&partnerID=40&md5=f62b6bf978a70f022b04ae0378243e08","Machine learning sits at the core of many essential products and services at Facebook. This paper describes the hardware and software infrastructure that supports machine learning at global scale. Facebook's machine learning workloads are extremely diverse: services require many different types of models in practice. This diversity has implications at all layers in the system stack. In addition, a sizable fraction of all data stored at Facebook flows through machine learning pipelines, presenting significant challenges in delivering data to high-performance distributed training flows. Computational requirements are also intense, leveraging both GPU and CPU platforms for training and abundant CPU capacity for real-time inference. Addressing these and other emerging challenges continues to require diverse efforts that span machine learning algorithms, software, and hardware design. © 2018 IEEE.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","620-629","","","2018-February","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Computer architecture; Computational requirements; Computer software; Applied machine learning; Artificial intelligence; Facebook; Hardware and software; Hardware design; Hardware software codesign; Hardware-software codesign; Learning algorithms; Learning systems; Machine learning; Products and services; Real-time inference; Social networking (online); Supercomputers; System stacks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on High-Performance Computer Architecture","","","","","","","","","","","","","","",""
"XZTNB9QQ","journalArticle","2011","Das, R.; Mutlu, O.; Moscibroda, T.; Das, C.","Aérgia: A network-on-chip exploiting packet latency slack","IEEE Micro","","","10.1109/MM.2010.98","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951833094&doi=10.1109%2fMM.2010.98&partnerID=40&md5=45e017b0ee41c62dbb3ded0e528ae3dd","A traditional Network-on-Chip (NoC) employs simple arbitration strategies, such as round robin or oldest first, which treat packets equally regardless of the source applications' characteristics. This is suboptimal because packets can have different effects on system performance. We define slack as a key measure for characterizing a packet's relative importance. Aérgia introduces new router prioritization policies that exploit interfering packets' available slack to improve overall system performance and fairness. © 2011 IEEE.","2011","2025-10-22 19:07:40","2025-10-22 19:07:40","","29-41","","1","31","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Multi core; Servers; Criticality (nuclear fission); arbitration; criticality; memory systems; multicore; On-chip networks; Packet networks; packet scheduling; prioritization; Prioritization; Routers; slack; VLSI circuits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZEZKLA6","conferencePaper","2019","Sarma, A.; Jiang, H.; Pattnaik, A.; Kotra, J.; Kandemir, M.T.; Das, C.R.","Cash: Compiler assisted hardware design for improving DRAM energy efficiency in CNN inference","","","","10.1145/3357526.3357536","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075853474&doi=10.1145%2f3357526.3357536&partnerID=40&md5=3db3c7b0a49d5760a62307515f1dc67e","The advent of machine learning (ML) and deep learning applications has led to the development of a multitude of hardware accelerators and architectural optimization techniques for parallel architectures. This is due in part to the regularity and parallelism exhibited by the ML workloads, especially convolutional neural networks (CNNs). However, CPUs continue to be one of the dominant compute fabric in data-centers today, thereby also being widely deployed for inference tasks. As CNNs grow larger, the inherent limitations of a CPU-based system become apparent, specifically in terms of main memory data movement. In this paper, we present CASH, a compiler-assisted hardware solution that eliminates redundant data-movement to and from the main memory and, therefore, reduces main memory bandwidth and energy consumption. Our experimental evaluations on a set of four different state-of-the-art CNN workloads indicate that CASH provides, on average, ∼40% and ∼18% reductions in main memory bandwidth and energy consumption, respectively. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","396-408","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Program compilers; Deep learning; Energy utilization; Bandwidth; State of the art; Integrated circuit design; Experimental evaluation; Hardware design; Compiler-assisted; Convolutional neural networks; Dynamic random access storage; Hardware accelerators; Hardware solutions; Inherent limitations; Optimization techniques; Parallel architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"W5NL6S5L","conferencePaper","2019","Dukic, V.; Singla, A.","Happiness index: Right-sizing the cloud’s tenant-provider interface","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088357108&partnerID=40&md5=75519c7457fec4a289e4b3cacbb55bd2","Cloud providers and their tenants have a mutual interest in identifying optimal configurations in which to run tenant jobs, i.e., ones that achieve tenants’ performance goals at minimum cost; or ones that maximize performance within a specified budget. However, different tenants may have different performance goals that are opaque to the provider. A consequence of this opacity is that providers today typically offer fixed bundles of cloud resources, which tenants must themselves explore and choose from. This is burdensome for tenants and can lead to choices that are sub-optimal for both parties. We thus explore a simple, minimal interface, which lets tenants communicate their happiness with cloud infrastructure to the provider, and enables the provider to explore resource configurations that maximize this happiness. Our early results indicate that this interface could strike a good balance between enabling efficient discovery of application resource needs and the complexity of communicating a full description of tenant utility from different configurations to the provider. © 2019 USENIX Association. All rights reserved.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Budget control; Cloud infrastructures; Cloud providers; Happiness Index; Minimum cost; Resource configurations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019, co-located with USENIX ATC 2019","","","","","","","","","","","","","","",""
"J4M2XVY7","journalArticle","","","","Fission Workflows","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080320465&partnerID=40&md5=fec721763da7b786d80c12b0f47d5ea1","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HZRVU9T","journalArticle","","","","Amazon Web Services","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349752533&partnerID=40&md5=027313702d289eeb7d91fe9d61390c12","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5UPQTRZ","journalArticle","2018","Hellerstein, J.M.; Faleiro, J.; Gonzalez, J.E.; Schleier-Smith, J.; Sreekanti, V.; Tumanov, A.; Wu, C.","Serverless computing: One step forward, two steps back","Serverless Computing: One Step Forward, Two Steps Back","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063882696&partnerID=40&md5=5c1ff7e752d2999d4dd74ad63968c46f","","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNC8EUGK","journalArticle","2015","Mauro, T.","","Adopting Microservices at Netflix: Lessons for Architectural Design","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963909685&partnerID=40&md5=410fc7ee0bb445a33f63b3e673f2dbb4","","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRMKY6Y3","conferencePaper","2020","Zhang, Y.; Crowcroft, J.; Li, D.; Zhang, C.; Li, H.; Wang, Y.; Yu, K.; Xiong, Y.; Chen, G.","KylinX: A dynamic library operating system for simplified and efficient cloud virtualization","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077459733&partnerID=40&md5=ce16e0d3fd31f98b9e0dacc83a6f3a1a","Unikernel specializes a minimalistic LibOS and a target application into a standalone single-purpose virtual machine (VM) running on a hypervisor, which is referred to as (virtual) appliance. Compared to traditional VMs, Unikernel appliances have smaller memory footprint and lower overhead while guaranteeing the same level of isolation. On the downside, Unikernel strips off the process abstraction from its monolithic appliance and thus sacrifices flexibility, efficiency, and applicability. This paper examines whether there is a balance embracing the best of both Unikernel appliances (strong isolation) and processes (high flexibility/efficiency). We present KylinX, a dynamic library operating system for simplified and efficient cloud virtualization by providing the pVM (process-like VM) abstraction. A pVM takes the hypervisor as an OS and the Unikernel appliance as a process allowing both page-level and library-level dynamic mapping. At the page level, KylinX supports pVM fork plus a set of API for inter-pVM communication (IpC). At the library level, KylinX supports shared libraries to be linked to a Unikernel appliance at runtime. KylinX enforces mapping restrictions against potential threats. KylinX can fork a pVM in about 1.3 ms and link a library to a running pVM in a few ms, both comparable to process fork on Linux (about 1 ms). Latencies of KylinX IpCs are also comparable to that of UNIX IPCs. © Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018. All rights reserved.","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","173-185","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hypervisor; Virtual reality; Virtualization; Computer operating systems; Runtimes; Mapping; Abstracting; Virtual machine; Dynamic mapping; High flexibility; Memory footprint; Potential threats; Shared libraries; Target application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018","","","","","","","","","","","","","","",""
"M63YEKTG","conferencePaper","2017","Zhang, H.; Rengasamy, P.V.; Zhao, S.; Nachiappan, N.C.; Sivasubramaniam, A.; Kandemir, M.T.; Iyer, R.; Das, C.R.","Race-To-sleep + content caching + display caching: A recipe for energy-efficient video streaming on handhelds","","","","10.1145/3123939.3123948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034109414&doi=10.1145%2f3123939.3123948&partnerID=40&md5=51c7075c40a5db98799b2f661f261b8c","Video streaming has become the most common application in handhelds and this trend is expected to grow in future to account for about 75% of all mobile data traffic by 2021. Thus, optimizing the performance and energy consumption of video processing in mobile devices is critical for sustaining the handheld market growth. In this paper, we propose three complementary techniques, race-to-sleep, content caching and display caching, to minimize the energy consumption of the video processing flows. Unlike the state-of-the-art frame-by-frame processing of a video decoder, the first scheme, race-to-sleep, uses two approaches, called batching of frames and frequency boosting to prolong its sleep state for saving energy, while avoiding any frame drops. The second scheme, content caching, exploits the content similarity of smaller video blocks, called macroblocks, to design a novel cache organization for reducing the memory pressure. The third scheme, in turn, takes advantage of content similarity at the display controller to facilitate display caching further improving energy efficiency. We integrate these three schemes for developing an end-to-end video processing framework and evaluate our design on a comprehensive mobile system design platform with a variety of video processing workloads. Our evaluations show that the proposed three techniques complement each other in improving performance by avoiding frame drops and reducing the energy consumption of video streaming applications by 21%, on average, compared to the current baseline design. © 2017 Association for Computing Machinery.","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","517-531","","","Part F131207","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Computer architecture; Mobile telecommunication systems; Video signal processing; Video streaming; Integrated circuit design; System-on-chip; Data storage equipment; Cache memory; Cache organization; Caching; Complementary techniques; Content similarity; Display; Display controller; Display devices; Drops; Improving performance; Memory; Mobile data traffic; Mobile SoC; Sleep research; SoC; Video Streaming Applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"SXBZHDPR","journalArticle","2018","Akkus, I.E.; Chen, R.; Rimac, I.; Stein, M.; Satzke, K.; Beck, A.; Aditya, P.; Hilt, V.","SAND: Towards High-Performance Serverless Computing","USENIX ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062596504&partnerID=40&md5=69803d1ae53e00a17efa1267107cd265","","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","923-935","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K9TNR4KG","conferencePaper","2015","Sharma, P.; Lee, S.; Guo, T.; Irwin, D.; Shenoy, P.","SpotCheck: Designing a derivative IaaS cloud on the spot market","","","","10.1145/2741948.2741953","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929584823&doi=10.1145%2f2741948.2741953&partnerID=40&md5=569b7364fd80a039909d1a56c1af465f","Infrastructure-as-a-Service (IaaS) cloud platforms rent resources, in the form of virtual machines (VMs), under a variety of contract terms that offer different levels of risk and cost. For example, users may acquire VMs in the spot market that are often cheap but entail significant risk, since their price varies over time based on market supply and demand and they may terminate at any time if the price rises too high. Currently, users must manage all the risks associated with using spot servers. As a result, conventional wisdom holds that spot servers are only appropriate for delay-tolerant batch applications. In this paper, we propose a derivative cloud platform, called SpotCheck, that transparently manages the risks associated with using spot servers for users. SpotCheck provides the illusion of an IaaS platform that offers always-available VMs on demand for a cost near that of spot servers, and supports all types of applications, including interactive ones. SpotCheck's design combines the use of nested VMs with live bounded-time migration and novel server pool management policies to maximize availability, while balancing risk and cost. We implement SpotCheck on Amazon's EC2 and show that it i) provides nested VMs to users that are 99.9989% available, ii) achieves nearly 5× cost savings compared to using equivalent types of ondemand VMs, and iii) eliminates any risk of losing VM state. Copyright © 2015 ACM.","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Platform as a Service (PaaS); Infrastructure as a service (IaaS); Balancing; Cloud platforms; Commerce; Contract terms; Delay tolerant; Iaas clouds; Management policy; Market supply and demand; On the spots; Spot market","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 10th European Conference on Computer Systems, EuroSys 2015","","","","","","","","","","","","","","",""
"6A8AY4TN","journalArticle","","","","IBM Serverless Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095546931&partnerID=40&md5=3cdaa5c2be56fe7ab21039b8a6cd784f","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W5V2KQBC","conferencePaper","2018","Rengasamy, P.V.; Zhang, H.; Zhao, S.; Nachiappan, N.C.; Sivasubramaniam, A.; Kandemir, M.T.; Das, C.R.","CritICs critiquing criticality in mobile apps","","","","10.1109/MICRO.2018.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060005773&doi=10.1109%2fMICRO.2018.00075&partnerID=40&md5=f6ce916e62036f960c6a76c924b0a891","In this paper, we conduct a systematic analysis to show that existing CPU optimizations targeting scientific/server workloads are not always well suited for mobile apps. In particular, we observe that the well-known and very important concept of identifying and accelerating individual critical instructions in workloads such as SPEC, are not as effective for mobile apps. Several differences in mobile app characteristics including (i) dependencies between critical instructions interspersed with non-critical instructions in the dependence chain, (ii) temporal proximity of the critical instructions in the dynamic stream, and (iii) the bottleneck shifting to the front from the rear of the datapath pipeline, are key contributors to the ineffectiveness of traditional criticality based optimizations. Instead, we propose the concept of Critical Instruction Chains (CritICs)-which are short, critical and self contained sequences of instructions, for aggregate level optimization. With motivating results, we show that an offline profiler/analysis framework can easily identify these CritICs, and we propose a very simple software mechanism in the compiler that exploits ARM's 16-bit ISA format to nearly double the fetch bandwidth of these instructions. We have implemented this entire framework-both profiler and compiler passes, and evaluated its effectiveness for 10 popular apps from the Play Store. Experimental evaluations show that our approach is much more effective than two previously studied criticality optimizations, yielding a speedup of 12.65%, and energy savings of 15% in the CPU (translating to a system wide energy savings of 4.6%), requiring very little additional hardware support. © 2018 IEEE.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","867-880","","","2018-October","","","","","","","","","","","","","Scopus","","","","","","","","Program compilers; Program processors; Computer architecture; Energy; Energy conservation; CPU; Criticality; Criticality (nuclear fission); Experimental evaluation; Fetch bandwidth; Hardware supports; Mobile; Mobile apps; Software mechanisms; Systematic analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"DYN34QSH","conferencePaper","2006","Pandey, V.; Jiang, W.; Zhou, Y.; Blanching, R.","DMA-aware memory energy management","","","","10.1109/HPCA.2006.1598120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748852203&doi=10.1109%2fHPCA.2006.1598120&partnerID=40&md5=d28838b3aaa649420a770679b9a25b3f","As increasingly larger memories are used to bridge the widening gap between processor and disk speeds, main memory energy consumption is becoming increasingly dominant. Even though much prior research has been conducted on memory energy management, no study has focused on data servers, where main memory is predominantly accessed by DMAs instead of processors. In this paper, we study DMA-aware techniques for memory energy management in data servers. We first characterize the effect of DMA accesses on memory energy and show that, due to the mismatch between memory and I/O bus band-widths, significant energy is wasted when memory is idle but still active during DMA transfers. To reduce this waste, we propose two novel performance-directed energy management techniques that maximize the utilization of memory devices by increasing the level of concurrency between multiple DMA transfers from different I/O buses to the same memory device. We evaluate our techniques using a detailed trace-driven simulator, and storage and database server traces. The results show that our techniques can effectively minimize the amount of idle energy waste during DMA transfers and, consequently, conserve up to 38.6% more memory energy than previous approaches while providing similar performance. © 2006 IEEE.","2006","2025-10-22 19:07:40","2025-10-22 19:07:40","","134-145","","","2006","","","","","","","","","","","","","Scopus","","","","","","","","Program processors; Energy utilization; Energy management; Servers; Data servers; Data storage equipment; Database systems; Disk speeds; DMA transfers; Dynamic mechanical analysis; Magnetic disk storage; Memory energy management; Storage allocation (computer)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on High-Performance Computer Architecture","","","","","","","","","","","","","","",""
"MD3GDU43","conferencePaper","2016","Delgado, P.; Didona, D.; Dinu, F.; Zwaenepoel, W.","Job-aware scheduling in eagle: Divide and stick to your probes","","","","10.1145/2987550.2987563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995553833&doi=10.1145%2f2987550.2987563&partnerID=40&md5=1df124fce5bd418eaf82e5878d991f28","We present Eagle, a new hybrid data center scheduler for data-parallel programs. Eagle dynamically divides the nodes of the data center in partitions for the execution of long and short jobs, thereby avoiding head-of-line blocking. Furthermore, it provides job awareness and avoids stragglers by a new technique, called Sticky Batch Probing (SBP). The dynamic partitioning of the data center nodes is accomplished by a technique called Succinct State Sharing (SSS), in which the distributed schedulers are informed of the locations where long jobs are executing. SSS is particularly easy to implement with a hybrid scheduler, in which the centralized scheduler places long jobs. With SBP, when a distributed scheduler places a probe for a job on a node, the probe stays there until all tasks of the job have been completed. When finishing the execution of a task corresponding to probe P, rather than executing a task corresponding to the next probe P' in its queue, the node may choose to execute another task corresponding to P. We use SBP in combination with a distributed approximation of Shortest Remaining Processing Time (SRPT) with starvation prevention. We have implemented Eagle as a Spark plugin, and we have measured job completion times for a subset of the Google trace on a 100-node cluster for a variety of cluster loads. We provide simulation results for larger clusters, different traces, and for comparison with other scheduling disciplines. We show that Eagle outperforms other state-oftheart scheduling solutions at most percentiles, and is more robust against mis-estimation of task duration.","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","497-509","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Cloud computing; Centralized schedulers; Data center; Data centers; Data handling; Data parallel programs; Distributed schedulers; Dynamic partitioning; Finishing; Head of line blocking; Scheduling discipline; Shortest remaining processing time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 7th ACM Symposium on Cloud Computing, SoCC 2016","","","","","","","","","","","","","","",""
"XANTJ57Z","conferencePaper","2017","Wang, C.; Urgaonkar, B.; Nasiriani, N.; Kesidis, G.","Using burstable instances in the public cloud: Why, when and how?","","","","10.1145/3078505.3078591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021822573&doi=10.1145%2f3078505.3078591&partnerID=40&md5=9e00f6949b8937ff15bc91824be21271","","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","56","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource allocation; Burstable instance; Capacity dynamism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SIGMETRICS 2017 Abstracts - Proceedings of the 2017 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems","","","","","","","","","","","","","","",""
"BLW7W3PJ","journalArticle","2011","Povey, D.; Ghoshal, A.; Boulianne, G.; Burget, L.; Glembek, O.; Goel, N.; Hannemann, M.; Motlicek, P.; Qian, Y.; Schwarz, P.; Silovsky, J.; Stemmer, G.; Vesely, K.","The kaldi speech recognition toolkit","Proc. ASRU","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858953642&partnerID=40&md5=a2114d55aa5c88fb66e91dcc67602237","","2011","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R82B7EES","journalArticle","2007","Kohavi, R.; Longbotham, R.","Online experiments: Lessons learned","Computer","","","10.1109/MC.2007.328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34748868419&doi=10.1109%2fMC.2007.328&partnerID=40&md5=4b11067d910674a269972b00efdfaa6b","Web experiments generate insights and promote innovation. © 2007 IEEE.","2007","2025-10-22 19:07:40","2025-10-22 19:07:40","","103-105","","9","40","","","","","","","","","","","","","Scopus","","","","","","","","Online experiments; Web technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLU9A6H5","journalArticle","","","","IBM Composer","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061814553&partnerID=40&md5=6ef0f6d4678e0850e05bc07c0ae45e35","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YT7LA6Z","conferencePaper","2018","Khaleq, A.A.; Ra, I.","Cloud-Based Disaster Management as a Service: A Microservice Approach for Hurricane Twitter Data Analysis","","","","10.1109/GHTC.2018.8601887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061838462&doi=10.1109%2fGHTC.2018.8601887&partnerID=40&md5=ff951a00244499db2772fb34bfd80e89","Disasters whether natural or man-made have great impact on countries and civilians. Proper information across the main disaster phases need to be delivered on time and to the right people to minimize the impact and provide needed resources. Social media and Twitter in particular, is an important mean of information sharing in real-Time as part of a complete cyber-physical emergency management system during a disaster. Twitter can be used in any place in the world through smartphones or other mediums with an internet access connection. The vast and varied number of tweets produced during a disaster will benefit from the cloud scalable storage and processing resources. As a centralized processing system is more vulnerable when a disaster strikes, there is a need for a more resilient distributed system architecture that allows for the distribution of both processing and storage resources. The goal of our study is to develop and evaluate a prototype of a microservice architecture for twitter data analytics during a disaster that meets the requirements of disaster management. In this paper, we design a cloud-based microservices twitter analytics framework for disaster management and implement a basic prototype system. Our prototype system demonstrates that the microservices approach allows for a distributed, dynamic, reliable and scalable system architecture on cloud platform that goes in hand with disaster domain requirements. © 2018 IEEE.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Big data; Information management; Cloud applications; Computer architecture; Storage resources; Architecture; Data Analytics; Digital storage; Social networking (online); Microservice architecture; microservice architecture; Risk management; Information sharing; Cloud-based; Disasters; Prototype system; Cloud analytics; cloud applications; disaster management; Disaster management; Disaster prevention; Hurricanes; Processing resources; Social media; Twitter analytic; twitter analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","GHTC 2018 - IEEE Global Humanitarian Technology Conference, Proceedings","","","","","","","","","","","","","","",""
"9TGBRFXE","conferencePaper","2016","Hendrickson, S.; Sturdevant, S.; Harter, T.; Venkataramani, V.; Arpaci-Dusseau, A.C.; Arpaci-Dusseau, R.H.","Serverless computation with OpenLambda","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084164509&partnerID=40&md5=1a21e36f6f88c72da58021cdea14a5d5","We present OpenLambda, a new, open-source platform for building next-generation web services and applications in the burgeoning model of serverless computation. We describe the key aspects of serverless computation, and present numerous research challenges that must be addressed in the design and implementation of such systems. We also include a brief study of current web applications, so as to better motivate some aspects of serverless application construction. © 2016 USENIX Association. All rights reserved.","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Design and implementations; Cloud computing; Web services; Research challenges; WEB application; Open source platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","8th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2016","","","","","","","","","","","","","","",""
"4ZCGY3BQ","journalArticle","2020","Sreekanti, V.; Wu, C.; Lin, X.C.; Schleier-Smith, J.; Faleiro, J.M.; Gonzalez, J.E.; Hellerstein, J.M.; Tumanov, A.","Cloudburst: Stateful functions-as-a-service","Cloudburst: Stateful functions-as-a-service","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086281019&partnerID=40&md5=ab57b28a082c003185256d0439147e50","","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2IZWHMM","journalArticle","2016","Abadi, M.","TensorFlow: Learning functions at scale","ACM SIGPLAN Notices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039716878&partnerID=40&md5=5e3e0918218e91fc4e1a1a4f9aeb5b21","","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","9","51","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXYBQFBG","journalArticle","","","","Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098487549&partnerID=40&md5=5ae153ebc160adfdb02cd449da782c20","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYGN5L8L","conferencePaper","2015","Delimitrou, C.; Sanchez, D.; Kozyrakis, C.","Tarcil: Reconciling scheduling speed and quality in large shared clusters","","","","10.1145/2806777.2806779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959036568&doi=10.1145%2f2806777.2806779&partnerID=40&md5=523707d41f70d4102eb4334422502869","Scheduling diverse applications in large, shared clusters is particularly challenging. Recent research on cluster scheduling focuses either on scheduling speed, using sampling to quickly assign resources to tasks, or on scheduling quality, using centralized algorithms that search for the resources that improve both task performance and cluster utilization. We present Tarcil, a distributed scheduler that targets both scheduling speed and quality. Tarcil uses an analytically derived sampling framework that adjusts the sample size based on load, and provides statistical guarantees on the quality of allocated resources. It also implements admission control when sampling is unlikely to find suitable resources. This makes it appropriate for large, shared clusters hosting shortand long-running jobs. We evaluate Tarcil on clusters with hundreds of servers on EC2. For highly-loaded clusters running short jobs, Tarcil improves task execution time by 41% over a distributed, sampling-based scheduler. For more general scenarios, Tarcil achieves near-optimal performance for 4× and 2× more jobs than sampling-based and centralized schedulers respectively. © 2015 ACM.","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","97-110","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Cloud computing; QoS; Centralized schedulers; Data centers; Distributed schedulers; Resource efficiencies; Near-optimal performance; Datacenters; Diverse applications; Scalability; Centralized algorithms; Resource-efficiency; Sampling; Statistical guarantee","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM SoCC 2015 - Proceedings of the 6th ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"MJ4K8WGS","journalArticle","2019","Buddha, J.P.; Beesetty, R.","Step Functions","The Definitive Guide to AWS Application Integration","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098411795&partnerID=40&md5=27877b13000e4908df896f0ccf53acf2","","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","263-342","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZRE4NCH","journalArticle","2017","","Function-as-a-Service Market by User Type (Developer-Centric and Operator-Centric), Application (Web and Mobile Based, Research and Academic), Service Type, Deployment Model, Organization Size, Industry Vertical, and Region - Global Forecast to 2021","Research and Markets","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098371439&partnerID=40&md5=8f4bf12242acb341652aca38b65c48f9","","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A94L3TTB","conferencePaper","2017","Jonas, E.; Pu, Q.; Venkataraman, S.; Stoica, I.; Recht, B.","Occupy the cloud: Distributed computing for the 99%","","","","10.1145/3127479.3128601","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032457554&doi=10.1145%2f3127479.3128601&partnerID=40&md5=297fd2995b565f6919acd69e150d9936","Distributed computing remains inaccessible to a large number of users, in spite of many open source platforms and extensive commercial offerings. While distributed computation frameworks have moved beyond a simple map-reduce model, many users are still left to struggle with complex cluster management and configuration tools, even for running simple embarrassingly parallel jobs. We argue that stateless functions represent a viable platform for these users, eliminating cluster management overhead, fulfilling the promise of elasticity. Furthermore, using our prototype implementation, Py-Wren, we show that this model is general enough to implement a number of distributed computing models, such as BSP, efficiently. Extrapolating from recent trends in network bandwidth and the advent of disaggregated storage, we suggest that stateless functions are a natural fit for data processing in future computing environments. © 2017 Association for Computing Machinery.","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","445-451","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Distributed computer systems; Open systems; Serverless; Prototype implementations; Digital storage; Computing environments; Data handling; Distributed computing; Open source platforms; AWS lambda; Distributed computation framework; Distributed computing models; PyWren","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2017 - Proceedings of the 2017 Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"VKLRDNVC","conferencePaper","2018","Chung, A.; Park, J.W.; Ganger, G.R.","Stratus: Cost-aware container scheduling in the public cloud","","","","10.1145/3267809.3267819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058982961&doi=10.1145%2f3267809.3267819&partnerID=40&md5=92b2e003340b423f8524c57fc0a3dace","Stratus is a new cluster scheduler specialized for orchestrating batch job execution on virtual clusters, dynamically allocated collections of virtual machine instances on public IaaS platforms. Unlike schedulers for conventional clusters, Stratus focuses primarily on dollar cost considerations, since public clouds provide effectively unlimited, highly heterogeneous resources allocated on demand. But, since resources are charged-for while allocated, Stratus aggressively packs tasks onto machines, guided by job runtime estimates, trying to make allocated resources be either mostly full (highly utilized) or empty (so they can be released to save money). Simulation experiments based on cluster workload traces from Google and TwoSigma show that Stratus reduces cost by 17–44% compared to state-of-the-art approaches to virtual cluster scheduling. © 2018 Association for Computing Machinery.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","121-134","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Cloud computing; Cluster computing; Cost-aware; State-of-the-art approach; Cluster scheduling; Container scheduling; Heterogeneous resources; Public clouds; Runtime estimates; Transient server; Virtual clusters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2018 - Proceedings of the 2018 ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"U92LGZ5F","conferencePaper","2016","Persico, V.; Montieri, A.; Pescape, A.","On the Network Performance of Amazon S3 Cloud-Storage Service","","","","10.1109/CloudNet.2016.16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010679733&doi=10.1109%2fCloudNet.2016.16&partnerID=40&md5=5910d41581a95a87b71ff3cd0066672a","The advances in networking technologies and the increase in the need for storage resources have prompted many companies to outsource their storage needs. Cloud-storage providers offer clean and simple file-system interfaces, abstracting away the complexities of direct hardware management. At the same time, however, such services eliminate the direct oversight of performance that final users with high service-level requirements traditionally expect. While several works in literature have addressed security-related issues (such as privacy, integrity, availability, etc.) few of them have targeted the network performance of this kind of services. In this work we propose the analysis of the performance of the network associated to the storage service offered by Amazon: S3. Thanks to a large-scale distributed campaign performed by leveraging the Bismark measurement platform, we have characterized how the performance of the network may impact the quality of service experienced by final users on the basis of their location and the configuration of services. We found how performance heavily changes (up to 1553 KiB/s) accordingto the location of the customers and the cloud region they rely on (up to 2117 KiB/s), also deriving a number of usageguidelines for the customers. In addition we characterize the impact of leveraging the Amazon CDN service to distributecontents, finding that while it guarantees up to a 275-percent performance improvement, cases exist for which additional costs may lead to worse performance. © 2016 IEEE.","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","113-118","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Network performance; Storage resources; Hardware management; Cloud networks; Additional costs; AWS; Cloud Networks; Cloud performance; Cloud Performance; Cloud Storage; Cloud storage services; Cloud storages; Networking technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 5th IEEE International Conference on Cloud Networking, CloudNet 2016","","","","","","","","","","","","","","",""
"99PGT532","journalArticle","2001","Welsh, M.; Culler, D.; Brewer, E.","SEDA: An architecture for well-conditioned, scalable internet services","Operating Systems Review (ACM)","","","10.1145/502059.502057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036041527&doi=10.1145%2f502059.502057&partnerID=40&md5=39444708ee3c15a575845675f72f1c4d","We propose a new design for highly concurrent Internet services, which we call the staged event-driven architecture (SEDA). SEDA is intended to support massive concurrency demands and simplify the construction of well-conditioned services. In SEDA, applications consist of a network of event-driven stages connected by explicit queues. This architecture allows services to be well-conditioned to load, preventing resources from being overcommitted when demand exceeds service capacity. SEDA makes use of a set of dynamic resource controllers to keep stages within their operating regime despite large fluctuations in load. We describe several control mechanisms for automatic tuning and load conditioning, including thread pool sizing, event batching, and adaptive load shedding. We present the SEDA design and an implementation of an Internet services platform based on this architecture. We evaluate the use of SEDA through two applications: a high-performance HTTP server and a packet router for the Gnutella peer-to-peer file sharing network. These results show that SEDA applications exhibit higher performance than traditional service designs, and are robust to huge variations in load.","2001","2025-10-22 19:07:40","2025-10-22 19:07:40","","230-243","","5","35","","","","","","","","","","","","","Scopus","","","","","","","","Packet switching; Internet; Computer architecture; HTTP; Telecommunication services; Routers; File organization; Queueing networks; Client server computer systems; Internet services; Congestion control (communication); Dynamic resource controllers; Packet router; Peer to peer file sharing network; Staged event driven architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"76238VCT","conferencePaper","2020","Zhao, S.; Zhang, H.; Bhuyan, S.; Mishra, C.S.; Ying, Z.; Kandemir, M.T.; Sivasubramaniam, A.; Das, C.R.","Déjà View: Spatio-Temporal Compute Reuse for' Energy-Efficient 360° VR Video Streaming","","","","10.1109/ISCA45697.2020.00030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091991854&doi=10.1109%2fISCA45697.2020.00030&partnerID=40&md5=f38f67d5801024d67b9baf3306fc494d","The emergence of virtual reality (VR) and augmented reality (AR) has revolutionized our lives by enabling a 360° artificial sensory stimulation across diverse domains, including, but not limited to, sports, media, healthcare, and gaming. Unlike the conventional planar video processing, where memory access is the main bottleneck, in 360° VR videos the compute is the primary bottleneck and contributes to more than 50% energy consumption in battery-operated VR headsets. Thus, improving the computational efficiency of the video processing pipeline in a VR is critical. While prior efforts have attempted to address this problem through acceleration using a GPU or FPGA, none of them has analyzed the 360° VR pipeline to examine if there is any scope to optimize the computation with known techniques such as memoization. Thus, in this paper, we analyze the VR computation pipeline and observe that there is significant scope to skip computations by leveraging the temporal and spatial locality in head orientation and eye correlations, respectively, resulting in computation reduction and energy efficiency. The proposed Déjà View design takes advantage of temporal reuse by memoizing head orientation and spatial reuse by establishing a relationship between left and right eye projection, and can be implemented either on a GPU or an FPGA. We propose both software modifications for existing compute pipeline and microarchitectural additions for further enhancement. We evaluate our design by implementing the software enhancements on an NVIDIA Jetson TX2 GPU board and our microarchitectural additions on a Xilinx Zynq-7000 FPGA model using five video workloads. Experimental results show that Déjà View can provide 34% computation reduction and 17% energy saving, compared to the state-of-the-art design. © 2020 IEEE.","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","241-253","","","2020-May","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Virtual reality; Energy efficient; Energy utilization; Field programmable gate arrays (FPGA); Video processing; Memory architecture; Computational efficiency; State of the art; Graphics processing unit; Video streaming; Integrated circuit design; Augmented reality; IoT; Edge Computing; Pipelines; 360° Video Processing; Computation reduction; Pipeline processing systems; Sensory stimulation; Software enhancements; Software modification; Temporal and spatial; Virtual Reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"HKRU8GUW","conferencePaper","2019","Baarzi, A.F.; Zhu, T.; Urgaonkar, B.","BurScale: Using Burstable Instances for Cost-Effective Autoscaling in the Public Cloud","","","","10.1145/3357223.3362706","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091803998&doi=10.1145%2f3357223.3362706&partnerID=40&md5=1353a8e9add9407b766677f9a3d1e3e6","Cloud providers have recently introduced burstable instances-virtual machines whose CPU capacity is rate limited by token-bucket mechanisms. A user of a burstable instance is able to burst to a much higher resource capacity (""peak rate"") than the instance's long-Term average capacity (""sustained rate""), provided the bursts are short and infrequent. A burstable instance tends to be much cheaper than a conventional instance that is always provisioned for the peak rate. Consequently, cloud providers advertise burstable instances as cost-effective options for customers with intermittent needs and small (e.g., single VM) clusters. By contrast, this paper presents two novel usage scenarios for burstable instances in larger clusters with sustained usage. We demonstrate (i) how burstable instances can be utilized alongside conventional instances to handle the transient queueing arising from variability in traffic, and (ii) how burstable instances can mask the VM startup/warmup time when autoscaling to handle flash crowds. We implement our ideas in a system called BurScale and use it to demonstrate cost-effective autoscaling for two important workloads: (i) a stateless web server cluster, and (ii) a stateful Memcached caching cluster. Results from our prototype system show that via its careful combination of burstable and regular instances, BurScale can ensure similar application performance as traditional autoscaling systems that use all regular instances while reducing cost by up to 50%. © 2019 ACM.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","126-138","","","","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; Usage scenarios; Virtual machine; Cloud providers; Cost effectiveness; Application performance; autoscaling; resource provisioning; Prototype system; Average capacities; burstable instances; Reducing costs; Resource capacity; Web server cluster","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2019 - Proceedings of the ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"A8HH7GLD","journalArticle","2017","Gujarati, A.; Elnikety, S.; He, Y.; McKinley, K. S.; Brandenburg, B. B.","Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency","USENIX Middleware Conference","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095484895&partnerID=40&md5=220c1fa5fda624b6df2f84c7fcf6f4e0","","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPPMJGAP","conferencePaper","2019","Wu, C.-J.; Brooks, D.; Chen, K.; Chen, D.; Choudhury, S.; Dukhan, M.; Hazelwood, K.; Isaac, E.; Jia, Y.; Jia, B.; Leyvand, T.; Lu, H.; Lu, Y.; Qiao, L.; Reagen, B.; Spisak, J.; Sun, F.; Tulloch, A.; Vajda, P.; Wang, X.; Wang, Y.; Wasti, B.; Wu, Y.; Xian, R.; Yoo, S.; Zhang, P.","Machine learning at facebook: Understanding inference at the edge","","","","10.1109/HPCA.2019.00048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064189318&doi=10.1109%2fHPCA.2019.00048&partnerID=40&md5=fce9ebef85a5b311645a3d1523a74cb6","At Facebook, machine learning provides a wide range of capabilities that drive many aspects of user experience including ranking posts, content understanding, object detection and tracking for augmented and virtual reality, speech and text translations. While machine learning models are currently trained on customized datacenter infrastructure, Facebook is working to bring machine learning inference to the edge. By doing so, user experience is improved with reduced latency (inference time) and becomes less dependent on network connectivity. Furthermore, this also enables many more applications of deep learning with important features only made available at the edge. This paper takes a datadriven approach to present the opportunities and design challenges faced by Facebook in order to enable machine learning inference locally on smartphones and other edge platforms. © 2019 IEEE.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","331-344","","","","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Virtual reality; Computer architecture; Network architecture; Learning systems; Machine learning; Social networking (online); Supercomputers; Machine learning models; Object detection; Augmented and virtual realities; Data-driven approach; Edge Inference; Important features; Network connectivity; Object detection and tracking; Reduced latencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 25th IEEE International Symposium on High Performance Computer Architecture, HPCA 2019","","","","","","","","","","","","","","",""
"J5EAPIRJ","conferencePaper","2019","Obetz, M.; Patterson, S.; Milanova, A.","Static call graph construction in AWS lambda serverless applications","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084163844&partnerID=40&md5=35c6f8ebd1837e9ea5344f84212d6117","We present new means for performing static program analysis on serverless programs. We propose a new type of call graph that captures the stateless, event-driven nature of such programs and describe a method for constructing these new extended service call graphs. Next, we survey applications of program analysis that can leverage our extended service call graphs to answer questions about code that executes on a serverless platform. We present findings on the applicability of our techniques to real open source serverless programs. Finally, we close with several open questions about how to best incorporate static analysis in problem solving for developing serverless applications. © 2019 USENIX Association. All rights reserved.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Cloud computing; XML; Static analysis; Open sources; Call graphs; Program analysis; Call graph construction; Event-driven; Static program analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019, co-located with USENIX ATC 2019","","","","","","","","","","","","","","",""
"8W493KRR","conferencePaper","2016","Villamizar, M.; Garces, O.; Ochoa, L.; Castro, H.; Salamanca, L.; Verano, M.; Casallas, R.; Gil, S.; Valencia, C.; Zambrano, A.; Lang, M.","Infrastructure Cost Comparison of Running Web Applications in the Cloud Using AWS Lambda and Monolithic and Microservice Architectures","","","","10.1109/CCGrid.2016.37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983458085&doi=10.1109%2fCCGrid.2016.37&partnerID=40&md5=794e884aa90085ecc838644b0e4b9f15","Large Internet companies like Amazon, Netflix, and LinkedIn are using the microservice architecture pattern to deploy large applications in the cloud as a set of small services that can be developed, tested, deployed, scaled, operated and upgraded independently. However, aside from gaining agility, independent development, and scalability, infrastructure costs are a major concern for companies adopting this pattern. This paper presents a cost comparison of a web application developed and deployed using the same scalable scenarios with three different approaches: 1) a monolithic architecture, 2) a microservice architecture operated by the cloud customer, and 3) a microservice architecture operated by the cloud provider. Test results show that microservices can help reduce infrastructure costs in comparison to standard monolithic architectures. Moreover, the use of services specifically designed to deploy and scale microservices reduces infrastructure costs by 70% or more. Lastly, we also describe the challenges we faced while implementing and deploying microservice applications. © 2016 IEEE.","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","179-182","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; cloud computing; Cloud computing; microservices; Software architecture; Distributed computer systems; Cluster computing; Grid computing; Computer architecture; software engineering; Software engineering; Web services; Costs; Amazon web services; AWS Lambda; Information services; Monolithic architecture; World Wide Web; WEB application; Service oriented architecture (SOA); software architecture; Cost reduction; microservice architecture; Amazon Web Services; Architecture patterns; Cost comparisons; Infrastructure costs; scalable applications; service oriented architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 16th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing, CCGrid 2016","","","","","","","","","","","","","","",""
"BN9YXMR3","conferencePaper","2019","Chen, S.; Delimitrou, C.; Martinez, J.F.","PARTIES: QoS-Aware Resource Partitioning for Multiple Interactive Services","","","","10.1145/3297858.3304005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064601154&doi=10.1145%2f3297858.3304005&partnerID=40&md5=4055a3f1ad5f004e9dfb025ceb4c7fc2","Multi-tenancy in modern datacenters is currently limited to a single latency-critical, interactive service, running alongside one or more low-priority, best-efort jobs. This limits the eiciency gains from multi-tenancy, especially as an increasing number of cloud applications are shifting from batch jobs to services with strict latency requirements. We present PARTIES, a QoS-aware resource manager that enables an arbitrary number of interactive, latency-critical services to share a physical node without QoS violations. PARTIES leverages a set of hardware and software resource partitioning mechanisms to adjust allocations dynamically at runtime, in a way that meets the QoS requirements of each co-scheduled workload, and maximizes throughput for the machine. We evaluate PARTIES on state-of-the-art server platforms across a set of diverse interactive services. Our results show that PARTIES improves throughput under QoS by 61% on average, compared to existing resource managers, and that the rate of improvement increases with the number of co-scheduled applications per physical host. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","107-120","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Datacenter; Cloud computing; Cloud-computing; resource management; Resource management; datacenters; Quality-of-service; Managers; quality of service; Interference; interference; isolation; resource partitioning; Interactive services; Isolation; Multi tenancies; QoS-aware; Resource partitioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"JXJ9M5ZJ","journalArticle","2016","Chen, Quan; Yang, Hailong; Mars, Jason; Tang, Lingjia","Bay-max: QoS Awareness and Increased Utilization for Non-Preemptive Accelerators in Warehouse Scale Computers","SIGARCH Computer Architecture News","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098370232&partnerID=40&md5=13168b4daffbc5318b6b5371997a63a5","","2016","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NCG2UI8C","conferencePaper","2017","Yang, H.; Chen, Q.; Riaz, M.; Luan, Z.; Tang, L.; Mars, J.","PowerChief: Intelligent power allocation for multi-stage applications to improve responsiveness on power constrained CMP","","","","10.1145/3079856.3080224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025619452&doi=10.1145%2f3079856.3080224&partnerID=40&md5=1b3762d3742b803bb5b2ea594b587a90","Modern user facing applications consist of multiple processing stages with a number of service instances in each stage. The latency profle of these multi-stage applications is intrinsically variable, making it challenging to provide satisfactory responsiveness. Given a limited power budget, improving the end-to-end latency requires intelligently boosting the bottleneck service across stages using multiple boosting techniques. However, prior work fail to acknowledge the multi-stage nature of user-facing applications and perform poorly in improving responsiveness on power constrained CMP, as they are unable to accurately identify bottleneck service and apply the boosting techniques adaptively. In this paper, we present PowerChief, a runtime framework that 1) provides joint design of service and query to monitor the latency statistics across service stages and accurately identifes the bottleneck service during runtime; 2) adaptively chooses the boosting technique to accelerate the bottleneck service with improved responsiveness; 3) dynamically reallocates the constrained power budget across service stages to accommodate the chosen boosting technique. Evaluated with real world multi-stage applications, PowerChief improves the average latency by 20.3× and 32.4× (99% tail latency by 13.3× and 19.4×) for Sirius and Natural Language Processing applications respectively compared to stage-agnostic power allocation. In addition, for the given QoS target, PowerChief reduces the power consumption of Sirius and Web Search applications by 23% and 33% respectively over prior work. © 2017 Association for Computing Machinery.","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","133-146","","","Part F128643","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Computer architecture; Budget control; Natural language processing systems; Power allocations; End to end latencies; Facings; Intelligent Service Boosting; Intelligent Services; Multi stage; Multi-Stage Application; Multiple processing; Number of services; Power Constrained CMP; Runtime frameworks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"WA8ATEDG","conferencePaper","2019","Kaviani, N.; Kalinin, D.; Maximilien, M.","Towards serverless as commodity: A case of Knative","","","","10.1145/3366623.3368135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078952724&doi=10.1145%2f3366623.3368135&partnerID=40&md5=646110fad1b668fef322752c42165706","Serverless computing promises to evolve cloud computing architecture from VMs and containers-as-a-service (CaaS) to function-as-a-service (FaaS). This takes away complexities of managing and scaling underlying infrastructure and can result in simpler code, cheaper realization of services, and higher availability. Nonetheless, one of the primary drawbacks customers face when making decision to move their software to a serverless platform is the potential for getting locked-in with a particular provider. This used to be a concern with Platform-as-a-Service (PaaS) offerings too. However with Kubernetes emerging as the industry standard PaaS layer, PaaS is closer to becoming commodity with the Kubernetes API as its common interface. The question is if a similar unification for the API interface layer and runtime contracts can be achieved for serverless. If achieved, this would free up serverless users from their fears of platform lock-in. Our goal in this paper is to extract a minimal common denominator model of execution that can move us closer to a unified serverless platform. As contributors to Knative [13] with in-depth understanding of its internal design, we use Knative as the baseline for this comparison and contrast its API interface and runtime contracts against other prominent serverless platforms to identify commonalities and differences. Influenced by the work in Knative, we also discuss challenges as well as the necessary evolution we expect to see as serverless platforms themselves reach commodity status. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","13-18","","","","","","","","","","","","","","","","Scopus","","","","","","","","Platform as a Service (PaaS); Performance; Serverless; Computer architecture; Clouds; Industry standards; Middleware; Application programming interfaces (API); Cloud; Scalability; Locks (fasteners); Cloud computing architectures; Common denominators; Common interfaces; In-depth understanding; Model of executions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","WOSC 2019 - Proceedings of the 2019 5th International Workshop on Serverless Computing, Part of Middleware 2019","","","","","","","","","","","","","","",""
"CIL5CBA2","conferencePaper","2019","Pattnaik, A.; Tang, X.; Kayiran, O.; Jog, A.; Mishra, A.; Kandemir, M.T.; Sivasubramaniam, A.; Das, C.R.","Opportunistic computing in GPU architectures","","","","10.1145/3307650.3322212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067674010&doi=10.1145%2f3307650.3322212&partnerID=40&md5=064f3aa92292124b1033b830a7ca4ba3","Data transfer overhead between computing cores and memory hierarchy has been a persistent issue for von Neumann architectures and the problem has only become more challenging with the emergence of manycore systems. A conceptually powerful approach to mitigate this overhead is to bring the computation closer to data, known as Near Data Computing (NDC). Recently, NDC has been investigated in different flavors for CPU-based multicores, while the GPU domain has received little attention. In this paper, we present a novel NDC solution for GPU architectures with the objective of minimizing on-chip data transfer between the computing cores and Last-Level Cache (LLC). To achieve this, we first identify frequently occurring Load-Compute-Store instruction chains in GPU applications. These chains, when offloaded to a compute unit closer to where the data resides, can significantly reduce data movement. We develop two offloading techniques, called LLC-Compute and Omni-Compute. The first technique, LLC-Compute, augments the LLCs with computational hardware for handling the computation offloaded to them. The second technique (Omni-Compute) employs simple bookkeeping hardware to enable GPU cores to compute instructions offloaded by other GPU cores. Our experimental evaluations on nine GPGPU workloads indicate that the LLC-Compute technique provides, on an average, 19% performance improvement (IPC), 11% performance/watt improvement, and 29% reduction in on-chip data movement compared to the baseline GPU design. The Omni-Compute design boosts these benefits to 31%, 16% and 44%, respectively. © 2019 ACM.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","210-223","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Program processors; Computation offloading; Memory architecture; GPU; Graphics processing unit; Experimental evaluation; Data transfer; Lastlevel caches (LLC); Manycore systems; Memory hierarchy; Near data computing; Neumann architecture; Opportunistic computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"DIE2GPXI","journalArticle","","","","WITS: Waikato Internet Traffic Storage","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870668438&partnerID=40&md5=fdeae5e938dbe2ee5bbc11117f041ae1","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83IHEJRM","journalArticle","2015","Chen, T.; Li, M.; Li, Y.; Lin, M.; Wang, N.; Wang, M.; Xiao, T.; Xu, B.; Zhang, C.; Zhang, Z.","Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems","CoRR","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018888481&partnerID=40&md5=f556582559a70d9c8f2f07d9bd0c56d0","","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EB97ULGE","journalArticle","2009","Urdaneta, G.; Pierre, G.; van Steen, M.","Wikipedia workload analysis for decentralized hosting","Computer Networks","","","10.1016/j.comnet.2009.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349226826&doi=10.1016%2fj.comnet.2009.02.019&partnerID=40&md5=b5fc02e0d8213494d9a714f5be814510","We study an access trace containing a sample of Wikipedia's traffic over a 107-day period aiming to identify appropriate replication and distribution strategies in a fully decentralized hosting environment. We perform a global analysis of the whole trace, and a detailed analysis of the requests directed to the English edition of Wikipedia. In our study, we classify client requests and examine aspects such as the number of read and save operations, significant load variations and requests for nonexisting pages. We also review proposed decentralized wiki architectures and discuss how they would handle Wikipedia's workload. We conclude that decentralized architectures must focus on applying techniques to efficiently handle read operations while maintaining consistency and dealing with typical issues on decentralized systems such as churn, unbalanced loads and malicious participating nodes. © 2009 Elsevier B.V. All rights reserved.","2009","2025-10-22 19:07:40","2025-10-22 19:07:40","","1830-1845","","11","53","","","","","","","","","","","","","Scopus","","","","","","","","Internet; Websites; Distribution strategies; P2P; Decentralized architecture; Decentralized hosting; Decentralized system; Global analysis; Unbalanced loads; Wikipedia; Workload analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEGSZSTR","conferencePaper","2019","Kaffes, K.; Yadwadkar, N.J.; Kozyrakis, C.","Centralized Core-granular Scheduling for Serverless Functions","","","","10.1145/3357223.3362709","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091770578&doi=10.1145%2f3357223.3362709&partnerID=40&md5=55e6a8163cf50fe7af99df21b5104efe","In recent years, many applications have started using serverless computing platforms primarily due to the ease of deployment and cost efficiency they offer. However, the existing scheduling mechanisms of serverless platforms fall short in catering to the unique characteristics of such applications: burstiness, short and variable execution times, statelessness and use of a single core. Specifically, the existing mechanisms fall short in meeting the requirements generated due to the combined effect of these characteristics: scheduling at a scale of millions of function invocations per second while achieving predictable performance. In this paper, we argue for a cluster-level centralized and core-granular scheduler for serverless functions. By maintaining a global view of the cluster resources, the centralized approach eliminates queue imbalances while the core granularity reduces interference; together these properties enable reduced performance variability. We expect such a scheduler to increase the adoption of serverless computing platforms by various latency and throughput sensitive applications. © 2019 ACM.","2019","2025-10-22 19:07:40","2025-10-22 19:07:40","","158-164","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; cloud computing; Cloud computing; Computing platform; serverless computing; Sensitive application; scheduling; resource allocation; Centralized approaches; Combined effect; Cost efficiency; Performance variability; Scheduling mechanism; Variable execution time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2019 - Proceedings of the ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"2LJCVL3A","conferencePaper","2018","Feng, L.; Kudva, P.; Da Silva, D.; Hu, J.","Exploring Serverless Computing for Neural Network Training","","","","10.1109/CLOUD.2018.00049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057438808&doi=10.1109%2fCLOUD.2018.00049&partnerID=40&md5=f06e623d4d0cec6601a12dd5fbed07cb","Serverless or functions as a service runtimes have shown significant benefits to efficiency and cost for event-driven cloud applications. Although serverless runtimes are limited to applications requiring lightweight computation and memory, such as machine learning prediction and inference, they have shown improvements on these applications beyond other cloud runtimes. Training deep learning can be both compute and memory intensive. We investigate the use of serverless runtimes while leveraging data parallelism for large models, show the challenges and limitations due to the tightly coupled nature of such models, and propose modifications to the underlying runtime implementations that would mitigate them. For hyperparameter optimization of smaller deep learning models, we show that serverless runtimes can provide significant benefit. © 2018 IEEE.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","334-341","","","2018-July","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Deep learning; Cloud applications; Serverless computing; Neural networks; Cloud cost and performance; Cloud scaling; Data parallelism; Hyper-parameter optimizations; Large models; Learning models; Neural network training; Tightly-coupled","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"M335VYRB","conferencePaper","2015","Karanasos, K.; Raol, S.; Curino, C.; Douglas, C.; Chaliparambil, K.; Fumarola, G.M.; Ramakrishnan, S.H.R.; Sakalanaga, S.","Mercury: Hybrid Centralized and Distributed Scheduling in Large Shared Clusters","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077131857&partnerID=40&md5=2eda27e797887c37a269c5dd9bcc7365","Datacenter-scale computing for analytics workloads is increasingly common. High operational costs force heterogeneous applications to share cluster resources for achieving economy of scale. Scheduling such large and diverse workloads is inherently hard, and existing approaches tackle this in two alternative ways: 1) centralized solutions offer strict, secure enforcement of scheduling invariants (e.g., fairness, capacity) for heterogeneous applications, 2) distributed solutions offer scalable, efficient scheduling for homogeneous applications. We argue that these solutions are complementary, and advocate a blended approach. Concretely, we propose Mercury, a hybrid resource management framework that supports the full spectrum of scheduling, from centralized to distributed. Mercury exposes a programmatic interface that allows applications to trade-off between scheduling overhead and execution guarantees. Our framework harnesses this flexibility by opportunistically utilizing resources to improve task throughput. Experimental results on production-derived workloads show gains of over 35% in task throughput. These benefits can be translated by appropriate application and framework policies into job throughput or job latency improvements. We have implemented and contributed Mercury as an extension of Apache Hadoop/YARN.1. © 2015 USENIX Annual Technical Conference.","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","485-497","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Economic and social effects; Computer software; Efficient scheduling; Throughput; Blended approach; Distributed solutions; Economy of scale; Full spectrum; Hybrid centralized; Hybrid resource managements; Job throughput; Mercury (metal)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2015 USENIX Annual Technical Conference, USENIX ATC 2015","","","","","","","","","","","","","","",""
"AHFNRF8Q","journalArticle","2015","Nachiappan, N.C.; Zhang, H.; Ryoo, J.; Soundararajan, N.; Sivasubramaniam, A.; Kandemir, M.T.; Iyer, R.; Das, C.R.","VIP: Virtualizing IP chains on handheld platforms","ACM SIGARCH Computer Architecture News","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027250997&partnerID=40&md5=615aeb13614e0bf7ddb079231c0d8cb9","","2015","2025-10-22 19:07:40","2025-10-22 19:07:40","","655-667","","3","43","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLQ758I9","journalArticle","2024","Konsor, P.","","Intel Power Gadget","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876078201&partnerID=40&md5=a51df9ce968f03e7e79f6cd83263fa4d","","2024","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5AXWHRU","journalArticle","2018","Chollet, F.","Deep Learning mit Python und Keras: Das Praxis-Handbuch vom Entwickler der Keras-Bibliothek","Deep Learning mit Python und Keras: Das Praxis-Handbuch vom Entwickler der Keras-Bibliothek","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082530819&partnerID=40&md5=40bb660655d66326ab9d500c767b123f","","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9WEY778V","journalArticle","2018","Cui, J.; Zhang, Y.; Wu, W.; Yang, J.; Wang, Y.; Huang, J.","DLV: Exploiting Device Level Latency Variations for Performance Improvement on Flash Memory Storage Systems","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","","10.1109/TCAD.2017.2766156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032436449&doi=10.1109%2fTCAD.2017.2766156&partnerID=40&md5=57cd4cef0a332c000a6a6af92112dc0a","NAND flash has been widely adopted in storage systems due to its better read and write performance and lower power consumption over traditional mechanical hard drives. To meet the increasing performance demand of modern applications, recent studies speed up flash accesses by exploiting access latency variations at the device level. Unfortunately, existing flash access schedulers are still oblivious to such variations, leading to suboptimal I/O performance improvements. In this paper, we propose DLV, a novel flash access scheduler for exploring scheduling opportunities due to device level access latency variations. DLV improves flash access speeds based on process variations and data retention time difference across flash blocks. More importantly, DLV integrates access speed optimization with access scheduling such that the average access response time can be effectively reduced on flash memory storage systems. Our experimental results show that DLV achieves an average of 41.5% performance improvement over the state-of-the-art. © 1982-2012 IEEE.","2018","2025-10-22 19:07:40","2025-10-22 19:07:40","","1546-1559","","8","37","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Mathematical programming; Performance evaluations; Time factors; Random access storage; Sensors; Random access memory; Error correction; Error correction codes; Flash memories; Flash memory; LDPC; low-density parity-check code (LDPC); Mechanical drives; Out of order; out-of-order scheduler; Parity check codes; Process Variation; process variation (PV); raw bit error rate (RBER); RBER; Retention age; retention age (RA)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITGPJ9B9","conferencePaper","2017","Castro, P.; Ishakian, V.; Muthusamy, V.; Slominski, A.","Serverless Programming (Function as a Service)","","","","10.1109/ICDCS.2017.305","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027280573&doi=10.1109%2fICDCS.2017.305&partnerID=40&md5=28b8e93ea54cb314f955313130e9c407","","2017","2025-10-22 19:07:40","2025-10-22 19:07:40","","2658-2659","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Distributed Computing Systems","","","","","","","","","","","","","","",""
"WCFRKZ9B","journalArticle","","","","Azure Durable Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095083784&partnerID=40&md5=73d56b97fab2f3e3d5e4da83dc7c87ff","","","2025-10-22 19:07:40","2025-10-22 19:07:40","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGAZP87F","conferencePaper","2020","Kumar, A.; Narayanan, I.; Zhu, T.; Sivasubramaniam, A.","The Fast and the Frugal: Tail Latency Aware Provisioning for Coping with Load Variations","","","","10.1145/3366423.3380117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086574713&doi=10.1145%2f3366423.3380117&partnerID=40&md5=9548743118b8b136fc81d22acc45edef","Small and medium sized enterprises use the cloud for running online, user-facing, tail latency sensitive applications with well-defined fixed monthly budgets. For these applications, adequate system capacity must be provisioned to extract maximal performance despite the challenges of uncertainties in load and request-sizes. In this paper, we address the problem of capacity provisioning under fixed budget constraints with the goal of minimizing tail latency. To tackle this problem, we propose building systems using a heterogeneous mix of low latency expensive resources and cheap resources that provide high throughput per dollar. As load changes through the day, we use more faster resources to reduce tail latency during low load periods and more cheaper resources to handle the high load periods. To achieve these tail latency benefits, we introduce novel heterogeneity-aware scheduling and autoscaling algorithms that are designed for minimizing tail latency. Using software prototypes and by running experiments on the public cloud, we show that our approach can outperform existing capacity provisioning systems by reducing the tail latency by as much as 45% under fixed-budget settings. © 2020 ACM.","2020","2025-10-22 19:07:40","2025-10-22 19:07:40","","314-326","","","","","","","","","","","","","","","","Scopus","","","","","","","","Budget control; Scheduling algorithms; Sensitive application; Software prototyping; World Wide Web; Building systems; Cheap resources; Existing capacity; Load variations; Low load periods; Small and medium sized enterprise; System Capacity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020","","","","","","","","","","","","","","",""
"M36AHYTX","conferencePaper","2007","Ghosh, M.; Lee, H.-H.S.","Smart refresh: An enhanced memory controller design for reducing energy in conventional and 3D die-stacked DRAMs","","","","10.1109/MICRO.2007.13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47349120126&doi=10.1109%2fMICRO.2007.13&partnerID=40&md5=11b5090eb7847c4d65a19e6e517976dd","DRAMs require periodic refresh for preserving data stored in them. The refresh interval for DRAMs depends on the vendor and the design technology they use. For each refresh in a DRAM row, the stored information in each cell is read out and then written back to itself as each DRAM bit read is self-destructive. The refresh process is inevitable for maintaining data correctness, unfortunately, at the expense of power and bandwidth overhead. The future trend to integrate layers of 3D die-stacked DRAMs on top of a processor further exacerbates the situation as accesses to these DRAMs will be more frequent and hiding refresh cycles in the available slack becomes increasingly difficult. Moreover, due to the implication of temperature increase, the refresh interval of 3D die-stacked DRAMs will become shorter than those of conventional ones. This paper proposes an innovative scheme to alleviate the energy consumed in DRAMs. By employing a time-out counter for each memory row of a DRAM module, all the unnecessary periodic refresh operations can be eliminated. The basic concept behind our scheme is that a DRAM row that was recently read or written to by the processor (or other devices that share the same DRAM) does not need to be refreshed again by the periodic refresh operation, thereby eliminating excessive refreshes and the energy dissipated. Based on this concept, we propose a low-cost technique in the memory controller for DRAM power reduction. The simulation results show that our technique can reduce up to 86% of all refresh operations and 59.3% on the average for a 2GB DRAM. This in turn results in a 52.6% energy savings for refresh operations. The overall energy saving in the DRAM is up to 25.7% with an average of 12.13% obtained for SPLASH-2, SPECint2000, and Biobench benchmark programs simulated on a 2GB DRAM. For a 64MB 3D DRAM, the energy saving is up to 21% and 9.37% on an average when the refresh rate is 64 ms. For a faster 32ms refresh rate the maximum and average savings are 12% and 6.8% respectively. © 2007 IEEE.","2007","2025-10-22 19:07:40","2025-10-22 19:07:40","","134-145","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy conservation; Dynamic random access storage; Micro architectures; Cost reduction; Energy savings; BASIC (programming language); Benchmark programs; Biobench; Canning; Design technologies; Dies; International symposium; Ketones; Memory controllers; Power reductions; Reducing energy; Simulation results; Temperature increase; Time outs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"APGXDSYV","journalArticle","2014","Han, R.; Ghanem, M.M.; Guo, L.; Guo, Y.; Osmond, M.","Enabling cost-aware and adaptive elasticity of multi-tier cloud applications","Future Generation Computer Systems","","","10.1016/j.future.2012.05.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891600220&doi=10.1016%2fj.future.2012.05.018&partnerID=40&md5=2b7a30910070a629e11affb87f30275c","Elasticity (on-demand scaling) of applications is one of the most important features of cloud computing. This elasticity is the ability to adaptively scale resources up and down in order to meet varying application demands. To date, most existing scaling techniques can maintain applications' Quality of Service (QoS) but do not adequately address issues relating to minimizing the costs of using the service. In this paper, we propose an elastic scaling approach that makes use of cost-aware criteria to detect and analyse the bottlenecks within multi-tier cloud-based applications. We present an adaptive scaling algorithm that reduces the costs incurred by users of cloud infrastructure services, allowing them to scale their applications only at bottleneck tiers, and present the design of an intelligent platform that automates the scaling process. Our approach is generic for a wide class of multi-tier applications, and we demonstrate its effectiveness against other approaches by studying the behaviour of an example e-commerce application using a standard workload benchmark.","2014","2025-10-22 19:07:40","2025-10-22 19:07:40","","82-98","","1","32","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Algorithms; Benchmarking; Elasticity; Cloud-based applications; Costs; Cloud infrastructures; Adaptive elasticity; Adaptive scaling; Adaptive scaling algorithm; Cost-aware; Cost-aware criteria; E-Commerce applications; Intelligent platform; Multi-tier applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XJYXYHA","journalArticle","2018","Harlap, A.; Chung, A.; Tumanov, A.; Ganger, G.R.; Gibbons, P.B.","Tributary: Spot-dancing for elastic services with latency SLOs","2018 USENIX Annual Technical Conference (USENIX ATC 18)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058985076&partnerID=40&md5=a8186c9bf0d66cef5aa332d36884d8be","","2018","2025-10-22 19:07:41","2025-10-22 19:07:41","","1-14","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5649962","conferencePaper","2019","Thinakaran, P.; Gunasekaran, J.R.; Sharma, B.; Kandemir, M.T.; Das, C.R.","Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters","","","","10.1109/CLUSTER.2019.8891040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075268776&doi=10.1109%2fCLUSTER.2019.8891040&partnerID=40&md5=c15599158265a13428a55a593c69384d","Compute heterogeneity is increasingly gaining prominence in modern datacenters due to the addition of accelerators like GPUs and FPGAs. We observe that datacenter schedulers are agnostic of these emerging accelerators, especially their resource utilization footprints, and thus, not well equipped to dynamically provision them based on the application needs. We observe that the state-of-the-art datacenter schedulers fail to provide fine-grained resource guarantees for latency-sensitive tasks that are GPU-bound. Specifically for GPUs, this results in resource fragmentation and interference leading to poor utilization of allocated GPU resources. Furthermore, GPUs exhibit highly linear energy efficiency with respect to utilization and hence proactive management of these resources is essential to keep the operational costs low while ensuring the end-to-end Quality of Service (QoS) in case of user-facing queries.Towards addressing the GPU orchestration problem, we build Knots, a GPU-aware resource orchestration layer and integrate it with the Kubernetes container orchestrator to build Kube-Knots. Kube-Knots can dynamically harvest spare compute cycles through dynamic container orchestration enabling co-location of latency-critical and batch workloads together while improving the overall resource utilization. We design and evaluate two GPU-based scheduling techniques to schedule datacenter-scale workloads through Kube-Knots on a ten node GPU cluster. Our proposed Correlation Based Prediction (CBP) and Peak Prediction (PP) schemes together improves both average and 99th percentile cluster-wide GPU utilization by up to 80% in case of HPC workloads. In addition, CBP+PP improves the average job completion times (JCT) of deep learning workloads by up to 36% when compared to state-of-the-art schedulers. This leads to 33% cluster-wide energy savings on an average for three different workloads compared to state-of-the-art GPU-agnostic schedulers. Further, the proposed PP scheduler guarantees the end-to-end QoS for latency-critical queries by reducing QoS violations by up to 53% when compared to state-of-the-art GPU schedulers. © 2019 IEEE.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","2019-September","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Containers; Energy efficiency; Deep learning; Program processors; Cluster computing; Computer architecture; State of the art; Graphics processing unit; Resource utilizations; Batch workloads; End-to-end QoS; End-to-end quality of service; Job completion; Proactive management; Scheduling techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE International Conference on Cluster Computing, ICCC","","","","","","","","","","","","","","",""
"4YTGACSJ","conferencePaper","2015","Hauswald, J.; Kang, Y.; Laurenzano, M.A.; Chen, Q.; Li, C.; Mudge, T.; Dreslinski, R.G.; Mars, J.; Tang, L.","DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers","","","","10.1145/2749469.2749472","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960091813&doi=10.1145%2f2749469.2749472&partnerID=40&md5=09fb751b876e19fca3a0ad4caa395fe0","As applications such as Apple Siri, Google Now, Microsoft Cortana, and Amazon Echo continue to gain traction, web-service companies are adopting large deep neural networks (DNN) for machine learning challenges such as image processing, speech recognition, natural language processing, among others. A number of open questions arise as to the design of a server platform specialized for DNN and how modern warehouse scale computers (WSCs) should be outfitted to provide DNN as a service for these applications. In this paper, we present DjiNN, an open infrastructure for DNN as a service in WSCs, and Tonic Suite, a suite of 7 end-to-end applications that span image, speech, and language processing. We use DjiNN to design a high throughput DNN system based on massive GPU server designs and provide insights as to the varying characteristics across applications. After studying the throughput, bandwidth, and power properties of DjiNN and Tonic Suite, we investigate several design points for future WSC architectures. We investigate the total cost of ownership implications of having a WSC with a disaggregated GPU pool versus a WSC composed of homogeneous integrated GPU servers. We improve DNN throughput by over 120x for all but one application (40x for Facial Recognition) on an NVIDIA K40 GPU. On a GPU server composed of 8 NVIDIA K40s, we achieve near-linear scaling (around 1000x throughput improvement) for 3 of the 7 applications. Through our analysis, we also find that GPU-enabled WSCs improve total cost of ownership over CPU-only designs by 4-20x, depending on the composition of the workload. © 2015 ACM.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","27-40","","","13-17-June-2015","","","","","","","","","","","","","Scopus","","","","","","","","Internet; Computer architecture; Network architecture; Design; Image processing; Implications for futures; Web services; Artificial intelligence; Learning algorithms; Learning systems; Computational linguistics; Cost benefit analysis; Deep neural networks; End-to-end application; Face recognition; Facial recognition; Language processing; NAtural language processing; Natural language processing systems; Speech recognition; Throughput; Throughput improvement; Total cost of ownership; Warehouses","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"6IBTTA2V","journalArticle","1997","Hochreiter, S.; Schmidhuber, J.","Long Short-Term Memory","Neural Computation","","","10.1162/neco.1997.9.8.1735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031573117&doi=10.1162%2fneco.1997.9.8.1735&partnerID=40&md5=6e4ee65c4bc5399487e5a65f4186aa19","Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.","1997","2025-10-22 19:07:41","2025-10-22 19:07:41","","1735-1780","","8","9","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Memory; algorithm; article; artificial neural network; biological model; learning; Learning; memory; Memory, Short-Term; Models, Neurological; Models, Psychological; nerve cell network; Nerve Net; Neural Networks (Computer); physiology; psychological model; short term memory; time; Time Factors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H6I6BBUK","conferencePaper","2019","Fouladi, S.; Romero, F.; Iter, D.; Li, Q.; Chatterjee, S.; Kozyrakis, C.; Zaharia, M.; Winstein, K.","From laptop to Lambda: Outsourcing everyday jobs to thousands of transient functional containers","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077087748&partnerID=40&md5=ec153ea5f9118d7208c1a52e894fa867","We present gg, a framework and a set of command-line tools that helps people execute everyday applications—e.g., software compilation, unit tests, video encoding, or object recognition—using thousands of parallel threads on a cloud-functions service to achieve near-interactive completion times. In the future, instead of running these tasks on a laptop, or keeping a warm cluster running in the cloud, users might push a button that spawns 10,000 parallel cloud functions to execute a large job in a few seconds from start. gg is designed to make this practical and easy. With gg, applications express a job as a composition of lightweight OS containers that are individually transient (lifetimes of 1–60 seconds) and functional (each container is hermetically sealed and deterministic). gg takes care of instantiating these containers on cloud functions, loading dependencies, minimizing data movement, moving data between containers, and dealing with failure and stragglers. We ported several latency-sensitive applications to run on gg and evaluated its performance. In the best case, a distributed compiler built on gg outperformed a conventional tool (icecc) by 2–5×, without requiring a warm cluster running continuously. In the worst case, gg was within 20% of the hand-tuned performance of an existing tool for video encoding (ExCamera). © Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019. All rights reserved.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","475-488","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Signal encoding; Laptop computers; Video signal processing; Command line; Completion time; Data movements; Distributed compilers; Encoding (symbols); Hermetically sealed; Object recognition; Sensitive application; Software compilation; Software testing; Video encodings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2019 USENIX Annual Technical Conference, USENIX ATC 2019","","","","","","","","","","","","","","",""
"ZRVDPDHN","conferencePaper","2019","Kannan, R.S.; Subramanian, L.; Raju, A.; Ahn, J.; Mars, J.; Tang, L.","GrandSLAm: Guaranteeing SLAs for jobs in microservices execution frameworks","","","","10.1145/3302424.3303958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063902706&doi=10.1145%2f3302424.3303958&partnerID=40&md5=3421b52ef10bf2d471d82be441436ba2","The microservice architecture has dramatically reduced user effort in adopting and maintaining servers by providing a catalog of functions as services that can be used as building blocks to construct applications. This has enabled datacenter operators to look at managing datacenter hosting microservices quite differently from traditional infrastructures. Such a paradigm shift calls for a need to rethink resource management strategies employed in such execution environments. We observe that the visibility enabled by a microservices execution framework can be exploited to achieve high throughput and resource utilization while still meeting Service Level Agreements, especially in multi-tenant execution scenarios. In this study, we present GrandSLAm, a microservice execution framework that improves utilization of datacenters hosting microservices. GrandSLAm estimates time of completion of requests propagating through individual microservice stages within an application. It then leverages this estimate to drive a runtime system that dynamically batches and reorders requests at each microservice in a manner where individual jobs meet their respective target latency while achieving high throughput. GrandSLAm significantly increases throughput by up to 3× compared to the our baseline, without violating SLAs for a wide range of real-world AI and ML applications. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Resource management; Service Level Agreements; Learning systems; Building blockes; Computer systems; Execution environments; Execution framework; Execution scenario; Machine Learning; Resource utilizations; Systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 14th EuroSys Conference 2019","","","","","","","","","","","","","","",""
"BFZE6LHX","conferencePaper","2016","Kostrzewa, A.; Saidi, S.; Ernst, R.","Slack-based resource arbitration for real-time Networks-on-Chip","","","","10.3850/9783981537079_0233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973629992&doi=10.3850%2f9783981537079_0233&partnerID=40&md5=a4fe9a5e520f78dcc0c39cc40eb7a85f","Networks-on-Chip (NoCs) designed for real-time systems must efficiently deal with a broad diversity of traffic requirements. This requires providing latency guarantees for hard real-time transmissions with minimum impact on performance sensitive best-effort traffic. In this work, we present a novel mechanism which achieves this goal through a slack-based global and dynamic prioritization of data streams. This is performed using an overlay network and a scheduling unit combining local arbitration performed in routers with global scheduling of entire logical transmissions for end to end guarantees. Consequently, our approach allows to decrease both hardware and temporal overhead when compared with existing solutions and to achieve a performance improvement up to around 60%. © 2016 EDAA.","2016","2025-10-22 19:07:41","2025-10-22 19:07:41","","1012-1017","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Real time systems; Prioritization; Best-Effort Traffic; Data stream; Global scheduling; Hard real-time; Interactive computer systems; Network-on-chip; Networks on chips; Real time network; Traffic requirements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2016 Design, Automation and Test in Europe Conference and Exhibition, DATE 2016","","","","","","","","","","","","","","",""
"UMILHANN","conferencePaper","2017","Sharma, P.; Irwin, D.; Shenoy, P.","Portfolio-driven Resource Management for Transient Cloud Servers","","","","10.1145/3078505.3078511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084586768&doi=10.1145%2f3078505.3078511&partnerID=40&md5=8629788bfdd8c27c9ca88bc61755102c","Cloud providers have begun to offer their surplus capacity in the form of low-cost transient servers, which can be revoked unilaterally at any time. While the low cost of transient servers makes them attractive for a wide range of applications, such as data processing and scientific computing, failures due to server revocation can severely degrade application performance. Since different transient server types offer different cost and availability tradeoffs, we present the notion of server portfolios that is based on financial portfolio modeling. Server portfolios enable construction of an ""optimal"" mix of severs to meet an application's sensitivity to cost and revocation risk. We implement model-driven portfolios in a system called ExoSphere, and show how diverse applications can use portfolios and application-specific policies to gracefully handle transient servers. We show that ExoSphere enables widely-used parallel applications such as Spark, MPI, and BOINC to be made transiency-aware with modest effort. Our experiments show that allowing the applications to use suitable transiency-aware policies, ExoSphere is able to achieve 80% cost savings when compared to on-demand servers and greatly reduces revocation risk compared to existing approaches. © 2017 Owner/Author.","2017","2025-10-22 19:07:41","2025-10-22 19:07:41","","59","","","45","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Resource management; Costs; Data handling; Cloud providers; Application performance; Application specific; Diverse applications; Financial portfolio; Ionosphere; Parallel application; Surplus capacity; transient servers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Performance Evaluation Review","","","","","","","","","","","","","","",""
"PIET82NF","conferencePaper","2015","Vamanan, B.; Sohail, H.B.; Hasan, J.; Vijaykumar, T.N.","TimeTrader: Exploiting latency tail to save datacenter energy for online search","","","","10.1145/2830772.2830779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959912236&doi=10.1145%2f2830772.2830779&partnerID=40&md5=d87e1398cbc5d247ceaf45713e3345b5","Online Search (OLS) is a key component of many popular Internet services. Datacenters running OLS consume significant amounts of energy. However, reducing their energy is challenging due to their tight response time requirements. A key aspect of OLS is that each user query goes to all or many of the nodes in the cluster, so that the overall time budget is dictated by the tail of the replies' latency distribution; replies see latency variations both in the network and compute. Previous work proposes to achieve load-proportional energy by slowing down the computation at lower datacenter loads based directly on response times (i.e., at lower loads, the proposal exploits the average slack in the time budget provisioned for the peak load). In contrast, we propose TimeTrader to reduce energy by exploiting the latency slack in the sub-critical replies which arrive before the deadline (e.g., 80% of replies are 3-4x faster than the tail). This slack is present at all loads and subsumes the previous work's load-related slack. While the previous work shifts the leaves' response time distribution to consume the slack at lower loads, TimeTrader reshapes the distribution at all loads by slowing down individual sub-critical nodes without increasing missed deadlines. TimeTrader exploits slack in both the network and compute budgets. Further, TimeTrader leverages Earliest Deadline First scheduling to largely decouple critical requests from the queuing delays of sub-critical requests which can then be slowed down without hurting critical requests. A combination of real-system measurements and at-scale simulations shows that without adding to missed deadlines, TimeTrader saves 15% and 40% energy at 90% and 30% loading, respectively, in a datacenter with 512 nodes, whereas previous work saves 0% and 30%. Further, as a proof-of-concept, we build a small-scale real implementation to evaluate TimeTrader and show 10-30% energy savings. © 2015 ACM.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","585-597","","","05-09-December-2015","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; datacenter; Internet; Computer architecture; Energy conservation; Budget control; Earliest deadline first scheduling; incast; latency tail; Latency variations; Online data; online data-intensive (OLDI) applications; online search (OLS); Online searching; Response time distribution; Scheduling algorithms; Time requirements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"2MPRMR8E","conferencePaper","2020","Boucher, S.; Kalia, A.; Andersen, D.G.; Kaminsky, M.","Putting the “micro” back in microservice","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060929156&partnerID=40&md5=01b3057f899a9e50397254abe5b659ed","Modern cloud computing environments strive to provide users with fine-grained scheduling and accounting, as well as seamless scalability. The most recent face to this trend is the “serverless” model, in which individual functions, or microservices, are executed on demand. Popular implementations of this model, however, operate at a relatively coarse granularity, occupying resources for minutes at a time and requiring hundreds of milliseconds for a cold launch. In this paper, we describe a novel design for providing “functions as a service” (FaaS) that attempts to be truly micro: cold launch times in microseconds that enable even finer-grained resource accounting and support latency-critical applications. Our proposal is to eschew much of the traditional serverless infrastructure in favor of language-based isolation. The result is microsecond-granularity launch latency, and microsecond-scale preemptive scheduling using high-precision timers. © Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018. All rights reserved.","2020","2025-10-22 19:07:41","2025-10-22 19:07:41","","645-650","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Fine grained; Cloud computing environments; Critical applications; High-precision; Novel design; On demands; Pre-emptive scheduling; Resource accountings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018","","","","","","","","","","","","","","",""
"QNQ9EHSF","conferencePaper","2003","Von Behren, R.; Condit, J.; Zhou, F.; Necula, G.C.; Brewer, E.","Capriccio: Scalable threads for internet services","","","","10.1145/1165389.945471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-21644460050&doi=10.1145%2f1165389.945471&partnerID=40&md5=5c1555e4f215e242d73e61edc32d1779","This paper presents Capriccio, a scalable thread package for use with high-concurrency servers. While recent work has advocated event-based systems, we believe that thread-based systems can provide a simpler programming model that achieves equivalent or superior performance. By implementing Capriccio as a user-level thread package, we have decoupled the thread package implementation from the underlying operating system. As a result, we can take advantage of cooperative threading, new asynchronous I/O mechanisms, and compiler support. Using this approach, we are able to provide three key features: (1) scalability to 100,000 threads, (2) efficient stack management, and (3) resource-aware scheduling. We introduce linked stack management, which minimizes the amount of wasted stack space by providing safe, small, and non-contiguous stacks that can grow or shrink at run time. A compiler analysis makes our stack implementation efficient and sound. We also present resource-aware scheduling, which allows thread scheduling and admission control to adapt to the system's current resource usage. This technique uses a blocking graph that is automatically derived from the application to describe the flow of control between blocking points in a cooperative thread package. We have applied our techniques to the Apache 2.0.44 web server, demonstrating that we can achieve high performance and scalability despite using a simple threaded programming model. Copyright 2003 ACM.","2003","2025-10-22 19:07:41","2025-10-22 19:07:41","","268-281","","","37","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Program compilers; Data structures; Internet; Servers; Computer programming; Blocking graph; Dynamic stack growth; Graph theory; Linked stack management; Mathematical models; Problem solving; Resource-aware scheduling; User-level threads","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Operating Systems Review (ACM)","","","","","","","","","","","","","","",""
"FP62I5VS","conferencePaper","2015","Yedlapalli, P.; Nachiappan, N.C.; Soundararajan, N.; Sivasubramaniam, A.; Kandemir, M.T.; Das, C.R.","Short-Circuiting Memory Traffic in Handheld Platforms","","","","10.1109/MICRO.2014.60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937697128&doi=10.1109%2fMICRO.2014.60&partnerID=40&md5=6461beb89e2a6277714ca99b3b02bd76","Handheld devices are ubiquitous in today's world. With their advent, we also see a tremendous increase in device-user interactivity and real-time data processing needs. Media (audio/video/camera) and gaming use-cases are gaining substantial user attention and are defining product successes. The combination of increasing demand from these use-cases and having to run them at low power (from a battery) means that architects have to carefully study the applications and optimize the hardware and software stack together to gain significant optimizations. In this work, we study workloads from these domains and identify the memory subsystem (system agent) to be a critical bottleneck to performance scaling. We characterize the lifetime of the ""frame-based"" data used in these workloads through the system and show that, by communicating at frame granularity, we miss significant performance optimization opportunities, caused by large IP-to-IP data reuse distances. By carefully breaking these frames into sub-frames, while maintaining correctness, we demonstrate substantial gains with limited hardware requirements. Specifically, we evaluate two techniques, flow-buffering and IP-IP short-circuiting, and show that these techniques bring both power-performance benefits and enhanced user experience. © 2014 IEEE.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","166-177","","","2015-January","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Computer architecture; User interfaces; Performance optimizations; System-on-chip; Data handling; Mobile; Data storage equipment; Memory; SoC; Hardware and software; Buffer; Frames; Locality; Power performance; Real-time data processing; Timing circuits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"Q4ZCS6CI","journalArticle","2019","","","Brigade-Azure","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098487850&partnerID=40&md5=ea53304fd7d94372fb76afffaefa61fb","","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IE2Q6SJR","journalArticle","2018","","","Google Cloud Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058988852&partnerID=40&md5=3754edb5c4abbd9a67b401f83d0d33ec","","2018","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFM9MW5E","journalArticle","2013","Carlson, J.L.","","Redis in Action","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907072305&partnerID=40&md5=2eb374aef30da01750e69449d26943b1","","2013","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X6BHQE2P","journalArticle","2018","Oakes, E.; Yang, L.; Zhou, D.; Houck, K.; Harter, T.; Arpaci-Dusseau, A.; Arpaci-Dusseau, R.","SOCK: Rapid task provisioning with serverless-optimized containers","USENIX ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062616330&partnerID=40&md5=9b225926df24cf1dbc5436bcf966f5ca","","2018","2025-10-22 19:07:41","2025-10-22 19:07:41","","57-70","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CIU6RJ2R","conferencePaper","2015","Hauswald, J.; Laurenzano, M.A.; Zhang, Y.; Li, C.; Rovinski, A.; Khurana, A.; Dreslinski, R.G.; Mudge, T.; Petrucci, V.; Tang, L.; Mars, J.","Sirius: An open end-to-end voice and vision personal assistant and its implications for future warehouse scale computers","","","","10.1145/2694344.2694347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939202658&doi=10.1145%2f2694344.2694347&partnerID=40&md5=1e5c86dc98b6a15e7c6049c7ffdcb0d6","As user demand scales for intelligent personal assistants (IPAs) such as Apple's Siri, Google's Google Now, and Microsoft's Cortana, we are approaching the computational limits of current datacenter architectures. It is an open question how future server architectures should evolve to enable this emerging class of applications, and the lack of an open-source IPA workload is an obstacle in addressing this question. In this paper, we present the design of Sirius, an open end-to-end IPA web-service application that accepts queries in the form of voice and images, and responds with natural language. We then use this workload to investigate the implications of four points in the design space of future accelerator-based server architectures spanning traditional CPUs, GPUs, manycore throughput co-processors, and FP-GAs. To investigate future server designs for Sirius, we decompose Sirius into a suite of 7 benchmarks (Sirius Suite) comprising the computationally intensive bottlenecks of Sirius. We port Sirius Suite to a spectrum of accelerator platforms and use the performance and power trade-offs across these platforms to perform a total cost of ownership (TCO) analysis of various server design points. In our study, we find that accelerators are critical for the future scalability of IPA services. Our results show that GPU- and FPGA-accelerated servers improve the query latency on average by 10 × and 16 ×. For a given throughput, GPU- and FPGA-accelerated servers can reduce the TCO of datacenters by 2.6 × and 1.4 ×, respectively. Copyright © 2015 ACM.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","223-238","","","2015-January","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Benchmarking; Implications for futures; Graphics processing unit; Digital storage; Integrated circuit design; Computer graphics equipment; Datacenters; Emerging workload; Emerging workloads; End to end; Google+; Intelligent personal assistants; MicroSoft; Personal assistants; Personal digital assistants; Query languages; Server architecture; Time sharing systems; User demands; Warehouse scale computer; Warehouse scale computers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"MLGPIT5Y","conferencePaper","2005","Bartlett, M.S.; Littlewort, G.; Frank, M.; Lainscsek, C.; Fasel, I.; Movellan, J.","Recognizing facial expression: Machine learning and application to spontaneous behavior","","","","10.1109/CVPR.2005.297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-24644474838&doi=10.1109%2fCVPR.2005.297&partnerID=40&md5=e27b251400f3321ed4a63b54202a8338","We present a systematic comparison of machine learning methods applied to the problem of fully automatic recognition of facial expressions. We report results on a series of experiments comparing recognition engines, including AdaBoost, support vector machines, linear discriminant analysis. We also explored feature selection techniques, including the use of AdaBoost for feature selection prior to classification by SVM or LDA. Best results were obtained by selecting a subset of Gabor filters using AdaBoost followed by classification with Support Vector Machines. The system operates in real-time, and obtained 93% correct generalization to novel subjects for a 7-way forced choice on the Cohn-Kanade expression dataset. The outputs of the classifiers change smoothly as a function of time and thus can be used to measure facial expression dynamics. We applied the system to to fully automated recognition of facial actions (FACS). The present system classifies 17 action units, whether they occur singly or in combination with other actions, with a mean accuracy of 94.8%. We present preliminary results for applying this system to spontaneous facial expressions.","2005","2025-10-22 19:07:41","2025-10-22 19:07:41","","568-573","","","II","","","","","","","","","","","","","Scopus","","","","","","","","Real time systems; Database systems; Learning systems; Facial expression dynamics; Facial expressions; Feature selection techniques; Optical filters; Pattern recognition; Support vector machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005","","","","","","","","","","","","","","",""
"AQEEADYP","conferencePaper","2017","McGrath, G.; Brenner, P.R.","Serverless Computing: Design, Implementation, and Performance","","","","10.1109/ICDCSW.2017.36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027531918&doi=10.1109%2fICDCSW.2017.36&partnerID=40&md5=7922eccabb0c16d5ecf2a4aba6079cf0","We present the design of a novel performance-oriented serverless computing platform implemented in. NET, deployed in Microsoft Azure, and utilizing Windows containers as function execution environments. Implementation challenges such as function scaling and container discovery, lifecycle, and reuse are discussed in detail. We propose metrics to evaluate the execution performance of serverless platforms and conduct tests on our prototype as well as AWS Lambda, Azure Functions, Google Cloud Functions, and IBM's deployment of Apache OpenWhisk. Our measurements show the prototype achieving greater throughput than other platforms at most concurrency levels, and we examine the scaling and instance expiration trends in the implementations. Additionally, we discuss the gaps and limitations in our current design, propose possible solutions, and highlight future research. © 2017 IEEE.","2017","2025-10-22 19:07:41","2025-10-22 19:07:41","","405-410","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Distributed computer systems; Web services; FaaS; Apache OpenWhisk; AWS Lambda; Azure Functions; Function-as-a-Service; Google Cloud Functions; IBM OpenWhisk; serverless computing; serverless performance; Windows operating system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE 37th International Conference on Distributed Computing Systems Workshops, ICDCSW 2017","","","","","","","","","","","","","","",""
"74SHVQS4","journalArticle","2018","Wang, L.; Li, M.; Zhang, Y.; Ristenpart, T.; Swift, M.","Peeking behind the curtains of serverless platforms","ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059031873&partnerID=40&md5=caa34109dbbbd9ed3461168088924e09","","2018","2025-10-22 19:07:41","2025-10-22 19:07:41","","133-146","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VDAYH9V","journalArticle","2010","Chodorow, K.; Dirolf, M.","","MongoDB: The Definitive Guide","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053414450&partnerID=40&md5=91309a4540699bdd8c19f002b62d9fdb","","2010","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P25V82TQ","conferencePaper","2019","Sriraman, A.; Dhanotia, A.; Wenisch, T.F.","SoftSKU: Optimizing server architectures for microservice diversity @scale","","","","10.1145/3307650.3322227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069454735&doi=10.1145%2f3307650.3322227&partnerID=40&md5=ab1d2deda28dc255ad24bd10331349d9","The variety and complexity of microservices in warehouse-scale data centers has grown precipitously over the last few years to support a growing user base and an evolving product portfolio. Despite accelerating microservice diversity, there is a strong requirement to limit diversity in underlying server hardware to maintain hardware resource fungibility, preserve procurement economies of scale, and curb qualification/test overheads. As such, there is an urgent need for strategies that enable limited server CPU architectures (a.k.a ""SKUs"") to provide performance and energy efficiency over diverse microservices. To this end, we first undertake a comprehensive characterization of the top seven microservices that run on the compute-optimized data center fleet at Facebook. Our characterization reveals profound diversity in OS and I/O interaction, cache misses, memory bandwidth utilization, instruction mix, and CPU stall behavior. Whereas customizing a CPU SKU for each microservice might be beneficial, it is prohibitive. Instead, we argue for ""soft SKUs"", wherein we exploit coarse-grain (e.g., boot time) configuration knobs to tune the platform for a particular microservice. We develop a tool, μSKU, that automates search over a soft-SKU design space using A/B testing in production and demonstrate how it can obtain statistically significant gains (up to 7.2% and 4.5% performance improvement over stock and production servers, respectively) with no additional hardware requirements. © 2019 ACM.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","513-526","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Energy efficiency; Microservice; Computer architecture; Green computing; Server architecture; Economics; Hardware resources; Economies of scale; Memory bandwidths; Product portfolios; Resource fungibility; Soft SKU","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"FFNRNKY7","journalArticle","2019","Singhvi, A.; Houck, K.; Balasubramanian, A.; Shaikh, M.D.; Venkataraman, S.; Akella, A.","","Archipelago: A Scalable Low-Latency Serverless Platform","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086275868&partnerID=40&md5=74375a642a1e604dccda8238e9406f1a","","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SIXCZJY3","journalArticle","2024","","Kubernetes","Kubernetes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193979418&partnerID=40&md5=f7b85be2a65bdd29ab785bed2cf78d41","","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AV5EP985","conferencePaper","2014","Klein, C.; Maggio, M.; Arzén, K.-E.; Hernández-Rodriguez, F.","Brownout: Building more robust cloud applications","","","","10.1145/2568225.2568227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994065778&doi=10.1145%2f2568225.2568227&partnerID=40&md5=65399bd44b01bdd11e43ebcda0ddb8ab","Self-adaptation is a first class concern for cloud applications, which should be able to withstand diverse runtime changes. Variations are simultaneously happening both at the cloud infrastructure level - for example hardware failures - and at the user workload level - flash crowds. However, robustly withstanding extreme variability, requires costly hardware over-provisioning. In this paper, we introduce a self-adaptation programming paradigm called brownout. Using this paradigm, applications can be designed to robustly withstand unpredictable runtime variations, without over-provisioning. The paradigm is based on optional code that can be dynamically deactivated through decisions based on control theory. We modified two popular web application prototypes - RUBiS and RUBBoS - with less than 170 lines of code, to make them brownout-compliant. Experiments show that brownout self-adaptation dramatically improves the ability to withstand flash-crowds and hardware failures. © 2014 ACM.","2014","2025-10-22 19:07:41","2025-10-22 19:07:41","","700-711","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Cloud applications; Clouds; Software engineering; Cloud infrastructures; Over provisioning; Cloud; Reconfigurable hardware; Hardware failures; Adaptive software; Adaptive Software; Brownout; Control theory; Control Theory; Programming paradigms; Run-time variations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"LUHT77Y5","journalArticle","2024","","","Locust","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212237688&partnerID=40&md5=ba928c4331d587e56c2d376188e52943","","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8B76JQZ","journalArticle","2014","Deng, W.; Liu, F.; Jin, H.; Li, B.; Li, D.","Harnessing renewable energy in cloud                      datacenters: Opportunities and challenges","IEEE Network","","","10.1109/MNET.2014.6724106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893874351&doi=10.1109%2fMNET.2014.6724106&partnerID=40&md5=cb6de00c7eb3b66d85598cfc7b2e0d49","The proliferation of cloud computing has promoted the wide deployment                         of largescale datacenters with tremendous power consumption and high carbon                         emission. To reduce power cost and carbon footprint, an increasing number of                         cloud service providers have considered green datacenters with renewable                         energy sources, such as solar or wind. However, unlike the stable supply of                         grid energy, it is challenging to utilize and realize renewable energy due                         to the uncertain, intermittent and variable nature. In this article, we                         provide a taxonomy of the state-of-the-art research in applying renewable                         energy in cloud computing datacenters from five key aspects, including                         generation models and prediction methods of renewable energy, capacity                         planning of green datacenters, intra-datacenter workload scheduling and load                         balancing across geographically distributed datacenters. By exploring new                         research challenges involved in managing the use of renewable energy in                         datacenters, this article attempts to address why, when, where and how to                         leverage renewable energy in datacenters, also with a focus on future                         research avenues. © 2014 IEEE.","2014","2025-10-22 19:07:41","2025-10-22 19:07:41","","48-55","","1","28","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; State of the art; Green computing; Research challenges; Cloud service providers; Carbon footprint; Environmental impact; Renewable energies; Capacity planning; Renewable energy resources; Computer supported cooperative work; Prediction methods; Renewable energy source; Use of renewable energies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGEBIDS7","conferencePaper","2019","Larsson, L.; Tarneberg, W.; Klein, C.; Elmroth, E.","Quality-Elasticity: Improved Resource Utilization, Throughput, and Response Times Via Adjusting Output Quality to Current Operating Conditions","","","","10.1109/ICAC.2019.00017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073231355&doi=10.1109%2fICAC.2019.00017&partnerID=40&md5=e88f0d1ee213ca825a9c8773645623b7","This work addresses two related problems for on-line services, namely poor resource utilization during regular operating conditions, and low throughput, long response times, or poor performance under periods of high system load. To address these problems, we introduce our notion of quality-elasticity as a manner of dynamically adapting response qualities from software services along a fine-grained spectrum. When resources are abundant, response quality can be increased, and when resources are scarce, responses are delivered at a lower quality to prioritize throughput and response times. We present an example of how a complex online shopping site can be made quality-elastic. Experiments show that, compared to state of the art, improvements in throughput (57% more served queries), lowered response times (8 time reduction for 95th percentile responses), and an estimated 40% profitability increase can be made using our quality-elastic approach. When resources are abundant, our approach may achieve upwards of twice as high resource utilization as prior work in this field. © 2019 IEEE.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","52-62","","","","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; Computer science; Elasticity; Computer programming; Resource utilizations; brownout; Adaptive software; Operating condition; Service delivery; adaptive software; Online shopping sites; Poor performance; service delivery; Software services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2019 IEEE International Conference on Autonomic Computing, ICAC 2019","","","","","","","","","","","","","","",""
"NE373CI5","conferencePaper","2024","Jacquet, P.; Ledoux, T.; Rouvoy, R.","SweetspotVM: Oversubscribing CPU without Sacrificing VM Performance","","","","10.1109/CCGrid59990.2024.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207968601&doi=10.1109%2fCCGrid59990.2024.00026&partnerID=40&md5=be3bbe3e8eb33bfab68e6d5c7e0b13cc","The adoption of computing resources oversubscription in cloud environments is conventionally limited to a restricted subset of Virtual Machines (VMs) within the providers' offerings, primarily driven by performance considerations. So far, VMs schedulers mostly implement all-or-nothing oversubscription strategies, wherein all VM resources are either oversubscribed or remain unaltered. While the former strategy offers higher consolidation rates, the latter delivers better performance guarantees.In this paper, we conducted an empirical study of the individual usage of virtual CPUs (vCPUs) in the OVHCloud production environment and we demonstrate that, as they are not uniformly utilized, the current holistic approach may not be appropriate. Based on these observations, we introduce a novel approach, named SweetspotVM, where oversubscription ratios are applied at the granularity of individual vCPU, instead of the whole VMs. This novel paradigm unlocks a more flexible oversubscription management strategy, pinning oversubscription ratios per vCPU within VMs. We present a prototype of SweetspotVM to illustrate the feasibility of accommodating multiple oversubscription levels within a single host and assigning them to individual vCPU.We assess the viability of our approach on a physical platform, demonstrating the possibility of dividing the cost of hosting VMs by 3, while maintaining the VMs performance at the level of non-oversubscribed platforms. We, therefore, believe that SweetspotVM opens new avenues to boost the consolidation of VMs on a reduced number of servers, with positive impacts on the environmental footprint of cloud computing.  © 2024 IEEE.","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","148-157","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Performance; Cloud environments; Empirical studies; Performance guarantees; Virtual machine; Cloud platforms; Cloud; Computing resource; IaaS; All or nothings; Iaa; Machine performance; Machine resources; Oversubscription","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2024","","","","","","","","","","","","","","",""
"7DNAZE7W","journalArticle","2022","Cherrueau, R.-A.; Delavergne, M.; van Kempen, A.; Lebre, A.; Pertin, D.; Balderrama, J.R.; Simonet, A.; Simonin, M.","EnosLib: A Library for Experiment-Driven Research in Distributed Computing","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2021.3111159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114742756&doi=10.1109%2fTPDS.2021.3111159&partnerID=40&md5=be6ea4f33bc372f075fb3c171ab0cf5a","Despite the importance of experiment-driven research in the distributed computing community, there has been little progress in helping researchers conduct their experiments. In most cases, they have to achieve tedious and time-consuming development and instrumentation activities to deal with the specifics of testbeds and the system under study. In order to relieve researchers of the burden of those efforts, we have developed ENOSLIB: a Python library that takes into account best experimentation practices and leverages modern toolkits on automatic deployment and configuration systems. ENOSLIB helps researchers not only in the process of developing their experimental artifacts, but also in running them over different infrastructures. To demonstrate the relevance of our library, we discuss three experimental engines built on top of ENOSLIB, and used to conduct empirical studies on complex software stacks between 2016 and 2019 (database systems, communication buses and OpenStack). By introducing ENOSLIB, our goal is to gather academic and industrial actors of our community around a library that aggregates everyday experiment-driven research operations. A library that has been already adopted by open-source projects and members of the scientific community thanks to its ease of use and extension. © 2021 IEEE.","2022","2025-10-22 19:07:41","2025-10-22 19:07:41","","1464-1477","","6","33","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Distributed computer systems; Industrial research; Software testing; Job analysis; Task analysis; Software; Libraries; performance evaluation; Performances evaluation; Benchmark testing; Automatic configuration; Automatic deployments; Code; Computing community; distributed computing experimentation library; Distributed computing experimentation library; Experiment-driven research","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZC4VH7GU","journalArticle","2021","Freitag, C.; Berners-Lee, M.; Widdicks, K.; Knowles, B.; Blair, G.S.; Friday, A.","The real climate and transformative impact of ICT: A critique of estimates, trends, and regulations","Patterns","","","10.1016/j.patter.2021.100340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122638594&doi=10.1016%2fj.patter.2021.100340&partnerID=40&md5=d7af9a116bbc52d9530b7e2158984995","In this paper, we critique ICT's current and projected climate impacts. Peer-reviewed studies estimate ICT's current share of global greenhouse gas (GHG) emissions at 1.8%–2.8% of global GHG emissions; adjusting for truncation of supply chain pathways, we find that this share could actually be between 2.1% and 3.9%. For ICT's future emissions, we explore assumptions underlying analysts' projections to understand the reasons for their variability. All analysts agree that ICT emissions will not reduce without major concerted efforts involving broad political and industrial action. We provide three reasons to believe ICT emissions are going to increase barring intervention and find that not all carbon pledges in the ICT sector are ambitious enough to meet climate targets. We explore the underdevelopment of policy mechanisms for enforcing sector-wide compliance, and contend that, without a global carbon constraint, a new regulatory framework is required to keep the ICT sector's footprint aligned with the Paris Agreement. © 2021 The Authors","2021","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","9","2","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; IoT; 'current; Carbon footprint; AI; big data; Block-chain; blockchain; Blockchain; carbon footprint; Climate impacts; Current share; data science; Gas emissions; Greenhouse gas emissions; Greenhouse gases; ICT; Industrial emissions; policy; Political actions; Regulation; regulations; Regulatory compliance; Supply chains; Trend; trends","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBKRJNLW","journalArticle","2021","Xu, M.; Toosi, A.N.; Buyya, R.","A Self-Adaptive Approach for Managing Applications and Harnessing Renewable Energy for Sustainable Cloud Computing","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2020.3014943","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089367582&doi=10.1109%2fTSUSC.2020.3014943&partnerID=40&md5=2f433e3f8ac589be591826822a62d110","Rapid adoption of Cloud computing for hosting services and its success is primarily attributed to its attractive features such as elasticity, availability and pay-as-you-go pricing model. However, the huge amount of energy consumed by cloud data centers makes it to be one of the fastest growing sources of carbon emissions. Approaches for improving the energy efficiency include enhancing the resource utilization to reduce resource wastage and applying the renewable energy as the energy supply. This work aims to reduce the carbon footprint of the data centers by reducing the usage of brown energy and maximizing the usage of renewable energy. Taking advantage of microservices and renewable energy, we propose a self-adaptive approach for the resource management of interactive workloads and batch workloads. To ensure the quality of service of workloads, a brownout-based algorithm for interactive workloads and a deferring algorithm for batch workloads are proposed. We have implemented the proposed approach in a prototype system and evaluated it with web services under real traces. The results illustrate our approach can reduce the brown energy usage by 21 percent and improve the renewable energy usage by 10 percent.  © 2020 IEEE.","2021","2025-10-22 19:07:41","2025-10-22 19:07:41","","544-558","","4","6","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Microservices; Cloud computing; QoS; Resource management; Cloud data centers; Web services; Resource utilizations; Carbon footprint; Environmental impact; Brownout; Carbon emissions; Renewable energies; Energy supplies; Prototype system; Renewable energy efficiency; Renewable energy resources; Self adaptive approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQAXB79T","journalArticle","2024","","","Image resizing application","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212220341&partnerID=40&md5=fca921ae4340cb6eb60d8c3752f546e9","","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KGPKLIB","conferencePaper","2005","Cappello, F.; Caron, E.; Dayde, M.; Desprez, F.; Jegou, Y.; Primet, P.; Jeannot, E.; Lanteri, S.; Leduc, J.; Melab, N.; Mornet, G.; Namyst, R.; Quetier, B.; Richard, O.","Grid'5000: A large scale and highly reconfigurable Grid experimental testbed","","","","10.1109/GRID.2005.1542730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749669647&doi=10.1109%2fGRID.2005.1542730&partnerID=40&md5=bf7e0a13b21c93e622ae73fd2c3728cf","Large scale distributed systems like Grids are difficult to study only from theoretical models and simulators. Most Grids deployed at large scale are production platforms that are inappropriate research tools because of their limited reconfiguration, control and monitoring capabilities. In this paper, we present Grid'5000, a 5000 CPUs nation-wide infrastructure for research in Grid computing. Grid'5000 is designed to provide a scientific tool for computer scientists similar to the large-scale instruments used by physicists, astronomers and biologists. We describe the motivations, design, architecture, configuration examples of Grid'5000 and performance results for the reconfiguration subsystem. © 2005 IEEE.","2005","2025-10-22 19:07:41","2025-10-22 19:07:41","","99-106","","","2005","","","","","","","","","","","","","Scopus","","","","","","","","Large scale systems; Distributed computer systems; Mathematical models; Research and development management; Astronomy; Large-scale instruments; Research tools; Theoretical models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE/ACM International Workshop on Grid Computing","","","","","","","","","","","","","","",""
"54G9YJR3","journalArticle","2019","Xu, M.; Buyya, R.","Brownout approach for adaptive management of resources and applications in cloud computing systems: A taxonomy and future directions","ACM Computing Surveys","","","10.1145/3234151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061091847&doi=10.1145%2f3234151&partnerID=40&md5=ffe6d0023e39b43b51be5143ff1727c6","Cloud computing has been regarded as an emerging approach to provisioning resources and managing applications. It provides attractive features, such as an on-demand model, scalability enhancement, and management cost reduction. However, cloud computing systems continue to face problems such as hardware failures, overloads caused by unexpected workloads, or the waste of energy due to inefficient resource utilization, which all result in resource shortages and application issues such as delays or saturation. A paradigm, the brownout, has been applied to handle these issues by adaptively activating or deactivating optional parts of applications or services to manage resource usage in cloud computing system. Brownout has successfully shown that it can avoid overloads due to changes in workload and achieve better load balancing and energy saving effects. This article proposes a taxonomy of the brownout approach for managing resources and applications adaptively in cloud computing systems and carries out a comprehensive survey. It identifies open challenges and offers future research directions. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","1","52","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Cloud-computing; Quality-of-service; Taxonomies; Energy conservation; On demands; Brownout; Computing system; Cost reduction; Adaptive management; Adaptive Management; Costs reduction; Demand modelling; Management costs; Optional service; Optional services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Z4RJSWL","conferencePaper","2022","Madon, M.; Da Costa, G.; Pierson, J.-M.","Characterization of Different User Behaviors for Demand Response in Data Centers","","","","10.1007/978-3-031-12597-3_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135769642&doi=10.1007%2f978-3-031-12597-3_4&partnerID=40&md5=2c805d05ac929b7271f8698f27354b7e","Digital technologies are becoming ubiquitous while their impact increases. A growing part of this impact happens far away from the end users, in networks or data centers, contributing to a rebound effect. A solution for a more responsible use is therefore to involve the user. As a first step in this quest, this work considers the users of a data center and characterizes their contribution to curtail the computing load for a short period of time by solely changing their job submission behavior. The contributions are: (i) an open-source plugin for the simulator Batsim to simulate users based on real data; (ii) the exploration of four types of user behaviors to curtail the load during a time window, namely delaying, degrading, reconfiguring or renouncing their job submissions. We study the impact of these behaviors on four different metrics: the energy consumed during and after the time window, the mean waiting time and the mean slowdown. We also characterize the conditions under which the involvement of users is the most beneficial. © 2022, Springer Nature Switzerland AG.","2022","2025-10-22 19:07:41","2025-10-22 19:07:41","","53-68","","","13440 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Datacenter; Data center; User behaviors; Parallel workloads; Demand response; Digital technologies; Job submission; Parallel workload; Reproducible research; Time windows; User involvement; User-aware","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"C333JAPE","journalArticle","2024","","","Resampling filters","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212188539&partnerID=40&md5=607b04b45ab9cab1ee8311194bdaab08","","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SP5TZH5N","conferencePaper","2019","Guyon, D.; Orgerie, A.-C.; Morin, C.; Agarwal, D.","Involving users in energy conservation: A case study in scientific clouds","","","","10.1504/IJGUC.2019.099667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066116496&doi=10.1504%2fIJGUC.2019.099667&partnerID=40&md5=47a3e60f59319ec76eb555898ca5494e","Services offered by cloud computing are convenient to users for reasons such as their ease of use, flexibility, and financial model. Yet data centres used for their execution are known to consume massive amounts of energy. The growing resource utilisation following the cloud success highlights the importance of the reduction of its energy consumption. This paper investigates a way to reduce the footprint of HPC cloud users by varying the size of the virtual resources they request. We analyse the influence of concurrent applications with different resources sizes on the system energy consumption. Simulation results show that resources with larger size are more energy consuming regardless of faster completion of applications. Although smaller-sized resources offer energy savings, it is not always favourable in terms of energy to reduce too much the size. High energy savings depend on the user profiles’ distribution. Copyright © 2019 Inderscience Enterprises Ltd.","2019","2025-10-22 19:07:41","2025-10-22 19:07:41","","272-282","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Energy utilization; Green computing; Energy conservation; Resource utilisation; High performance computing; System energy consumption; Data centres; Energy savings; Financial modeling; HPC applications; User profile; Users involvement; Virtual resource","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Journal of Grid and Utility Computing","","","","","","","","","","","","","","",""
"LKVNAS6L","journalArticle","2024","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212220117&partnerID=40&md5=62d97aefbd0c41cefc44fc735f82fa6e","","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVZL7ANY","journalArticle","1995","Gamma, E.; Helm, R.; Johnson, R.; Vlissides, J.","","Design Patterns: Elements of Reusable Object-Oriented Software","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003880013&partnerID=40&md5=a6dd1fec98664d3b577c87cb9905d476","","1995","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6HQZFZHC","journalArticle","2017","Hasan, M.S.; Alvares, F.; Ledoux, T.; Pazat, J.-L.","Investigating energy consumption and performance trade-off for interactive cloud application","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2017.2714959","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028694906&doi=10.1109%2fTSUSC.2017.2714959&partnerID=40&md5=e7ad009f49f86a7a36283d0a0e834618","With the ever growing demand and popularity of cloud based services, data centers have to urgently face energy consumption issue. Similar to other large consumers of power, data centers find themselves increasingly pressured to reduce their carbon footprint. In response, cloud providers have started to set sustainability goals to reduce carbon emissions by using renewable sources to their services. Traditionally, batch processing cloud applications are deadline oriented, hence they can be easily adapted with the different green energy profile. Whereas, interactive cloud applications are imposed with several performance criteria. This paper, the first of its kind, investigates a thorough analysis of energy consumption and performance trade-off by allowing smart usage of green energy for interactive cloud application. Moreover, we propose an auto-scaler, named SaaScaler, that implements several control loop based application controllers to satisfy different performance (i.e., response time, availability, and user experience) and resource aware metrics (i.e., quality of energy). Based on extensive experiments with RUBiS benchmark and real workload traces using single compute node in Openstack/Grid'5000, results suggest that 13 percent brown energy consumption can be reduced without deprovisioning any physical or virtual resources at IaaS layer while 29 percent more users can access the application by dynamically adjusting capacity requirements. Furthermore, our investigation verifies that the energy consumption deviates as little as.07 percent when our approach is scaled using several physical nodes. © 2016 IEEE.","2017","2025-10-22 19:07:41","2025-10-22 19:07:41","","113-126","","2","2","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Cloud applications; Energy utilization; Economic and social effects; Benchmarking; Green computing; Carbon footprint; Environmental impact; Quality control; Batch data processing; energy consumption; performance analysis; autonomic computing; sustainable computing; green IT; Autonomic Computing; Capacity requirement; Cloud application; Performance criterion; Performance trade-off; Quality of energies; Sustainable computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPMNBRBQ","journalArticle","2022","Long, S.; Li, Y.; Huang, J.; Li, Z.; Li, Y.","A review of energy efficiency evaluation technologies in cloud data centers","Energy and Buildings","","","10.1016/j.enbuild.2022.111848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125382557&doi=10.1016%2fj.enbuild.2022.111848&partnerID=40&md5=d25a3ad812b00dc2909c72992dfa5997","The energy consumption by data centers is expanding in tandem with the rapid rise of the digital economy. Data centers, as high-energy-consumption organizations, have garnered extensive attention from society in order to accomplish energy conservation and emission reduction. As a result, improving the energy efficiency of cloud data centers has become a major topic of research. Researchers are working hard to develop practical energy efficiency evaluation methodologies and metrics in order to attain this goal. This article summarizes data center energy efficiency evaluation methods, classifies existing energy efficiency evaluation metrics, examines the current state and challenges of data center energy efficiency evaluation, and makes recommendations for improving energy efficiency evaluation technology to assist cloud operators, decision-makers, and researchers in developing appropriate energy efficiency evaluation strategies. We give data center researchers a better grasp of energy efficiency evaluation and encourage them to combine theory and practice in energy efficiency evaluation and utilize more advanced metrics to assess data center energy efficiency. This is a critical step in the quest for the most advanced green technology, as well as a significant step toward reaching sustainable development goals. © 2022 Elsevier B.V.","2022","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","260","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Datacenter; Cloud data centers; Energy utilization; Decision making; Energy-consumption; Green computing; Energy consumption; Data center; Metrics; Data center energy efficiencies; Digital economy; Emission control; Energy efficiency evaluation; Evaluation; Evaluation metrics; High energy consumption; Metric","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FT4NI8EM","conferencePaper","2018","Pastor, J.; Menaud, J.M.","SeDuCe: Toward a testbed for research on thermal and power management in datacenters","","","","10.1145/3208903.3213523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050245662&doi=10.1145%2f3208903.3213523&partnerID=40&md5=c55368b81e22fa331ecea1f1662a794e","With the advent of Cloud Computing, the size of datacenters is ever increasing and the management of servers and their power consumption and heat production have become challenges. The management of the heat produced by servers has been experimentally less explored than the management of their power consumption. It can be partly explained by the lack of a public testbed that provides reliable access to both thermal and power metrics of server rooms. In this paper we propose SeDuCe, a testbed that targets research on power and thermal management of servers, by providing public access to precise data about the power consumption and the thermal dissipation of 48 servers integrated in Grid’5000 as the new ecotype cluster. We present the chosen software and hardware architecture for the rst version of the SeDuCe testbed, highlighting its current limitation and proposing some improvements that will increase its relevance. © 2018 Copyright held by the owner/author(s).","2018","2025-10-22 19:07:41","2025-10-22 19:07:41","","513-518","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Electric power utilization; Green computing; Data centers; Software and hardwares; Testbeds; Smart power grids; Current limitation; Heat production; Power metrics; Public Access; Thermal dissipation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","e-Energy 2018 - Proceedings of the 9th ACM International Conference on Future Energy Systems","","","","","","","","","","","","","","",""
"RDD2W2YP","journalArticle","2024","","","Ecotype","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212181198&partnerID=40&md5=cf3338a479a8d6ef61d9165d3e5b9951","","2024","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZKQ9KGZC","journalArticle","2009","Singh, K.; Bhadauria, M.; McKee, S.A.","Real time power estimation and thread scheduling via performance counters","SIGARCH Comput. Archit. News","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954733934&partnerID=40&md5=6ede599fd480ff4c4984431a506a6fc3","","2009","2025-10-22 19:07:41","2025-10-22 19:07:41","","46-55","","2","37","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D3FIAB32","journalArticle","2012","Bircher, W.L.; John, L.K.","Complete System Power Estimation Using Processor Performance Events","IEEE Transactions on Computers","","","10.1109/TC.2011.47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008569578&doi=10.1109%2fTC.2011.47&partnerID=40&md5=b0b54bc5d6ee43fe0edaca148f26cb21","This paper proposes the use of microprocessor performance counters for online measurement of complete system powe consumption. The approach takes advantage of the “trickle-down” effect of performance events in microprocessors. While it has bee known that CPU power consumption is correlated to processor performance, the use of well-known performance-related events withi a microprocessor such as cache misses and DMA transactions to estimate power consumption in memory and disk and other subsystems outside of the microprocessor is new. Using measurement of actual systems running scientific, commercial and productivity workloads, power models for six subsystems (CPU, memory, chipset, I/O, disk, and GPU) on two platforms (server an desktop) are developed and validated. These models are shown to have an average error of less than nine percent per subsystem across the considered workloads. Through the use of these models and existing on-chip performance event counters, it is possible 1 estimate system power consumption without the need for power sensing hardware. © 2012, IEEE","2012","2025-10-22 19:07:41","2025-10-22 19:07:41","","563-577","","4","61","","","","","","","","","","","","","Scopus","","","","","","","","power management; modeling; Energy-aware systems; evaluation; measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SN7HA9CF","conferencePaper","2012","Jin, Y.; Wen, Y.; Chen, Q.","Energy efficiency and server virtualization in data centers: An empirical investigation","","","","10.1109/INFCOMW.2012.6193474","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862075555&doi=10.1109%2fINFCOMW.2012.6193474&partnerID=40&md5=89c392d0ab77b4eefd6218e1d9d4cfe4","With a growing concern on the considerable energy consumed by data centers, research efforts are targeting toward green data centers with higher energy efficiency. In particular, server virtualization is emerging as the prominent approach to consolidate applications from multiple applications to one server, with an objective to save energy usage. However, little understanding has been obtained about the potential overhead in energy consumption and the throughput reduction for virtualized servers in data centers. In this research, we take the initiative to characterize the energy usage on virtualized servers. An empirical approach is adopted to investigate how server virtualization affects the energy usage in physical servers. Through intensive data collection and analysis, we identify a fundamental trade-off between the energy saving from server consolidation and the detrimental effects (e.g., energy overhead and throughput reduction) from server virtualization. This characterization lays a mathematical foundation for server consolidation in green data center architecture. © 2012 IEEE.","2012","2025-10-22 19:07:41","2025-10-22 19:07:41","","133-138","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Virtual reality; Energy utilization; Virtualizations; Data centers; Server consolidation; Cost reduction; Multiple applications; Data collection; Save energy; Research efforts; Data center architecture; Detrimental effects; Empirical approach; Empirical investigation; Energy usage; Mathematical foundations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"UTJ3E7R3","journalArticle","2014","Lively, C.; Taylor, V.; Wu, X.; Chang, H.-C.; Su, C.-Y.; Cameron, K.; Moore, S.; Terpstra, D.","E-AMOM: An energy-aware modeling and optimization methodology for scientific applications","Computer Science - Research and Development","","","10.1007/s00450-013-0239-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904729129&doi=10.1007%2fs00450-013-0239-3&partnerID=40&md5=361553ed0a0550f132e7207fdff05edf","In this paper, we present the Energy-Aware Modeling and Optimization Methodology (E-AMOM) framework, which develops models of runtime and power consumption based upon performance counters and uses these models to identify energy-based optimizations for scientific applications. E-AMOM utilizes predictive models to employ run-time Dynamic Voltage and Frequency Scaling (DVFS) and Dynamic Concurrency Throttling (DCT) to reduce power consumption of the scientific applications, and uses cache optimizations to further reduce runtime and energy consumption of the applications. The models and optimization are done at the level of the kernels that comprise the application. Our models resulted in an average error rate of at most 6.79 % for Hybrid MPI/OpenMP and MPI implementations of six scientific applications. With respect to optimizations, we were able to reduce the energy consumption by up to 21 %, with a reduction in runtime by up to 14.15 %, and a reduction in power consumption by up to 12.50 %. © 2013 Springer-Verlag Berlin Heidelberg.","2014","2025-10-22 19:07:41","2025-10-22 19:07:41","","197-210","","3-4","29","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Electric power utilization; Embedded systems; Energy aware; Energy-consumption; Energy consumption; Performance optimization; Performance optimizations; Dynamic frequency scaling; Performance Modeling; Modeling and optimization; Modeling methodology; Performance modeling; Power consumption; Hybrid MPI/openmp; Hybrid MPI/OpenMP; MPI; Optimization methodology; Power prediction; Power predictions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GR6NYNR8","conferencePaper","2003","Isci, C.; Martonosi, M.","Runtime power monitoring in high-end processors: Methodology and empirical data","","","","10.1109/MICRO.2003.1253186","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944414165&doi=10.1109%2fMICRO.2003.1253186&partnerID=40&md5=99f5cf447bd12c523bf066899b63992d","With power dissipation becoming an increasingly vexing problem across many classes of computer systems, measuring power dissipation of real, running systems has become crucial for hardware and software system research and design. Live power measurements are imperative for studies requiring execution times too long for simulation, such as thermal analysis. Furthermore, as processors become more complex and include a host of aggressive dynamic power management techniques, per-component estimates of power dissipation have become both more challenging as well as more important. In this paper we describe our technique for a coordinated measurement approach that combines real total power measurement with performance-counter-based, per-unit power estimation. The resulting tool offers live total power measurements for Intel Pentium 4 processors, and also provides power breakdowns for 22 of the major CPU subunits over minutes of SPEC2000 and desktop workload execution. As an example application, we use the generated component power breakdowns to identify program power phase behaviour. Overall, this paper demonstrates a processor power measurement and estimation methodology and also gives experiences and empirical application results that can provide a basis for future power-aware research. © 2003 IEEE.","2003","2025-10-22 19:07:41","2025-10-22 19:07:41","","93-104","","","2003-January","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Power management; Application programs; Computer architecture; Software engineering; Runtimes; Software systems; Energy dissipation; Computer software; Electric losses; Electric power measurement; Hardware and software; Microprocessor chips; Power measurement; Analytical models; Computational modeling; Runtime; Software measurement; Dynamic power management; Computational model; Computerized monitoring; Electric breakdown; Electric power system measurement; Estimation methodologies; Pentium 4 Processors; Power dissipation; Software Measurement; Thermoanalysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"RB3H6T3E","conferencePaper","2013","Song, S.; Su, C.; Rountree, B.; Cameron, K.W.","A simplified and accurate model of power-performance efficiency on emergent GPU architectures","","","","10.1109/IPDPS.2013.73","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884823629&doi=10.1109%2fIPDPS.2013.73&partnerID=40&md5=2071e2ab79d99755c974c84584a17062","Emergent heterogeneous systems must be optimized for both power and performance at exascale. Massive parallelism combined with complex memory hierarchies form a barrier to efficient application and architecture design. These challenges are exacerbated with GPUs as parallelism increases orders of magnitude and power consumption can easily double. Models have been proposed to isolate power and performance bottlenecks and identify their root causes. However, no current models combine simplicity, accuracy, and support for emergent GPU architectures (e.g. NVIDIA Fermi). We combine hardware performance counter data with machine learning and advanced analytics to model power-performance efficiency for modern GPU-based systems. Our performance counter based approach is simpler than previous approaches and does not require detailed understanding of the underlying architecture. The resulting model is accurate for predicting power (within 2.1%) and performance (within 6.7%) for application kernels on modern GPUs. Our model can identify power-performance bottlenecks and their root causes for various complex computation and memory access patterns (e.g. global, shared, texture). We measure the accuracy of our power and performance models on a NVIDIA Fermi C2075 GPU for more than a dozen CUDA applications. We show our power model is more accurate and robust than the best available GPU power models - multiple linear regression models MLR and MLR+. We demonstrate how to use our models to identify power-performance bottlenecks and suggest optimization strategies for high-performance codes such as GEM, a biomolecular electrostatic analysis application. We verify our power-performance model is accurate on clusters of NVIDIA Fermi M2090s and useful for suggesting optimal runtime configurations on the Keeneland supercomputer at Georgia Tech. © 2013 IEEE.","2013","2025-10-22 19:07:41","2025-10-22 19:07:41","","673-686","","","","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Program processors; Supercomputers; Distributed parameter networks; Heterogeneous systems; Hardware performance counters; Performance bottlenecks; Biomolecular electrostatics; Linear regression; Memory access patterns; Multiple linear regression models; Power-performance efficiency; Run-time configuration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE 27th International Parallel and Distributed Processing Symposium, IPDPS 2013","","","","","","","","","","","","","","",""
"JTZKMERW","conferencePaper","2008","Seo, C.; Malek, S.; Medvidovic, N.","Component-level energy consumption estimation for distributed java-based software systems","","","","10.1007/978-3-540-87891-9_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350536310&doi=10.1007%2f978-3-540-87891-9_7&partnerID=40&md5=a0fe76b07b2ce1c8c458dab3cacb0951","Efficiency with respect to energy consumption has increasingly been recognized as an important quality attribute for distributed software systems in embedded and pervasive environments. In this paper we present a framework for estimating the energy consumption of distributed software systems implemented in Java. Our primary objective in devising the framework is to enable an engineer to make informed decisions when adapting a system's architecture, such that the energy consumption on hardware devices with a finite battery life is reduced, and the lifetime of the system's key software services increases. Our framework explic itly takes a component-based perspective, which renders it well suited for a large class of today's distributed, embedded, and pervasive applications. The framework allows the engineer to estimate the distributed system's energy consumption at sys tem construction-time and refine it at runtime. In a large number of distributed application scenarios, the framework showed very good precision on the whole, giving results that were within 5% (and often less) of the actual energy consump tion incurred by executing the software. Our work to date has also highlighted the framework's practical applications and a number of possible enhancements. © 2008 Springer.","2008","2025-10-22 19:07:41","2025-10-22 19:07:41","","97-113","","","5282 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Embedded systems; Distributed computer systems; Distributed systems; Energy utilization; Java programming language; Energy consumption; Distributed applications; Pervasive applications; Distributed database systems; Java; Component based software; Component-based software; Distributed software system; Pervasive environments; Quality attributes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"4IHX52QG","conferencePaper","2015","Singh, J.; Naik, K.; Mahinthan, V.","Impact of developer choices on energy consumption of software on servers","","","","10.1016/j.procs.2015.08.423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962609274&doi=10.1016%2fj.procs.2015.08.423&partnerID=40&md5=b387e232bd2ea964415da1d5a56b88a9","The power cost of running a data center is a significant portion of its total annual operating budget. With the aim of reducing power bills of data centers, ""Green Computing"" has emerged with the primary goal of making software more energy efficient without compromising the performance. Developers play an important role in controlling the energy cost of data center software while writing code. In this paper, we show how software developers can contribute to energy efficiency of servers by choosing energy efficient APIs (Application Programming Interface) with the optimal choice of parameters while implementing file reading, file copy, file compression and file decompression operations in Java; that are performed extensively on large scale servers in data centers. We performed extensive measurements of energy cost of those operations on a Dell Power Edge 2950 machine running Linux and Windows servers. Measurement results show that energy costs of various APIs for those operations are sensitive to the buffer size selection. The choice of a particular Java API for file reading with different buffer sizes has significant impact on the energy cost, giving an opportunity to save up to 76%. To save energy while copying files, it is important to use APIs with tunable buffer sizes, rather than APIs using fixed size buffers. In addition, there is a trade off between compression ratio and energy cost: because of more compression ratio, xz compression API consumes more energy than zip and gzip compression APIs. Finally, we model the energy costs of APIs by polynomial regression to avoid repeated measurements. © 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","385-394","","","62","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Energy efficiency; Computer operating systems; Energy efficient; Energy utilization; Java programming language; Economic and social effects; Software engineering; Software developer; Computer software; Application programming interfaces (API); Costs; Data centers; Budget control; Windows operating system; Developer choices; Energy efficient software; Energy performance evaluation; Energy performance evaluations; Ion beams; Operating budgets; Polynomial regression; Repeated measurements; Soft computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Procedia Computer Science","","","","","","","","","","","","","","",""
"8GLAWMP7","journalArticle","2007","Barroso, L.A.; Hölzle, U.","The case for energy-proportional computing","Computer","","","10.1109/MC.2007.443","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47249127725&doi=10.1109%2fMC.2007.443&partnerID=40&md5=402a0a6da009e78f271427bb0569ba91","Energy-proportional designs would enable large energy savings in servers, potentially doubling their efficiency in real-life use. Achieving energy-proportionality will require significant improvements in the energy usage profile of every system component, particularly the memory and disk subsystems. © 2007 IEEE.","2007","2025-10-22 19:07:41","2025-10-22 19:07:41","","33-37","","12","40","","","","","","","","","","","","","Scopus","","","","","","","","Green computing; Energy-proportional computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESQBBPQ2","book","2015","Calero, C.; Piattini, M.","Green in software engineering","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944526351&doi=10.1007%2f978-3-319-08581-4&partnerID=40&md5=4bda434062430f89a16e131e8102074f","This is the first book that presents a comprehensive overview of sustainability aspects in software engineering. Its format follows the structure of the SWEBOK and covers the key areas involved in the incorporation of green aspects in software engineering, encompassing topics from requirement elicitation to quality assurance and maintenance, while also considering professional practices and economic aspects. The book consists of thirteen chapters, which are structured in five parts. First the “Introduction” gives an overview of the primary general concepts related to Green IT, discussing what Green in Software Engineering is and how it differs from Green by Software Engineering. Next ""Environments, Processes and Construction"" presents green software development environments, green software engineering processes and green software construction in general. The third part, “Economic and Other Qualities,” details models for measuring how well software supports green software engineering techniques and for performing trade-off analyses between alternative green practices from an economic perspective. ""Software Development Process"" then details techniques for incorporating green aspects at various stages of software development, including requirements engineering, design, testing, and maintenance. In closing, “Practical Issues” addresses the repercussions of green software engineering on decision-making, stakeholder participation and innovation management. The audience for this book includes software engineering researchers in academia and industry seeking to understand the challenges and impact of green aspects in software engineering, as well as practitioners interested in learning about the state of the art in Green in Software Engineering. © Springer International Publishing Switzerland 2015.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","","1","","","","","","Green in Software Engineering","","","","","","","","","Scopus","","","","","","","","Economic and social effects; Software design; Software engineering; Decision making; Software testing; Engineering education; Computer software maintenance; Engineering techniques; Professional aspects; Professional practices; Quality assurance; Requirement elicitation; Requirements engineering; Software construction; Software development environment; Software development process; Software engineering process; Stakeholder participation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFSHKXM2","conferencePaper","2007","Fan, X.; Weber, W.-D.; Barroso, L.A.","Power provisioning for a warehouse-sized computer","","","","10.1145/1250662.1250665","https://www.scopus.com/inward/record.uri?eid=2-s2.0-35348835964&doi=10.1145%2f1250662.1250665&partnerID=40&md5=0ba10bc53962f2321e9062dec64e3177","Large-scale Internet services require a computing infrastructure that can beappropriately described as a warehouse-sized computing system. The cost ofbuilding datacenter facilities capable of delivering a given power capacity tosuch a computer can rival the recurring energy consumption costs themselves.Therefore, there are strong economic incentives to operate facilities as closeas possible to maximum capacity, so that the non-recurring facility costs canbe best amortized. That is difficult to achieve in practice because ofuncertainties in equipment power ratings and because power consumption tends tovary significantly with the actual computing activity. Effective powerprovisioning strategies are needed to determine how much computing equipmentcan be safely and efficiently hosted within a given power budget. In this paper we present the aggregate power usage characteristics of largecollections of servers (up to 15 thousand) for different classes ofapplications over a period of approximately six months. Those observationsallow us to evaluate opportunities for maximizing the use of the deployed powercapacity of datacenters, and assess the risks of over-subscribing it. We findthat even in well-tuned applications there is a noticeable gap (7 - 16%)between achieved and theoretical aggregate peak power usage at the clusterlevel (thousands of servers). The gap grows to almost 40% in wholedatacenters. This headroom can be used to deploy additional compute equipmentwithin the same power budget with minimal risk of exceeding it. We use ourmodeling framework to estimate the potential of power management schemes toreduce peak power and energy usage. We find that the opportunities for powerand energy savings are significant, but greater at the cluster-level (thousandsof servers) than at the rack-level (tens). Finally we argue that systems needto be power efficient across the activity range, and not only at peakperformance levels. Copyright 2007 ACM.","2007","2025-10-22 19:07:41","2025-10-22 19:07:41","","13-23","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Power modeling; Internet; Telecommunication services; Mathematical models; Warehouses; Power provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"GKRHYXTX","journalArticle","2018","","","IntelR 64 and IA-32 Architectures Software Developer's Manual","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956506076&partnerID=40&md5=44d6a3448690ccb63f34cea1126ce4bd","","2018","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XR2MDKKV","journalArticle","2012","Capra, E.; Francalanci, C.; Slaughter, S.A.","Measuring application software energy efficiency","IT Professional","","","10.1109/MITP.2012.39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859168181&doi=10.1109%2fMITP.2012.39&partnerID=40&md5=bbb95e5c1bbd02331ef1647aac5524d3","Researchers have studied the energy efficiency of hardware, but what about application software? Using an experimental approach, the authors show how applications affect total energy consumption and discuss design factors that could influence software energy efficiency. © 2006 IEEE.","2012","2025-10-22 19:07:41","2025-10-22 19:07:41","","54-61","","2","14","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Software design; Information technology; Computer software; Green IT; application development environment; Application development environment; Application softwares; Design factors; Experimental approaches; green IT; information technology; Measuring applications; software design; software energy efficiency; Total energy consumption","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGDYU7PU","journalArticle","2010","Ad Anton Beloglazov, R.B.; Abawajy, J.H.","","Energy-efficient Management of Data Center Resources for Cloud Computing: A Vision, Architectural Elements, Open Challenges","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073221577&partnerID=40&md5=676b5f08192f5c4c6893493b6fa83d15","","2010","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6CNKSTZ","journalArticle","2012","Glanz, J.","Power, pollution and the internet","Power, Pollution and the Internet","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874546725&partnerID=40&md5=e2f609209af82f944ff852005f1c111e","","2012","2025-10-22 19:07:41","2025-10-22 19:07:41","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8RFVMHK","journalArticle","2014","Tsafack Chetsa, G.L.; Lefèvre, L.; Pierson, J.M.; Stolf, P.; Da Costa, G.","Exploiting performance counters to predict and improve energy performance of HPC systems","Future Generation Computer Systems","","","10.1016/j.future.2013.07.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899622479&doi=10.1016%2fj.future.2013.07.010&partnerID=40&md5=fbee48a53e2626db15c3679abfd67cf7","Hardware monitoring through performance counters is available on almost all modern processors. Although these counters are originally designed for performance tuning, they have also been used for evaluating power consumption. We propose two approaches for modelling and understanding the behaviour of high performance computing (HPC) systems relying on hardware monitoring counters. We evaluate the effectiveness of our system modelling approach considering both optimizing the energy usage of HPC systems and predicting HPC applications' energy consumption as target objectives. Although hardware monitoring counters are used for modelling the system, other methods-including partial phase recognition and cross platform energy prediction-are used for energy optimization and prediction. Experimental results for energy prediction demonstrate that we can accurately predict the peak energy consumption of an application on a target platform; whereas, results for energy optimization indicate that with no a priori knowledge of workloads sharing the platform we can save up to 24% of the overall HPC system's energy consumption under benchmarks and real-life workloads. © 2013 Elsevier B.V. All rights reserved.","2014","2025-10-22 19:07:41","2025-10-22 19:07:41","","287-298","","","36","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Electric power utilization; Energy efficiency; Forecasting; Optimization; Energy utilization; Benchmarking; High performance computing; Green IT; Energy optimization; Energy performance; Power consumption; Performance tuning; High performance computing systems; Performance counters; Hardware performance counters; Electric load forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJYQZH26","conferencePaper","2010","Zhang, L.; Tiwana, B.; Qian, Z.; Wang, Z.; Dick, R.P.; Mao, Z.M.; Yang, L.","Accurate online power estimation and automatic battery behavior based power model generation for smartphones","","","","10.1145/1878961.1878982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650632079&doi=10.1145%2f1878961.1878982&partnerID=40&md5=b2a1cafc966a30341aee60665a3db9e7","This paper describes PowerBooter, an automated power model construction technique that uses built-in battery voltage sensors and knowledge of battery discharge behavior to monitor power consumption while explicitly controlling the power management and activity states of individual components. It requires no external measurement equipment. We also describe PowerTutor, a component power management and activity state introspection based tool that uses the model generated by PowerBooter for online power estimation. PowerBooter is intended to make it quick and easy for application developers and end users to generate power models for new smartphone variants, which each have different power consumption properties and therefore require different power models. PowerTutor is intended to ease the design and selection of power efficient software for embedded systems. Combined, PowerBooter and PowerTutor have the goal of opening power modeling and analysis for more smartphone variants and their users.","2010","2025-10-22 19:07:41","2025-10-22 19:07:41","","105-114","","","","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Embedded systems; Power modeling; Mobile devices; Application developers; Mobile phones; Signal encoding; Energy management; Smart phones; Power managements; Power model; Telephone sets; Behavior-based; Power estimations; Power Consumption; battery; Battery; Battery discharge; Battery voltages; Embedded software; End users; Human computer interaction; Individual components; Measurement equipment; Power efficient; Telecommunication equipment; Telephone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Embedded Systems Week 2010 - Proceedings of the 8th IEEE/ACM/IFIP International Conference on Compilers, Architecture and Synthesis for Embedded Systems, CODES+ISSS'2010","","","","","","","","","","","","","","",""
"HU8WMZYJ","journalArticle","2015","Flores, H.; Hui, P.; Tarkoma, S.; Li, Y.; Srirama, S.; Buyya, R.","Mobile code offloading: From concept to practice and beyond","IEEE Communications Magazine","","","10.1109/MCOM.2015.7060486","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925843954&doi=10.1109%2fMCOM.2015.7060486&partnerID=40&md5=05ceca4e6ad341560d992bc838aab01a","The emerging mobile cloud has expanded the horizon of application development and deployment with techniques such as code offloading. While offloading has been widely considered for saving energy and increasing responsiveness of mobile devices, the technique still faces many challenges pertaining to practical usage. In this article, we adopt a systemic approach for analyzing the components of a generic code offloading architecture. Based on theoretical and experimental analysis, we identify the key limitations for code offloading in practice and then propose solutions to mitigate these limitations. We develop a generic architecture to evaluate the proposed solutions. The results provide insights regarding the evolution and deployment of code offloading. © 2015 IEEE.","2015","2025-10-22 19:07:41","2025-10-22 19:07:41","","80-88","","3","53","","","","","","","","","","","","","Scopus","","","","","","","","Codes (symbols); Mobile devices; Mobile codes; Experimental analysis; Generic architecture; Application development; Generic codes; Mobile clouds; Saving energy; Systemic approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCSU7TV5","conferencePaper","2013","Li, D.; Hao, S.; Halfond, W.G.J.; Govindan, R.","Calculating source line level energy information for Android applications","","","","10.1145/2483760.2483780","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881289459&doi=10.1145%2f2483760.2483780&partnerID=40&md5=14c81c262e9c760849491698a43c893f","The popularity of mobile apps continues to grow as developers take advantage of the sensors and data available on mobile devices. However, the increased functionality comes with a higher energy cost, which can cause a problem for users on battery constrained mobile devices. To improve the energy consumption of mobile apps, developers need detailed information about the energy consumption of their applications. Existing techniques have drawbacks that limit their usefulness or provide information at too high of a level of granularity, such as components or methods. Our approach is able to calculate source line level energy consumption information. It does this by combining hardware-based power measurements with program analysis and statistical modeling. Our empirical evaluation of the approach shows that it is fast and accurate. © 2013 ACM.","2013","2025-10-22 19:07:41","2025-10-22 19:07:41","","78-89","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Mobile devices; Electric power measurement; Software testing; Energy measurement; Energy cost; Program analysis; Android app; Android applications; Empirical evaluations; Energy information; Source line level; Statistical modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2013 International Symposium on Software Testing and Analysis, ISSTA 2013 - Proceedings","","","","","","","","","","","","","","",""
"RJSVKLEK","conferencePaper","2016","Wu, X.; Taylor, V.","Utilizing hardware performance counters to model and optimize the energy and performance of large scale scientific applications on power-aware supercomputers","","","","10.1109/IPDPSW.2016.78","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991693802&doi=10.1109%2fIPDPSW.2016.78&partnerID=40&md5=dc13a7c94f118199d6a28e0956e8a96b","Hardware performance counters are used as effective proxies to estimate power consumption and runtime. In this paper we present a performance counter-based power and performance modeling and optimization method, and use the method to model four metrics: runtime, system power, CPU power and memory power. The performance counters that compose the models are used to explore some counter-guided optimizations with two large-scale scientific applications: an earthquake simulation and an aerospace application. We demonstrate the use of the method using two power-aware supercomputers, Mira at Argonne National Laboratory and SystemG at Virginia Tech. The counter-guided optimizations result in a reduction in energy by an average of 18.28% on up to 32,768 cores on Mira and 11.28% on up to 128 cores on SystemG for the aerospace application. For the earthquake simulation, the average energy reductions achieved are 48.65% on up to 4,096 cores on Mira and 30.67% on up to 256 cores on SystemG. © 2016 IEEE.","2016","2025-10-22 19:07:41","2025-10-22 19:07:41","","1180-1189","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Power management; Power-aware; Power modeling; Supercomputers; Reconfigurable hardware; Power model; Scientific applications; Performance modeling; Performance counters; Hardware performance counters; Performance Model; Aerospace applications; Argonne National Laboratory; Counter-guided optimization; Earthquake engineering; Earthquake simulation; Earthquakes; Geophysics; Power-aware supercomputers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 IEEE 30th International Parallel and Distributed Processing Symposium, IPDPS 2016","","","","","","","","","","","","","","",""
"92AZ8XKG","journalArticle","2016","Nordrum, A.","The internet of fewer things [News]","IEEE Spectrum","","","10.1109/MSPEC.2016.7572524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991205682&doi=10.1109%2fMSPEC.2016.7572524&partnerID=40&md5=72f8e91eb18439c3aa0fe979e2ca33be","If you follow discussions about the Internet of Things, you've probably heard this stunning prediction at least once: The world will have 50 billion Internet-connected devices by 2020. Ericsson's former CEO, Hans Vestburg, was among the first to toss out that number, when he gave a 2010 presentation to shareholders. The following year, Dave Evans, who worked for Cisco at the time, published the same prediction in a white paper. © 2016 IEEE.","2016","2025-10-22 19:07:41","2025-10-22 19:07:41","","12-13","","10","53","","","","","","","","","","","","","Scopus","","","","","","","","Internet; Electrical engineering; Ericsson; Technology; White papers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KBZKQ95P","journalArticle","2014","Pandruvada, S.","Running average power limit-rapl","Running Average Power Limit","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009149645&partnerID=40&md5=5c9c804e9f3f35ba6132a3022fa70d78","","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LU9NT5PP","journalArticle","2009","Van Hoorn, A.; Rohr, M.; Hasselbring, W.; Waller, J.; Ehlers, J.; Frey, S.; Kieselhorst, D.","Continuous monitoring of software services: Design and application of the kieker framework Kiel University","Forschungsbericht","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073249021&partnerID=40&md5=0f4c475908ece05ea7f8d3967c675ad8","","2009","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZZETNY5","conferencePaper","2014","Yasin, A.","A Top-Down method for performance analysis and counters architecture","","","","10.1109/ISPASS.2014.6844459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904497623&doi=10.1109%2fISPASS.2014.6844459&partnerID=40&md5=324610a9db40b3b289d029e4e71abe22","Optimizing an application's performance for a given microarchitecture has become painfully difficult. Increasing microarchitecture complexity, workload diversity, and the unmanageable volume of data produced by performance tools increase the optimization challenges. At the same time resource and time constraints get tougher with recently emerged segments. This further calls for accurate and prompt analysis methods. In this paper a Top-Down Analysis is developed - a practical method to quickly identify true bottlenecks in out-of-order processors. The developed method uses designated performance counters in a structured hierarchical approach to quickly and, more importantly, correctly identify dominant performance bottlenecks. The developed method is adopted by multiple in-production tools including VTune. Feedback from VTune average users suggests that the analysis is made easier thanks to the simplified hierarchy which avoids the high-learning curve associated with microarchitecture details. Characterization results of this method are reported for the SPEC CPU2006 benchmarks as well as key enterprise workloads. Field case studies where the method guides software optimization are included, in addition to architectural exploration study for most recent generations of Intel Core™ products. The insights from this method guide a proposal for a novel performance counters architecture that can determine the true bottlenecks of a general out-of-order processor. Unlike other approaches, our analysis method is low-cost and already featured in in-production systems - it requires just eight simple new performance events to be added to a traditional PMU. It is comprehensive - no restriction to predefined set of performance issues. It accounts for granular bottlenecks in super-scalar cores, missed by earlier approaches. © 2014 IEEE.","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","35-44","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Computer architecture; Micro architectures; Performance counters; Performance bottlenecks; Hierarchical approach; Out-of-order processors; Software optimization; Workload diversities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ISPASS 2014 - IEEE International Symposium on Performance Analysis of Systems and Software","","","","","","","","","","","","","","",""
"NK47BP6P","conferencePaper","2009","Zaparanuks, D.; Jovic, M.; Hauswirth, M.","Accuracy of performance counter measurements","","","","10.1109/ISPASS.2009.4919635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349170794&doi=10.1109%2fISPASS.2009.4919635&partnerID=40&md5=493fe0ec70461b798a5906edffc39ab2","Many experimental performance evaluations depend on accurate measurements of the cost of executing a piece of code. Often these measurements are conducted using infrastructures to access hardware performance counters. Most modern processors provide such counters to count microarchitectural events such as retired instructions or clock cycles. These counters can be difficult to configure, may not be programmable or readable from user-level code, and can not discriminate between events caused by different software threads. Various software infrastructures address this problem, providing access to per-thread counters from application code. This paper constitutes the first comparative study of the accuracy of three commonly used measurement infrastructures (perfctr, perfmon2, and PAPI) on three common processors (Pentium D, Core 2 Duo, and AMD ATHLON 64 ×2). © 2009 IEEE.","2009","2025-10-22 19:07:42","2025-10-22 19:07:42","","23-32","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Computer software; Modern processors; Performance counters; Hardware performance counters; Accurate measurement; Application codes; Athlon 64; Clock cycles; Comparative studies; Experimental performance evaluations; Pentium; Software infrastructure; Software threads; User-level codes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ISPASS 2009 - International Symposium on Performance Analysis of Systems and Software","","","","","","","","","","","","","","",""
"HPPUB2VL","conferencePaper","2010","David, H.; Gorbatov, E.; Hanebutte, U.R.; Khanna, R.; Le, C.","RAPL: Memory power estimation and capping","","","","10.1145/1840845.1840883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957942221&doi=10.1145%2f1840845.1840883&partnerID=40&md5=335285081760d0cd206366592a9687b9","The drive for higher performance and energy efficiency in data-centers has influenced trends toward increased power and cooling requirements in the facilities. Since enterprise servers rarely operate at their peak capacity, efficient power capping is deemed as a critical component of modern enterprise computing environments. In this paper we propose a new power measurement and power limiting architecture for main memory. Specifically, we describe a new approach for measuring memory power and demonstrate its applicability to a novel power limiting algorithm. We implement and evaluate our approach in the modern servers and show that we achieve up to 40% lower performance impact when compared to the stateof- art baseline across the power limiting range. Copyright 2010 ACM.","2010","2025-10-22 19:07:42","2025-10-22 19:07:42","","189-194","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Critical component; Performance; New approaches; Design; Performance impact; Data centers; Power measurement; Measurement; Power estimations; Efficient power; Enterprise computing environment; Enterprise servers; Experimentation; Main memory; Peak capacity; Power electronics; Power limiting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Symposium on Low Power Electronics and Design","","","","","","","","","","","","","","",""
"WVHYPQL7","conferencePaper","2010","Chen, X.; Xu, C.; Dick, R.P.; Mao, Z.M.","Performance and power modeling in a multi-programmed multi-core environment","","","","10.1145/1837274.1837479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956210093&doi=10.1145%2f1837274.1837479&partnerID=40&md5=2fdb1f99d1e78194d838f0f4790992a8","This paper describes a fast, automated technique for accurate on-line estimation of the performance and power consumption of interacting processes in a multi-programmed, multi-core environment. The proposed technique does not require modifying hardware or applications. The performance model uses reuse distance histograms, cache access frequencies, and the relationship between the throughput and cache miss rate of each process to predict throughput. The system-level power model is derived using multi-variable linear regression, accounting for cache contention. Both models are validated on multiple real multi-core systems using SPEC CPU2000 benchmarks; their performance and power estimates are within 3.5% of measured values on average. We explain how to integrate the two models for power estimation during process assignment, helpful for power-aware assignment. Copyright 2010 ACM.","2010","2025-10-22 19:07:42","2025-10-22 19:07:42","","813-818","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Power-aware; Multi core; Power modeling; Automation; Microprocessor chips; Computer aided design; Power model; System levels; Performance modeling; Power estimations; Power Consumption; Multi-core systems; Assignment; Automated techniques; Cache access; Cache miss rates; Interacting process; Multi-variable linear regression; On-line estimation; Performance Model; Process assignment; Reuse distance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - Design Automation Conference","","","","","","","","","","","","","","",""
"7X4T88VK","conferencePaper","2018","Von Kistowski, J.; Eismann, S.; Schmitt, N.; Bauer, A.; Grohmann, J.; Kounev, S.","TeaStore: A micro-service reference application for benchmarking, modeling and resource management research","","","","10.1109/MASCOTS.2018.00030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058299875&doi=10.1109%2fMASCOTS.2018.00030&partnerID=40&md5=b9ee5510d42b5ac1ead035c7c172885c","Modern distributed applications offer complex performance behavior and many degrees of freedom regarding deployment and configuration. Researchers employ various methods of analysis, modeling, and management that leverage these degrees of freedom to predict or improve non-functional properties of the software under consideration. In order to demonstrate and evaluate their applicability in the real world, methods resulting from such research areas require test and reference applications that offer a range of different behaviors, as well as the necessary degrees of freedom. Existing production software is often inaccessible for researchers or closed off to instrumentation. Existing testing and benchmarking frameworks, on the other hand, are either designed for specific testing scenarios, or they do not offer the necessary degrees of freedom. Further, most test applications are difficult to deploy and run, or are outdated. In this paper, we introduce the TeaStore, a state-of-The-Art micro-service-based test and reference application. TeaStore offers services with different performance characteristics and many degrees of freedom regarding deployment and configuration to be used as a benchmarking framework for researchers. The TeaStore allows evaluating performance modeling and resource management techniques; it also offers instrumented variants to enable extensive run-Time analysis. We demonstrate TeaStore's use in three contexts: performance modeling, cloud resource management, and energy efficiency analysis. Our experiments show that TeaStore can be used for evaluating novel approaches in these contexts and also motivates further research in the areas of performance modeling and resource management. © 2018 IEEE.","2018","2025-10-22 19:07:42","2025-10-22 19:07:42","","223-236","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Power; Microservice; Performance; Container; Energy Efficiency; Clouds; Benchmarking; Green computing; Natural resources management; Resource allocation; Cloud; Deployment and configuration; Auto Scaler; Models; Degrees of freedom (mechanics); Energy efficiency analysis; Performance characteristics; Resource management techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 26th IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems, MASCOTS 2018","","","","","","","","","","","","","","",""
"L6KJQGWM","conferencePaper","2019","Lim, H.; Kansal, A.; Liu, J.","Power budgeting for virtualized data centers","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077062938&partnerID=40&md5=67c8e58f613f0d894bcb843d0257e605","Power costs are very significant for data centers. To maximally utilize the provisioned power capacity, data centers often employ over-subscription, that is, the sum of peak consumptions of individual servers may be greater than the provisioned capacity. Power budgeting methods are employed to ensure that actual consumption never exceeds capacity. However, current power budgeting methods enforce capacity limits in hardware and are not well suited for virtualized servers because the hardware is shared among multiple applications. We present a power budgeting system for virtualized infrastructures that enforces power limits on individual distributed applications. Our system enables multiple applications to share the same servers but operate with their individual quality of service guarantees. It responds to workload and power availability changes, by dynamically allocating appropriate amount of power to different applications and tiers within applications. The design is mindful of practical constraints such the data center's limited visibility into hosted application performance. We evaluate the system using workloads derived from real world data center traces.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","59-72","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Quality of service; Budget control; Distributed applications; Application performance; Virtualized data centers; Multiple applications; Power budgeting; Limited visibility; Power capacity; Quality of service guarantees","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2011 USENIX Annual Technical Conference, USENIX ATC 2011","","","","","","","","","","","","","","",""
"QRVZ494N","conferencePaper","2010","Lim, M.Y.; Porterfield, A.; Fowler, R.","SoftPower: Fine-grain power estimations using performance counters","","","","10.1145/1851476.1851517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650033616&doi=10.1145%2f1851476.1851517&partnerID=40&md5=b633b0aa54c8e639bdd4a0f30ad292f1","We present and evaluate a surrogate model, based on hardware performance counter measurements, to estimate computer system power consumption. Power and energy are especially important in the design and operation of large data centers and of clusters used for scientific computing. Tradeoffs are made between performance and power consumption, this needs to be dynamic because activity varies over time. While it is possible to instrument systems for fine-grain power monitoring, such instrumentation is costly and not commonly available. Furthermore, the latency and sampling periods of hardware power monitors can be large compared to time scales at which workloads can change and dynamic power controls can operate. Given these limitations, we argue that surrogate models of the kind we present here can provide low-cost and accurate estimates of power consumption to drive on-line dynamic control mechanisms and for use in off-line tuning. In this brief paper, we discuss a general approach to building system power estimation models based on hardware performance counters. Using this technique, we then present a model for an Intel Core i7 system that has an absolute estimation error of 5.32 percent (median) and acceptable data collection overheads on varying workloads, CPU power states (frequency and voltage), and number of active cores. Since this method is based on event sampling of hardware counters, one can make a tradeoff between estimation accuracy and data-collection overhead. Copyright 2010 ACM.","2010","2025-10-22 19:07:42","2025-10-22 19:07:42","","308-311","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware counters; Data acquisition; Instruments; Time-scales; Data collection; Power estimations; Power Consumption; Performance counters; Estimation errors; Hardware performance counters; Estimation; Building systems; CPU power; Design and operations; Dynamic controls; Dynamic power control; Frequency estimation; Fuel additives; General approach; Instrument systems; Large data; Power estimation; Power monitor; Power monitoring; Sampling period; Scientific computing; Surrogate model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","HPDC 2010 - Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing","","","","","","","","","","","","","","",""
"THZ839UN","conferencePaper","2012","Pathak, A.; Hu, Y.C.; Zhang, M.","Where is the energy spent inside my app?: Fine grained energy accounting on smartphones with eprof","","","","10.1145/2168836.2168841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860588880&doi=10.1145%2f2168836.2168841&partnerID=40&md5=7e5e7c394e2c4c1aa4599acddc188741","Where is the energy spent inside my app? Despite the immense popularity of smartphones and the fact that energy is the most crucial aspect in smartphone programming, the answer to the above question remains elusive. This paper first presents epro f, the first fine-grained energy profiler for smartphone apps. Compared to profiling the runtime of applications running on conventional computers, profiling energy consumption of applications running on smartphones faces a unique challenge, asynchronous power behavior, where the effect on a component's power state due to a program entity lasts beyond the end of that program entity. We present the design, implementation and evaluation of eprof on two mobile OSes, Android and Windows Mobile. We then present an in-depth case study, the first of its kind, of six popular smartphones apps (including Angry-Birds, Facebook and Browser). Eprof sheds lights on internal energy dissipation of these apps and exposes surprising findings like 65%-75% of energy in free apps is spent in third-party advertisement modules. Eprof also reveals several ""wakelock bugs"", a family of ""energy bugs"" in smart-phone apps, and effectively pinpoints their location in the source code. The case study highlights the fact that most of the energy in smartphone apps is spent in I/O, and I/O events are clustered, often due to a few routines. This motivates us to propose bundles, a new accounting presentation of app I/O energy, which helps the developer to quickly understand and optimize the energy drain of her app. Using the bundle presentation, we reduced the energy consumption of four apps by 20% to 65%. © 2012 ACM.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","29-42","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy accounting; Energy utilization; Runtimes; Smartphones; Signal encoding; Energy; Fine grained; Energy dissipation; Mobile; Facebook; Source codes; Conventional computers; Energy drain; Eprof; Power state; Windows mobiles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EuroSys'12 - Proceedings of the EuroSys 2012 Conference","","","","","","","","","","","","","","",""
"53CUDU3I","journalArticle","2013","Rodrigues, R.; Annamalai, A.; Koren, I.; Kundu, S.","A study on the use of performance counters to estimate power in microprocessors","IEEE Transactions on Circuits and Systems II: Express Briefs","","","10.1109/TCSII.2013.2285966","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890856183&doi=10.1109%2fTCSII.2013.2285966&partnerID=40&md5=42d883289d120d43e48a715684651370","We present a study on estimating the dynamic power consumption of a processor based on performance counters. Today's processors feature a large number of such counters to monitor various CPU and memory parameters, such as utilization, occupancy, bandwidth, page, cache, and branch buffer hit rates. The use of various sets of performance counters to estimate the power consumed by the processor has been demonstrated in the past. Our goal is to find out whether there exists a subset of counters that can be used to estimate, with sufficient accuracy, the dynamic power consumption of processors with varying microarchitecture. To this end, we consider two recent processor configurations representing two extremes of the performance spectrum, one targeting low power and the other high performance. Our results indicate that only three counters measuring 1) the number of fetched instructions, 2) level-1 cache hits, and 3) dispatch stalls are sufficient to achieve adequate precision. These counters are shown to be effective in predicting the dynamic power consumption across processors of varying resource sizes achieving a prediction accuracy of 95%. © 2004-2012 IEEE.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","882-886","","12","60","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Micro architectures; Low Power; Power estimations; Performance counters; Dynamic power consumption; Electrical engineering; Electronics engineering; High-performance core (HPerf); low-power core (LP); performance counters; Performance spectrum; power estimation; Prediction accuracy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MAHYFTHR","journalArticle","2014","Whitney, J.; Delforge, P.","Data center efficiency assessment","Data Center Efficiency Assessment","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955280182&partnerID=40&md5=c2aff8c790412a8447c9a15d4555890a","","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3G46CNNZ","journalArticle","2012","Rotem, E.; Naveh, A.; Ananthakrishnan, A.; Weissmann, E.; Rajwan, D.","Power-management architecture of the intel microarchitecture code-named Sandy Bridge","IEEE Micro","","","10.1109/MM.2012.12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859729360&doi=10.1109%2fMM.2012.12&partnerID=40&md5=ac411761c3d90741a5eebafa6fed9716","Modern microprocessors are evolving into system-on-a-chip designs with high integration levels, catering to ever-shrinking form factors. Portability without compromising performance is a driving market need. An architectural approach that's adaptive to and cognizant of workload behavior and platform physical constraints is indispensable to meeting these performance and efficiency goals. This article describes power-management innovations introduced on Intel's Sandy Bridge microprocessor. © 2012 IEEE.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","20-27","","2","32","","","","","","","","","","","","","Scopus","","","","","","","","Program processors; Energy management; Application specific integrated circuits; Approximation theory; Architectural approach; energy management; Form factors; High integration level; Market needs; Micro architectures; Microprocessor chips; Modern microprocessor; Physical constraints; power management; Power managements; Sandy Bridge; System-on-a-chip designs; Turbo Boost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5FTRPI8","conferencePaper","2011","Dong, M.; Zhong, L.","Self-constructive high-rate system energy modeling for battery-powered mobile systems","","","","10.1145/1999995.2000027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961068480&doi=10.1145%2f1999995.2000027&partnerID=40&md5=657d48bfa00a439eb38824f38d639126","System energy models are important for energy optimization and management in mobile systems. However, existing system energy models are built in a lab setting with the help from a second computer. Not only are they labor-intensive; but also they do not adequately account for the great diversity in the hardware and usage of mobile systems. Moreover, existing system energy models are intended for energy estimation for time intervals of one second or longer; they do not provide the required rate for fine-grain use such as per-application energy accounting. In this work, we study a self-modeling paradigm in which a mobile system automatically generates its energy model without any external assistance. Our solution, Sesame, leverages the possibility of self power measurement through the smart battery interface and employs a suite of novel techniques to achieve accuracy and rate much higher than that of the smart battery interface. We report the implementation and evaluation of Sesame on a laptop and a smartphone. The experiment results show that Sesame is able to generate system energy models of 95% accuracy at one estimation per second and of 88% accuracy at one estimation per 10ms, without any external assistance. Two five-day field studies with four laptop and four smartphone users further demonstrate the effectiveness, efficiency, and non-invasiveness of Sesame. © 2011 ACM.","2011","2025-10-22 19:07:42","2025-10-22 19:07:42","","335-348","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy accounting; Signal encoding; Smart phones; Laptop computers; Low Power; Energy model; Energy optimization; low power; System energy; Novel techniques; Energy estimation; Estimation; energy modeling; Energy modeling; Existing systems; Field studies; High-rate systems; mobile systems; Mobile systems; Time interval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","MobiSys'11 - Compilation Proceedings of the 9th International Conference on Mobile Systems, Applications and Services and Co-located Workshops","","","","","","","","","","","","","","",""
"YZ7WVPFF","conferencePaper","2013","Hao, S.; Li, D.; Halfond, W.G.J.; Govindan, R.","Estimating mobile application energy consumption using program analysis","","","","10.1109/ICSE.2013.6606555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886424945&doi=10.1109%2fICSE.2013.6606555&partnerID=40&md5=d1be15a97911487f3e5c18a2be35bb4e","Optimizing the energy efficiency of mobile applications can greatly increase user satisfaction. However, developers lack viable techniques for estimating the energy consumption of their applications. This paper proposes a new approach that is both lightweight in terms of its developer requirements and provides fine-grained estimates of energy consumption at the code level. It achieves this using a novel combination of program analysis and per-instruction energy modeling. In evaluation, our approach is able to estimate energy consumption to within 10% of the ground truth for a set of mobile applications from the Google Play store. Additionally, it provides useful and meaningful feedback to developers that helps them to understand application energy consumption behavior. © 2013 IEEE.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","92-101","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; New approaches; Computer applications; Energy utilization; Software engineering; Mobile applications; Mobile computing; Mobile app; Energy estimation; Estimation; fine-grained energy estimation; Google plays; Ground truth; program analysis; Program analysis; User satisfaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"U63LIWYH","conferencePaper","2015","Tomas, L.; Klein, C.; Tordsson, J.; Hernandez-Rodriguez, F.","The straw that broke the camel's back: Safe cloud overbooking with application brownout","","","","10.1109/ICCAC.2014.10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923972497&doi=10.1109%2fICCAC.2014.10&partnerID=40&md5=8b2ea2c3f695f04eef39fc7e39e61500","Resource overbooking is an admission control technique to increase utilization in cloud environments. However, due to uncertainty about future application workloads, overbooking may result in overload situations and deteriorated performance. We mitigate this using brownout, a feedback approach to application performance steering, that ensures graceful degradation during load spikes and thus avoids overload. Additionally, brownout management information is included into the overbooking system, enabling the development of improved reactive methods to overload situations. Our combined brownout-overbooking approach is evaluated based on real-life interactive workloads and non-interactive batch applications. The results show that our approach achieves an improvement of resource utilization of 11 to 37 percentage points, while keeping response times lower than the set target of 1 second, with negligible application degradation. © 2014 IEEE.","2015","2025-10-22 19:07:42","2025-10-22 19:07:42","","151-160","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Cloud environments; Future applications; Computer science; Graceful degradation; Computer programming; Resource utilizations; Application performance; Management information; Over-booking approaches; Resource overbooking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2014 International Conference on Cloud and Autonomic Computing, ICCAC 2014","","","","","","","","","","","","","","",""
"5WR4MARB","journalArticle","2017","Docker, I.","","Docker Compose File Version 3 Reference","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061106799&partnerID=40&md5=0f4f39d246cd3efb265b611c962dfbe5","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6G6C6B9C","conferencePaper","2014","Klein, C.; Maggio, M.; Arzén, K.-E.; Hernández-Rodriguez, F.","Brownout: Building more robust cloud applications","","","","10.1145/2568225.2568227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994065778&doi=10.1145%2f2568225.2568227&partnerID=40&md5=65399bd44b01bdd11e43ebcda0ddb8ab","Self-adaptation is a first class concern for cloud applications, which should be able to withstand diverse runtime changes. Variations are simultaneously happening both at the cloud infrastructure level - for example hardware failures - and at the user workload level - flash crowds. However, robustly withstanding extreme variability, requires costly hardware over-provisioning. In this paper, we introduce a self-adaptation programming paradigm called brownout. Using this paradigm, applications can be designed to robustly withstand unpredictable runtime variations, without over-provisioning. The paradigm is based on optional code that can be dynamically deactivated through decisions based on control theory. We modified two popular web application prototypes - RUBiS and RUBBoS - with less than 170 lines of code, to make them brownout-compliant. Experiments show that brownout self-adaptation dramatically improves the ability to withstand flash-crowds and hardware failures. © 2014 ACM.","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","700-711","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Cloud applications; Clouds; Software engineering; Cloud infrastructures; Over provisioning; Cloud; Reconfigurable hardware; Hardware failures; Adaptive software; Adaptive Software; Brownout; Control theory; Control Theory; Programming paradigms; Run-time variations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"QNTH3GM2","conferencePaper","2012","Liu, Z.; Chen, Y.; Bash, C.; Wierman, A.; Gmach, D.; Wang, Z.; Marwah, M.; Hyser, C.","Renewable and cooling aware workload management for sustainable data centers","","","","10.1145/2254756.2254779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864700984&doi=10.1145%2f2254756.2254779&partnerID=40&md5=dfdf71c33e8d6ec1bb243fe5c0840045","Recently, the demand for data center computing has surged, increasing the total energy footprint of data centers worldwide. Data centers typically comprise three subsystems: IT equipment provides services to customers; power infrastructure supports the IT and cooling equipment; and the cooling infrastructure removes heat generated by these subsystems. This work presents a novel approach to model the energy flows in a data center and optimize its operation. Traditionally, supply-side constraints such as energy or cooling availability were treated independently from IT workload management. This work reduces electricity cost and environmental impact using a holistic approach that integrates renewable supply, dynamic pricing, and cooling supply including chiller and outside air cooling, with IT workload planning to improve the overall sustainability of data center operations. Specifically, we first predict renewable energy as well as IT demand. Then we use these predictions to generate an IT workload management plan that schedules IT workload and allocates IT resources within a data center according to time varying power supply and cooling efficiency. We have implemented and evaluated our approach using traces from real data centers and production systems. The results demonstrate that our approach can reduce both the recurring power costs and the use of non-renewable energy by as much as 60% compared to existing techniques, while still meeting the Service Level Agreements. © 2012 ACM.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","175-186","","","40","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Optimization; Information management; Service Level Agreements; Information technology; Data centers; Computer systems; Cooling; scheduling; Non-renewable energy; Renewable energies; Cost reduction; Cooling equipment; Power infrastructures; Total energy; Time varying; Air cooling; Cooling efficiency; cooling optimization; Cooling optimization; Data center operations; demand shaping; Dynamic pricing; Electricity costs; Energy flow; Holistic approach; IT equipment; IT resources; Power costs; Power supply; Production system; renewable energy; sustainable data center; Workload management; Workload planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Performance Evaluation Review","","","","","","","","","","","","","","",""
"7YWUNXVA","journalArticle","","Luzzardi, A.","","Scale Testing Docker Swarm to 30,000 Containers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994686335&partnerID=40&md5=84cfef52310b7eb2ac410692044cc6aa","","","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJEKFYA3","journalArticle","2013","Mastroianni, C.; Meo, M.; Papuzzo, G.","Probabilistic Consolidation of Virtual Machines in Self-Organizing Cloud Data Centers","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2013.17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969916663&doi=10.1109%2fTCC.2013.17&partnerID=40&md5=ca388967b1d387943d840d8ba2d0e6ec","Power efficiency is one of the main issues that will drive the design of data centers, especially of those devoted to provide Cloud computing services. In virtualized data centers, consolidation of Virtual Machines (VMs) on the minimum number of physical servers has been recognized as a very efficient approach, as this allows unloaded servers to be switched off or used to accommodate more load, which is clearly a cheaper alternative to buy more resources. The consolidation problem must be solved on multiple dimensions, since in modern data centers CPU is not the only critical resource: depending on the characteristics of the workload other resources, for example, RAM and bandwidth, can become the bottleneck. The problem is so complex that centralized and deterministic solutions are practically useless in large data centers with hundreds or thousands of servers. This paper presents ecoCloud a self-organizing and adaptive approach for the consolidation of VMs on two resources, namely CPU and RAM. Decisions on the assignment and migration of VMs are driven by probabilistic processes and are based exclusively on local information, which makes the approach very simple to implement. Both a fluid-like mathematical model and experiments on a real data center show that the approach rapidly consolidates the workload, and CPU-bound and RAM-bound VMs are balanced, so that both resources are exploited efficiently. © 2013 IEEE.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","215-228","","2","1","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud data centers; Digital storage; Energy conservation; Virtual machine; Data centers; Network security; Virtualized data centers; VM consolidation; Cloud computing services; Critical resources; data center; energy saving; Multiple dimensions; Probabilistic consolidations; Probabilistic process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"96J75GRC","journalArticle","2017","","","Docker Documentation | Docker Documentation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061078756&partnerID=40&md5=a9b8991f6c6d87bfda7ef2335cf3c527","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSPEXGES","journalArticle","2011","Kim, K.H.; Beloglazov, A.; Buyya, R.","Power-aware provisioning of virtual machines for real-time Cloud services","Concurrency and Computation: Practice and Experience","","","10.1002/cpe.1712","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051798127&doi=10.1002%2fcpe.1712&partnerID=40&md5=99b529f15e78a203deecd0580efda5df","Reducing power consumption has been an essential requirement for Cloud resource providers not only to decrease operating costs, but also to improve the system reliability. As Cloud computing becomes emergent for the Anything as a Service (XaaS) paradigm, modern real-time services also become available through Cloud computing. In this work, we investigate power-aware provisioning of virtual machines for real-time services. Our approach is (i) to model a real-time service as a real-time virtual machine request; and (ii) to provision virtual machines in Cloud data centers using dynamic voltage frequency scaling schemes. We propose several schemes to reduce power consumption by hard real-time services and power-aware profitable provisioning of soft real-time services. © 2011 John Wiley & Sons, Ltd.","2011","2025-10-22 19:07:42","2025-10-22 19:07:42","","1491-1505","","13","23","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Electric power utilization; Energy efficiency; cloud computing; Cloud computing; Cloud data centers; Real time systems; Green computing; Web services; Dynamic frequency scaling; Virtual machine; Hard real-time; Operating costs; Network security; Information services; Resource providers; Dynamic voltage frequency scaling; Energy efficient computing; energy-efficient computing; green data centers; Green data centers; Real time service; real-time services; System reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZPYYTD4","journalArticle","2017","","","Apache JMeter-Apache JMeter™","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050792283&partnerID=40&md5=659268e5695b4f76e5bbd078230dca60","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KC3SR2KS","conferencePaper","2008","Buyya, R.; Yeo, C.S.; Venugopal, S.","Market-oriented cloud computing: Vision, hype, and reality for delivering IT services as computing utilities","","","","10.1109/HPCC.2008.172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-56349150824&doi=10.1109%2fHPCC.2008.172&partnerID=40&md5=6c72d9bf489047e57ce934a25be09075","This keynote paper: presents a 21st century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3 rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision. © 2008 IEEE.","2008","2025-10-22 19:07:42","2025-10-22 19:07:42","","5-13","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Grid computing; Clouds; Resource allocation; Computing environments; Computer systems; Risk analysis; Computational risk managements; Computing paradigms; GRID technologies; High performance liquid chromatography; It services; Management; Marketing; Planning; Resource Management strategies; Risk management; Service managements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 10th IEEE International Conference on High Performance Computing and Communications, HPCC 2008","","","","","","","","","","","","","","",""
"B47U7MA3","journalArticle","2013","Beloglazov, A.; Buyya, R.","Managing overloaded hosts for dynamic consolidation of virtual machines in cloud data centers under quality of service constraints","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2012.240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878476684&doi=10.1109%2fTPDS.2012.240&partnerID=40&md5=01be4a531f0874fe562725f0dc176ae7","Dynamic consolidation of virtual machines (VMs) is an effective way to improve the utilization of resources and energy efficiency in cloud data centers. Determining when it is best to reallocate VMs from an overloaded host is an aspect of dynamic VM consolidation that directly influences the resource utilization and quality of service (QoS) delivered by the system. The influence on the QoS is explained by the fact that server overloads cause resource shortages and performance degradation of applications. Current solutions to the problem of host overload detection are generally heuristic based, or rely on statistical analysis of historical data. The limitations of these approaches are that they lead to suboptimal results and do not allow explicit specification of a QoS goal. We propose a novel approach that for any known stationary workload and a given state configuration optimally solves the problem of host overload detection by maximizing the mean intermigration time under the specified QoS goal based on a Markov chain model. We heuristically adapt the algorithm to handle unknown nonstationary workloads using the Multisize Sliding Window workload estimation technique. Through simulations with workload traces from more than a thousand PlanetLab VMs, we show that our approach outperforms the best benchmark algorithm and provides approximately 88 percent of the performance of the optimal offline algorithm. © 1990-2012 IEEE.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","1366-1379","","7","24","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Performance degradation; cloud computing; Cloud computing; Algorithms; Distributed systems; Virtualizations; Benchmarking; Resource utilizations; Dynamic consolidation; Computer simulation; dynamic consolidation; energy efficiency; host overload detection; Overload detection; Quality of Service constraints; Utilization of resources; virtualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7UT7IG8H","journalArticle","2016","Bawden, T.","Global Warming: Data Centres to Consume Three Times as Much Energy in Next Decade, Experts Warn. Independent","Global Warming: Data Centres to Consume Three Times As Much Energy in Next Decade, Experts Warn","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027445487&partnerID=40&md5=123e9283abd4476f899e2d3f932614ad","","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86VL79QA","journalArticle","2017","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081760324&partnerID=40&md5=415a49868af0ccf4777abd03d2c145e8","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XI555R5R","journalArticle","2014","Whitney, J.; Delforge, P.","Data center efficiency assessment-scaling up energy efficiency across the data center industry: Evaluating key drivers and barriers","Data Center Efficiency Assessment-Scaling Up Energy Efficiency Across the Data Center Industry: Evaluating Key Drivers and Barriers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957375958&partnerID=40&md5=74d0323715ac988c9cdcb79ae0c9b082","","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7XRFAIA","journalArticle","2016","Khanouche, M.E.; Amirat, Y.; Chibani, A.; Kerkar, M.; Yachir, A.","Energy-Centered and QoS-Aware Services Selection for Internet of Things","IEEE Transactions on Automation Science and Engineering","","","10.1109/TASE.2016.2539240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979723409&doi=10.1109%2fTASE.2016.2539240&partnerID=40&md5=3d14b30a4a317db17e3e8c18f342f0a5","An important challenge to be addressed in the domain of Internet of Things (IoT) is the development of efficient services selection algorithms for an optimal management of both energy and Quality of Service (QoS) in the context of IoT services composition. This issue becomes crucial in the case of large-scale IoT environments composed of thousands of distributed entities. In this paper, an energy-centered and QoS-aware services selection algorithm (EQSA) is proposed for IoT services composition. The proposed selection approach consists of preselecting the services offering the QoS level required for user's satisfaction using a lexicographic optimization strategy and QoS constraints relaxation technique. In order to reduce the energy consumption of a composite service without affecting the user's satisfaction, the most suitable services among the preselected ones are then selected using the concept of relative dominance of services in the sense of Pareto. The relative dominance of a candidate service depends on its energy profile and QoS attributes, and user's preferences. The proposed algorithm has been evaluated through several simulation scenarios. The obtained results show clearly the good performances of the EQSA algorithm in terms of selection time, energy efficiency, composition lifetime, and optimality and its added value in comparison with algorithms dealing separately with QoS and energy consumption. © 2016 IEEE.","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","1256-1269","","3","13","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Energy utilization; Internet of things; Internet of Things (IOT); Web services; Telecommunication services; Multiobjective optimization; Internet of Things (IoT); multi-objective optimization; Services composition; Linear programming; Energy profile; lexicographic optimization; Lexicographic optimization; quality of service (QoS); services composition; services selection; Services selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2SRDJQ8","conferencePaper","2015","Chen, Q.; Chen, J.; Zheng, B.; Cui, J.; Qian, Y.","Utilization-based VM consolidation scheme for power efficiency in cloud data centers","","","","10.1109/ICCW.2015.7247462","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947776140&doi=10.1109%2fICCW.2015.7247462&partnerID=40&md5=c79891a7cdb7bf5e860a097a90b342c3","Cloud computing offers utility-oriented services to users, which is supported by large-scale data center. Although virtualized data centers provide high performance computing service, they also consume enormous amount of power. To solve the problem, dynamic consolidation of Virtual Machines (VMs) is considered as an efficient way to reduce power consumption and guarantee Quality of Service (QoS). Live migration is applied into the dynamic consolidation, which allows VMs to be migrated to other hosts and aims to minimize the number of hosts in data centers. However, the migration overhead is essential to be taken into account and massive migrations will lead to performance degradation and extra power consumption. In this paper, we propose a utilization-based migration algorithm (UMA) to migrate VMs to stable hosts, which efficiently reduces migration time and power consumption. Experiment results show that our UMA can reduce about 77.5%-82.4% migrations and save up to 39.3% -42.2% power consumption compared with the MinPower policy. © 2015 IEEE.","2015","2025-10-22 19:07:42","2025-10-22 19:07:42","","1928-1933","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Electric power utilization; Energy efficiency; Performance degradation; Cloud data centers; Virtual machine; Dynamic consolidation; High performance computing; Large scale data; Migration algorithms; Power efficiency; Virtualized data centers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 IEEE International Conference on Communication Workshop, ICCW 2015","","","","","","","","","","","","","","",""
"DI5E5JGD","journalArticle","2016","Teng, F.; Yu, L.; Li, T.; Deng, D.; Magoulès, F.","Energy efficiency of vm consolidation in iaas clouds","J. Supercomput.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054315522&partnerID=40&md5=68e6992837656e7866c72685d36c854d","","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","1-28","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FRZ3EXJR","journalArticle","2012","Beloglazov, A.; Abawajy, J.; Buyya, R.","Energy-aware resource allocation heuristics for efficient management of data centers for Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2011.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370722&doi=10.1016%2fj.future.2011.04.017&partnerID=40&md5=404d8a6f96e7208ce49f7fb3ffc699cd","Cloud computing offers utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of electrical energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only minimize operational costs but also reduce the environmental impact. In this paper, we define an architectural framework and principles for energy-efficient Cloud computing. Based on this architecture, we present our vision, open research challenges, and resource provisioning and allocation algorithms for energy-efficient management of Cloud computing environments. The proposed energy-aware allocation heuristics provision data center resources to client applications in a way that improves energy efficiency of the data center, while delivering the negotiated Quality of Service (QoS). In particular, in this paper we conduct a survey of research in energy-efficient computing and propose: (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering QoS expectations and power usage characteristics of the devices; and (c) a number of open research challenges, addressing which can bring substantial benefits to both resource providers and consumers. We have validated our approach by conducting a performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant cost savings and demonstrates high potential for the improvement of energy efficiency under dynamic workload scenarios. © 2011 Elsevier B.V. All rights reserved.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","755-768","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Energy efficient; Virtualizations; Energy aware; Resource allocation; Energy-efficient resource allocation; Computing environments; Research challenges; Data centers; Client applications; Computer systems; Performance evaluation; Cost saving; Dynamic consolidation; Allocation algorithm; Architectural frameworks; Architectural principles; Business domain; Carbon footprint; Computing solutions; Electrical energy; Environmental impact; Green IT; High potential; IT services; Operational costs; Pay-as-you-go; Pervasive applications; Power usage; Research; Resource providers; Resource provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5L2W9C9","conferencePaper","2014","Ferdaus, M.H.; Murshed, M.; Calheiros, R.N.; Buyya, R.","Virtual machine consolidation in cloud data centers using ACO metaheuristic","","","","10.1007/978-3-319-09873-9_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958546557&doi=10.1007%2f978-3-319-09873-9_26&partnerID=40&md5=8d940660c30a5c80492576433b3d1e30","In this paper, we propose the AVVMC VM consolidation scheme that focuses on balanced resource utilization of servers across different computing resources (CPU, memory, and network I/O) with the goal of minimizing power consumption and resource wastage. Since the VM consolidation problem is strictly NP-hard and computationally infeasible for large data centers, we propose adaptation and integration of the Ant Colony Optimization (ACO) metaheuristic with balanced usage of computing resources based on vector algebra. Our simulation results show that AVVMC outperforms existing methods and achieves improvement in both energy consumption and resource wastage reduction. © 2014 Springer International Publishing Switzerland.","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","306-317","","","8632 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Cloud data centers; Energy utilization; Virtual machine consolidations; Artificial intelligence; Resource utilizations; Computing resource; Ant colony optimization; Ant Colony Optimization (ACO); Metaheuristic; Network I/O; Vector algebra","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"SAPSU949","journalArticle","2020","Gai, K.; Qiu, L.; Zhao, H.; Qiu, M.","Cost-Aware Multimedia Data Allocation for Heterogeneous Memory Using Genetic Algorithm in Cloud Computing","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2016.2594172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097852644&doi=10.1109%2fTCC.2016.2594172&partnerID=40&md5=cd4c7bebee53fb44b787663a80271aec","Recent expansions of Internet-of-Things (IoT) applying cloud computing have been growing at a phenomenal rate. As one of the developments, heterogeneous cloud computing has enabled a variety of cloud-based infrastructure solutions, such as multimedia big data. Numerous prior researches have explored the optimizations of on-premise heterogeneous memories. However, the heterogeneous cloud memories are facing constraints due to the performance limitations and cost concerns caused by the hardware distributions and manipulative mechanisms. Assigning data tasks to distributed memories with various capacities is a combinatorial NP-hard problem. This paper focuses on this issue and proposes a novel approach, Cost-Aware Heterogeneous Cloud Memory Model (CAHCM), aiming to provision a high performance cloud-based heterogeneous memory service offerings. The main algorithm supporting CAHCM is Dynamic Data Allocation Advance (2DA) Algorithm that uses genetic programming to determine the data allocations on the cloud-based memories. In our proposed approach, we consider a set of crucial factors impacting the performance of the cloud memories, such as communication costs, data move operating costs, energy performance, and time constraints. Finally, we implement experimental evaluations to examine our proposed model. The experimental results have shown that our approach is adoptable and feasible for being a cost-aware cloud-based solution. © 2013 IEEE.","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","1212-1222","","4","8","","","","","","","","","","","","","Scopus","","","","","","","","Big data; Cloud computing; Cloud-computing; Performance; Internet of things; Computational complexity; Cost-aware; Operating costs; Optimisations; Genetic algorithms; genetic algorithm; Heterogeneous memory; Cloud-based; data allocation; Data allocation; Genetic programming; heterogeneous memory; Memory modeling; multimedia big data; Multimedia data; Multimedium big data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2B8HI9DB","conferencePaper","2014","Zheng, K.; Wang, X.; Li, L.; Wang, X.","Joint power optimization of data center network and servers with correlation analysis","","","","10.1109/INFOCOM.2014.6848207","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904410981&doi=10.1109%2fINFOCOM.2014.6848207&partnerID=40&md5=ec3b4daf09fd8b2c667563df1cd786e4","Data center power optimization has recently received a great deal of research attention. For example, server consolidation has been demonstrated as one of the most effective energy saving methodologies. Likewise, traffic consolidation has also been recently proposed to save energy for data center networks (DCNs). However, current research on data center power optimization focuses on servers and DCN separately. As a result, the optimization results are often inferior, because server consolidation without considering the DCN may cause traffic congestion and thus degraded network performance. On the other hand, server consolidation may change the DCN topology, allowing new opportunities for energy savings. In this paper, we propose PowerNetS, a power optimization strategy that leverages workload correlation analysis to jointly minimize the total power consumption of servers and the DCN. The design of PowerNetS is based on the key observations that the workloads of different servers and DCN traffic flows do not peak at exactly the same time. Thus, more energy savings can be achieved if the workload correlations are considered in server and traffic consolidations. In addition, PowerNetS considers the DCN topology during server consolidation, which leads to less inter-server traffic and thus more energy savings and shorter network delays. We implement PowerNetS on a hardware testbed composed of 10 virtual switches configured with a production 48-port OpenFlow switch and 6 servers. Our empirical results with Wikipedia, Yahoo!, and IBM traces demonstrate that PowerNetS can save up to 51.6% of energy for a data center. PowerNetS also outperforms two state-of-the-art baselines by 44.3% and 15.8% on energy savings, respectively. Our simulation results with 72 switches and 122 servers also show the superior energy efficiency of PowerNetS over the baselines. © 2014 IEEE.","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","2598-2606","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Data center networks; Data center networks (DCNs); Correlation analysis; Correlation methods; Hardware testbeds; Power Optimization; Server consolidation; Topology; Total power consumption; Traffic congestion; Workload correlations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"VF7MNNRK","conferencePaper","2016","Han, Z.; Tan, H.; Chen, G.; Wang, R.; Chen, Y.; Lau, F.C.M.","Dynamic virtual machine management via approximate Markov decision process","","","","10.1109/INFOCOM.2016.7524384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983261312&doi=10.1109%2fINFOCOM.2016.7524384&partnerID=40&md5=ad72f6d581877dfd92d061df60b3b28e","Efficient virtual machine (VM) management can dramatically reduce energy consumption in data centers. Existing VM management algorithms fall into two categories based on whether the VMs' resource demands are assumed to be static or dynamic. The former category fails to maximize the resource utilization as they cannot adapt to the dynamic nature of VMs' resource demands. Most approaches in the latter category are heuristical and lack theoretical performance guarantees. In this work, we formulate dynamic VM management as a large-scale Markov Decision Process (MDP) problem and derive an optimal solution. Our analysis of real-world data traces supports our choice of the modeling approach. However, solving the large-scale MDP problem suffers from the curse of dimensionality. Therefore, we further exploit the special structure of the problem and propose an approximate MDP-based dynamic VM management method, called MadVM. We prove the convergence of MadVM and analyze the bound of its approximation error. Moreover, MadVM can be implemented in a distributed system, which should suit the needs of real data centers. Extensive simulations based on two real-world workload traces show that MadVM achieves significant performance gains over two existing baseline approaches in power consumption, resource shortage and the number of VM migrations. Specifically, the more intensely the resource demands fluctuate, the more MadVM outperforms. © 2016 IEEE.","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","2016-July","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Decision making; Extensive simulations; Resource utilizations; Approximation errors; Curse of dimensionality; Markov Decision Processes; Markov processes; Reduce energy consumption; Telecommunication networks; Theoretical performance; Virtual machine management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"HKTURYEF","journalArticle","2015","Newman, S.","","Building Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950338538&partnerID=40&md5=aec25db8f81564a4ab82f370c5e620cc","","2015","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDRDXN2X","journalArticle","2019","Pahl, C.; Brogi, A.; Soldani, J.; Jamshidi, P.","Cloud container technologies: A state-of-the-art review","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2017.2702586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050374433&doi=10.1109%2fTCC.2017.2702586&partnerID=40&md5=ba46e14ad12f81852ca97648461e4504","—Containers as a lightweight technology to virtualise applications have recently been successful, particularly to manage applications in the cloud. Often, the management of clusters of containers becomes essential and the orchestration of the construction and deployment becomes a central problem. This emerging topic has been taken up by researchers, but there is currently no secondary study to consolidate this research. We aim to identify, taxonomically classify and systematically compare the existing research body on containers and their orchestration and specifically the application of this technology in the cloud. We have conducted a systematic mapping study of 46 selected studies. We classified and compared the selected studies based on a characterisation framework. This results in a discussion of agreed and emerging concerns in the container orchestration space, positioning it within the cloud context, but also moving it closer to current concerns in cloud platforms, microservices and continuous development. © 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","677-692","","3","7","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Container; Systematic mapping studies; Systematic Review; Cluster; Orchestration; Continuous development; Container technologies; Systematic review; State-of-the art reviews; Characterisation framework; Index terms; Index Terms—Cloud; Space platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STZMNEDA","conferencePaper","2012","Beloglazov, A.; Buyya, R.","Optimal online deterministic algorithms and adaptive heuristics for energy and performance efficient dynamic consolidation of virtual machines in Cloud data centers","","","","10.1002/cpe.1867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864511735&doi=10.1002%2fcpe.1867&partnerID=40&md5=980cb3c4add37bca4eeb9ddb689564e6","The rapid growth in demand for computational power driven by modern service applications combined with the shift to the Cloud computing model have led to the establishment of large-scale virtualized data centers. Such data centers consume enormous amounts of electrical energy resulting in high operating costs and carbon dioxide emissions. Dynamic consolidation of virtual machines (VMs) using live migration and switching idle nodes to the sleep mode allows Cloud providers to optimize resource usage and reduce energy consumption. However, the obligation of providing high quality of service to customers leads to the necessity in dealing with the energy-performance trade-off, as aggressive consolidation may lead to performance degradation. Because of the variability of workloads experienced by modern applications, the VM placement should be optimized continuously in an online manner. To understand the implications of the online nature of the problem, we conduct a competitive analysis and prove competitive ratios of optimal online deterministic algorithms for the single VM migration and dynamic VM consolidation problems. Furthermore, we propose novel adaptive heuristics for dynamic consolidation of VMs based on an analysis of historical data from the resource usage by VMs. The proposed algorithms significantly reduce energy consumption, while ensuring a high level of adherence to the service level agreement. We validate the high efficiency of the proposed algorithms by extensive simulations using real-world workload traces from more than a thousand PlanetLab VMs. Copyright © 2011 John Wiley & Sons, Ltd. Copyright © 2011 John Wiley & Sons, Ltd.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","1397-1420","","","24","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Performance degradation; Optimization; Cloud computing; resource management; Resource management; Virtualization; Energy utilization; Service Level Agreements; Economic and social effects; Green computing; Virtual machine; Operating costs; Network security; Reduce energy consumption; Dynamic consolidation; Virtualized data centers; Green IT; dynamic consolidation; virtualization; Carbon dioxide; Carbon dioxide emissions; Deterministic algorithms; Global warming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Concurrency and Computation: Practice and Experience","","","","","","","","","","","","","","",""
"SWWZENP6","journalArticle","2017","Nadjaran Toosi, A.; Qu, C.; de Assunção, M.D.; Buyya, R.","Renewable-aware geographical load balancing of web applications for sustainable data centers","Journal of Network and Computer Applications","","","10.1016/j.jnca.2017.01.036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013218316&doi=10.1016%2fj.jnca.2017.01.036&partnerID=40&md5=fc714bb8bc882da6f70ef53c4f5bac7f","The ever-increasing demand for web applications deployed across multiple data centers results in large electricity costs for service providers and significant impact on the environment. This has motivated service providers to move towards more sustainable data centers powered by renewable or green sources of energy, such as solar or wind. However, efficient utilization of green energy to service web applications is a challenging problem due to intermittency and unpredictability of both application workload and renewable energy availability. One possible solution to reduce cost and increase renewable energy utilization is to exploit the spatio-temporal variations in on-site power and grid power prices by balancing the load among multiple data centers geographically distributed. In this paper, we propose a framework for reactive load balancing of web application requests among Geo-distributed sustainable data centers based on the availability of renewable energy sources on each site. A system prototype is developed, its underlying design and algorithms are described, and experiments are conducted with it using real infrastructure (Grid'5000 in France) and workload traces (real traffic to English Wikipedia). The experimental results demonstrate that our approach can reduce cost and brown energy usage with efficient utilization of green energy and without a priori knowledge of future workload, availability of renewable energy, and grid electricity prices. © 2017 Elsevier Ltd","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","155-168","","","83","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Green computing; Costs; Cost saving; Electric power transmission networks; WEB application; Renewable energies; Cost reduction; Energy policy; Auto-scaling; Green energy; Renewable energy resources; Wikipedia; Brown energy; Geographical load balancing; Green Energy; Renewable energy; System prototype; Web applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLU3VXCF","conferencePaper","2015","Pietri, I.; Sakellariou, R.","Energy-Aware Workflow Scheduling Using Frequency Scaling","","","","10.1109/ICPPW.2014.26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946568373&doi=10.1109%2fICPPW.2014.26&partnerID=40&md5=78127246419cc2193a6bbad390d1d0fb","Dynamic Voltage and Frequency Scaling (DVFS) is a power management technique used to decrease the processor frequency and minimize power consumption in modern computing systems. This may lead to higher energy savings for large-scale computational problems, with scientific workflows comprising an important category of applications among these. However, as frequency scaling may result in increased execution time overall, idle time on the processors may also increase, to such a degree that any gains in power are annulled, this depends on the system and workflow characteristics. In this paper, we propose a scheduling algorithm that adopts frequency scaling to reduce overall energy consumption of scientific workflows given an allocation of tasks onto machines and a deadline to complete the execution. Based on the observation that using the lowest possible frequency may not necessarily be energy-efficient, the proposed algorithm works iteratively to scale the frequency further and distribute any slack time, only when overall energy consumption can be decreased. Synthetic data based on parameters of real scientific workflows are used in the evaluation. The results show that the proposed algorithm can achieve energy savings, sometimes at the expense of execution time to reduce the idle time of the processors and decrease overall energy consumption. © 2014 IEEE.","2015","2025-10-22 19:07:42","2025-10-22 19:07:42","","104-113","","","2015-May","","","","","","","","","","","","","Scopus","","","","","","","","Energy-aware scheduling; Scheduling; Voltage scaling; Energy efficiency; Parallel processing systems; Energy utilization; Green computing; Dynamic frequency scaling; Iterative methods; Scheduling algorithms; workflow; DAG scheduling; DVFS; Frequency-scaling; energy-aware scheduling; frequency scaling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel Processing Workshops","","","","","","","","","","","","","","",""
"PDIL2V6H","journalArticle","2016","Wang, S.; Zhou, A.; Hsu, C.-H.; Xiao, X.; Yang, F.","Provision of Data-Intensive Services Through Energy-and QoS-Aware Virtual Machine Placement in National Cloud Data Centers","IEEE Transactions on Emerging Topics in Computing","","","10.1109/TETC.2015.2508383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976510805&doi=10.1109%2fTETC.2015.2508383&partnerID=40&md5=d87e788b1dcb97d7055c050a64508194","Many data-intensive services (e.g., planet analysis, gene analysis, and so on) are becoming increasingly reliant on national cloud data centers (NCDCs) because of growing scientific collaboration among countries. In NCDCs, tens of thousands of virtual machines (VMs) are assigned to physical servers to provide data-intensive services with a quality-of-service (QoS) guarantee, and consume a massive amount of energy in the process. Although many VM placement schemes have been proposed to solve this problem of energy consumption, most of these assume that all the physical servers are homogeneous. However, the physical server configurations of NCDCs often differ significantly, which leads to varying energy consumption characteristics. In this paper, we explore an alternative VM placement approach to minimize energy consumption during the provision of data-intensive services with a global QoS guarantee in NCDCs. We use an improved particle swarm optimization algorithm to develop an optimal VM placement approach involving a tradeoff between energy consumption and global QoS guarantee for data-intensive services. Experimental results show that our approach significantly outperforms other approaches to energy optimization and global QoS guarantee in NCDCs. © 2013 IEEE.","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","290-300","","2","4","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; cloud computing; Cloud computing; QoS; Algorithms; Cloud data centers; Energy utilization; Java programming language; Virtual machines; Energy consumption; Energy optimization; Virtual machine placements; Virtual machine placement; Particle swarm optimization (PSO); Data-intensive service; Data-intensive services; Improved particle swarm optimization algorithms; National cloud data center; Quality of service (QoS) guarantees; Scientific collaboration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6C2UM8R","conferencePaper","2012","Deng, Q.; Meisner, D.; Bhattacharjee, A.; Wenisch, T.F.; Bianchini, R.","CoScale: Coordinating CPU and memory system DVFS in server systems","","","","10.1109/MICRO.2012.22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876526315&doi=10.1109%2fMICRO.2012.22&partnerID=40&md5=58eb4b43654b660b4b23401474a3658a","Recent work has introduced memory system dynamic voltage and frequency scaling (DVFS), and has suggested that balanced scaling of both CPU and the memory system is the most promising approach for conserving energy in server systems. In this paper, we first demonstrate that CPU and memory system DVFS often conflict when performed independently by separate controllers. In response, we propose Co Scale, the first method for effectively coordinating these mechanisms under performance constraints. Co Scale relies on execution profiling of each core via (existing and new) performance counters, and models of core and memory performance and power consumption. Co Scale explores the set of possible frequency settings in such a way that it efficiently minimizes the full-system energy consumption within the performance bound. Our results demonstrate that, by effectively coordinating CPU and memory power management, Co Scale conserves a significant amount of system energy compared to existing approaches, while consistently remaining within the prescribed performance bounds. The results also show that Co Scale conserves almost as much system energy as an offline, idealized approach. © 2012 IEEE.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","143-154","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Computer architecture; Energy conservation; dynamic voltage and frequency scaling; Dynamic voltage and frequency scaling; energy conservation; Performance counters; coordination; Memory performance; Memory power management; Performance bounds; Performance constraints; Prescribed performance bounds","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2012 IEEE/ACM 45th International Symposium on Microarchitecture, MICRO 2012","","","","","","","","","","","","","","",""
"ISYDX5GI","journalArticle","2018","Gai, K.; Qiu, M.; Zhao, H.","Energy-aware task assignment for mobile cyber-enabled applications in heterogeneous cloud computing","Journal of Parallel and Distributed Computing","","","10.1016/j.jpdc.2017.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028741784&doi=10.1016%2fj.jpdc.2017.08.001&partnerID=40&md5=a2823efa0fbd16efa745da8e5c83f491","Recent remarkable growth of mobile computing has led to an exceptional hardware upgrade, including the adoption of the multiple core processors. Along with this trend, energy consumptions are becoming greater when the computation capacity or workload grows. As one of the solutions, using cloud computing can mitigate energy costs due to the centralized computation. However, simply offloading the workloads to the remote side cannot efficiently reduce the energy consumptions when the energy costs caused by wireless communications are greater than that of on mobile devices. In this paper, we focus on the energy-saving problem and consider the energy wastes when tasks are assigned to remote cloud servers or heterogeneous core processors. Our solution aims to reduce the total energy cost of the mobile heterogeneous embedded systems by a novel task assignment to heterogeneous cores and mobile clouds. The proposed model is called Energy-Aware Heterogeneous Cloud Management (EA-HCM) model and the main algorithm is Heterogeneous Task Assignment Algorithm (HTA2). Our experimental evaluations have proved that our approach is effective to save energy when deploying heterogeneous embedded systems in mobile cloud systems. © 2017 Elsevier Inc.","2018","2025-10-22 19:07:42","2025-10-22 19:07:42","","126-135","","","111","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Cloud computing; Energy aware; Mobile cloud computing; Wireless communications; Energy conservation; Power management (telecommunication); Experimental evaluation; Cost reduction; Energy-aware; Computation capacity; NP-hard; Energy-saving problems; Centralized computation; Cyber-enabled applications; Heterogeneous embedded system; Mobile embedded systems; Task assignment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTTEID2M","journalArticle","2014","Lavallée, Brian","","Data Center Energy: Reducing Your Carbon Footprint | Data Center Knowledge","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081759269&partnerID=40&md5=d98cf00e066a6d60f49a7a7c5768e8b5","","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3XJ8MF8S","journalArticle","2016","Xu, M.; Dastjerdi, A.V.; Buyya, R.","Energy Efficient Scheduling of Cloud Application Components with Brownout","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2017.2661339","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081713746&doi=10.1109%2fTSUSC.2017.2661339&partnerID=40&md5=e00446747da4f43b0f291cc8f5ee0154","It is common for cloud data centers meeting unexpected loads like request bursts, which may lead to overloaded situation and performance degradation. Dynamic Voltage Frequency Scaling and VM consolidation have been proved effective to manage overloads. However, they cannot function when the whole data center is overloaded. Brownout provides a promising direction to avoid overloads through configuring applications to temporarily degrade user experience. Additionally, brownout can also be applied to reduce data center energy consumption. As a complementary option for Dynamic Voltage Frequency Scaling and VM consolidation, our combined brownout approach reduces energy consumption through selectively and dynamically deactivating application optional components, which can also be applied to self-contained microservices. The results show that our approach can save more than 20 percent energy consumption and there are trade-offs between energy saving and discount offered to users. © 2016 IEEE.","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","40-43","","2","1","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; microservices; Application components; Cloud data centers; Energy efficient; Energy utilization; Economic and social effects; Green computing; Dynamic frequency scaling; application component; brownout; energy efficient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9LYEQ7P4","journalArticle","2017","","","Weaveshop-microservices-demo","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081759485&partnerID=40&md5=6b703dba0fc256353541fe6285ca937e","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4KFPRTB","journalArticle","2017","","","Ansible Is Simple IT Automation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042654270&partnerID=40&md5=e699d71a8dd588cf5f2b444fc17375c3","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7APXR33M","journalArticle","2016","Gai, K.; Qiu, M.; Zhao, H.; Tao, L.; Zong, Z.","Dynamic energy-aware cloudlet-based mobile cloud computing model for green computing","Journal of Network and Computer Applications","","","10.1016/j.jnca.2015.05.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949627105&doi=10.1016%2fj.jnca.2015.05.016&partnerID=40&md5=5abb99d76ead892a44038e02e5a26544","Employing mobile cloud computing (MCC) to enable mobile users to acquire benefits of cloud computing by an environmental friendly method is an efficient strategy for meeting current industrial demands. However, the restrictions of wireless bandwidth and device capacity have brought various obstacles, such as extra energy waste and latency delay, when deploying MCC. Addressing this issue, we propose a dynamic energy-aware cloudlet-based mobile cloud computing model (DECM) focusing on solving the additional energy consumptions during the wireless communications by leveraging dynamic cloudlets (DCL)-based model. In this paper, we examine our model by a simulation of practical scenario and provide solid results for the evaluations. The main contributions of this paper are twofold. First, this paper is the first exploration in solving energy waste problems within the dynamic networking environment. Second, the proposed model provides future research with a guideline and theoretical supports. © 2015 Elsevier Ltd. All rights reserved.","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","46-54","","","59","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Cloud computing; Energy aware; Mobile cloud computing; Green computing; Wireless communications; Wireless telecommunication systems; Power management (telecommunication); Cloudlets; Dynamic models; Dynamic program; Dynamic programs; Efficient strategy; Energy-aware; Environmental friendly methods; Wireless bandwidth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CFP972P","conferencePaper","2017","Xu, M.; Buyya, R.","Energy efficient scheduling of application components via brownout and approximate markov decision process","","","","10.1007/978-3-319-69035-3_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034095398&doi=10.1007%2f978-3-319-69035-3_14&partnerID=40&md5=9bb690276a53bfcfee72db0e06c927ac","Unexpected loads in Cloud data centers may trigger overloaded situation and performance degradation. To guarantee system performance, cloud computing environment is required to have the ability to handle overloads. The existing approaches, like Dynamic Voltage Frequency Scaling and VM consolidation, are effective in handling partial overloads, however, they cannot function when the whole data center is overloaded. Brownout has been proved to be a promising approach to relieve the overloads through deactivating application non-mandatory components or microservices temporarily. Moreover, brownout has been applied to reduce data center energy consumption. It shows that there are trade-offs between energy saving and discount offered to users (revenue loss) when one or more services are not provided temporarily. In this paper, we propose a brownout-based approximate Markov Decision Process approach to improve the aforementioned trade-offs. The results based on real trace demonstrate that our approach saves 20% energy consumption than VM consolidation approach. Compared with existing energy-efficient brownout approach, our approach reduces the discount amount given to users while saving similar energy consumption. © Springer International Publishing AG 2017.","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","206-220","","","10601 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Performance degradation; Microservices; Application components; Distributed computer systems; Energy utilization; Economic and social effects; Decision making; Green computing; Dynamic frequency scaling; Energy conservation; Commerce; Cloud computing environments; Markov Decision Processes; Markov processes; Dynamic voltage frequency scaling; Brownout; Application component; Cloud energy efficiency; Energy-Efficient Scheduling; Markov decision process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"8GCIA7VL","journalArticle","2020","Masanet, E.; Shehabi, A.; Lei, N.; Smith, S.; Koomey, J.","Recalibrating global data center energy-use estimates: Growth in energy use has slowed owing to efficiency gains that smart policies can help maintain in the near term","Science","","","10.1126/science.aba3758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080913294&doi=10.1126%2fscience.aba3758&partnerID=40&md5=e714910a4e298ff7a30d72190beae6c0","","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","984-986","","6481","367","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; power supply; energy efficiency; policy; priority journal; energy; data processing; electricity; information technology; calibration; client server application; data assimilation; energy use; funding; information storage; internet protocol; investment; policy making; power usage effectiveness; Review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65VBBF96","conferencePaper","2012","Liu, Z.; Chen, Y.; Bash, C.; Wierman, A.; Gmach, D.; Wang, Z.; Marwah, M.; Hyser, C.","Renewable and cooling aware workload management for sustainable data centers","","","","10.1145/2254756.2254779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864700984&doi=10.1145%2f2254756.2254779&partnerID=40&md5=dfdf71c33e8d6ec1bb243fe5c0840045","Recently, the demand for data center computing has surged, increasing the total energy footprint of data centers worldwide. Data centers typically comprise three subsystems: IT equipment provides services to customers; power infrastructure supports the IT and cooling equipment; and the cooling infrastructure removes heat generated by these subsystems. This work presents a novel approach to model the energy flows in a data center and optimize its operation. Traditionally, supply-side constraints such as energy or cooling availability were treated independently from IT workload management. This work reduces electricity cost and environmental impact using a holistic approach that integrates renewable supply, dynamic pricing, and cooling supply including chiller and outside air cooling, with IT workload planning to improve the overall sustainability of data center operations. Specifically, we first predict renewable energy as well as IT demand. Then we use these predictions to generate an IT workload management plan that schedules IT workload and allocates IT resources within a data center according to time varying power supply and cooling efficiency. We have implemented and evaluated our approach using traces from real data centers and production systems. The results demonstrate that our approach can reduce both the recurring power costs and the use of non-renewable energy by as much as 60% compared to existing techniques, while still meeting the Service Level Agreements. © 2012 ACM.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","175-186","","","40","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Optimization; Information management; Service Level Agreements; Information technology; Data centers; Computer systems; Cooling; scheduling; Non-renewable energy; Renewable energies; Cost reduction; Cooling equipment; Power infrastructures; Total energy; Time varying; Air cooling; Cooling efficiency; cooling optimization; Cooling optimization; Data center operations; demand shaping; Dynamic pricing; Electricity costs; Energy flow; Holistic approach; IT equipment; IT resources; Power costs; Power supply; Production system; renewable energy; sustainable data center; Workload management; Workload planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Performance Evaluation Review","","","","","","","","","","","","","","",""
"92I3ZC38","journalArticle","2019","Stavrinides, G.L.; Karatza, H.D.","An energy-efficient, QoS-aware and cost-effective scheduling approach for real-time workflow applications in cloud computing systems utilizing DVFS and approximate computations","Future Generation Computer Systems","","","10.1016/j.future.2019.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061666574&doi=10.1016%2fj.future.2019.02.019&partnerID=40&md5=76a3a60640ec03022fd8f31b42d67a7a","Green cloud computing attracts significant attention from both academia and industry. One of the major challenges involved, is to provide a high level of Quality of Service (QoS) in a cost-effective way for the end users and in an energy-efficient manner for the cloud providers. Towards this direction, this paper presents an energy-efficient, QoS-aware and cost-effective scheduling strategy for real-time workflow applications in cloud computing systems. The proposed approach utilizes per-core Dynamic Voltage and Frequency Scaling (DVFS) on the underlying heterogeneous multi-core processors, as well as approximate computations, in order to fill in schedule gaps. At the same time, it takes into account the effects of input error on the processing time of the component tasks. Our goal is to provide timeliness and energy efficiency by trading off result precision, while keeping the result quality of the completed jobs at an acceptable standard and the monetary cost required for the execution of the jobs at a reasonable level. The proposed scheduling heuristic is compared to two other baseline policies, under the impact of various QoS requirements. The simulation experiments reveal that our approach outperforms the other examined policies, providing promising results. © 2019 Elsevier B.V.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","216-226","","","96","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Voltage scaling; Energy efficiency; Cloud computing; Real time systems; Green computing; Dynamic frequency scaling; Cost effectiveness; Job shop scheduling; Work-flows; Scheduling heuristics; Quality of Service; Approximate computation; Approximate computations; Cost effective scheduling strategy; Heterogeneous multi core processors; Per-core DVFS; QoS requirements; Real-time workflows; Workflow applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAWS3A5A","conferencePaper","2020","Valera, H.H.A.; Dalmau, M.; Roose, P.; Larracoechea, J.; Herzog, C.","DRACeo: A smart simulator to deploy energy saving methods in microservices based networks","","","","10.1109/WETICE49692.2020.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100714002&doi=10.1109%2fWETICE49692.2020.00026&partnerID=40&md5=6dde8162ca929d1cfeb833956e56d257","Nowadays, many researchers work to identify microservices-based application deployments and scheduling solutions to save energy without decreasing functional QoS. In this work, we present DRACeo: A simulator that allows facing this challenge in a simple and efficient way, enabling its users to focus uniquely on microservices deployment/scheduling algorithms and its hardware/software repercussions (load vs. energy consumption) without worrying about low-level network configurations or operating system issues. DRACeo is able to deploy and schedule (move, duplicate, start/stop) microservices and their dependencies on various devices with software and hardware heterogeneity (CPU, bandwidth, RAM, Battery, etc.), taking into account various scheduling heuristics algorithms: centralized vs non-centralized. To do this, DRACeo allows deploying custom network topologies based on client-server schemes or p2p distributions, where devices can (dis)appear, turn on/off obeying random circumstances or user strategies. Finally, the simulator performs relevant operations such as QoS definition, resource monitoring, calculation of energy saved and consumption tracking (at device and network level). We tested some ideas based on our previous work 'Kaligreen' to demonstrate the effectiveness of DRACeo. © 2020 IEEE.","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","94-99","","","2020-September","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Scheduling; microservices; Energy utilization; Energy conservation; CPU; Software and hardwares; Application deployment; energy; middleware; Network topology; consumption; hard disk; network; prototype; simulator; Energy saving methods; Hardware/software; Network configuration; Resource monitoring; Scheduling heuristics; Simulators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE","","","","","","","","","","","","","","",""
"FZPTUQZU","journalArticle","2018","Guizzardi, R.S.; Perini, A.","Goal-oriented decision modeling: A position paper","Istar@ Caise","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132719762&partnerID=40&md5=10fe90c15390f479b4fff311e9efce23","","2018","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BQFR3NZB","conferencePaper","2020","Thi, M.-T.; Pierson, J.-M.; Da Costa, G.","Game-based negotiation between power demand and supply in green datacenters","","","","10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108028950&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom51426.2020.00112&partnerID=40&md5=3b71c813352ce106a7569fb763e4acbc","The power consumption of datacenters is growing rapidly and becoming a major concern. For reducing carbon footprint and increasing energy efficiency, a promising solution is to locally supply datacenters with renewable energies. However, a challenging problem in building such green datacenter is the coordinating between the power demand and the intermittent power supply. To address this problem, we propose to model the green datacenter as two subsystems, namely, Information Technology (IT) subsystem which consumes energy, and electrical subsystem which supplies energy. Then we aim to find an efficient compromise between the power supply and power demand, taking into account the constraints of both subsystems. Based on buyer-supplier game, we introduce a negotiation approach, in which the two subsystems are modeled as the energy buyer and energy supplier. A negotiation algorithm is proposed, allowing the two subsystems to negotiate and reach an efficient trade-off, while respecting their own utility/monetary gain. The algorithm is evaluated in our middleware of renewable energies-powered datacenter. The experimental results show that the proposed algorithm allows the negotiation process to reach stable points. This algorithm also obtains significant improvement in the datacenter's utility and quality of service (QoS), compared to the algorithms in which joint IT-energy management is not considered. © 2020 IEEE.","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","690-697","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Electric power utilization; Energy efficiency; Big data; Cloud computing; Economic and social effects; Middleware; Game theory; Green computing; Power demands; Commerce; Social networking (online); Carbon footprint; Renewable energies; Power supply; Electric power systems; Electrical subsystems; Energy suppliers; Green Datacenter; Negotiation; Negotiation algorithm; Negotiation process; Stable points","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE International Symposium on Parallel and Distributed Processing with Applications, 2020 IEEE International Conference on Big Data and Cloud Computing, 2020 IEEE International Symposium on Social Computing and Networking and 2020 IEEE International Conference on Sustainable Computing and Communications, ISPA-BDCloud-SocialCom-SustainCom 2020","","","","","","","","","","","","","","",""
"RQ55J5LP","journalArticle","2019","Aldwyan, Y.; Sinnott, R.O.","Latency-aware failover strategies for containerized web applications in distributed clouds","Future Generation Computer Systems","","","10.1016/j.future.2019.07.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069934073&doi=10.1016%2fj.future.2019.07.032&partnerID=40&md5=df05d6c2a0efbc2d6468b98536b5eacf","Despite advances in Cloud computing, ensuring high availability (HA) remains a challenge due to varying loads and the potential for Cloud outages. Deploying applications in distributed Clouds can help overcome this challenge by geo-replicating applications across multiple Cloud data centers (DCs). However, this distributed deployment can be a performance bottleneck due to network latencies between users and DCs as well as inter-DC latencies incurred during the geo-replication process. For most web applications, both HA and Performance (HAP) are essential and need to meet pre-agreed Service Level Objectives (SLOs). Efficiently placing and managing primary and backup replicas of applications in distributed Clouds to achieve HAP is a challenging task. Existing solutions consider either HA or performance but not both. In this paper we propose an approach for automating the process of providing a latency-aware failover strategy through a server placement algorithm leveraging genetic algorithms that factor in the proximity of users and inter-DC latencies. To facilitate the distributed deployment of applications and avoid the overheads of Clouds, we utilize container technologies. To evaluate our proposed approach, we conduct experiments on the Australia-wide National eResearch Collaboration Tools and Resources (NeCTAR - www.nectar.org.au) Research Cloud. Our results show at least a 23.3% and 22.6% improvement in response times under normal and failover conditions respectively compared to traditional, latency-unaware approaches. Also, the 95th percentile of response times in our approach are at most1.5 ms above the SLO compared to 11–32 ms using other approaches. © 2019 Elsevier B.V.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","1081-1095","","","101","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Performance; High availability; WEB application; Genetic algorithms; Container technologies; Web applications; Cloud outages; Distributed clouds; Distributed Clouds; Distributed deployment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XRPF2ZAY","journalArticle","2018","Benoit, A.; Lefèvre, L.; Orgerie, A.-C.; Raïs, I.","Reducing the energy consumption of large-scale computing systems through combined shutdown policies with multiple constraints","International Journal of High Performance Computing Applications","","","10.1177/1094342017714530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039869052&doi=10.1177%2f1094342017714530&partnerID=40&md5=16390b43f86e710b523417082387d1fb","Large-scale distributed systems (high-performance computing centers, networks, data centers) are expected to consume huge amounts of energy. In order to address this issue, shutdown policies constitute an appealing approach able to dynamically adapt the resource set to the actual workload. However, multiple constraints have to be taken into account for such policies to be applied on real infrastructures: the time and energy cost of switching on and off, the power and energy consumption bounds caused by the electricity grid or the cooling system, and the availability of renewable energy. In this article, we propose models translating these various constraints into different shutdown policies that can be combined for a multiconstraint purpose. Our models and their combinations are validated through simulations on a real workload trace. © 2017, © The Author(s) 2017.","2018","2025-10-22 19:07:42","2025-10-22 19:07:42","","176-188","","1","32","","","","","","","","","","","","","Scopus","","","","","","","","Distributed computer systems; Energy utilization; Green computing; Energy model; simulation; High performance computing; Energy policy; Multiple constraint; Large-scale distributed system; energy models; Large-scale computing systems; Large-scale distributed systems; Power and energy consumption; shutdown policies; Shutdown policies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MW2AA43C","journalArticle","2011","Loos, P.; Nebel, W.; Gómez, J.M.; Hasan, H.; Watson, R.T.; Brocke, J.V.; Seidel, S.; Recker, J.","Green IT: A matter of business and information systems engineering?","Business and Information Systems Engineering","","","10.1007/s12599-011-0165-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856547763&doi=10.1007%2fs12599-011-0165-5&partnerID=40&md5=a05fcbd7691c30e7c1bfc3e67ed799de","","2011","2025-10-22 19:07:42","2025-10-22 19:07:42","","245-252","","4","3","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KUMYYBT","journalArticle","2017","Acton, M.","","2018 Best Practice Guidelines for the EU Code of Conduct on Data Centre Energy Efficiency. Technical Report. EUR 29103 EN","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132728098&partnerID=40&md5=8e92befe639c7eebba74f9cb3ccde267","","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","2018","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GG9KJAY6","journalArticle","2020","Gholipour, N.; Arianyan, E.; Buyya, R.","A novel energy-aware resource management technique using joint VM and container consolidation approach for green computing in cloud data centers","Simulation Modelling Practice and Theory","","","10.1016/j.simpat.2020.102127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086469770&doi=10.1016%2fj.simpat.2020.102127&partnerID=40&md5=f6c07590171b1d1c04d2407d84f70c54","Cloud computing is being rapidly adopted for managing IT services as a notable solution due to diverse beneficiaries such as automatically optimized resource management as well as modern service delivery models. The container as a service has been recently introduced by cloud providers as a new service apart from traditional cloud services. Containers enable applications to run and deploy on isolated virtual space, and the operating system kernel is shared among them. Also, containerization has some attributes such as scalability, highly portable properties, and lightweight, for those reasons, it is applied for running isolated applications. Reducing energy consumption, as well as their CO2 emissions, are great deals for cloud providers. In this direction, consolidation is recommended as a vital energy-aware approach in cloud data centers. Previously, independent virtual machine migration or container migration was proposed in the literature for green computing in cloud data centers. However, this paper proposes a new cloud resource management procedure based on a multi-criteria decision-making method that takes advantage of a joint virtual machine and container migration approach concurrently. The results of simulations using ContainerCloudsim simulator validates the applicability of the proposed approach which shows notable reductions in energy consumption, SLA violation, and number of migrations in comparison with the state-of-the-art algorithms. © 2020 Elsevier B.V.","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","104","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Containers; Datacenter; Cloud computing; Information management; Resource management; Energy utilization; Decision making; Green computing; Containerization; Energy consumption; Natural resources management; Resource allocation; Virtual machine; Network security; Reducing energy consumption; State-of-the-art algorithms; Consolidation; Computer aided software engineering; Virtual machine migrations; Resource management techniques; Energy aware approaches; Multi-criteria decision making methods; Operating system kernel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2A3CJSJK","journalArticle","2016","Wajid, U.; Cappiello, C.; Plebani, P.; Pernici, B.; Mehandjiev, N.; Vitali, M.; Gienger, M.; Kavoussanakis, K.; Margery, D.; Perez, D.G.; Sampaio, P.","On Achieving Energy Efficiency and Reducing CO2 Footprint in Cloud Computing","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2015.2453988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976563351&doi=10.1109%2fTCC.2015.2453988&partnerID=40&md5=8950a4ac081e6f203a8245bdc8c7372b","With the increasing popularity of the cloud computing model and rapid proliferation of cloud infrastructures there are increasing concerns about energy consumption and consequent impact of cloud computing as a contributor to global CO2 emissions. To date, little is known about how to incorporate energy consumption and CO2 concerns into cloud application development and deployment decision models. In this respect, this paper describes an eco-aware approach that relies on the definition, monitoring and utilization of energy and CO2 metrics combined with the use of innovative application scheduling and runtime adaptation techniques to optimize energy consumption and CO2 footprint of cloud applications as well as the underlying infrastructure. The eco-aware approach involves measuring or quantifying the energy consumption and CO2 at different levels of cloud computing, using that information to create scheduling and adaptation techniques that contribute towards reducing the energy consumption and CO2 emissions, and finally testing and validating the developed solutions in a multi-site cloud environment with the help of challenging case study applications. The experimental and validation results show the potential of the eco-aware approach to significantly reduce the CO2 footprint and consequent environmental impact of cloud applications. © 2013 IEEE.","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","138-151","","2","4","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Scheduling; Energy efficiency; Cloud computing; Cloud applications; Energy utilization; Cloud infrastructures; Carbon footprint; Environmental impact; Application scheduling; Carbon dioxide; Energy-aware systems; Evaluation; Adaptation techniques; Runtime adaptation; Scheduling and task partitioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TY2FPXHB","journalArticle","2020","Lucivero, F.","Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives","Science and Engineering Ethics","","","10.1007/s11948-019-00171-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077193813&doi=10.1007%2fs11948-019-00171-7&partnerID=40&md5=3c4562e342b30f8c1641e0966ddb6eb2","This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives’ environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production. © 2019, The Author(s).","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","1009-1030","","2","26","","","","","","","","","","","","","Scopus","","","","","","","","Big Data; Sustainability; Technology; Environmental impacts; Materiality; Responsibility; technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJLEWP5I","journalArticle","2019","","OMG: Decision model and notation version 1.3","OMG","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132781047&partnerID=40&md5=986acfbc393a1b6137cf90fd9dac5d8f","","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z75KKD2N","journalArticle","2011","Singh, H.","Data center maturity model. Techn. Ber","The Green Grid","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124062848&partnerID=40&md5=14bf3faf41290d038c42d365ae3b7975","","2011","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFYV9GPS","journalArticle","2021","Hu, X.; Li, P.; Sun, Y.","Minimizing Energy Cost for Green Data Center by Exploring Heterogeneous Energy Resource","Journal of Modern Power Systems and Clean Energy","","","10.35833/MPCE.2019.000052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100023467&doi=10.35833%2fMPCE.2019.000052&partnerID=40&md5=381fb359c26bf2289314afb380e5b16d","With the deteriorating effects resulting from global warming in many areas, geographically distributed data centers contribute greatly to carbon emissions, because the major energy supply is fossil fuels. Considering this issue, many geographically distributed data centers are attempting to use clean energy as their energy supply, such as fuel cells and renewable energy sources. However, not all workloads can be powered by a single power sources, since different workloads exhibit different characteristics. In this paper, we propose a fine-grained heterogeneous power distribution model with an objective of minimizing the total energy costs and the sum of the energy gap generated by the geographically distributed data centers powered by multiple types of energy resources. In order to achieve these two goals, we design a two-stage online algorithm to leverage the power supply of each energy source. In each time slot, we also consider a chance-constraint problem and use the Bernstein approximation to solve the problem. Finally, simulation results based on real-world traces illustrate that the proposed algorithm can achieve satisfactory performance.  © 2021 State Grid Electric Power Research Institute.","2021","2025-10-22 19:07:42","2025-10-22 19:07:42","","148-159","","1","9","","","","","","","","","","","","","Scopus","","","","","","","","Green computing; Data center; energy management; Green data centers; Minimizing energy; Carbon emissions; On-line algorithms; Renewable energy resources; Fossil fuels; Renewable energy source; Global warming; Bernstein approximation; Chance constraint; Distributed data; Fossil fuel power plants; Fuel cells; heterogeneous energy resources; power distribution algorithm; Power distribution modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FYGYCHX3","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132753568&partnerID=40&md5=65010e3a8816238a36c1ba1ffad3f862","","","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2KWBWMJ","journalArticle","2019","Lottick, K.; Susai, S.; Friedler, S.A.; Wilson, J.P.","Energy usage reports: Environmental awareness as part of algorithmic accountability","Energy usage reports: Environmental awareness as part of algorithmic accountability","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102644245&partnerID=40&md5=2893d7fe594fc83783af1041ab63593a","","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4E35685X","journalArticle","2011","","","Business Process Model and Notation (BPMN) Version 2.0","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956069069&partnerID=40&md5=91913c5f0d92775fa13cc2d3d2285d8a","","2011","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YEG6MMM5","conferencePaper","2013","Goiri, I.; Katsak, W.; Ley, K.; Nguyen, T.D.; Bianchini, R.","Parasol and greenswitch: Managing datacenters powered by renewable energy","","","","10.1145/2499368.2451123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880122979&doi=10.1145%2f2499368.2451123&partnerID=40&md5=5963c44ef24b0b8265b88d4b48e45b87","Several companies have recently announced plans to build ""green"" datacenters, i.e. datacenters partially or completely powered by renewable energy. These datacenters will either generate their own renewable energy or draw it directly from an existing nearby plant. Besides reducing carbon footprints, renewable energy can potentially reduce energy costs, reduce peak power costs, or both. However, certain renewable fuels are intermittent, which requires approaches for tackling the energy supply variability. One approach is to use batteries and/or the electrical grid as a backup for the renewable energy. It may also be possible to adapt the workload to match the renewable energy supply. For highest benefits, green datacenter operators must intelligently manage their workloads and the sources of energy at their disposal. In this paper, we first discuss the tradeoffs involved in building green datacenters today and in the future. Second, we present Parasol, a prototype green datacenter that we have built as a research platform. Parasol comprises a small container, a set of solar panels, a battery bank, and a grid-tie. Third, we describe GreenSwitch, our model-based approach for dynamically scheduling the workload and selecting the source of energy to use. Our real experiments with Parasol, GreenSwitch, and MapReduce workloads demonstrate that intelligent workload and energy source management can produce significant cost reductions. Our results also isolate the cost implications of peak power management, storing energy on the grid, and the ability to delay the MapReduce jobs. Finally, our results demonstrate that careful workload and energy source management can minimize the negative impact of electrical grid outages.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","51-63","","","48","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Data centers; Datacenters; Carbon footprint; Model based approach; Renewable energies; Research platforms; Cost reduction; Batteries; Renewable energy resources; Renewable energy; Electrical grids; Outages; Small containers; Solar cells; Source of energy; Sources of energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM SIGPLAN Notices","","","","","","","","","","","","","","",""
"JW3CFG88","journalArticle","2013","Vom Brocke, J.; Watson, R.T.; Dwyer, C.; Elliot, S.; Melville, N.","Green information systems: Directives for the IS discipline","Communications of the Association for Information Systems","","","10.17705/1cais.03330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892159927&doi=10.17705%2f1cais.03330&partnerID=40&md5=2005e85fdadc1fda6f90a563e1549d00","Green IS offers the promise for IS scholars to make a significant contribution to reducing greenhouse gas emissions and mitigating the effects of global climate change and other environmental problems. While significant achievements have been made in shaping Green IS as a subfield in the IS discipline, the emergence of Green IS is still by far too slow, given the magnitude of the problem. Against this background a panel was organized at ICIS 2012 in order to discuss future directives for the IS discipline. This article, co-authored by the panelists, reports on the major issues raised by this panel. First, the article gives an account of major achievements in the field of Green IS. Second, it presents five specific directives which we agree are important for the future of our discipline. © 2013 by the Association for Information Systems.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","509-520","","1","33","","","","","","","","","","","","","Scopus","","","","","","","","Climate change; Gas emissions; Greenhouse gases; Sustainable development; Sustainability; Business transformation; Business transformations; Energy informatics; Environmental problems; Global climate changes; Green information systems; Green is; Green IS; Is disciplines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZX2B3S8R","journalArticle","2012","Pedram, M.","Energy-efficient datacenters","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","","10.1109/TCAD.2012.2212898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866609789&doi=10.1109%2fTCAD.2012.2212898&partnerID=40&md5=da8813937e1c7f70fcfef51e520f0804","Pervasive use of cloud computing and the resulting rise in the number of datacenters and hosting centers (that provide platform or software services to clients who do not have the means to set up and operate their own computing facilities) have brought forth many concerns, including the electrical energy cost, peak power dissipation, cooling, and carbon emission. With power consumption becoming an increasingly important issue for the operation and maintenance of the hosting centers, corporate and business owners are becoming increasingly concerned. Furthermore, provisioning resources in a cost-optimal manner so as to meet different performance criteria, such as throughput or response time, has become a critical challenge. The goal of this paper is to provide an introduction to resource provisioning and power or thermal management problems in datacenters, and to review strategies that maximize the datacenter energy efficiency subject to peak or total power consumption and thermal constraints, while meeting stipulated service level agreements in terms of task throughput and/or response time. © 2012 IEEE.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","1465-1484","","10","31","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Datacenter; resource management; Resource management; green computing; Temperature control; Dynamic Power; dynamic power and thermal management; energy efficient design; Energy-efficient design; enterprise computing; Enterprise computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHAWDK77","journalArticle","2020","Valderas, P.; Torres, V.; Pelechano, V.","A microservice composition approach based on the choreography of BPMN fragments","Information and Software Technology","","","10.1016/j.infsof.2020.106370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086996899&doi=10.1016%2fj.infsof.2020.106370&partnerID=40&md5=262618c8ab816ad2e63461161ea2c11c","Context: Microservices must be composed to provide users with complex and elaborated functionalities. It seems that the decentralized nature of microservices makes a choreography style more appropriate to achieve such cooperation, where lighter solutions based on asynchronous events are generally used. However, a microservice composition based on choreography distributes the flow logic of the composition among microservices making further analysis and updating difficult, i.e. there is not a big picture of the composition that facilitates these tasks. Business Process Model and Notation (BPMN) is the OMG standard developed to represent Business Processes (BPs), being widely used to define the big picture of such compositions. However, BPMN is usually considered in orchestration-based solutions, and orchestration can be a drawback to achieve the decoupling pursued by a microservice architecture. Objective: Defining a microservice composition approach that allows us to create a composition in a BPMN model, which facilitates further analysis for taking engineering decisions, and execute them through an event-based choreography to have a high degree of decoupling and independence among microservices. Method: We followed a research methodology for information systems that consists of a 5-step process: awareness of the problem, suggestion, development, evaluation, and conclusion. Results: We presented a microservice composition approach based on the choreography of BPMN fragments. On the one hand, we propose to describe the big picture of the composition with a BPMN model, providing a valuable mechanism to analyse it when engineering decisions need to be taken. On the other hand, this model is split into fragments in order to be executed through an event-based choreography form, providing the high degree of decoupling among microservices demanded in this type of architecture. This composition approach is supported by a microservice architecture defined to achieve that both descriptions of a composition (big picture and split one) coexist. A realization of this architecture in Java/Spring technology is also presented. Conclusions: The evaluation that is done to our work allows us to conclude that the proposed approach for composing microservices is more efficient than solutions based on ad-hoc development. © 2020","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","127","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Architecture; Business Process; AND splits; Asynchronous event; BPMN; Business process model and notation (BPMN); Choreography; Composition; Engineering decisions; Event-based; Flow logic; Image analysis; Research methodologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XEPYPP2K","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132727055&partnerID=40&md5=dca938c54289a58318ac660a9f5664ad","","","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"25U6DGEH","conferencePaper","2011","Cappiello, C.; Fugini, M.; Ferreira, A.M.; Plebani, P.; Vitali, M.","Business process co-design for energy-aware adaptation","","","","10.1109/ICCP.2011.6047917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80755125694&doi=10.1109%2fICCP.2011.6047917&partnerID=40&md5=f8c79e0bf9ccbdb071ad01f6414bd3a1","Green IT mainly focuses on techniques to extend the products longevity or to virtualise physical resources as well as the provision of energy efficient hardware infrastructures. Less attention has been paid on the applications that run on the machines and their impact on energy consumption. This paper proposes an approach for enabling an efficient use of energy driven by the design of energy-aware business processes. Energy-awareness is given by an enrichment of a typical Business Process conceptual model with annotations able to support the assessment of the energy consumption of the involved business tasks. This information is the basis for the energy-aware adaptation to enact specific strategies to adapt process execution in case energy consumption needs to be lowered or energy leakages have been identified. © 2011 IEEE.","2011","2025-10-22 19:07:42","2025-10-22 19:07:42","","463-470","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Energy efficiency; Resource management; Energy efficient; Energy utilization; Energy aware; Service Oriented; Wireless sensor networks; Information services; Green IT; Service oriented architecture (SOA); Physical resources; Business Process; Co-designs; Context-Aware; Energy-awareness; Adaptive and context-aware processes; Conceptual model; Efficient use of energy; Energy leakage; Green IT and energy-aware applications; Process execution; Resource management in business process execution; Service-oriented architectures for BPM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing, ICCP 2011","","","","","","","","","","","","","","",""
"T7SBE4GX","journalArticle","2019","Horkoff, J.; Aydemir, F.B.; Cardoso, E.; Li, T.; Maté, A.; Paja, E.; Salnitri, M.; Piras, L.; Mylopoulos, J.; Giorgini, P.","Goal-oriented requirements engineering: an extended systematic mapping study","Requirements Engineering","","","10.1007/s00766-017-0280-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029538454&doi=10.1007%2fs00766-017-0280-z&partnerID=40&md5=1d72593d98289d844a0cb85d2815b55b","Over the last two decades, much attention has been paid to the area of goal-oriented requirements engineering (GORE), where goals are used as a useful conceptualization to elicit, model, and analyze requirements, capturing alternatives and conflicts. Goal modeling has been adapted and applied to many sub-topics within requirements engineering (RE) and beyond, such as agent orientation, aspect orientation, business intelligence, model-driven development, and security. Despite extensive efforts in this field, the RE community lacks a recent, general systematic literature review of the area. In this work, we present a systematic mapping study, covering the 246 top-cited GORE-related conference and journal papers, according to Scopus. Our literature map addresses several research questions: we classify the types of papers (e.g., proposals, formalizations, meta-studies), look at the presence of evaluation, the topics covered (e.g., security, agents, scenarios), frameworks used, venues, citations, author networks, and overall publication numbers. For most questions, we evaluate trends over time. Our findings show a proliferation of papers with new ideas and few citations, with a small number of authors and papers dominating citations; however, there is a slight rise in papers which build upon past work (implementations, integrations, and extensions). We see a rise in papers concerning adaptation/variability/evolution and a slight rise in case studies. Overall, interest in GORE has increased. We use our analysis results to make recommendations concerning future GORE research and make our data publicly available. © 2017, The Author(s).","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","133-160","","2","24","","","","","","","","","","","","","Scopus","","","","","","","","Mapping; Systematic mapping studies; Systematic mapping study; Systematic literature review; Paper; Requirements engineering; Object oriented programming; Aspect orientation; Goal model; Goal modeling; Goal-oriented requirements engineering; GORE; Model driven development; Research questions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUD52KST","journalArticle","2017","Garrett-Peltier, H.","Green versus brown: Comparing the employment impacts of energy efficiency, renewable energy, and fossil fuels using an input-output model","Economic Modelling","","","10.1016/j.econmod.2016.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007467164&doi=10.1016%2fj.econmod.2016.11.012&partnerID=40&md5=f04db1592f0a96b8c6becba5923b071f","Global carbon emissions have reached unsustainable levels, and transforming the energy sector by increasing efficiency and use of renewables is one of the primary strategies to reduce emissions. Policy makers need to understand both the environmental and economic impacts of fiscal and regulatory policies regarding the energy sector. Transitioning to lower-carbon energy will entail a contraction of the fossil fuel sector, along with a loss of jobs. An important question is whether clean energy will create more jobs than will be lost in fossil fuels. This article presents a method of using Input-Output (I-O) tables to create “synthetic” industries – namely clean energy industries that do not currently exist in I-O tables. This approach allows researchers to evaluate public and private spending in clean energy and compare it to the effects of spending on fossil fuels. Here we focus on employment impacts in the short-to-medium term, and leave aside the long-term comparison of operations and maintenance employment. We find that on average, 2.65 full-time-equivalent (FTE) jobs are created from $1 million spending in fossil fuels, while that same amount of spending would create 7.49 or 7.72 FTE jobs in renewables or energy efficiency. Thus each $1 million shifted from brown to green energy will create a net increase of 5 jobs. © 2016 Elsevier Ltd","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","439-447","","","61","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Renewable energy; Employment multipliers; Fiscal policy; Fossil Fuels; Input-output","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLG7HJ9W","journalArticle","2018","Hasić, F.; De Smedt, J.; Vanthienen, J.","Augmenting processes with decision intelligence: Principles for integrated modelling","Decision Support Systems","","","10.1016/j.dss.2017.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039774541&doi=10.1016%2fj.dss.2017.12.008&partnerID=40&md5=a53e3647e0f9625efad6fc58eade7a54","Until recently decisions were mostly modelled within the process. Such an approach was shown to impair the maintainability, scalability, and flexibility of both processes and decisions. Lately, literature is moving towards a separation of concerns between the process and decision model. Most notably, the introduction of the Decision Model and Notation (DMN) standard provides a suitable solution for filling the void of decision representation. This raises the question whether decisions and processes can easily be separated and consistently integrated. We introduce an integrated way of modelling the process, while providing a decision model which encompasses the process in its entirety, rather than focusing on local decision points only. Specifically, this paper contributes formal definitions for decision models and for the integration of processes and decisions. Additionally, inconsistencies between process and decision models are identified and we remedy those inconsistencies by establishing Five Principles for integrated Process and Decision Modelling (5PDM). The principles are subsequently illustrated and validated on a case of a Belgian accounting company. © 2017 Elsevier B.V.","2018","2025-10-22 19:07:42","2025-10-22 19:07:42","","1-12","","","107","","","","","","","","","","","","","Scopus","","","","","","","","Information systems; BPMN; Decision modelling; Decision support systems; DMN; Integrated modelling; Process modelling; Separation of concerns","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8VEDLU6","journalArticle","2017","Kratzke, N.; Quint, P.-C.","Understanding cloud-native applications after 10 years of cloud computing - A systematic mapping study","Journal of Systems and Software","","","10.1016/j.jss.2017.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009186306&doi=10.1016%2fj.jss.2017.01.001&partnerID=40&md5=00833465689b49e90c3ae3861f0862ab","It is common sense that cloud-native applications (CNA) are intentionally designed for the cloud. Although this understanding can be broadly used it does not guide and explain what a cloud-native application exactly is. The term “cloud-native” was used quite frequently in birthday times of cloud computing (2006) which seems somehow obvious nowadays. But the term disappeared almost completely. Suddenly and in the last years the term is used again more and more frequently and shows increasing momentum. This paper summarizes the outcomes of a systematic mapping study analyzing research papers covering “cloud-native” topics, research questions and engineering methodologies. We summarize research focuses and trends dealing with cloud-native application engineering approaches. Furthermore, we provide a definition for the term “cloud-native application” which takes all findings, insights of analyzed publications and already existing and well-defined terminology into account. © 2017 Elsevier Inc.","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","1-16","","","126","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Cloud computing; Mapping; Systematic mapping studies; Systematic mapping study; Cloud-native application; CNA; Elastic platform; Pattern; Self service; Softwareization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V78CTAJ5","journalArticle","2014","Vitali, M.; Pernici, B.","A survey on energy efficiency in information systems","International Journal of Cooperative Information Systems","","","10.1142/S0218843014500014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906266660&doi=10.1142%2fS0218843014500014&partnerID=40&md5=7c3bad7cd71ee7d53e7f9b1e8ba4cc2d","Concerns about energy and sustainability are growing everyday involving a wide range of fields. Even Information Systems (ISs) are being influenced by the issue of reducing pollution and energy consumption and new fields are rising dealing with this topic. One of these fields is Green Information Technology (IT), which deals with energy efficiency with a focus on IT. Researchers have faced this problem according to several points of view. The purpose of this paper is to understand the trends and the future development of Green IT by analyzing the state-of-the-art and classifying existing approaches to understand which are the components that have an impact on energy efficiency in ISs and how this impact can be reduced. At first, we explore some guidelines that can help to understand the efficiency level of an organization and of an IS. Then, we discuss measurement and estimation of energy efficiency and identify which are the components that mainly contribute to energy waste and how it is possible to improve energy efficiency, both at the hardware and at the software level. © 2014 World Scientific Publishing Company.","2014","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","3","23","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Green IT; Green IS; adaptivity; assessment; Information Systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5J9UVMD","conferencePaper","2020","Béziers La Fosse, T.; Tisi, M.; Mottu, J.-M.; Sunyé, G.","Annotating executable DSLs with energy estimation formulas","","","","10.1145/3426425.3426930","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097711159&doi=10.1145%2f3426425.3426930&partnerID=40&md5=81c27a72ed30adb5ec3fce4903105aa9","Reducing the energy consumption of a complex, especially cyber-physical, system is a cross-cutting concern through the system layers, and typically requires long feedback loops between experts in several engineering disciplines. Having an immediate automatic estimation of the global system consumption at design-time would significantly accelerate this process, but cross-layer tools are missing in several domains. Executable domain-specific modeling languages (xDSLs) can be used to design several layers of the system under development in an integrated view. By including the behavioral specification for software and physical components of the system, they are an effective source artifact for cross-layer energy estimation. In this paper we propose EEL, a language for annotating xDSL primitives with energy-related properties, i.e. how their execution would contribute to the energy consumption on a specific runtime platform. Given an xDSL, energy specialists create EEL models of that xDSL for each considered runtime platform. The models are used at design time, to predict the energy consumption of the real systems. This avoids the need of energetic analysis by deployment and measurement on all runtime platforms, that is slow and expensive. We augment an existing language workbench for xDSLs with an editor for EEL models and a component that computes energy-consumption estimations during model editing. The evaluation shows that EEL can be used to represent estimation models from literature, and provide useful predictions.  © 2020 ACM.","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","22-38","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Real time systems; Modeling languages; cyber-physical systems; DSL; Automatic estimation; Behavioral specification; Computer programming languages; Cross-cutting concerns; Digital subscriber lines; Domain specific modeling languages; energy estimation; Energy specialists; Engineering disciplines; Language workbenches; Physical components; Specification languages; xDSL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SLE 2020 - Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering, Co-located with SPLASH 2020","","","","","","","","","","","","","","",""
"UHE2CWVB","journalArticle","2021","Ajibola, O.O.; El-Gorashi, T.; Elmirghani, J.","Energy efficient placement of workloads in composable data center networks","Journal of Lightwave Technology","","","10.1109/JLT.2021.3063325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102297167&doi=10.1109%2fJLT.2021.3063325&partnerID=40&md5=450f3edf04ce174688cd5b761aa2e04c","This paper studies the energy efficiency of composable data center (DC) infrastructures over network topologies. Using a mixed integer linear programming (MILP) model, we compare the performance of disaggregation at rack-scale and pod-scale over selected electrical, optical and hybrid network topologies relative to a traditional DC. Relative to a pod-scale DC, the results show that physical disaggregation at rack-scale is sufficient for optimal efficiency when the optical network topology is adopted, and resource components are allocated in a suitable manner. The optical network topology also enables optimal energy efficiency in composable DCs. The paper also studies logical disaggregation of traditional DC servers over an optical network topology. Relative to physical disaggregation at rack-scale, logical disaggregation of server resources within each rack enables marginal fall in the total DC power consumption (TDPC) due to improved resource demands placement. Hence, an adaptable composable infrastructure that can support both in memory (access) latency sensitive and insensitive workloads is enabled. We also conduct a study of the adoption of micro-service architecture in both traditional and composable DCs. Our results show that increasing the modularity of workloads improves the energy efficiency in traditional DCs, but disproportionate utilization of DC resources persists. A combination of disaggregation and micro-services achieved up to 23% reduction in the TDPC of the traditional DC by enabling optimal resources utilization and energy efficiencies. Finally, we propose a heuristic for energy efficient placement of workloads in composable DCs which replicates the trends produced by the MILP model formulated in this paper.  © 1983-2012 IEEE.","2021","2025-10-22 19:07:42","2025-10-22 19:07:42","","3037-3063","","10","39","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy efficient; Green computing; Integer programming; Data center networks; Resource demands; Resources utilizations; Topology; Composable infrastructures; Network topology; DC power consumption; Energy efficient data centers; Fiber optic networks; Micro-services; Milp; Mixed integer linear programming model; Optical networks; Optimal efficiency; Rack-scale data center; Software defined infrastructures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YD2QUVJS","journalArticle","2012","Nowak, A.; Binz, T.; Fehling, C.; Kopp, O.; Leymann, F.; Wagner, S.","Pattern-driven green adaptation of process-based applications and their runtime infrastructure","Computing","","","10.1007/s00607-012-0188-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864571412&doi=10.1007%2fs00607-012-0188-x&partnerID=40&md5=8636a305081456245beee386c74a5f77","Business processes are a key aspect of modern organization. In recent years, business process management and optimization has been applied to different cross-cutting concerns such as security, compliance, or Green IT, for example. Based on the ecological characteristics of a business process, proper environmentally sustainable adaptation strategies can be chosen to improve the total environmental impact of the business process. We use ecological sustainable adaptation strategies that are described as green business process patterns. The application of such a green business process pattern, however, affects the business process layer, the application component and the infrastructure layer. This implies that changes in the application infrastructure also need to be considered. Hence, we use best practices of cloud application architectures which are described as Cloud patterns. To guide developers through the adaptation process we propose a pattern-based approach in this work. We correlate Cloud patterns relevant for sustainable business processes to green business process patterns and organize them within a classification. To provide concrete implementation supportwe further annotate these Cloud patterns to application component models that are described with the topology and orchestration specification for cloud applications (TOSCA). Using these annotations, we describe a method that provides the means to optimize business processes based on green business process patterns through adapting the implementation of application components with concrete TOSCA implementation models. © Springer-Verlag 2012.","2012","2025-10-22 19:07:42","2025-10-22 19:07:42","","463-487","","6","94","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Information technology; Cloud pattern; Green IT; Sustainable development; Business Process; Adaptation of applications; Ecological sustainable business processes; Ecology; Enterprise resource management; Green business process pattern; Sustainable business; TOSCA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4R87GRQK","journalArticle","2020","Brondolin, R.; Santambrogio, M.D.","A Black-box Monitoring Approach to Measure Microservices Runtime Performance","ACM Transactions on Architecture and Code Optimization","","","10.1145/3418899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097221697&doi=10.1145%2f3418899&partnerID=40&md5=a35a5b1cfd13bccdec489a30d18ccd45","Microservices changed cloud computing by moving the applications' complexity from one monolithic executable to thousands of network interactions between small components. Given the increasing deployment sizes, the architectural exploitation challenges, and the impact on data-centers' power consumption, we need to efficiently track this complexity. Within this article, we propose a black-box monitoring approach to track microservices at scale, focusing on architectural metrics, power consumption, application performance, and network performance. The proposed approach is transparent w.r.t. the monitored applications, generates less overhead w.r.t. black-box approaches available in the state-of-the-art, and provides fine-grain accurate metrics. © 2020 ACM.","2020","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","4","17","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Microservices; cloud computing; Run-time performance; State of the art; Green computing; Data centers; Application performance; Complex networks; kubernetes; docker; network performance monitoring; performance monitoring; power attribution; Black box approach; Monitoring approach; Network interaction; Small components","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTCBPLJ2","journalArticle","2019","Pierson, J.-M.; Baudic, G.; Caux, S.; Celik, B.; Da Costa, G.; Grange, L.; Haddad, M.; Lecuivre, J.; Nicod, J.-M.; Philippe, L.; Rehn-Sonigo, V.; Roche, R.; Rostirolla, G.; Sayah, A.; Stolf, P.; Thi, M.-T.; Varnier, C.","Datazero: Datacenter with zero emission and robust management using renewable energy","IEEE Access","","","10.1109/ACCESS.2019.2930368","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076226061&doi=10.1109%2fACCESS.2019.2930368&partnerID=40&md5=7b284126f13bafd903b5e1137bd6f5dc","As the need for cloud services has been growing steadily, the size and energy consumption of datacenters have increased significantly over the past years. Due to economic and environmental constraints, energy efficiency in datacenters and greenhouse emissions have become a major concern. Renewable energy is widely seen as a promising solution to supply datacenters using local energy, without greenhouse gas emissions. However, the intermittent power generation resulting from the use of renewable energy imposes a paradigm change in the way energy and computation activities are managed. On the one hand, service placement and scheduling may be used on the IT (information technologies) side to adapt to the available power. On the other hand, the storage units may be used to lessen power generation variations. Existing literature and actual deployment mainly design optimization algorithms including the entire system (from cloud service to electrical management, the latter often being neglected or simplified). Conversely to these approaches, we propose a solution where each side optimizes its own objectives, both interacting through a negotiation loop process to reach a common agreement. In this paper, we present DATAZERO, a project developing this idea to ensure high availability of IT services, avoiding unnecessary redundancies, under the constraints due to the intermittent nature of electrical and cloud services flows. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","103209-103230","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Energy utilization; Middleware; Green computing; Web services; High availability; Gas emissions; Greenhouse gases; Renewable energies; Greenhouse emissions; Service placements; Use of renewable energies; Negotiation; Cloud datacenters; Common agreement; Design optimization; Environmental constraints; Power models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64EISSSC","journalArticle","2017","Gannon, D.; Barga, R.; Sundaresan, N.","Cloud-Native Applications","IEEE Cloud Computing","","","10.1109/MCC.2017.4250939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038610210&doi=10.1109%2fMCC.2017.4250939&partnerID=40&md5=198ead132dc790dd17c30a4142e93127","The term 'cloud-native' refers to a set of technologies and design patterns that have become the standard for building large-scale cloud applications. In this editorial we describe basic properties of successful cloud applications including dynamic scalability, extreme fault tolerance, seamless upgradeability and maintenance and security. To make it possible to build applications that meet these requirements we describe the microservice architecture and serverless computing foundation that are central to cloud-native design. © 2017 IEEE.","2017","2025-10-22 19:07:42","2025-10-22 19:07:42","","16-21","","5","4","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; microservices; Cloud applications; Distributed computer systems; serverless; Fault tolerance; Design Patterns; cloud-native; distributed computing; Upgradeability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UEBWIXSA","journalArticle","2019","Neumann, J.; Franke, S.; Rockstroh, M.; Kasparick, M.; Neumuth, T.","Extending BPMN 2.0 for intraoperative workflow modeling with IEEE 11073 SDC for description and orchestration of interoperable, networked medical devices","International Journal of Computer Assisted Radiology and Surgery","","","10.1007/s11548-019-01982-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065302899&doi=10.1007%2fs11548-019-01982-6&partnerID=40&md5=6db0fcc7709cbdbce8caa9f0e3925390","Purpose: Surgical workflow management in integrated operating rooms (ORs) enables the implementation of novel computer-aided surgical assistance and new applications in process automation, situation awareness, and decision support. The context-sensitive configuration and orchestration of interoperable, networked medical devices is a prerequisite for an effective reduction in the surgeons’ workload, by providing the right service and right information at the right time. The information about the surgical situation must be described as surgical process models and distributed to the medical devices and IT systems in the OR. Available modeling languages are not capable of describing surgical processes for this application. Methods: In this work, the BPMNSIX modeling language for intraoperative processes is technically enhanced and implemented for workflow build-time and run-time. Therefore, particular attention is given to the integration of the recently published IEEE 11073 SDC standard family for a service-oriented architecture of networked medical devices. In addition, interaction patterns for context-aware configuration and device orchestration were presented. Results: The identified interaction patterns were implemented in BPMNSIX for an ophthalmologic use case. Therefore, the examples of the process-driven incorporation and control of device services could be demonstrated. Conclusion: The modeling of surgical procedures with BPMNSIX allows the implementation of context-sensitive surgical assistance functionalities and enables flexibility in terms of the orchestration of dynamically changing device ensembles and integration of unknown devices in the surgical workflow management. © 2019, CARS.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","1403-1413","","8","14","","","","","","","","","","","","","Scopus","","","","","","","","Automation; Algorithms; automation; algorithm; Software; software; human; Article; priority journal; workflow; Workflow; Humans; commercial phenomena; anatomic model; Business Process Model and Notation; cataract extraction; clinical decision support system; computer language; computer simulation; Computer Simulation; computer system; Computer Systems; Decision Support Systems, Clinical; devices; IEEE 11073 SDC; Integrated OR; intraoperative period; medical decision making; Medical device interoperability; medical informatics; Medical Informatics; Models, Anatomic; operating room; Operating Rooms; ophthalmology; Ophthalmology; procedures; process model; Process modeling; Programming Languages; Surgical workflow","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9F8ZDIUP","journalArticle","2015","Vitali, M.; Pernici, B.; O'Reilly, U.-M.","Learning a goal-oriented model for energy efficient adaptive applications in data centers","Information Sciences","","","10.1016/j.ins.2015.01.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930842086&doi=10.1016%2fj.ins.2015.01.023&partnerID=40&md5=eb7c0876a252bd23f2c30a9d88e9054e","This work has been motivated by the growing demand of energy coming from the IT sector. We propose a goal-oriented approach where the state of the system is assessed using a set of indicators. These indicators are evaluated against thresholds that are used as goals of our system. We propose a self-adaptive context-aware framework, where we learn both the relations existing between the indicators and the effect of the available actions over the indicators state. The system is also able to respond to changes in the environment, keeping these relations updated to the current situation. Results have shown that the proposed methodology is able to create a network of relations between indicators and to propose an effective set of repair actions to contrast suboptimal states of the data center. The proposed framework is an important tool for assisting the system administrator in the management of a data center oriented towards Energy Efficiency (EE), showing him the connections occurring between the sometimes contrasting goals of the system and suggesting the most likely successful repair action(s) to improve the system state, both in terms of EE and QoS. © 2015 Elsevier Inc. All rights reserved.","2015","2025-10-22 19:07:42","2025-10-22 19:07:42","","152-170","","","319","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Information management; Energy efficient; Current situation; Green computing; Data center; Data centers; System administrators; Adaptive application; Goal oriented modeling; Goal-oriented; Goal-oriented adaptation; Goal-oriented approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQSTKENI","conferencePaper","2018","Brondolin, R.; Sardelli, T.; Santambrogio, M.D.","DEEP-mon: Dynamic and energy efficient power monitoring for container-based infrastructures","","","","10.1109/IPDPSW.2018.00110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052236003&doi=10.1109%2fIPDPSW.2018.00110&partnerID=40&md5=b3fc988b43b9d7d4cf6b652e09435256","In the last few years energy efficiency of large scale infrastructures gained a lot of attention, as power consumption became one of the most impacting factors of the operative costs of a data-center and of its Total Cost of Ownership (TCO). Power consumption can be observed at different layers of the data-center, from the overall power grid, moving to each rack and arriving to each machine and system. Given the rise of application containers both in the cloud computing and High Performance Computing (HPC) scenarios, it becomes more and more important to measure power consumption also at the application level, where power-aware schedulers and orchestrators can optimize the execution of the workloads not only from a performance perspective, but also considering performance/power trade-offs. In this paper we propose DEEP-mon, a novel monitoring tool able to measure power consumption and attribute it for each thread and application container running in the system. Moreover, we show how the proposed approach has a negligible impact on the monitored system and on the running workloads, overcoming the limitations of the previous works in the field. © 2018 IEEE.","2018","2025-10-22 19:07:42","2025-10-22 19:07:42","","676-684","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Monitoring; Electric power utilization; Power awareness; Containers; Energy efficiency; Distributed computer systems; Economic and social effects; Green computing; Total cost of ownership; Application containers; Application level; Electric power transmission networks; High performance computing (HPC); Impacting factor; Large scale infrastructures; Monitored systems; Power attribution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2018 IEEE 32nd International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2018","","","","","","","","","","","","","","",""
"QN6HS6KT","conferencePaper","2019","Schneider, J.; Basalla, M.; Seidel, S.","Principles of green data mining","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084268601&partnerID=40&md5=71404958600ace3dbea27590a8995f59","This paper develops a set of principles for green data mining, related to the key stages of business understanding, data understanding, data preparation, modeling, evaluation, and deployment. The principles are grounded in a review of the Cross Industry Standard Process for Data mining (CRISP-DM) model and relevant literature on data mining methods and Green IT. We describe how data scientists can contribute to designing environmentally friendly data mining processes, for instance, by using green energy, choosing between make-or-buy, exploiting approaches to data reduction based on business understanding or pure statistics, or choosing energy friendly models. © 2019 IEEE Computer Society. All rights reserved.","2019","2025-10-22 19:07:42","2025-10-22 19:07:42","","2065-2074","","","2019-January","","","","","","","","","","","","","Scopus","","","","","","","","Data mining; Green energy; Business understanding; Cross industry; Data mining methods; Data mining process; Data preparation; Data understanding; Green manufacturing; Make-or-buy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual Hawaii International Conference on System Sciences","","","","","","","","","","","","","","",""
"V4XG3G3B","journalArticle","2013","Yuventi, J.; Mehdizadeh, R.","A critical analysis of Power Usage Effectiveness and its use in communicating data center energy consumption","Energy and Buildings","","","10.1016/j.enbuild.2013.04.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878469495&doi=10.1016%2fj.enbuild.2013.04.015&partnerID=40&md5=35a45daec83f8b0f88268d82057748e9","Data centers represent an increasingly popular construction project type, supported by the continued growth in internet-based services. These facilities can, however, consume large amounts of electricity and - especially if growth trends continue - put strain on utility grids and energy resources. Many metrics have been proposed to evaluate and communicate energy use in data centers. In many cases, the goal is that these metrics will be used to develop energy conscious behavior and perhaps data center energy rating systems or building codes to reduce average energy use. In this paper, we examine one of the more popular metrics, Power Usage Effectiveness (PUE), and discuss its shortcomings toward effectively communicating energy consumption. Our inference is that PUE is an instantaneous representation of electrical energy consumption that encourages operators to report the minimum observed values of PUE. Hence, PUE only conveys an understanding of the minimum possible energy use. Instead, we propose the use of energy-based metrics or average PUE over a significant time period - e.g., a year - to better understand the energy efficiency of a data center and to develop energy rating/ranking systems and energy codes. © 2013 Elsevier B.V. All rights reserved.","2013","2025-10-22 19:07:42","2025-10-22 19:07:42","","90-94","","","64","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Data centers; Power usage; Energy resources; Building codes; Building rating systems; Building ratings; Construction projects; Electrical energy consumption; Energy efficiency metrics; Internet-based services; Power Usage Effectiveness; Power Usage Effectiveness (PUE)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38BIKEIP","journalArticle","2015","","","IBM ACME Air","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058264827&partnerID=40&md5=580dacad3f53e22722037e4aaf2f6241","","2015","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDY6J2H7","journalArticle","2016","","","CloudScale Consortium CloudStore","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058341351&partnerID=40&md5=9619448846ce21d13b7ef88287fbea43","","2016","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6WDTZWYU","journalArticle","2008","","","RUBiS Users Manual","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058324416&partnerID=40&md5=13ee76ddb2fef024539b9157faf9afec","","2008","2025-10-22 19:07:42","2025-10-22 19:07:42","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMVLKQF6","journalArticle","1995","Littlewood, B.; Strigini, L.","Validation of ultra-high dependability for software-based systems","Predictably Dependable Computing Systems","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0742267398&partnerID=40&md5=6485180a392bb9ed968304ee5f0b2fe1","","1995","2025-10-22 19:07:42","2025-10-22 19:07:42","","473-493","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WTQSHXHC","journalArticle","2008","Rausch, A.; Reussner, R.; Mirandola, R.; Plášil, F.","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): Preface","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-54249093386&partnerID=40&md5=a9001efba7a80b038512e38ec015b524","","2008","2025-10-22 19:07:43","2025-10-22 19:07:43","","V","","","5153 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4X6T97Q","conferencePaper","2012","Van Hoorn, A.; Waller, J.; Hasselbring, W.","Kieker: A framework for application performance monitoring and dynamic software analysis","","","","10.1145/2188286.2188326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861019240&doi=10.1145%2f2188286.2188326&partnerID=40&md5=2c4581b4ee83dc7f5038d08a011b3f61","Kieker is an extensible framework for monitoring and analyzing the runtime behavior of concurrent or distributed software systems. It provides measurement probes for application performance monitoring and control-ow tracing. Analysis plugins extract and visualize architectural models, augmented by quantitative observations. Configurable readers and writers allow Kieker to be used for online and offine analysis. This paper reviews the Kieker framework focusing on its features, its provided extension points for custom components, as well the imposed monitoring overhead. Copyright 2012 ACM.","2012","2025-10-22 19:07:43","2025-10-22 19:07:43","","247-248","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application performance; Engineering; Industrial engineering; Distributed software system; Architectural models; Dynamic softwares; Extensible framework; Plug-ins; Runtime behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE'12 - Proceedings of the 3rd Joint WOSP/SIPEW International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"XC4XQ5FG","conferencePaper","2018","Kistowski, J.V.; Deffner, M.; Kounev, S.","Run-time prediction of power consumption for component deployments","","","","10.1109/ICAC.2018.00025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058276849&doi=10.1109%2fICAC.2018.00025&partnerID=40&md5=771bcfad4c98f3502ecffb80de61a8f0","The Power consumption of servers in data centers depends greatly on the software running on each server and how it interacts with the hardware. Different deployments of distributed software components on heterogeneous servers can lead to significant differences in power consumption, depending on the server allocation and the current workload. As workloads and load intensity change, components may be re-deployed or exchanged in order to reduce the power consumption for the current load profile. The decision on which component to place on which server during run-time remains difficult as the power consumption that would result from such a placement remains unknown. Existing work on component deployment optimization at run-time focuses on maximizing performance or considers power in the context of static design time decisions. In this paper, we introduce a model to predict the power consumption of component placements at run-time based on the load and power profile collected for a running distributed application in a heterogeneous environment. In addition, we present a model that enables the use of our approach without dedicated power measurement devices, predicting power consumption based on load intensity and performance counters. We show that we can predict the power consumption of two different distributed web applications with a mean absolute percentage error of 2.21% and with an error of 1.04% when predicting a previously unobserved load level. © 2018 IEEE.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","151-156","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Forecasting; Power; Microservice; Energy; Green computing; Servers; Prediction; Component; Regression; SERT; Server; Service","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 15th IEEE International Conference on Autonomic Computing, ICAC 2018","","","","","","","","","","","","","","",""
"2MTKMRFR","conferencePaper","2012","Basmadjian, R.; Ali, N.; Niedermeier, F.; De Meer, H.; Giuliani, G.","A methodology to predict the power consumption of servers in data centres","","","","10.1145/2318716.2318718","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864128556&doi=10.1145%2f2318716.2318718&partnerID=40&md5=9d473a68ac7040a8c3a3bc3050cbbafb","Until recently, there have been relatively few studies exploring the power consumption of ICT resources in data centres. In this paper, we propose a methodology to capture the behaviour of most relevant energy-related ICT resources in data centres and present a generic model for them. This is achieved by decomposing the design process into four modelling phases. Furthermore, unlike the state-of-the-art approaches, we provide detailed power consumption models at server and storage levels. We evaluate our model for different types of servers and show that it suffers from an error rate of 2% in the best case, and less than 10% in the worst case. Copyright 2011 ACM.","2012","2025-10-22 19:07:43","2025-10-22 19:07:43","","1-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Information technology; State-of-the-art approach; Models; Power consumption; Data centres; IT resources; Data centre; Design process; Error rate; Generic models; Modelling; Power consumption model; Storage level","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"QQM73JRK","conferencePaper","2010","Gong, Z.; Gu, X.; Wilkes, J.","PRESS: PRedictive Elastic reSource Scaling for cloud systems","","","","10.1109/CNSM.2010.5691343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951632052&doi=10.1109%2fCNSM.2010.5691343&partnerID=40&md5=bdd6833a2056a110f4ba800f2b58b6e4","Cloud systems require elastic resource allocation to minimize resource provisioning costs while meeting service level objectives (SLOs). In this paper, we present a novel PRedictive Elastic reSource Scaling (PRESS) scheme for cloud systems. PRESS unobtrusively extracts fine-grained dynamic patterns in application resource demands and adjust their resource allocations automatically. Our approach leverages light-weight signal processing and statistical learning algorithms to achieve online predictions of dynamic application resource requirements. We have implemented the PRESS system on Xen and tested it using RUBiS and an application load trace from Google. Our experiments show that we can achieve good resource prediction accuracy with less than 5% over-estimation error and near zero under-estimation error, and elastic resource scaling can both significantly reduce resource waste and SLO violations. © 2010 IEEE.","2010","2025-10-22 19:07:43","2025-10-22 19:07:43","","9-16","","","","","","","","","","","","","","","","Scopus","","","","","","","","Signal processing; Cloud systems; Resource allocation; Learning algorithms; Service level objective; Resource demands; Resource provisioning; Dynamic applications; Resource requirements; Network management; Estimation errors; Online prediction; Dynamic patterns; Light weight; Over-estimation; Presses (machine tools); Resource prediction; Resource wastes; Statistical learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2010 International Conference on Network and Service Management, CNSM 2010","","","","","","","","","","","","","","",""
"DW6GGV24","journalArticle","2016","Software, P.","","Spring PetClinic","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298437&partnerID=40&md5=6653542145f2fba29a4d4871afa81245","","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3JY8PE4R","journalArticle","2011","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058293065&partnerID=40&md5=3d815023a53064e536036ad7032e30a0","","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U8ZPJ5RA","journalArticle","2017","","","NET Foundation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058298677&partnerID=40&md5=6f46dbf2d61e35f414ace6ad45a269ee","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3AJLMA7","journalArticle","1995","Lee, I.; Iyer, R.K.","Software Dependability in the Tandem GUARDIAN System","IEEE Transactions on Software Engineering","","","10.1109/32.387474","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001631180&doi=10.1109%2f32.387474&partnerID=40&md5=acc04a2fe79b465f910a110066051352","Based on extensive field failure data for Tandem's GUARDIAN operating system, this paper discusses evaluation of the dependability of operational software. Software faults considered are major defects that result in processor failures and invoke backup processes to take over. The paper categorizes the underlying causes of software failures and evaluates the effectiveness of the process pair technique in tolerating software faults. A model to describe the impact of software faults on the reliability of an overall system is proposed. The model is used to evaluate the significance of key factors that determine software dependability and to identify areas for improvement An analysis of the data shows that about 77% of processor failures that are initially considered due to software are confirmed as software problems. The analysis shows that the use of process pairs to provide checkpointing and restart (originally intended for tolerating hardware faults) allows the system to tolerate about 75% of reported software faults that result in processor failures. The loose coupling between processors, which results in the backup execution (the processor state and the sequence of events) being different from the original execution, is a major reason for the measured software fault tolerance. Over two-thirds (72%) of measured software failures are recurrences of previously reported faults. Modeling, based on the data, shows that, in addition to reducing the number of software faults, software dependability can be enhanced by reducing the recurrence rate. © 1995 IEEE","1995","2025-10-22 19:07:43","2025-10-22 19:07:43","","455-467","","5","21","","","","","","","","","","","","","Scopus","","","","","","","","software reliability; Measurement; fault categorization; operational phase; recurrence; software fault tolerance; Tandem GUARDIAN System","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XMHBRJW","journalArticle","2011","Happe, J.; Koziolek, H.; Reussner, R.","Facilitating performance predictions using software components","IEEE Software","","","10.1109/MS.2011.25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955559323&doi=10.1109%2fMS.2011.25&partnerID=40&md5=eae75e318b7cd3fc0e6a289d17d2b90f","Component-based software engineering (CBSE) poses challenges for predicting and evaluating software performance but also offers several advantages. Software performance engineering can benefit from CBSE ideas and concepts. The MediaStore, a fictional system, demonstrates how to achieve compositional reasoning about software performance. © 2011 IEEE.","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","27-33","","3","28","","","","","","","","","","","","","Scopus","","","","","","","","Software architecture; Software component; Software performance; Performance prediction; component-based software architecture; Component-based software architecture; Component-based software engineering; Compositional reasoning; Evaluating software; quality assessment; Quality assessment; software performance engineering; Software performance engineerings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BUFVNWSM","conferencePaper","2016","Rygielski, P.; Seliuchenko, M.; Kounev, S.","Modeling and prediction of Software-Defined Networks performance using Queueing Petri Nets","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052600005&partnerID=40&md5=7e441b4582d847a63a656e0c8e9b62b4","Using various modeling and simulation approaches for predicting network performance requires extensive experience and involves a number of time consuming manual steps regarding each of the modeling formalisms. Descartes Network Infrastructure (DNI) is a data center network performance modeling approach that addresses this challenge by offering multiple performance models but requiring to use only a single modeling language. In this paper, we thoroughly extend DNI to support new networking paradigms like, among others, Software-Defined Networking (SDN) and Network-Function Virtualization (NFV). Additionally, we demonstrate how SDN-based networks can be modeled using DNI and how are they transformed later into Queueing Petri Nets (QPN) using a model-to-model transformation. In the analysis of the performance prediction accuracy, we show that automatically generated QPN models represent the performance of heterogeneous SDN hardware with maximal prediction accuracy error of 12%. Copyright © 2016 EAI.","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","66-75","","","","","","","","","","","","","","","","Scopus","","","","","","","","Forecasting; Network performance; Network function virtualization; Data center networks; Modeling languages; Queueing networks; Petri nets; Performance modeling; Software defined networking; Software defined networking (SDN); Performance Model; Performance prediction; Automatically generated; Meta model; Meta-modeling; Model to model transformation; Modeling and predictions; Software-defined networking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 9th EAI International Conference on Simulation Tools and Techniques, SIMUTools 2016","","","","","","","","","","","","","","",""
"CQW5BP5V","journalArticle","2012","","","Power and Performance Benchmark Methodology","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043146402&partnerID=40&md5=da4aa23f60e16997ce20e59077c8ba9b","","2012","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CIRFY7WL","journalArticle","2014","Happe, L.; Buhnova, B.; Reussner, R.","Stateful component-based performance models","Software and Systems Modeling","","","10.1007/s10270-013-0336-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911008093&doi=10.1007%2fs10270-013-0336-6&partnerID=40&md5=a8be1980dd6f2f36e44fd4c67b2efc10","The accuracy of performance-prediction models is crucial for widespread adoption of performance prediction in industry. One of the essential accuracy-influencing aspects of software systems is the dependence of system behaviour on a configuration, context or history related state of the system, typically reflected with a (persistent) system attribute. Even in the domain of component-based software engineering, the presence of state-reflecting attributes (the so-called internal states) is a natural ingredient of the systems, implying the existence of stateful services, stateful components and stateful systems as such. Currently, there is no consensus on the definition or method to include state-related information in component-based prediction models. Besides the task to identify and localise different types of stateful information across component-based software architecture, the issue is to balance the expressiveness and complexity of prediction models via an effective abstraction of state modelling. In this paper, we identify and classify stateful information in component-based software systems, study the performance impact of the individual state categories, and discuss the costs of their modelling in terms of the increased model size. The observations are formulated into a set of heuristics-guiding software engineers in state modelling. Finally, practical effect of state modelling on software performance is evaluated on a real-world case study, the SPECjms2007 Benchmark. The observed deviation of measurements and predictions was significantly decreased by more precise models of stateful dependencies. © 2013, Springer-Verlag Berlin Heidelberg.","2014","2025-10-22 19:07:43","2025-10-22 19:07:43","","1319-1343","","4","13","","","","","","","","","","","","","Scopus","","","","","","","","Forecasting; Benchmarking; Classification (of information); Computer software; Predictive analytics; Software performance; Prediction accuracy; Performance prediction; Component-based software architecture; Component-based software engineering; Component-based software systems; Performance prediction models; Stateful components","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VGEEBJ4Q","conferencePaper","2015","Von Kistowski, J.; Beckett, J.; Lange, K.-D.; Block, H.; Arnold, J.A.; Kounev, S.","Energy Efficiency of Hierarchical Server Load Distribution Strategies","","","","10.1109/MASCOTS.2015.11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962213192&doi=10.1109%2fMASCOTS.2015.11&partnerID=40&md5=6f654663ce47bc05b76f98041aafe772","Energy efficiency of servers has become a significant issue over the last years. Load distribution plays a crucial role in the improvement of energy efficiency as (un-)balancing strategies can be leveraged to distribute load over one or multiple systems in a way in which resources are utilized at high performance, yet low overall power consumption. This can be achieved on multiple levels, from load distribution on single CPU cores to machine level load balancing on distributed systems. With modern day server architectures providing load balancing opportunities at several layers, answering the question of optimal load distribution has become non-trivial. Work has to be distributed hierarchically in a fashion that enables maximum energy efficiency at each level. Current approaches balance load based on generalized assumptions about the energy efficiency of servers. These assumptions are based either on very machine-specific or highly generalized observations that may or may not hold true over a variety of systems and configurations. In this paper, we use a modified version of the SPEC SERT suite to measure the energy efficiency of a variety of hierarchical load distribution strategies on single and multi-node systems. We introduce a new strategy and evaluate energy efficiency for homogeneous and heterogeneous workloads over different hardware configurations. Our results show that the selection of a load distribution strategy depends heavily on workload, system utilization, as well as hardware. Used in conjunction with existing strategies, our new load distribution strategy can reduce a single system's power consumption by up to 10.7%. © 2015 IEEE.","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","75-84","","","2015-November","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Electric power utilization; Energy efficiency; Program processors; Distributed systems; Hierarchical systems; Servers; Power demands; Heterogeneous workloads; Software testing; Reconfigurable hardware; Distribution strategies; Network management; Power demand; Benchmark testing; Electric load management; Hardware configurations; Distribution strategy; Electric power plant loads; Load distribution strategies; Load management; Load testing; Optimal load distributions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS","","","","","","","","","","","","","","",""
"FSZ9DXF7","journalArticle","2015","Brunnert, A.","Performance-oriented DevOps: A research agenda","Performance-oriented DevOps: A Research Agenda","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968786582&partnerID=40&md5=d1fd18c1d6fc32df2dcd050e13cee27e","","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SNZEEB5","journalArticle","2016","Garetto, M.; Leonardi, E.; Martina, V.","A unified approach to the performance analysis of caching systems","ACM Transactions on Modeling and Performance Evaluation of Computing Systems","","","10.1145/2896380","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074675553&doi=10.1145%2f2896380&partnerID=40&md5=5007b772db46dd9a7cfbb140cd8df404","We propose a unified methodology to analyze the performance of caches (both isolated and interconnected), by extending and generalizing a decoupling technique originally known as Che's approximation, which provides very accurate results at low computational cost. We consider several caching policies (including a very attractive one, called k-LRU), taking into account the effects of temporal locality. In the case of interconnected caches, our approach allows us to do better than the Poisson approximation commonly adopted in prior work. Our results, validated against simulations and trace-driven experiments, provide interesting insights into the performance of caching systems. © 2016 ACM 2376-3639/2016/05-ART12 $15.00","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","3","1","","","","","","","","","","","","","Scopus","","","","","","","","Hardware; Performance analysis; Distributed computer systems; Computer science; Content delivery network; Caching; Computer programming; Computer network performance evaluation; Content delivery networks; Decoupling technique; Information-centric networking; Information-centric networkings; Inter-connected caches; Poisson approximations; Trace driven experiments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFIALGUQ","journalArticle","2009","Becker, S.; Koziolek, H.; Reussner, R.","The Palladio component model for model-driven performance prediction","Journal of Systems and Software","","","10.1016/j.jss.2008.03.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-55249125447&doi=10.1016%2fj.jss.2008.03.066&partnerID=40&md5=ce8cbacdbf56b0e251572a8f67d837d9","One aim of component-based software engineering (CBSE) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in CBSE stems from its specific development process: Software components should be specified and implemented independently from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influencing factors like the hardware platform or the usage profile into account. Our approach uses the Palladio component model (PCM) to specify component-based software architectures in a parametric way. This model offers direct support of the CBSE development process by dividing the model creation among the developer roles. This paper presents our model and a simulation tool based on it, which is capable of making performance predictions. Within a case study, we show that the resulting prediction accuracy is sufficient to support the evaluation of architectural design decisions. © 2008 Elsevier Inc. All rights reserved.","2009","2025-10-22 19:07:43","2025-10-22 19:07:43","","3-22","","1","82","","","","","","","","","","","","","Scopus","","","","","","","","Forecasting; Software architecture; Software engineering; Computer software; Software reliability; Architectural design; Simulation tools; Computer software reusability; Prediction methods; Performance prediction; Component-based software engineering; Case studies; Component models; Development processes; Functional properties; Hardware platforms; Influencing factors; Maturation stages; Model creations; Performance predictions; Prediction accuracies; Reliability theory; Software components","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RII49DLH","journalArticle","2016","Herbst, N.","Ready for rain? A view from SPEC research on the future of cloud metrics","Ready for Rain? A View from SPEC Research on the Future of Cloud Metrics","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019039933&partnerID=40&md5=ff7477cb445c6095456bcec8aa7db532","","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJNPY8N4","journalArticle","2015","Spinner, S.; Casale, G.; Brosig, F.; Kounev, S.","Evaluating approaches to resource demand estimation","Performance Evaluation","","","10.1016/j.peva.2015.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938851133&doi=10.1016%2fj.peva.2015.07.005&partnerID=40&md5=17fc45471db545e9b1a2005a5585d868","Abstract Resource demands are a key parameter of stochastic performance models that needs to be determined when performing a quantitative performance analysis of a system. However, the direct measurement of resource demands is not feasible in most realistic systems. Therefore, statistical approaches that estimate resource demands based on coarse-grained monitoring data (e.g., CPU utilization, and response times) have been proposed in the literature. These approaches have different assumptions and characteristics that need to be considered when estimating resource demands. This paper surveys the state-of-the-art in resource demand estimation and proposes a classification scheme for estimation approaches. Furthermore, it contains an experimental evaluation comparing the impact of different factors (monitoring window size, number of workload classes, load level, collinearity, and model mismatch) on the estimation accuracy of seven different approaches. The classification scheme and the experimental comparison helps performance engineers to select an approach to resource demand estimation that fulfills the requirements of a given analysis scenario. © 2015 Elsevier B.V.","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","51-71","","","92","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Experimental evaluation; Resource demands; Stochastic systems; Experimental comparison; Stochastic models; Performance modeling; Performance Model; Classification scheme; Estimation approaches; Quantitative performance analysis; Resource demand estimation; Workload characterization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQJH8ZWS","bookSection","2017","Walter, J.; Di Marco, A.; Spinner, S.; Inverardi, P.; Kounev, S.","Online learning of run-time models for performance and resource management in data centers","Self-Aware Computing Systems","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019438468&doi=10.1007%2f978-3-319-47474-8_17&partnerID=40&md5=e3565bd3acac9316b26add6c00bd1042","In this chapter, we explain how to extract and learn run-timemodels that a system can use for self-aware performance and resource management in data centers. We abstract from concrete formalisms and identify extraction aspects relevant to performance models. We categorize the learning aspects into: (i) model structure, (ii) model parametrization (estimation and calibration of model parameters), and (iii) model adaptation options (change point detection and run-time reconfiguration). The chapter identifies alternative approaches for the respective model aspects. The type and granularity of each aspect depend on the characteristic of the concrete performance models. © Springer International Publishing AG 2017.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","507-528","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DUDQ6MFQ","conferencePaper","2006","Schroeder, B.; Wierman, A.; Harchol-Balter, M.","Open versus closed: A cautionary tale","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093921502&partnerID=40&md5=4c23a91785ef30a3a5421955ebfe08b3","Workload generators may be classified as based on a closed system model, where new job arrivals are only triggered by job completions (followed by think time), or an open system model, where new jobs arrive independently of job completions. In general, system designers pay little attention to whether a workload generator is closed or open. Using a combination of implementation and simulation experiments, we illustrate that there is a vast difference in behavior between open and closed models in real-world settings. We synthesize these differences into eight simple guiding principles, which serve three purposes. First, the principles specify how scheduling policies are impacted by closed and open models, and explain the differences in user level performance. Second, the principles motivate the use of partly open system models, whose behavior we show to lie between that of closed and open models. Finally, the principles provide guidelines to system designers for determining which system model is most appropriate for a given workload. © NSDI 2006.All Rights Reserved.","2006","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Systems analysis; Real world setting; Cautionary tales; Guiding principles; Scheduling policies; System designers; System modeling; User-level performance; Workload generators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","3rd Symposium on Networked Systems Design and Implementation, NSDI 2006","","","","","","","","","","","","","","",""
"CB5G3Z9I","journalArticle","2005","","","Oracle and S. Microsystems JPetStore 2.0","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058266828&partnerID=40&md5=0d31c3134612e88e7bf6368d6ede3fc6","","2005","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IL933RV6","journalArticle","2017","Groenda, H.; Stier, C.; Krzywda, J.; Byrne, J.; Svorobej, S.; Castañ, G.G.; Papazachos, Z.; Sheridan, C.; Whigham, D.; Hauser, C.","","Cactos Toolkit Version 2: Accompanying Document for Prototype Deliverable d5. 2.2","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058281345&partnerID=40&md5=098f0da0b04af4ae2cd7bdb3f8f51eb3","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHMZLH2V","conferencePaper","2017","Ilyushkin, A.; Ali-Eldin, A.; Herbst, N.; Papadopoulos, A.V.; Ghit, B.; Epema, D.; Iosup, A.","An experimental performance evaluation of autoscaling policies for complex workflows","","","","10.1145/3030207.3030214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019018662&doi=10.1145%2f3030207.3030214&partnerID=40&md5=c8b601ce3d9af02185391daebeb015a3","Simplifying the task of resource management and scheduling for customers, while still delivering complex Quality-of-Service (QoS), is key to cloud computing. Many autoscaling policies have been proposed in the past decade to decide on behalf of cloud customers when and how to provision resources to a cloud application utilizing cloud elasticity features. However, in prior work, when a new policy is proposed, it is seldom compared to the state-of-the-art, and is often compared only to static provisioning using a predefined QoS target. This reduces the ability of cloud customers and of cloud operators to choose and deploy an autoscaling policy. In our work, we conduct an experimental performance evaluation of autoscaling policies, using as application model workflows, a commonly used formalism for automating resource management for applications with well-defined yet complex structure. We present a detailed comparative study of general state-of-the-art autoscaling policies, along with two new workflow-specific policies. To understand the performance differences between the 7 policies, we conduct various forms of pairwise and group comparisons. We report both individual and aggregated metrics. Our results highlight the trade-offs between the suggested policies, and thus enable a better understanding of the current state-of-the-art. © 2017 ACM.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","75-86","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Resource management; Cloud applications; Economic and social effects; Natural resources management; Resource allocation; Sales; Comparative studies; Experimental performance evaluations; Application modeling; Cloud elasticities; Complex workflows; Resource management and scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2017 - Proceedings of the 2017 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"6JTF2BQH","conferencePaper","2002","Cecchet, E.; Marguerite, J.; Zwaenepoel, W.","Performance and scalability of EJB applications","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038486621&partnerID=40&md5=9cce9b3e09bdb0f5062d03931ee5fc81","A study was conducted on several Enterprise JavabEJB implementations of the same e-commerce application, using different application implementation methods, container designs and communication layers. It was shown that stateless session beans with bean-managed persistence coupled with an efficient communication layer offer performance comparable to a servlets-only implementation. Entity beans impose a row-level access to the database resulting in a finer-grain access and significantly lower performance.","2002","2025-10-22 19:07:43","2025-10-22 19:07:43","","246-261","","","","","","","","","","","","","","","","Scopus","","","","","","","","Data communication systems; Optimization; Program compilers; Performance; Java programming language; Servers; Websites; Scalability; Response time (computer systems); Semantics; Interfaces (computer); Communication optimization; EJB container design; Profiling; Run time; Software package Enterprise JavaBeans","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA","","","","","","","","","","","","","","",""
"AIJGSSK3","conferencePaper","2017","Brataas, G.; Herbst, N.; Ivansek, S.; Polutnik, J.","Scalability Analysis of Cloud Software Services","","","","10.1109/ICAC.2017.34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034448448&doi=10.1109%2fICAC.2017.34&partnerID=40&md5=f88fb2d56dd26ec9f8a3e0eab7b8fe4c","Cloud computing theoretically offers its customers unlimited cloud resources. However, the scalability of software services is often limited by their underlying architecture. In contrast to current scalability analysis approaches, we make work parameters, quality thresholds, as well as the resource space explicit in a conceptually consistent set of equations. We propose two scalability metric functions based on these equations. The resource scalability metric function describes the relation between the capacity of the multi-tier cloud software service and its use of cloud resources, whereas the cost scalability metric function replaces cloud resources with cost. We validate using the Cloud-Store application. CloudStore follows the TPC-W specification, representing an online book store. We have experimented with 21 different public Amazon Web Service configurations and two private OpenStack configurations. © 2017 IEEE.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","285-292","","","","","","","","","","","","","","","","Scopus","","","","","","","","cloud; Clouds; Web services; Costs; Amazon web services; Scalability; Quality control; scalability; cost; Measurements; measurement; Software services; metric; Multi-tier; Resource space; Scalability analysis; service","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE International Conference on Autonomic Computing, ICAC 2017","","","","","","","","","","","","","","",""
"SB7WH6I6","conferencePaper","2016","Ezhilchelvan, P.; Mitrani, I.","Optimal provision of multiple service types","","","","10.1109/MASCOTS.2016.16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010424700&doi=10.1109%2fMASCOTS.2016.16&partnerID=40&md5=23e05b5d2327d8a2f1ea42ae17139f7f","Services of different types are provided to paying customers on servers hired from a cloud. Different virtual machines can share a server, subject to one or more resource constraints. Incoming jobs whose resource requirements cannot be satisfied are lost. The objective is to maximize the long-term average profit per unit time. A single-server model is analyzed exactly and the results provide approximations for the system with n servers. The latter is also solved exactly when the servers are dedicated and when the VMs can migrate instantaneously. Numerical examples and comparisons with simulations are presented. © 2016 IEEE.","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","21-29","","","","","","","","","","","","","","","","Scopus","","","","","","","","Java programming language; Network security; Virtual machine migrations; Service provisioning; Erlang model; Multiple job types; Revenue optimisation; Revenue Optimisation; Service Provisioning; Virtual Machine migration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 IEEE 24th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems, MASCOTS 2016","","","","","","","","","","","","","","",""
"PDRCXUUA","journalArticle","2008","Gérard, S.; Selic, B.","The uml-marte standardized profile","IFAC Proceedings Volumes","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047760462&partnerID=40&md5=8e3359d33ffe03cb55f58bb1a77d6492","","2008","2025-10-22 19:07:43","2025-10-22 19:07:43","","6909-6913","","2","41","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGP9MNK5","conferencePaper","2009","Chieu, T.C.; Mohindra, A.; Karve, A.A.; Segal, A.","Dynamic scaling of web applications in a virtualized cloud computing environment","","","","10.1109/ICEBE.2009.45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950987607&doi=10.1109%2fICEBE.2009.45&partnerID=40&md5=88acee7d2db24889fbf1c5a4f330a76b","Scalability is critical to the success of many enterprises currently involved in doing business on the web and in providing information that may vary drastically from one time to another. Maintaining sufficient resources just to meet peak requirements can be costly. Cloud computing provides a powerful computing model that allows users to access resources on-demand. In this paper, we will describe a novel architecture for the dynamic scaling of web applications based on thresholds in a virtualized Cloud Computing environment. We will illustrate our scaling approach with a front-end load-balancer for routing and balancing user requests to web applications deployed on web servers installed in virtual machine instances. A dynamic scaling algorithm for automated provisioning of virtual machine resources based on threshold number of active sessions will be introduced. The on-demand capability of the Cloud to rapidly provision and dynamically allocate resources to users will be discussed. Our work has demonstrated the compelling benefits of the Cloud which is capable of handling sudden load surges, delivering IT resources on-demands to users, and maintaining higher resource utilization, thus reducing infrastructure and management costs. © 2009 IEEE.","2009","2025-10-22 19:07:43","2025-10-22 19:07:43","","281-286","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Virtualization; Virtualizations; Virtual machines; Computing model; Virtual machine; Balancing; Resource utilizations; Scalability; Electronic commerce; World Wide Web; WEB application; Cost reduction; Novel architecture; Technical presentations; Management costs; IT resources; Dynamic scaling; On-Demand; Threshold numbers; Web servers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE International Conference on e-Business Engineering, ICEBE 2009; IEEE Int. Workshops - AiR 2009; SOAIC 2009; SOKMBI 2009; ASOC 2009","","","","","","","","","","","","","","",""
"7B5A8SNX","conferencePaper","2005","Lemire, D.; Maclachlan, A.","Slope one predictors for online rating-based collaborative filtering","","","","10.1137/1.9781611972757.43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880129466&doi=10.1137%2f1.9781611972757.43&partnerID=40&md5=b0a0c19f430dd04a3350515903d3af97","Rating-based collaborative filtering is the process of predicting how a user would rate a given item from other user ratings. We propose three related slope one schemes with predictors of the form f(x) = x + b, which precompute the average difference between the ratings of one item and another for users who rated both. Slope one algorithms are easy to implement, efficient to query, reasonably accurate, and they support both online queries and dynamic updates, which makes them good candidates for real-world systems. The basic SLOPE ONE scheme is suggested as a new reference scheme for collaborative filtering. By factoring in items that a user liked separately from items that a user disliked, we achieve results competitive with slower memory-based schemes over the standard benchmark EachMovie and Movielens data sets while better fulfilling the desiderata of CF applications. Copyright © by SIAM.","2005","2025-10-22 19:07:43","2025-10-22 19:07:43","","471-475","","","","","","","","","","","","","","","","Scopus","","","","","","","","Data mining; Online systems; Benchmarking; Electronic commerce; Average difference; Collaborative filtering; Dynamic update; E-commerce; Knowledge discovery; Online ratings; Real-world system; Recommender; Slope one schemes; Slope ones; User rating","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2005 SIAM International Conference on Data Mining, SDM 2005","","","","","","","","","","","","","","",""
"VSSQQYVS","journalArticle","2013","Koziolek, A.; Ardagna, D.; Mirandola, R.","Hybrid multi-attribute QoS optimization in component based software systems","Journal of Systems and Software","","","10.1016/j.jss.2013.03.081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882598370&doi=10.1016%2fj.jss.2013.03.081&partnerID=40&md5=3816ffabd78ddfff2a0373d27f45ffe7","Design decisions for complex, component-based systems impact multiple quality of service (QoS) properties. Often, means to improve one quality property deteriorate another one. In this scenario, selecting a good solution with respect to a single quality attribute can lead to unacceptable results with respect to the other quality attributes. A promising way to deal with this problem is to exploit multi-objective optimization where the objectives represent different quality attributes. The aim of these techniques is to devise a set of solutions, each of which assures an optimal trade-off between the conflicting qualities. Our previous work proposed a combined use of analytical optimization techniques and evolutionary algorithms to efficiently identify an optimal set of design alternatives with respect to performance and costs. This paper extends this approach to more QoS properties by providing analytical algorithms for availability-cost optimization and three-dimensional availability-performance-cost optimization. We demonstrate the use of this approach on a case study, showing that the analytical step provides a better-than-random starting population for the evolutionary optimization, which lead to a speed-up of 28% in the availability-cost case. © 2013 Elsevier Inc.","2013","2025-10-22 19:07:43","2025-10-22 19:07:43","","2542-2558","","10","86","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Software engineering; Costs; Multiobjective optimization; Availability; Component-based software systems; Analytical algorithms; Analytical optimizations; Architecture optimization; Component based systems; Design alternatives; Evolutionary optimizations; Quality properties; Software architecture optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNI832QU","conferencePaper","2015","Willnecker, F.; Brunnert, A.; Gottesheim, W.; Krcmar, H.","Using dynatrace monitoring data for generating performance models of java EE applications","","","","10.1145/2668930.2688061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923923744&doi=10.1145%2f2668930.2688061&partnerID=40&md5=f4b0d47898ce9bae1d9207c824547980","Performance models assist capacity management and planning for large-scale enterprise applications by predicting their performance for different workloads and hardware environments. Manually creating these models often outweighs their benefits. Automatic performance model generators have been introduced to facilitate the model creation. These generators often use custom monitoring solutions to generate the required input data for the model creation. In contrast, standardized application performance management (APM) solutions are used in industry to control performance metrics for productive systems. This work presents the integration of industry standard APM solutions with a performance model generation framework. We apply the integration concepts using the APM solution Dynatrace and a performance model generation framework for Palladio Component Models (PCM). Copyright © 2015 ACM.","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","103-104","","","","","","","","","","","","","","","","Scopus","","","","","","","","Java programming language; Industry standards; Application performance; Performance evaluation; Capacity management; Enterprise applications; Load testing; Application performance management; Control performance; Hardware environment; Productive systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2015 - Proceedings of the 6th ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"YT33FFMM","conferencePaper","2005","Bondarev, E.; De With, P.; Chaudron, M.; Muskens, J.","Modelling of input-parameter dependency for performance predictions of component-based embedded systems","","","","10.1109/EUROMICRO.2005.40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747428299&doi=10.1109%2fEUROMICRO.2005.40&partnerID=40&md5=47950250eb70ffc3fb295a2b6325a38f","The guaranty of meeting the timing constraints during the design phase of real-time component-based embedded software has not been realized. To satisfy real-time requirements, we need to understand behaviour and resource usage of a system over time. In this paper we address both aspects in detail by observing the influence of input data on the system behaviour and performance. We extend an existing scenario simulation approach that features the modelling of input parameter dependencies and simulating the execution of the models. The approach enables specification of the dependencies in the component models, as well as initialisation of the parameters in the application scenario model. This gives a component-based application designer an explorative possibility of going through all possible execution scenarios with different parameter initialisations, and finding the worst-case scenarios where the predicted performance does not satisfy the requirements. The identification of these scenarios is important because it avoids system redesign at the later stage. In addition, the conditional behaviour and resource usage modelling with respect to the input data provide more accurate prediction. © 2005 IEEE.","2005","2025-10-22 19:07:43","2025-10-22 19:07:43","","36-43","","","2005","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Software engineering; Real time systems; Data reduction; Resource allocation; Mathematical models; Parameter estimation; Embedded software; Constraint theory; Resource usage modeling; Scenario simulation; Worst-case scenarios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Software Engineering and Advanced Applications, 2005. 31st EUROMICRO Conference","","","","","","","","","","","","","","",""
"NT2E6QNF","conferencePaper","2017","Aderaldo, C.M.; Mendonça, N.C.; Pahl, C.; Jamshidi, P.","Benchmark Requirements for Microservices Architecture Research","","","","10.1109/ECASE.2017.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027445401&doi=10.1109%2fECASE.2017.4&partnerID=40&md5=61d346a021eccc94d7914ec326403ca7","Microservices have recently emerged as a new architectural style in which distributed applications are broken up into small independently deployable services, each running in its own process and communicating via lightweight mechanisms. However, there is still a lack of repeatable empirical research on the design, development and evaluation of microservices applications. As a first step towards filling this gap, this paper proposes, discusses and illustrates the use of an initial set of requirements that may be useful in selecting a community-owned architecture benchmark to support repeatable microservices research. © 2017 IEEE.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","8-13","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Software architecture; Software engineering; Architectural style; Distributed applications; software architecture; Engineering; Industrial engineering; Architecture research; Empirical research; research benchmark; Running-in","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE/ACM 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering, ECASE 2017","","","","","","","","","","","","","","",""
"3QNKVMX3","journalArticle","2017","Becker, S.; Bulej, L.; Bures, T.; Hnetynka, P.; Kapova, L.; Kofron, J.; Koziolek, H.; Kraft, J.; Mirandola, R.; Stammel, J.; Tamburelli, G.; Trifu, M.","","Q-impress Consortium","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058269056&partnerID=40&md5=4145fd7925e14e222e2a5af08b21dd5a","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DT5HGVFS","journalArticle","2003","Cecchet, E.; Chanda, A.; Elnikety, S.; Marguerite, J.; Zwaenepoel, W.","Performance comparison of middleware architectures for generating dynamic web content","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/3-540-44892-6_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-35248840419&doi=10.1007%2f3-540-44892-6_13&partnerID=40&md5=d5f1d64aa8d6f739e43d7cae8d8c373a","On-line services are making increasing use of dynamically generated Web content. Serving dynamic content is more complex than serving static content. Besides a Web server, it typically involves a server-side application and a database to generate and store the dynamic content. A number of standard mechanisms have evolved to generate dynamic content. We evaluate three specific mechanisms in common use: PHP, Java servlets, and Enterprise Java Beans (EJB). These mechanisms represent three different architectures for generating dynamic content. PHP scripts are tied to the Web server and require writing explicit database queries. Java servlets execute in a different process from the Web server, allowing them to be located on a separate machine for better load balancing. The database queries are written explicitly, as in PHP, but in certain circumstances the Java synchronization primitives can be used to perform locking, reducing database lock contention and the amount of communication between servlets and the database. Enterprise Java Beans (EJB) provide several services and facilities. In particular, many of the database queries can be generated automatically. We measure the performance of these three architectures using two application benchmarks: an online bookstore and an auction site. These benchmarks represent common applications for dynamic content and stress different parts of a dynamic content Web server. The auction site stresses the server front-end, while the online bookstore stresses the server back-end. For all measurements, we use widely available open-source software (the Apache Web server, Tomcat servlet engine, JOnAS EJB server, and MySQL relational database). While Java servlets are less efficient than PHP, their ability to execute on a different machine from the Web server and their ability to perform synchronization leads to better performance when the front-end is the bottleneck or when there is database lock contention. EJB facilities and services come at the cost of lower performance than both PHP and Java servlets. © IFIP International Federation for Information Processing 2003.","2003","2025-10-22 19:07:43","2025-10-22 19:07:43","","242-261","","","2672","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Java programming language; Open systems; Dynamics; Middleware; Benchmarking; Memory architecture; Synchronization primitive; Web services; Websites; Balancing; Query languages; Electronic commerce; Performance comparison; Apache web server; Dynamic web content; Enterprise Java Beans; Middleware architecture; Online bookstore; Relational Database","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X9I87V8S","journalArticle","2009","Consortium, O.","","Rice University Bidding System","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75149156792&partnerID=40&md5=7e14c298222ac11b067cda89a1f40370","","2009","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMR5I5XW","conferencePaper","2018","Eismann, S.; Walter, J.; Von Kistowski, J.; Kounev, S.","Modeling of Parametric Dependencies for Performance Prediction of Component-Based Software Systems at Run-Time","","","","10.1109/ICSA.2018.00023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051114862&doi=10.1109%2fICSA.2018.00023&partnerID=40&md5=cc9fd78b93c3d7ffdd0f6d73b483b543","Model-based performance analysis can be leveraged to explore performance properties of software systems. To capture the behavior of varying workload mixes, configurations, and deployments of a software system requires formal modeling of the impact of configuration parameters and user input on the system behavior. Such influences are represented as parametric dependencies in software performance models. Existing modeling approaches focus on modeling parametric dependencies at design-time. This paper identifies runtime specific parametric dependency features, which are not supported by existing work. Therefore, this paper proposes a novel modeling methodology for parametric dependencies and a corresponding graph-based resolution algorithm. This algorithm enables the solution of models containing component instance-level dependencies, variables with multiple descriptions in parallel, and correlations modeled as parametric dependencies. We integrate our work into the Descartes Modeling Language (DML), allowing for accurate and efficient modeling and analysis of parametric dependencies. These performance predictions are valuable for various purposes such as capacity planning, bottleneck analysis, configuration optimization and proactive auto-scaling. Our evaluation analyzes a video store application. The prediction for varying language mixes and video sizes shows a mean error below 5% for utilization and below 10% for response time. © 2018 IEEE.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","135-144","","","","","","","","","","","","","","","","Scopus","","","","","","","","Forecasting; Performance; Software architecture; Architecture; Runtimes; Computer software; Graphic methods; Modeling languages; Runtime; Parameter estimation; Performance Model; Component based systems; Component-based-systems; Descartes; Descartes-Modeling-Language; Parametric dependencies; Parametric-dependencies; Performance-modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2018 IEEE 15th International Conference on Software Architecture, ICSA 2018","","","","","","","","","","","","","","",""
"U2FCB25N","journalArticle","2016","Okanović, D.; Van Hoorn, A.; Heger, C.; Wert, A.; Siegl, S.","Towards performance tooling interoperability: An open format for representing execution traces","Proc. of the 13th European Workshop on Performance Engineering (EPEW)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051676027&partnerID=40&md5=5553a9ed3194b10c3c70a3e30a7b5526","","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EVERFBLT","conferencePaper","2017","Walter, J.; Stier, C.; Koziolek, H.; Kounev, S.","An expandable extraction framework for architectural performance models","","","","10.1145/3053600.3053634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019501371&doi=10.1145%2f3053600.3053634&partnerID=40&md5=0184ea21486209a6e8384d95ea97bc4b","Providing users with Quality of Service (QoS) guarantees and the prevention of performance problems are challenging tasks for software systems. Architectural performance models can be applied to explore performance properties of a software system at design time and run time. At design time, architectural performance models support reasoning on effects of design decisions. At run time, they enable automatic reconfigurations by reasoning on the effects of changing user behavior. In this paper, we present a framework for the extraction of architectural performance models based on monitoring logfiles generalizing over the targeted architectural modeling language. Using the presented framework, the creation of a performance model extraction tool for a specific modeling formalism requires only the implementation of a key set of object creation routines specific to the formalism. Our framework integrates them with extraction techniques that apply to many architectural performance models, e.g., resource demand estimation techniques. This lowers the effort to implement performance model extraction tools tremendously through a high level of reuse. We evaluate our framework presenting builders for the Descartes Modeling Language (DML) and the Palladio Component Model (PCM). For the extracted models we compare simulation results with measurements receiving accurate results. © 2017 ACM.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","165-170","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Behavioral research; Computer software; Network function virtualization; Modeling languages; Extraction; Architectural design; Performance Model; Quality of service (QoS) guarantees; Architectural modeling languages; Automatic reconfiguration; Extraction techniques; Modeling formalisms; Performance problems; Performance properties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2017 - Companion of the 2017 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"LIZ2UUCV","journalArticle","2012","Beloglazov, A.; Abawajy, J.; Buyya, R.","Energy-aware resource allocation heuristics for efficient management of data centers for Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2011.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370722&doi=10.1016%2fj.future.2011.04.017&partnerID=40&md5=404d8a6f96e7208ce49f7fb3ffc699cd","Cloud computing offers utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of electrical energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only minimize operational costs but also reduce the environmental impact. In this paper, we define an architectural framework and principles for energy-efficient Cloud computing. Based on this architecture, we present our vision, open research challenges, and resource provisioning and allocation algorithms for energy-efficient management of Cloud computing environments. The proposed energy-aware allocation heuristics provision data center resources to client applications in a way that improves energy efficiency of the data center, while delivering the negotiated Quality of Service (QoS). In particular, in this paper we conduct a survey of research in energy-efficient computing and propose: (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering QoS expectations and power usage characteristics of the devices; and (c) a number of open research challenges, addressing which can bring substantial benefits to both resource providers and consumers. We have validated our approach by conducting a performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant cost savings and demonstrates high potential for the improvement of energy efficiency under dynamic workload scenarios. © 2011 Elsevier B.V. All rights reserved.","2012","2025-10-22 19:07:43","2025-10-22 19:07:43","","755-768","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Energy efficient; Virtualizations; Energy aware; Resource allocation; Energy-efficient resource allocation; Computing environments; Research challenges; Data centers; Client applications; Computer systems; Performance evaluation; Cost saving; Dynamic consolidation; Allocation algorithm; Architectural frameworks; Architectural principles; Business domain; Carbon footprint; Computing solutions; Electrical energy; Environmental impact; Green IT; High potential; IT services; Operational costs; Pay-as-you-go; Pervasive applications; Power usage; Research; Resource providers; Resource provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBB9HGTX","journalArticle","2016","Vittorio Papadopoulos, A.; Ali-Eldin, A.; Arzén, K.-E.; Tordsson, J.; Elmroth, E.","PEAS: A performance evaluation framework for auto-scaling strategies in cloud applications","ACM Transactions on Modeling and Performance Evaluation of Computing Systems","","","10.1145/2930659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074674305&doi=10.1145%2f2930659&partnerID=40&md5=39dafecaa11d9622b5424d3fcb7da914","Numerous auto-scaling strategies have been proposed in the past few years for improving various Quality of Service (QoS) indicators of cloud applications, for example, response time and throughput, by adapting the amount of resources assigned to the application to meet the workload demand. However, the evaluation of a proposed auto-scaler is usually achieved through experiments under specific conditions and seldom includes extensive testing to account for uncertainties in the workloads and unexpected behaviors of the system. These tests by no means can provide guarantees about the behavior of the system in general conditions. In this article, we present a Performance Evaluation framework for Auto-Scaling (PEAS) strategies in the presence of uncertainties. The evaluation is formulated as a chance constrained optimization problem, which is solved using scenario theory. The adoption of such a technique allows one to give probabilistic guarantees of the obtainable performance. Six different auto-scaling strategies have been selected from the literature for extensive test evaluation and compared using the proposed framework. We build a discrete event simulator and parameterize it based on real experiments. Using the simulator, each auto-scaler's performance is evaluated using 796 distinct real workload traces from projects hosted on the Wikimedia foundations' servers, and their performance is compared using PEAS. The evaluation is carried out using different performance metrics, highlighting the flexibility of the framework, while providing probabilistic bounds on the evaluation and the performance of the algorithms. Our results highlight the problem of generalizing the conclusions of the original published studies and show that based on the evaluation criteria, a controller can be shown to be better than other controllers. © 2016 ACM 2376-3639/2016/08-ART15 $15.00","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","4","1","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; Elasticity; Computation theory; Performance evaluation; Constrained optimization; Performance evaluations; Auto-scaling; Chance constrained optimization problems; Discrete-event simulators; Frequency dividing circuits; Performance evaluation frameworks; Probabilistic bounds; Probabilistic guarantees; Randomized optimization; Randomized optimizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXJTNJ59","journalArticle","2010","Krogmann, K.; Kuperberg, M.; Reussner, R.","Using genetic search for reverse engineering of parametric behavior models for performance prediction","IEEE Transactions on Software Engineering","","","10.1109/TSE.2010.69","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649781035&doi=10.1109%2fTSE.2010.69&partnerID=40&md5=90fc286a25c58fc1e393d8acdb79772d","In component-based software engineering, existing components are often reused in new applications. Correspondingly, the response time of an entire component-based application can be predicted from the execution durations of individual component services. These execution durations depend on the runtime behavior of a component which itself is influenced by three factors: the execution platform, the usage profile, and the component wiring. To cover all relevant combinations of these influencing factors, conventional prediction of response times requires repeated deployment and measurements of component services for all such combinations, incurring a substantial effort. This paper presents a novel comprehensive approach for reverse engineering and performance prediction of components. In it, genetic programming is utilized for reconstructing a behavior model from monitoring data, runtime bytecode counts, and static bytecode analysis. The resulting behavior model is parameterized over all three performance-influencing factors, which are specified separately. This results in significantly fewer measurements: The behavior model is reconstructed only once per component service, and one application-independent bytecode benchmark run is sufficient to characterize an execution platform. To predict the execution durations for a concrete platform, our approach combines the behavior model with platform-specific benchmarking results. We validate our approach by predicting the performance of a file sharing application. © 2006 IEEE.","2010","2025-10-22 19:07:43","2025-10-22 19:07:43","","865-877","","6","36","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Forecasting; Software engineering; Runtimes; Benchmarking; Response time; performance prediction; Models; Individual components; New applications; Performance prediction; Genetic programming; Runtime behaviors; Component-based software engineering; Behavior model; Bytecode analysis; bytecode benchmarking; Bytecodes; Component based applications; File sharing application; genetic programming; Genetic search; Influencing factor; Parameterized; reverse engineering; Reverse engineering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZV8DUVW","journalArticle","2015","Bastani, K.","","Spring Cloud Example Project","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058283557&partnerID=40&md5=94a0ded6fcd94e5b1a26bfdfd3e579c1","","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9226QSA","conferencePaper","2014","Spinner, S.; Casale, G.; Zhu, X.; Kounev, S.","LibReDE: A library for resource demand estimation","","","","10.1145/2568088.2576093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899689594&doi=10.1145%2f2568088.2576093&partnerID=40&md5=a02d48c5bd6b7f2bed864f10906054dc","When creating a performance model, it is necessary to quantify the amount of resources consumed by an application serving individual requests. In distributed enterprise systems, these resource demands usually cannot be observed directly, their estimation is a major challenge. Different statistical approaches to resource demand estimation based on monitoring data have been proposed, e.g., using linear regression or Kalman filtering techniques. In this paper, we present LibReDE, a library of ready-to-use implementations of approaches to resource demand estimation that can be used for online and offline analysis. It is the first publicly available tool for this task and aims at supporting performance engineers during performance model construction. The library enables the quick comparison of the estimation accuracy of different approaches in a given context and thus helps to select an optimal one.","2014","2025-10-22 19:07:43","2025-10-22 19:07:43","","227-228","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource demands; Engineering; Industrial engineering; Estimation; Performance Model; Enterprise system; Kalman filtering techniques; Online and offline analysis; Statistical approach","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2014 - Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"35JP3PHL","conferencePaper","2015","Willnecker, F.; Dlugi, M.; Brunnert, A.; Spinner, S.; Kounev, S.; Gottesheim, W.; Krcmar, H.","Comparing the accuracy of resource demand measurement and estimation techniques","","","","10.1007/978-3-319-23267-6_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944728289&doi=10.1007%2f978-3-319-23267-6_8&partnerID=40&md5=64bde25b287b84a76f9e8f3a6e723fad","Resource demands are a core aspect of performance models. They describe how an operation utilizes a resource and therefore influence the systems performance metrics: response time, resource utilization and throughput. Such demands can be determined by two extraction classes: direct measurement or demand estimation. Selecting the best suited technique depends on available tools, acceptable measurement overhead and the level of granularity necessary for the performance model. This work compares two direct measurement techniques and an adaptive estimation technique based on multiple statistical approaches to evaluate strengths and weaknesses of each technique. We conduct a series of experiments using the SPECjEnterprise2010 industry benchmark and an automatic performance model generator for architecture level performance models based on the Palladio Component Model. To compare the techniques we conduct two experiments with different levels of granularity on a standalone system, followed by one experiment using a distributed SPECjEnterprise2010 deployment combining both extraction classes for generating a full-stack performance model. © Springer International Publishing Switzerland 2015.","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","115-129","","","9272","","","","","","","","","","","","","Scopus","","","","","","","","Benchmarking; Resource utilizations; Resource demands; Extraction; Performance Model; Statistical approach; Adaptive estimation techniques; Estimation techniques; Performance model generation; Resource demand estimations; Resource demand measurements; Specjenterprise2010; Systems performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"5FB7X7GW","journalArticle","2017","Von Kistowski, J.; Herbst, N.; Kounev, S.; Groenda, H.; Stier, C.; Lehrig, S.","Modeling and extracting load intensity profiles","ACM Transactions on Autonomous and Adaptive Systems","","","10.1145/3019596","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009291187&doi=10.1145%2f3019596&partnerID=40&md5=378f9006f5e59f185f2e223ec42f94cd","Today's system developers and operators face the challenge of creating software systems that make efficient use of dynamically allocated resources under highly variable and dynamic load profiles, while at the same time delivering reliable performance. Autonomic controllers, for example, an advanced autoscaling mechanism in a cloud computing context, can benefit from an abstracted load model as knowledge to reconfigure on time and precisely. Existing workload characterization approaches have limited support to capture variations in the interarrival times of incoming work units over time (i.e., a variable load profile). For example, industrial and scientific benchmarks support constant or stepwise increasing load, or interarrival times defined by statistical distributions or recorded traces. These options show shortcomings either in representative character of load variation patterns or in abstraction and flexibility of their format. In this article, we present the Descartes Load Intensity Model (DLIM) approach addressing these issues. DLIM provides a modeling formalism for describing load intensity variations over time. A DLIM instance is a compact formal description of a load intensity trace. DLIM-based tools provide features for benchmarking, performance, and recorded load intensity trace analysis. As manually obtaining and maintaining DLIM instances becomes time consuming, we contribute three automated extraction methods and devised metrics for comparison and method selection. We discuss how these features are used to enhance systemmanagement approaches for adaptations during runtime, and how they are integrated into simulation contexts and enable benchmarking of elastic or adaptive behavior. We show that automatically extracted DLIM instances exhibit an average modeling error of 15.2% over 10 different real-world traces that cover between 2 weeks and 7 months. These results underline DLIM model expressiveness. In terms of accuracy and processing speed, our proposed extraction methods for the descriptive models are comparable to existing time series decomposition methods. Additionally, we illustrate DLIM applicability by outlining approaches of workload modeling in systems engineering that employ or rely on our proposed load intensity modeling formalism. © 2017 ACM.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","4","11","","","","","","","","","","","","","Scopus","","","","","","","","Benchmarking; Abstracting; Extraction; Dynamic loads; Load intensity; Load intensity variation; Load profile; Load profiles; Metamodeling; Model extraction; Open workloads; Transformation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7F2NB6H","journalArticle","2013","Bianchi, G.; Detti, A.; Caponi, A.; Blefari-Melazzi, N.","Check before storing: What is the performance price of content integrity verification in LRU caching?","Computer Communication Review","","","10.1145/2500098.2500106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901503736&doi=10.1145%2f2500098.2500106&partnerID=40&md5=83fcf69ce2177a6977e112d5c6aadaee","In some network and application scenarios, it is useful to cache content in network nodes on the y, at line rate. Resilience of in-network caches can be improved by guaranteeing that all content therein stored is valid. Digital signatures could be indeed used to verify content integrity and provenance. However, their operation may be much slower than the line rate, thus limiting caching of cryptographically verified objects to a small subset of the forwarded ones. How this affects caching performance? To answer such a question, we devise a simple analytical approach which permits to assess performance of an LRU caching strategy storing a randomly sampled subset of requests. A key feature of our model is the ability to handle traffic beyond the traditional Independent Reference Model, thus permitting us to understand how performance vary in different temporal locality conditions. Results, also verified on real world traces, show that content integrity verification does not necessarily bring about a performance penalty; rather, in some specific (but practical) conditions, performance may even improve.","2013","2025-10-22 19:07:43","2025-10-22 19:07:43","","60-67","","3","43","","","","","","","","","","","","","Scopus","","","","","","","","Application scenario; Communication; Caching; Authentication; Performance modeling; Performance penalties; Performance Model; Analytical approach; Content integrity verifications; Digital signatures; Electronic document identification systems; Independent reference models; Information centric networks; Information Centric Networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZXGFMR3","journalArticle","2017","Huber, N.; Brosig, F.; Spinner, S.; Kounev, S.; Bähr, M.","Model-based self-Aware performance and resource management using the descartes modeling language","IEEE Transactions on Software Engineering","","","10.1109/TSE.2016.2613863","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021706923&doi=10.1109%2fTSE.2016.2613863&partnerID=40&md5=6a2eed2925417c44cec41c3a25ea3c25","Modern IT systems have increasingly distributed and dynamic architectures providing flexibility to adapt to changes in the environment and thus enabling higher resource efficiency. However, these benefits come at the cost of higher system complexity and dynamics. Thus, engineering systems that manage their end-To-end application performance and resource efficiency in an autonomic manner is a challenge. In this article, we present a holistic model-based approach for self-Aware performance and resource management leveraging the Descartes Modeling Language (DML), an architecture-level modeling language for online performance and resource management. We propose a novel online performance prediction process that dynamically tailors the model solving depending on the requirements regarding accuracy and overhead. Using these prediction capabilities, we implement a generic modelbased control loop for proactive system adaptation. We evaluate our model-based approach in the context of two representative case studies showing that with the proposed methods, significant resource efficiency gains can be achieved while maintaining performance requirements. These results represent the first end-To-end validation of our approach, demonstrating its potential for self-Aware performance and resource management in the context of modern IT systems and infrastructures. © 2016 IEEE.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","432-452","","5","43","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Natural resources management; Resource allocation; Efficiency; Modeling languages; Model-based OPC; Adaptation; Autonomic; Model-based; Modeling language; Self-aware; Self-Aware","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXQAXERZ","journalArticle","2009","Van Hoorn, A.; Rohr, M.; Hasselbring, W.; Waller, J.; Ehlers, J.; Frey, S.; Kieselhorst, D.","Continuous monitoring of software services: Design and application of the kieker framework","Continuous Monitoring of Software Services: Design and Application of the Kieker Framework","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952129079&partnerID=40&md5=d55f0c7f2ad675b73aa55be6f4a70f72","","2009","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7V8T2Q9K","conferencePaper","2001","Sitaraman, M.; Kulczycki, G.; Krone, J.; Ogden, W.F.; Reddy, A.L.N.","Performance specification of software components","","","","10.1145/379377.375223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035790616&doi=10.1145%2f379377.375223&partnerID=40&md5=c90a03984af9adef91250961f9bbd3c9","Component-based software engineering is concerned with predictability in both functional and performance behavior, though most formal techniques have typically focused their attention on the former. Reasoning about the (functional or performance) behavior of a component-based system must be compositional in order to be scalable. Compositional performance reasoning demands that components include performance specifications, in addition to descriptions of functional behavior. Unfortunately, as explained in this paper, classical techniques and notations for performance analysis are either unsuitable or unnatural to capture performance behaviors of generic software components. They fail to work in the presence of parameterization and layering. The paper introduces elements of a compositional approach to performance analysis using a detailed example. It explains that performance specification problems are so basic that there are unresolved research issues to be tackled even for the simplest reusable components. These issues must be tackled by any practical proposal for sound performance reasoning. Only then will software developers be able to engineer new systems by Choosing and assembling components that best fit their performance (time and space) requirements.","2001","2025-10-22 19:07:43","2025-10-22 19:07:43","","3-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","Data structures; Software engineering; Data storage equipment; Specifications; Software components; Data Structures; Generic Objects; Storage Management; Time & Space Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of SSR'01 2001 Symposium on Software Reusability","","","","","","","","","","","","","","",""
"QYZTBVBW","journalArticle","2000","Arlitt, M.; Jin, T.","Workload characterization study of the 1998 World Cup Web site","IEEE Network","","","10.1109/65.844498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033690948&doi=10.1109%2f65.844498&partnerID=40&md5=0f65b842deb7348874717cdb0ff42e17","This article presents a detailed workload characterization study of the 1998 World Cup Web site. Measurements from this site were collected over a three-month period. During this time the site received 1.35 billion requests, making this the largest Web workload analyzed to date. By examining this extremely busy site and through comparison with existing characterization studies, we are able to determine how Web server workloads are evolving. We find that improvements in the caching architecture of the World Wide Web are changing the workloads of Web servers, but major improvements to that architecture are still necessary. In particular, we uncover evidence that a better consistency mechanism is required for World Wide Web caches.","2000","2025-10-22 19:07:43","2025-10-22 19:07:43","","30-37","","3","14","","","","","","","","","","","","","Scopus","","","","","","","","Computer systems programming; Data communication systems; World Wide Web; Response time (computer systems); Client server computer systems; Telecommunication traffic; Congestion control (communication); Web servers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HY566N9A","journalArticle","2018","Lehrig, S.; Sanders, R.; Brataas, G.; Cecowski, M.; Ivanšek, S.; Polutnik, J.","CloudStore — towards scalability, elasticity, and efficiency benchmarking and analysis in Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2017.04.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018428867&doi=10.1016%2fj.future.2017.04.018&partnerID=40&md5=2497fbf19368ffe5ac5014e417b74cad","This paper describes CloudStore, an open source application that lends itself to analyzing key characteristics of Cloud computing platforms. Based on an earlier standard from transaction processing, it represents a simplified version of a typical e-commerce application–an electronic book store. We detail how a deployment on a popular public cloud offering can be instrumented to gain insight into system characteristics such as capacity, scalability, elasticity and efficiency. Based on our insights, we create a CloudStore performance model, allowing to accurately predict such properties already at design time. © 2017 Elsevier B.V.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","115-126","","","78","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Performance; Open systems; Elasticity; Web services; Efficiency; Amazon web services; E-Commerce applications; Scalability; Measurements; Amazon Web Services; Cloud computing platforms; Capacity; Efficiency benchmarking; Open source application; System characteristics; TPC-W","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MPS4SG6","journalArticle","2010","Benz, D.; Hotho, A.; Jäschke, R.; Krause, B.; Mitzlaff, F.; Schmitz, C.; Stumme, G.","The social bookmark and publication management system bibsonomy","VLDB Journal","","","10.1007/s00778-010-0208-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650521205&doi=10.1007%2fs00778-010-0208-4&partnerID=40&md5=445da64fbb3aacb6cb5a29187fdca7e6","Social resource sharing systems are central elements of the Web 2.0 and use the same kind of lightweight knowledge representation, called folksonomy. Their large user communities and ever-growing networks of user-generated content have made them an attractive object of investigation for researchers from different disciplines like Social Network Analysis, Data Mining, Information Retrieval or Knowledge Discovery. In this paper, we summarize and extend our work on different aspects of this branch of Web 2.0 research, demonstrated and evaluated within our own social bookmark and publication sharing system BibSonomy, which is currently among the three most popular systems of its kind. We structure this presentation along the different interaction phases of a user with our system, coupling the relevant research questions of each phase with the corresponding implementation issues. This approach reveals in a systematic fashion important aspects and results of the broad bandwidth of folksonomy research like capturing of emergent semantics, spam detection, ranking algorithms, analogies to search engine log data, personalized tag recommendations and information extraction techniques. We conclude that when integrating a real-life application like BibSonomy into research, certain constraints have to be considered; but in general, the tight interplay between our scientific work and the running system has made BibSonomy a valuable platform for demonstrating and evaluating Web 2.0 research. © 2010 Springer-Verlag.","2010","2025-10-22 19:07:43","2025-10-22 19:07:43","","849-875","","6","19","","","","","","","","","","","","","Scopus","","","","","","","","Data mining; Classification (of information); Web services; Running systems; Research; Semantic Web; Semantics; Log data; Knowledge representation; Research questions; BibSonomy; Broad bandwidths; Central elements; Collaborative tagging; Electric network analysis; Folksonomies; Folksonomy; Information extraction techniques; Information retrieval; Knowledge Discovery; Management systems; Ranking algorithm; Real-life applications; Resource sharing systems; Search engines; Sharing systems; Social Network Analysis; Spam detection; Tag recommendations; User communities; User-generated content; Web 2.0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9IWJ8A3C","journalArticle","","","","Standard Performance Evaluation Corporation (SPEC) SPEC JEnterprise 2010 Design Document","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058336784&partnerID=40&md5=c011fe9c7b9ddbb71efc44f94d299c81","","","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92TAI77R","journalArticle","2018","Ilyushkin, A.; Ali-Eldin, A.; Herbst, N.; Bauer, A.; Papadopoulos, A.V.; Epema, D.; Iosup, A.","An experimental performance evaluation of autoscalers for complex workflows","ACM Transactions on Modeling and Performance Evaluation of Computing Systems","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058277561&partnerID=40&md5=83e1b37d732f52cf8862eaa5accff449","","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","2","3","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJSXBP43","journalArticle","2017","","","Weaveworks Inc Sock Shop: A Microservice Demo Application Accessed: 19.10.2017","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058315585&partnerID=40&md5=8bf7469d03ffcaae09cbc4e32c6bfba8","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5S3NCBB","journalArticle","2017","","","Greencloud - The Green Cloud Simulator","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100766769&partnerID=40&md5=9e3da01ca853c62fca50013719ba2773","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G8AEVN54","journalArticle","2009","Jones, M.T.","Inside the linux 2.6 completely fair scheduler","Inside the Linux 2.6 Completely Fair Scheduler","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751519891&partnerID=40&md5=b2f473806b87bc5dd5b8983bd2360473","","2009","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PAEU4JHI","journalArticle","2004","","","Enhanced Intel SpeedStep Technology for the Intel Pentium M Processor","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746279684&partnerID=40&md5=caf5513fb73ecdf14a9b669e30ddc5b4","","2004","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JI4QLGCU","journalArticle","2017","","","Samsung V-NAND Ssd 860 Evo","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100738579&partnerID=40&md5=6cfd312038f753ade131473f69c87c38","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJ9BDHGV","journalArticle","2018","","","Network Simulation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100702819&partnerID=40&md5=d58e4d3fee94e93ff4f03b0d864e8f36","","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6ZTGBJF","conferencePaper","2017","Gupta, H.; Vahid Dastjerdi, A.; Ghosh, S.K.; Buyya, R.","iFogSim: A toolkit for modeling and simulation of resource management techniques in the Internet of Things, Edge and Fog computing environments","","","","10.1002/spe.2509","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021248358&doi=10.1002%2fspe.2509&partnerID=40&md5=f5351d8461158bc62bf3f14acd916f12","Internet of Things (IoT) aims to bring every object (eg, smart cameras, wearable, environmental sensors, home appliances, and vehicles) online, hence generating massive volume of data that can overwhelm storage systems and data analytics applications. Cloud computing offers services at the infrastructure level that can scale to IoT storage and processing requirements. However, there are applications such as health monitoring and emergency response that require low latency, and delay that is caused by transferring data to the cloud and then back to the application can seriously impact their performances. To overcome this limitation, Fog computing paradigm has been proposed, where cloud services are extended to the edge of the network to decrease the latency and network congestion. To realize the full potential of Fog and IoT paradigms for real-time analytics, several challenges need to be addressed. The first and most critical problem is designing resource management techniques that determine which modules of analytics applications are pushed to each edge device to minimize the latency and maximize the throughput. To this end, we need an evaluation platform that enables the quantification of performance of resource management policies on an IoT or Fog computing infrastructure in a repeatable manner. In this paper we propose a simulator, called iFogSim, to model IoT and Fog environments and measure the impact of resource management techniques in latency, network congestion, energy consumption, and cost. We describe two case studies to demonstrate modeling of an IoT environment and comparison of resource management policies. Moreover, scalability of the simulation toolkit of RAM consumption and execution time is verified under different circumstances. Copyright © 2017 John Wiley & Sons, Ltd.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","1275-1296","","","47","","","","","","","","","","","","","Scopus","","","","","","","","Online systems; Distributed computer systems; Energy utilization; Internet of things; Edge computing; Internet of Things (IOT); Natural resources management; Resource allocation; Digital storage; Fog computing; Computing environments; Resource management policy; Environmental management; Internet of Things (IoT); Model and simulation; Computing infrastructures; Random access storage; Fog; Resource management techniques; Industrial management; modeling and simulation; Domestic appliances; Evaluation platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Software - Practice and Experience","","","","","","","","","","","","","","",""
"2TZLI9JW","journalArticle","2016","","","Desktop Hdd Product Manual","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100813024&partnerID=40&md5=689610d04b90f0283edb78919307b376","","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6A4VET4Q","journalArticle","2020","","","IP Wan Emulator","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100762625&partnerID=40&md5=635556cb558ca45595414e6e45d05e35","","2020","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5B3N8WHX","conferencePaper","2018","Agrawal, S.; Shailendra, S.; Panigrahi, B.; Rath, H.K.; Simha, A.","O-ICN Simulator (OICNSIM) an NS-3 based simulator for overlay information centric networking (O-ICN)","","","","10.1145/3265997.3266000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061480842&doi=10.1145%2f3265997.3266000&partnerID=40&md5=a638f492f9ebe12eb8aafe3cfdf2ce62","Information Centric Networking (ICN) is envisioned to advocate the efficient usage of the networking resources. Overlay ICN (O-ICN), a newly proposed architecture for ICN, is designed to be backward compatible and interoperable with the current Internet. O-ICN architecture can also be incrementally deployed without forcing the operators to upgrade the entire network at the same time. In this paper, we present the Overlay ICN simulator (OICNSIM) to simulate the O-ICN architecture. Additionally, we have studied the performance of OICNSIM for different ICN caching policies. © 2018 Association for Computing Machinery.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","13-15","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Network architecture; Proposed architectures; 'current; Simulators; Information-centric networkings; Backward compatible; Caching policy; Forcings; Networking architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM","","","","","","","","","","","","","","",""
"T9SIP7MG","conferencePaper","2014","Da, K.; Dalmau, M.; Roose, P.","Kalimucho: Middleware for mobile applications","","","","10.1145/2554850.2554883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905652787&doi=10.1145%2f2554850.2554883&partnerID=40&md5=c88b567dba93ee6384b57b3bbd3ba1ee","Developing ubiquitous applications is particularly complex. Beyond the dynamic aspect of such applications, the evolution of computing towards the multiplication of mobile access terminals is not making things easier. One solution to simplifying the development and use of such applications is to use software platforms dedicated to deployment and adaptation of applications and handling the heterogeneity of peripherals. They allow designers to focus on business aspects and facilitate reuse. The Kalimucho platform was designed and developed against this background. It executes and supervises applications based on software components. Copyright 2014 ACM.","2014","2025-10-22 19:07:43","2025-10-22 19:07:43","","413-419","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Performance; Software component; Design; Middleware; Mobile applications; Query languages; Reliability; Measurement; Measurements; Business aspects; Dynamic aspects; Languages; Mobile access; Software platforms; Ubiquitous application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Symposium on Applied Computing","","","","","","","","","","","","","","",""
"F7UNC99D","conferencePaper","2014","Zhan, K.; Lung, C.-H.; Srivastava, P.","A green analysis of mobile cloud computing applications","","","","10.1145/2554850.2555069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905637579&doi=10.1145%2f2554850.2555069&partnerID=40&md5=a1b9a6bbb272621e55d54e65fd49f773","With the widespread of rich mobile applications, the usage of mobile devices, especially smart phones and tablets, has become popular nowadays. However, battery in the mobile devices often limits continuous usages with its small size and capacity. Therefore, power consumption of mobile devices is a critical issue, not only for extending lifetime use of mobile devices, but also for creating a green IT which is a raising concern in academic and industrial communities. The goal of this paper is to investigate the power consumption of mobile devices and resource usages for various applications. To meet the goal, we have performed a number of experiments and detailed evaluations of resource usages and power consumption for various applications using a number of tools. In addition, we have measured performance metrics for applications either using a mobile device or running in the Amazon cloud. We examine the impact of various factors and provide insights on power consumption for different mobile applications. Copyright 2014 ACM.","2014","2025-10-22 19:07:43","2025-10-22 19:07:43","","357-362","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Performance metrics; Mobile devices; Mobile applications; Mobile computing; Mobile cloud computing; Green computing; Resource usage; CPU; Power consumption; Amazon; Critical issues; Industrial communities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Symposium on Applied Computing","","","","","","","","","","","","","","",""
"PX4IVHRI","journalArticle","2016","","","Containercloudsim: An Environment for Modeling and Simulation of Containers in Cloud Data Centers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100702586&partnerID=40&md5=ac0d531391dbc5a95cf32d5ba3db2283","","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G8WSI2EZ","journalArticle","2015","Bongers, E.; Pouwelse, J.","","A Survey of P2P Multidimensional Indexing Structures","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009829721&partnerID=40&md5=2af19d476143121dc7585daaf730226d","","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGCDQHND","journalArticle","2019","de M. Del Esposte, A.; Santana, E.F.Z.; Kanashiro, L.; Costa, F.M.; Braghetto, K.R.; Lago, N.; Kon, F.","Design and evaluation of a scalable smart city software platform with large-scale simulations","Future Generation Computer Systems","","","10.1016/j.future.2018.10.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056458360&doi=10.1016%2fj.future.2018.10.026&partnerID=40&md5=7d224d740a6105559dbb9c95abd0b280","Smart Cities combine advances in Internet of Things, Big Data, Social Networks, and Cloud Computing technologies with the demand for cyber–physical applications in areas of public interest, such as Health, Public Safety, and Mobility. The end goal is to leverage the use of city resources to improve the quality of life of its citizens. Achieving this goal, however, requires advanced support for the development and operation of applications in a complex and dynamic environment. Middleware platforms can provide an integrated infrastructure that enables solutions for smart cities by combining heterogeneous city devices and providing unified, high-level facilities for the development of applications and services. Although several smart city platforms have been proposed in the literature, there are still open research and development challenges related to their scalability, maintainability, interoperability, and reuse in the context of different cities, to name a few. Moreover, available platforms lack extensive scientific validation, which hinders a comparative analysis of their applicability. Aiming to close this gap, we propose InterSCity, a microservices-based, open-source, smart city platform that enables the collaborative development of large-scale systems, applications, and services for the cities of the future, contributing to turn them into truly smart cyber–physical environments. In this paper, we present the architecture of the InterSCity platform, followed by a comprehensive set of experiments that evaluate its scalability. The experiments were conducted using a smart city simulator to generate realistic workloads used to assess the platform in extreme conditions. The experimental results demonstrate that the platform can scale horizontally to handle the highly dynamic demands of a large smart city while maintaining low response times. The experiments also show the effectiveness of the technique used to generate synthetic workloads. © 2018 Elsevier B.V.","2019","2025-10-22 19:07:43","2025-10-22 19:07:43","","427-441","","","93","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Microservices; Big data; Large scale systems; Distributed computer systems; Open systems; Dynamics; Middleware; Smart city; Scalability; Open sources; Open source; Simulation; Smart cities; Cloud computing technologies; Collaborative development; Development and operations; Integrated infrastructure; Smart urban spaces; Social sciences computing; Urban spaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TRTGFQ7","journalArticle","2025","Blog, N.T.","","Netflix Conductor: A Microservices Orchestrator","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088595149&partnerID=40&md5=4e2096496f24a0abd19ff8a02142cc5f","","2025","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XP6BJW3Y","journalArticle","2011","Chiaravalloti, S.; Idzikowski, F.; Budzisz, L.","Power consumption of WLAN network elements","Power Consumption of WLAN Network Elements","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865796739&partnerID=40&md5=c02a2b7082d8f28c1c0b3914d64daff3","","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWSZDT8L","conferencePaper","2014","Cornea, B.F.; Orgerie, A.-C.; Lefèvre, L.","Studying the energy consumption of data transfers in Clouds: The Ecofen approach","","","","10.1109/CloudNet.2014.6968983","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925859008&doi=10.1109%2fCloudNet.2014.6968983&partnerID=40&md5=dcd337cdf783b075b4254c04e9ecb48b","Energy consumption is one of the main limiting factors for designing large scale Clouds. Evaluating the energy consumption of Clouds networking architectures and providing multi-level views required by providers and users, is a challenging issue. In this paper, we show how to evaluate and understand network choices (protocols, topologies) in terms of contributions to the energy consumption of the global Cloud infrastructures. By applying the ECOFEN model (Energy Consumption mOdel For End-to-end Networks) and the corresponding simulation framework, we profile and analyze the energy consumption of data transfers in Clouds. © 2014 IEEE.","2014","2025-10-22 19:07:43","2025-10-22 19:07:43","","143-148","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Green computing; simulation; energy consumption; Energy consumption model; Data transfer; Simulation framework; Cloud data; Networking architecture; Cloud data transfers; End-to-end network; ethernet networks; Ethernet networks; Global clouds","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 IEEE 3rd International Conference on Cloud Networking, CloudNet 2014","","","","","","","","","","","","","","",""
"SRTURERB","journalArticle","2016","Novotny, P.; Wolf, A.L.","Simulating services-based systems hosted in networks with dynamic topology","Simulating Services-based Systems Hosted in Networks with Dynamic Topology","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047181173&partnerID=40&md5=bd1c57a545e32645f42742bd48b8d8ec","","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6C76LFEH","conferencePaper","2004","Sundresh, S.; Kim, W.; Agha, G.","SENS: A sensor, environment and network simulator","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-3142724988&partnerID=40&md5=bc33435ebf398a4fabe49df46b9366d6","Recent advances in micro electro-mechanical systems and VLSI lithography have enabled the miniaturization of sensors and controllers. Such minitiarization facilitates the deployment of large-scale wireless sensor networks (WSNs). However, the considerable cost of deploying and maintaining large-scale WSNs for experimental purposes makes simulation useful in developing dependable and portable WSN applications. SENS is a customizable sensor network simulator for WSN applications, consisting of interchangeable and extensible components for applications, network communication, and the physical environment. Multiple component implementations in SENS offer varying degrees of realism. Users can assemble application-specific environments; such environments are modeled in SENS by their different signal propagation characteristics. The same source code that is executed on simulated sensor nodes in SENS may also be deployed on actual sensor nodes; this enables application portability. Furthermore, SENS provides diagnostic facilities such as power utilization analysis for development of dependable applications. We validate and demonstrate usability of these capabilities through analyzing two simple WSN services.","2004","2025-10-22 19:07:43","2025-10-22 19:07:43","","221-228","","","","","","","","","","","","","","","","Scopus","","","","","","","","Signal processing; Computation theory; Wireless telecommunication systems; VLSI circuits; Microprocessor chips; Sensors; Control equipment; Lithography; Microelectromechanical devices; Network communication; VLSI lithography; Wireless sensor networks (WSN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the IEEE Annual Simulation Symposium","","","","","","","","","","","","","","",""
"JCUUFWVG","conferencePaper","2017","Nikdel, Z.; Gao, B.; Neville, S.W.","DockerSim: Full-stack simulation of container-based Software-as-a-Service (SaaS) cloud deployments and environments","","","","10.1109/PACRIM.2017.8121898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043471766&doi=10.1109%2fPACRIM.2017.8121898&partnerID=40&md5=85b8169e3568e6f3631063bdda732342","Container-based Software-as-a-Service (SaaS) systems are rapidly emerging as a dominate cloud deployment paradigm, as supported via Docker, etc. This has opened new research avenues as lighter-weight containers replace heavierweight virtual machines (VMs) as atomic cloud deployment units. Advancing such research requires sufficiently rich, containeraware cloud simulation frameworks so as to explore issues such as optimal cloud orchestration and elastic service strategies, achieving assured application-layer quality of service (QoS), etc. This work presents DockerSim, an extension and augmentation of the iCanCloud OMNet++ cloud simulator to incorporate: i) a full container deployment and behavioral layer, ii) full packet-level network and protocol behaviors, iii) full multi-layer OS process scheduling behaviors, and iv) a generic queuing network approach to modeling application-layer SaaS deployments. To our knowledge DockerSim is the first cloud simulation platform fully incorporating capabilities (i)-(iv), as required to rigorous explore a wide range of timing sensitive container-based computing cloud and SaaS-deployment issues. © 2017 IEEE.","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","1-6","","","2017-January","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Containers; Signal processing; Cloud computing; Cloud Computing; Computer software; Web services; Application layers; Software as a service (SaaS); Simulation; Cloud deployments; Cloud simulation; Cloud simulation platforms; Container-as-a-Service(CaaS); Docker-style container simulation; Full-stack cloud simulation; Model application; Process scheduling; Software-as-a-Service (SaaS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, PACRIM 2017 - Proceedings","","","","","","","","","","","","","","",""
"HZ45E7VZ","journalArticle","2020","","","Cisco Packet Tracer","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091950863&partnerID=40&md5=13e8d067e8816e2ac2de13a00c3e8d38","","2020","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTH4V8BG","conferencePaper","2015","Kiertscher, S.; Schnor, B.","Scalability evaluation of an energy-aware resource management system for clusters of web servers","","","","10.1109/SPECTS.2015.7285285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992036358&doi=10.1109%2fSPECTS.2015.7285285&partnerID=40&md5=8fde33c6f96f037481f6dcf2f4c96100","For green cluster computing resource management systems have to be energy-aware. CHERUB is such an energy-aware resource management system which works together with the Linux Virtual Server. Experiments in a small cluster setup with two nodes have shown the benefit of CHERUB. This paper presents necessary design changes to make CHERUB also work in big cluster setups. Our methodological approach is two-fold. First, we present unit measurements to evaluate the scaling of the re-implemented functions. Second, a cluster simulator is presented and validated which makes it possible to test CHERUB for backend clusters of arbitrary size. © 2015 Society for Modeling and Simulation International.","2015","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Computer operating systems; Energy Efficiency; Cluster computing; Computer architecture; Natural resources management; Resource allocation; Scalability; Green IT; Simulation; Energy management systems; Green-IT; Computing resource management; Resource management systems; Energy awareness; Cluster Computing; Energy Awareness; Integrated modeling; Integrated Modeling and Measurement; Methodological approach; Scalability evaluation; Scalability Studies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2015 International Symposium on Performance Evaluation of Computer and Telecommunication Systems, SPECTS 2015 - Part of SummerSim 2015 Multiconference","","","","","","","","","","","","","","",""
"VS727WK3","conferencePaper","2019","Valera, H.H.L.; Dalmau, M.; Roose, P.; Herzog, C.","The Architecture of Kaligreen V2: A Middleware Aware of Hardware Opportunities to Save Energy","","","","10.1109/IOTSMS48152.2019.8939237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077969153&doi=10.1109%2fIOTSMS48152.2019.8939237&partnerID=40&md5=7b937f6435a19d89b288227377d059e7","Nowadays, energy saving in the use of information technologies is a very important issue both from the economic and sustainability point of view. Many scientists investigate methods to save energy at different application levels (cloud: i.e., architectures, grid: i.e., middlewares and frameworks and hardware management: i.e., operating systems) and many of them agree on the strategy of executing programs, processes or virtual machines only using the time and resources that are strictly necessary. For this, it is necessary to plan strategies for deployment and relocation of processes; but always taking into account hardware repercussions and the knowledge of the architecture and applications behavior. On the other hand, it has already been demonstrated that the use of microservices brings numerous advantages in availability and efficiency; but we do not find many jobs that exploit this technique on the energy level. In this article, we present the architecture of a middleware for distributed microservices-based applications, which allows any negotiation-based scheduling algorithm to duplicate or move microservices from one device to another in a non-centralized way for energy savings, taking into account the consumption characteristics of the microservices and the capabilities that the hardware components offer. © 2019 IEEE.","2019","2025-10-22 19:07:43","2025-10-22 19:07:43","","79-86","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; microservices; Program processors; Internet of things; Network architecture; Networks (circuits); Middleware; Energy conservation; CPU; Scheduling algorithms; Application level; energy; middleware; consumption; hard disk; network; Hard disk storage; Hardware components; Hardware management; Information use; Save energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 6th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2019","","","","","","","","","","","","","","",""
"GRF9Z7FD","conferencePaper","2019","Zhang, Y.; Gan, Y.; Delimitrou, C.","μqSim: Enabling Accurate and Scalable Simulation for Interactive Microservices","","","","10.1109/ISPASS.2019.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065406209&doi=10.1109%2fISPASS.2019.00034&partnerID=40&md5=6d6d2dddbd199083af596f9b032e8407","Current cloud services are moving away from monolithic designs and towards graphs of many loosely-coupled, single-concerned microservices. Microservices have several advantages, including speeding up development and deployment, allowing specialization of the software infrastructure, and helping with debugging and error isolation. At the same time they introduce several hardware and software challenges. Given that most of the performance and efficiency implications of microservices happen at scales larger than what is available outside production deployments, studying such effects requires designing the right simulation infrastructures. We present j);qSim, a scalable and validated queueing network simulator designed specifically for interactive microser-vices. μqSim provides detailed intra- and inter-microservice models that allow it to faithfully reproduce the behavior of complex, many-tier applications. μqSim is also modular, allowing reuse of individual models across microservices and end-to-end applications. We have validated μqSim both against simple and more complex microservices graphs, and have shown that it accurately captures performance in terms of throughput and tail latency. Finally, we use μqSim to model the tail at scale effects of request fanout, and the performance impact of power management in latency -sensitive microservices. © 2019 IEEE.","2019","2025-10-22 19:07:43","2025-10-22 19:07:43","","212-222","","","","","","","","","","","","","","","","Scopus","","","","","","","","Program debugging; Performance impact; Hardware and software; End-to-end application; Complex networks; Network simulators; Loosely coupled; Software infrastructure; Individual models; Monolithic design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2019 IEEE International Symposium on Performance Analysis of Systems and Software, ISPASS 2019","","","","","","","","","","","","","","",""
"TRZHY8TU","conferencePaper","2016","Azmy, N.M.; El-Maddah, I.A.M.; Mohamed, H.K.","Adaptive power panel of cloud computing controlling cloud power consumption","","","","10.1145/2944165.2944167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985990751&doi=10.1145%2f2944165.2944167&partnerID=40&md5=c5b64478913d045dc22f54d9b7cff5fa","Cloud computing had created a new era of network design, where end-users can get their required services without having to purchase expensive infrastructure or even to care about troubleshooting. Power consumption is a challenge facing the Cloud Providers to operate their Datacenters. One solution to overcome this is the Virtual Machine (VM) migration, which is a technique used to switch under-utilized hosts to sleep mode in order to save power, and to avoid over-utilized hosts from Service Level Agreement (SLA) violation. But still the problem is that the Cloud Service Provider apply a single policy on all nodes. Our proposed solution is an adaptive power panel where different policies can be applied based on both of the nature of the tasks running on hosts, and the Cloud Provider decision. © 2016 ACM.","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","9-14","","","28-29-May-2016","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Cloud computing; Distributed computer systems; Software engineering; Virtual machines; Migration; Green computing; Virtual Machine; Placement; Green Computing; Adaptive; Allocation; Cloudsim; Selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"YZK5LMAR","conferencePaper","2018","Lvarez-Valera, H.H.; Roose, P.; Dalmau, M.; Herzog, C.; Respicio, K.","Kali green: A distributed scheduler for energy saving","","","","10.1016/j.procs.2018.10.172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058349351&doi=10.1016%2fj.procs.2018.10.172&partnerID=40&md5=762a84024c90ed200594143af3fc90ed","A commonplace issue with portable technology is battery efficiency. While many industries are trying their best to improve battery life without sacrificing a products quality and efficiency, we believe that further can be done to improve battery consumption on ones mobile devicefrom tablets to smartphones to laptops to everything else. Many applications on these devices are based on a microservice architecture. In this article, we introduce a new algorithm KaliGreen that can maneuver the microservices within a network of devices in order to maximize the run-time of a microservice-based application; moreover, KaliGreen allows a 54% increase in the average run-time of an application by shifting microservices from 6 devices (as example) with low battery or inefficient processing ratios to devices in better conditions. To achieve this, KaliGreen utilizes KaliMucho middleware, which is able manipulate microservices in run-time. This algorithm provides a plausible solution to maximizing energy consumption within a network of devices. © 2018 The Authors. Published by Elsevier Ltd.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","223-230","","","141","","","","","","","","","","","","","Scopus","","","","","","","","Electric batteries; Microservices; Energy utilization; Middleware; Smartphones; Green computing; Energy conservation; Distributed schedulers; Green Computing; Battery consumption; Battery efficiencies; Battery life; Distributed applicatioggns; mHealth; Portable technologies; Products quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Procedia Computer Science","","","","","","","","","","","","","","",""
"HDIPCQVD","journalArticle","2020","","","Debug Your App, Not Your Environment","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087273352&partnerID=40&md5=d1ea1829764f9ff729983d6da3150d70","","2020","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RDBDZDVB","journalArticle","2019","Services, A.W.","","Implementing Microservices on Aws","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100772318&partnerID=40&md5=c64d1506936741d57056a6ff7d1375dc","","2019","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","2019","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZTHRKKU","conferencePaper","2011","Orgerie, A.-C.; Lefèvre, L.; Guérin-Lassous, I.; Lopez Pacheco, D.M.","ECOFEN: An end-to-end energy cost model and simulator for evaluating power consumption in large-scale networks","","","","10.1109/WoWMoM.2011.5986203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052698432&doi=10.1109%2fWoWMoM.2011.5986203&partnerID=40&md5=59543a30d002fd0aae1815e186a1e3f4","Wired networks are increasing in size and their power consumption is becoming a matter of concern. Evaluating the end-to-end electrical cost of new network architectures and protocols is difficult due to the lack of monitored realistic infrastructures. We propose an End-to-End energy Cost mOdel and simulator For Evaluating power consumption in large-scale Networks (ECOFEN) whose user's entries are the network topology and traffic. Based on configurable measurement of different network components (routers, switches, NICs, etc.), it provides the power consumption of the overall network including the end-hosts as well as the power consumption of each equipment over time. © 2011 IEEE.","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Network architecture; Wireless networks; Costs; Topology; Energy cost; Network topology; Power consumption; Simulators; Network simulator; Wired networks; Configurable; Electric network topology; Electrical costs; Energy cost model; Large-scale network; Switches; Time switches","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, WoWMoM 2011 - Digital Proceedings","","","","","","","","","","","","","","",""
"YBVL5GJT","journalArticle","2022","Camilli, M.; Janes, A.; Russo, B.","Automated test-based learning and verification of performance models for microservices systems","Journal of Systems and Software","","","10.1016/j.jss.2022.111225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124274286&doi=10.1016%2fj.jss.2022.111225&partnerID=40&md5=5f4a1691c78038edaca0ea24e420f6f2","Effective and automated verification techniques able to provide assurances of performance and scalability are highly demanded in the context of microservices systems. In this paper, we introduce a methodology that applies specification-driven load testing to learn the behavior of the target microservices system under multiple deployment configurations. Testing is driven by realistic workload conditions sampled in production. The sampling produces a formal description of the users’ behavior through a Discrete Time Markov Chain. This model drives multiple load testing sessions that query the system under test and feed a Bayesian inference process which incrementally refines the initial model to obtain a complete specification from run-time evidence as a Continuous Time Markov Chain. The complete specification is then used to conduct automated verification by using probabilistic model checking and to compute a configuration score that evaluates alternative deployment options. This paper introduces the methodology, its theoretical foundation, and the toolchain we developed to automate it. Our empirical evaluation shows its applicability, benefits, and costs on a representative microservices system benchmark. We show that the methodology detects performance issues, traces them back to system-level requirements, and, thanks to the configuration score, provides engineers with insights on deployment options. The comparison between our approach and a selected state-of-the-art baseline shows that we are able to reduce the cost up to 73% in terms of number of tests. The verification stage requires negligible execution time and memory consumption. We observed that the verification of 360 system-level requirements took ∼1 minute by consuming at most 34 KB. The computation of the score involved the verification of ∼7k (automatically generated) properties verified in ∼72 seconds using at most ∼50 KB. © 2022 The Author(s)","2022","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","187","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Automation; Learning systems; Markov processes; Bayesian networks; Performance Modeling; Inference engines; Specifications; Model checking; Continuous time systems; Load testing; Automated test; Automated verification; Markov modeling; Markov models; Model learning; Performance testing; Statistical tests; System-level requirements; Test-based model learning; Verification techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RW2QE3IH","conferencePaper","2011","Ghanbari, H.; Simmons, B.; Litoiu, M.; Iszlai, G.","Exploring alternative approaches to implement an elasticity policy","","","","10.1109/CLOUD.2011.101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053169900&doi=10.1109%2fCLOUD.2011.101&partnerID=40&md5=7dde0a70b9837e8c4ea7bdde16f7f28e","An elasticity policy governs how and when resources (e.g., application server instances at the PaaS layer) are added to and/or removed from a cloud environment. The elasticity policy can be implemented as a conventional control loop or as a set of heuristic rules. In the control-theoretic approach, complex constructs such as tracking filters, estimators, regulators, and controllers are utilized. In the heuristic, rule-based approach, various alerts (e.g., events) are defined on instance metrics (e.g., CPU utilization), which are then aggregated at a global scale in order to make provisioning decisions for a given application tier. This work provides an overview of our experiences designing and working with both approaches to construct an autoscaler for simple applications. We enumerate different criteria such as design complexity, ease of comprehension, and maintenance upon which we form an informal comparison between the different methods. We conclude with a brief discussion of how these approaches can be used in the governance of resources to better meet a high-level goal over time. © 2011 IEEE.","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","716-723","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Elasticity; CPU utilization; Alternative approach; Application Servers; Control-theoretic approach; Conventional control; Design complexity; Global scale; Heuristic rules; Rule-based approach; Tracking filter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2011 IEEE 4th International Conference on Cloud Computing, CLOUD 2011","","","","","","","","","","","","","","",""
"MP8EKM5Q","journalArticle","2024","","","Container Resize Policies","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213702158&partnerID=40&md5=20b3c24101fab98ff919f53a67485f5f","","2024","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXNE9YS3","conferencePaper","2011","Forejt, V.; Kwiatkowska, M.; Norman, G.; Parker, D.","Automated verification techniques for probabilistic systems","","","","10.1007/978-3-642-21455-4_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959282379&doi=10.1007%2f978-3-642-21455-4_3&partnerID=40&md5=ed0f3baeb4f73c313c751356e0b1db99","This tutorial provides an introduction to probabilistic model checking, a technique for automatically verifying quantitative properties of probabilistic systems. We focus on Markov decision processes (MDPs), which model both stochastic and nondeterministic behaviour. We describe methods to analyse a wide range of their properties, including specifications in the temporal logics PCTL and LTL, probabilistic safety properties and cost- or reward-based measures. We also discuss multi-objective probabilistic model checking, used to analyse trade-offs between several different quantitative properties. Applications of the techniques in this tutorial include performance and dependability analysis of networked systems, communication protocols and randomised distributed algorithms. Since such systems often comprise several components operating in parallel, we also cover techniques for compositional modelling and verification of multi-component probabilistic systems. Finally, we describe three large case studies which illustrate practical applications of the various methods discussed in the tutorial. © 2011 Springer-Verlag.","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","53-113","","","6659 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Economic and social effects; Design; Communication; Computer software; Stochastic systems; Markov Decision Processes; Markov processes; Networked systems; Stochastic models; Multi objective; Model checking; Probabilistic model checking; Formal methods; Automated verification; Compositional modelling; Dependability analysis; Multicomponents; Probabilistic logics; Probabilistic safety; Probabilistic systems; Temporal logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"JV2F3JH8","journalArticle","2021","Nunes, J.P.K.; Bianchi, T.; Iwasaki, A.Y.; Nakagawa, E.Y.","State of the art on microservices autoscaling: An overview","Anais do XLVIII Seminário Integrado de Software e Hardware","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138084486&partnerID=40&md5=5222bb372ab1de4e761b5dbf3f612cd4","","2021","2025-10-22 19:07:43","2025-10-22 19:07:43","","30-38","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLJK2NQI","journalArticle","2022","Jawaddi, S.N.A.; Johari, M.H.; Ismail, A.","A review of microservices autoscaling with formal verification perspective","Software - Practice and Experience","","","10.1002/spe.3135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136984240&doi=10.1002%2fspe.3135&partnerID=40&md5=8f6e93508ba189b1ca0b43f0ca82724e","The process of scaling microservices is a challenging task, especially in maintaining optimum resource provisioning while respecting QoS constraints and SLA. Many research works have proposed autoscaling approaches for microservices, however, less likely concerned with the correctness guarantee of the proposed algorithms. Hence, it is significant to gather and summarize these approaches to foster future innovation. Meanwhile, a few reviews have been published concerning microservices from different aspects. Therefore, our review complements the existing by focusing on autoscaling with verification perspectives. This study highlights the recent contributions in three inter-related main topics that were published within the year 2017 to 2022, namely, microservice, verification, and autoscaling. Due to limited resources on verification for microservice autoscaling, we widen the perspective by considering the verification for autoscaling in cloud-based systems. Based on our findings, we found that the formal method is not a new thing in verifying the autoscaling policies in cloud-based systems, and one recent study that implements the formal method in the microservices area has been identified. Apart from the autoscaling techniques, we have also determined several factors that have been a concern in scaling the microservices as well as the relatable metrics. Meanwhile, from a verification perspective, we identified that probabilistic model checking is the common formal verification technique used to verify microservices and cloud autoscaling. Finally, we recommend open challenges from two perspectives which highlight the verification for existing microservice autoscaling and verification for ML-based microservice autoscaling. © 2022 John Wiley & Sons Ltd.","2022","2025-10-22 19:07:43","2025-10-22 19:07:43","","2476-2495","","11","52","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Microservice; Autoscaling; scalability; microservice; autoscaling; Formal verification; Model checking; Probabilistic model checking; Probabilistic model-checking; Scalings; Cloud-based; Verification techniques; formal verification; Future innovations; probabilistic model checking; QoS constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXQTK5S5","journalArticle","2023","","","Cluster Autoscaling","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213699581&partnerID=40&md5=84fd93296046d3e3c47bac933e6c2bca","","2023","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AN6P8G4","journalArticle","2023","Ray, K.; Banerjee, A.","Prioritized Fault Recovery Strategies for Multi-Access Edge Computing Using Probabilistic Model Checking","IEEE Transactions on Dependable and Secure Computing","","","10.1109/TDSC.2022.3143877","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123372496&doi=10.1109%2fTDSC.2022.3143877&partnerID=40&md5=ea219289ced67c337cef7753b35b9fdd","The advent of Multi-Access Edge Computing (MEC) has enabled service providers to mitigate high network latencies often encountered in accessing cloud services by deploying containerized application instances on edge servers situated near end users. MEC servers are, however, susceptible to various types of failures such as communication link failures, hardware failures and so on. A fault recovery strategy determines which MEC servers to utilize to re-deploy application containers in the event of a failure. In this work, we propose a two-fold fault recovery strategy characterized by application priority. We propose a Formal Methods driven local recovery strategy for high-priority applications. We use Stochastic Multi-Player Games as a Formal Model to characterize the interactions between the different components in an MEC environment. We use objectives specified in Probabilistic Alternating-Time Temporal Logic with a Probabilistic Model Checker to derive recovery strategies considering all possible execution scenarios of the model. For lower priority applications, we resort to a global recovery strategy by designing a greedy heuristic considering each server's failure probability. We use benchmark datasets to validate our approach. Experimental results show an average 14% reduction in latency with our approach in comparison with other state-of-the-art methods. © 2004-2012 IEEE.","2023","2025-10-22 19:07:43","2025-10-22 19:07:43","","797-812","","1","20","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Online systems; Real time systems; Edge computing; Computer games; Multiaccess; Social networking (online); Interactive computer systems; Real - Time system; Stochastic systems; Fault tolerance; Stochastic models; fault-tolerance; Multi-access edge computing; Model checking; Probabilistic model checking; Probabilistic model-checking; Probabilistic logics; probabilistic model checking; Computer circuits; Game","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNK22FHE","bookSection","2018","Baier, C.; De Alfaro, L.; Forejt, V.; Kwiatkowska, M.","Model checking probabilistic systems","Handbook of Model Checking","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053872104&doi=10.1007%2f978-3-319-10575-8_28&partnerID=40&md5=be18cbef6bda96e335dc0ff836088398","The model-checking approach was originally formulated for verifying qualitative properties of systems, for example safety and liveness (see Chap. 2), and subsequently extended to also handle quantitative features, such as real time (see Chap. 29), continuous flows (see Chap. 30), as well as stochastic phenomena, where system evolution is governed by a given probability distribution. Probabilistic model checking aims to establish the correctness of probabilistic system models against quantitative probabilistic specifications, such as those capable of expressing, for example, the probability of an unsafe event occurring, expected time to termination, or expected power consumption in the start-up phase. In this chapter, we present the foundations of probabilistic model checking, focusing on finite-state Markov decision processes as models and quantitative properties expressed in probabilistic temporal logic. Markov decision processes can be thought of as a probabilistic variant of labelled transition systems in the following sense: transitions are labelled with actions, which can be chosen nondeterministically, and successor states for the chosen action are specified by means of discrete probabilistic distributions, thus specifying the probability of transiting to each successor state. To reason about expectations, we additionally annotate Markov decision processes with quantitative costs, which are incurred upon taking the selected action from a given state. Quantitative properties are expressed as formulas of the probabilistic computation tree logic (PCTL) or using linear temporal logic (LTL). We summarise the main model-checking algorithms for both PCTL and LTL, and illustrate their working through examples. The chapter ends with a brief overview of extensions to more expressive models and temporal logics, existing probabilistic model-checking tool support, and main application domains. © Springer International Publishing AG, part of Springer Nature 2018. All rights reserved.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","963-999","","","","","","","","","","","","","","","","Scopus","","","","","","","","Stochastic systems; Markov Decision Processes; Markov processes; Model checking; Probabilistic model checking; Probability distributions; Probabilistic logics; Temporal logic; Computer circuits; Labelled transition systems; Model checking algorithm; Probabilistic computation tree logic (PCTL); Probabilistic distribution; Probabilistic specifications; Probabilistic temporal logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KM3NUB4U","journalArticle","2016","Hameed, A.; Khoshkbarforoushha, A.; Ranjan, R.; Jayaraman, P.P.; Kolodziej, J.; Balaji, P.; Zeadally, S.; Malluhi, Q.M.; Tziritas, N.; Vishnu, A.; Khan, S.U.; Zomaya, A.","A survey and taxonomy on energy efficient resource allocation techniques for cloud computing systems","Computing","","","10.1007/s00607-014-0407-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901734176&doi=10.1007%2fs00607-014-0407-8&partnerID=40&md5=2210ab831c2623c652538ad760c0836d","In a cloud computing paradigm, energy efficient allocation of different virtualized ICT resources (servers, storage disks, and networks, and the like) is a complex problem due to the presence of heterogeneous application (e.g., content delivery networks, MapReduce, web applications, and the like) workloads having contentious allocation requirements in terms of ICT resource capacities (e.g., network bandwidth, processing speed, response time, etc.). Several recent papers have tried to address the issue of improving energy efficiency in allocating cloud resources to applications with varying degree of success. However, to the best of our knowledge there is no published literature on this subject that clearly articulates the research problem and provides research taxonomy for succinct classification of existing techniques. Hence, the main aim of this paper is to identify open challenges associated with energy efficient resource allocation. In this regard, the study, first, outlines the problem and existing hardware and software-based techniques available for this purpose. Furthermore, available techniques already presented in the literature are summarized based on the energy-efficient research dimension taxonomy. The advantages and disadvantages of the existing techniques are comprehensively analyzed against the proposed research dimension taxonomy namely: resource adaption policy, objective function, allocation method, allocation operation, and interoperability. © 2014, Springer-Verlag Wien.","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","751-774","","7","98","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Cloud computing; Distributed computer systems; Energy utilization; Taxonomies; Energy consumption; Resource allocation; Energy-efficient resource allocation; Content delivery network; Hardware and software; Complex networks; Network bandwidth; Resource capacity; Objective functions; Allocation methods; Energy efficient resource allocation; Research problems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBMT97B8","journalArticle","2018","Al-Dhuraibi, Y.; Paraiso, F.; Djarallah, N.; Merle, P.","Elasticity in Cloud Computing: State of the Art and Research Challenges","IEEE Transactions on Services Computing","","","10.1109/TSC.2017.2711009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045377245&doi=10.1109%2fTSC.2017.2711009&partnerID=40&md5=1cc70c9e36479a0cd20b9b4c0d4d12bc","Elasticity is a fundamental property in cloud computing that has recently witnessed major developments. This article reviews both classical and recent elasticity solutions and provides an overview of containerization, a new technological trend in lightweight virtualization. It also discusses major issues and research challenges related to elasticity in cloud computing. We comprehensively review and analyze the proposals developed in this field. We provide a taxonomy of elasticity mechanisms according to the identified works and key properties. Compared to other works in literature, this article presents a broader and detailed analysis of elasticity approaches and is considered as the first survey addressing the elasticity of containers. © 2018 IEEE.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","430-447","","2","11","","","","","","","","","","","","","Scopus","","","","","","","","Containers; cloud computing; Cloud computing; containers; Elasticity; State of the art; Research challenges; Scalability; scalability; auto-scaling; Auto-scaling; Fundamental properties; Elasticity approaches; Elasticity solutions; resource provision; Resource provisions; Technological trends","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLJ5KXQS","journalArticle","2012","Pedram, M.","Energy-efficient datacenters","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","","10.1109/TCAD.2012.2212898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866609789&doi=10.1109%2fTCAD.2012.2212898&partnerID=40&md5=da8813937e1c7f70fcfef51e520f0804","Pervasive use of cloud computing and the resulting rise in the number of datacenters and hosting centers (that provide platform or software services to clients who do not have the means to set up and operate their own computing facilities) have brought forth many concerns, including the electrical energy cost, peak power dissipation, cooling, and carbon emission. With power consumption becoming an increasingly important issue for the operation and maintenance of the hosting centers, corporate and business owners are becoming increasingly concerned. Furthermore, provisioning resources in a cost-optimal manner so as to meet different performance criteria, such as throughput or response time, has become a critical challenge. The goal of this paper is to provide an introduction to resource provisioning and power or thermal management problems in datacenters, and to review strategies that maximize the datacenter energy efficiency subject to peak or total power consumption and thermal constraints, while meeting stipulated service level agreements in terms of task throughput and/or response time. © 2012 IEEE.","2012","2025-10-22 19:07:43","2025-10-22 19:07:43","","1465-1484","","10","31","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Datacenter; resource management; Resource management; green computing; Temperature control; Dynamic Power; dynamic power and thermal management; energy efficient design; Energy-efficient design; enterprise computing; Enterprise computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GEK2KN3","journalArticle","2024","Sousa, B.; Dias, D.; Antunes, N.; Cámara, J.; Wagner, R.; Schmerl, B.; Garlan, D.; Fidalgo, P.","MONDEO-Tactics5G: Multistage botnet detection and tactics for 5G/6G networks","Computers and Security","","","10.1016/j.cose.2024.103768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186112209&doi=10.1016%2fj.cose.2024.103768&partnerID=40&md5=6209ad82884ec4e5065dcd3e85d3b392","Mobile malware is a malicious code specifically designed to target mobile devices to perform multiple types of fraud. The number of attacks reported each day is increasing constantly and is causing an impact not only at the end-user level but also at the network operator level. Malware like FluBot contributes to identity theft and data loss but also enables remote Command & Control (C2) operations, which can instrument infected devices to conduct Distributed Denial of Service (DDoS) attacks. Current mobile device-installed solutions are not effective, as the end user can ignore security warnings or install malicious software. This article designs and evaluates MONDEO-Tactics5G - a multistage botnet detection mechanism that does not require software installation on end-user devices, together with tactics for 5G network operators to manage infected devices. We conducted an evaluation that demonstrates high accuracy in detecting FluBot malware, and in the different adaptation strategies to reduce the risk of DDoS while minimising the impact on the clients' satisfaction by avoiding disrupting established sessions. © 2024 The Author(s)","2024","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","140","","","","","","","","","","","","","Scopus","","","","","","","","Network operator; End-users; 5G mobile communication systems; Malware; Network security; Queueing networks; DDoS; Denial-of-service attack; Botnet; Botnet detections; Botnets; Command control; Command control server; Command Control server; Distributed denial of service; Malwares; Mobile security; Multi-stages; Tactic; Tactics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JVZPHF3D","conferencePaper","2011","Kwiatkowska, M.; Norman, G.; Parker, D.","PRISM 4.0: Verification of probabilistic real-time systems","","","","10.1007/978-3-642-22110-1_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960351824&doi=10.1007%2f978-3-642-22110-1_47&partnerID=40&md5=ffaf7f6b04e786a99356c0aafd8f2cff","This paper describes a major new release of the PRISM probabilistic model checker, adding, in particular, quantitative verification of (priced) probabilistic timed automata. These model systems exhibiting probabilistic, nondeterministic and real-time characteristics. In many application domains, all three aspects are essential; this includes, for example, embedded controllers in automotive or avionic systems, wireless communication protocols such as Bluetooth or Zigbee, and randomised security protocols. PRISM, which is open-source, also contains several new components that are of independent use. These include: an extensible toolkit for building, verifying and refining abstractions of probabilistic models; an explicit-state probabilistic model checking library; a discrete-event simulation engine for statistical model checking; support for generation of optimal adversaries/strategies; and a benchmark suite. © 2011 Springer-Verlag.","2011","2025-10-22 19:07:43","2025-10-22 19:07:43","","585-591","","","6806 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Benchmark suites; Open-source; Real time systems; Communication; Wireless telecommunication systems; Network security; Computer simulation; Application domains; Model checking; Probabilistic model checking; Prisms; Avionic systems; Avionics; Computer aided analysis; Discrete events; Embedded controllers; Model system; New components; Probabilistic models; Probabilistic timed automata; Quantitative verification; Real time characteristics; Security protocols; Simulation engine; Statistical models; Wireless communication protocols; Zig-Bee","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"IFWTYG27","journalArticle","","Kinyae, N.","","Kubernetes Resource & Performance Metrics Allocation.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213690814&partnerID=40&md5=1d40f4c6e03e882909850bf8815cbf5b","","","2025-10-22 19:07:43","2025-10-22 19:07:43","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFYJV3Z5","conferencePaper","2016","Hasselbring, W.","Microservices for scalability: [Keynote talk abstract]","","","","10.1145/2851553.2858659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009195980&doi=10.1145%2f2851553.2858659&partnerID=40&md5=5bc2faf13d6d79850273bddf0cd1e9bf","Microservice architectures provide small services that may be deployed and scaled independently of each other, and may employ different middleware stacks for their implementation. Microservice architectures emphasize transaction-less coordination between services, with explicit acceptance of eventual consistency. Polyglott persistence in this context means that the individual microservices may employ multiple data storage technologies. Microservice architectures are ""cloud native"" allowing for automated and rapid elasticity. Fault-tolerance mechanisms achieve that failures of individual mircroservices do not affect other services thanks to container isolation. Since services can fail at any time, it is important to be able to detect the failures quickly and, if possible, automatically restore services. Essential for success in such a setting is advanced monitoring. In this keynote, I discuss how mircoservices support scalability for both, runtime performance and development performance, via polyglott persistence, eventual consistency, loose coupling, open source frameworks, and continuous monitoring for elastic capacity management. © 2016 ACM.","2016","2025-10-22 19:07:43","2025-10-22 19:07:43","","133-134","","","","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Microservices; Run-time performance; Architecture; Middleware; Digital storage; Scalability; Fault tolerance; Capacity management; Continuous monitoring; Development performance; Eventual consistency; Fault tolerance mechanisms; Open source frameworks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2016 - Proceedings of the 7th ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"GKP6LUZT","bookSection","2017","Kwiatkowska, M.; Norman, G.; Parker, D.","Probabilistic model checking: Advances and applications","Formal System Verification: State-of the-Art and Future Trends","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033345325&doi=10.1007%2f978-3-319-57685-5_3&partnerID=40&md5=825693adb1cb692784f0fdd7f50ef565","","2017","2025-10-22 19:07:43","2025-10-22 19:07:43","","73-121","","","","","","","","","","","","","","","","Scopus","","","","","","","","Model checking; Probabilistic model checking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4IWZE8VZ","conferencePaper","2018","Bertot, L.; Genaud, S.; Gossa, J.","An overview of cloud simulation enhancement using the monte-carlo method","","","","10.1109/CCGRID.2018.00064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050965525&doi=10.1109%2fCCGRID.2018.00064&partnerID=40&md5=db9e25470dbc29054d3da3856b158e9d","In the cloud computing model, cloud providers invoice clients for resource consumption. Hence, tools helping the client to budget the cost of running their application are of pre-eminent importance. However, the opaque and multi-tenant nature of clouds, make job runtimes both variable and hard to predict. In this paper, we propose an improved simulation framework that takes into account this variability using the Monte-Carlo method. We consider the execution of batch jobs on an actual platform, scheduled using typical heuristics based on the user estimates of tasks' runtimes. We model the observed variability through simple distributions to use as inputs to the Monte-Carlo simulation. We show that, our method can capture over 90% of the empirical observations of total execution times. © 2018 IEEE.","2018","2025-10-22 19:07:43","2025-10-22 19:07:43","","386-387","","","","","","","","","","","","","","","","Scopus","","","","","","","","Multi tenants; Cloud computing; Cluster computing; Grid computing; Runtimes; Budget control; Cloud providers; Job shop scheduling; Resource consumption; Computer simulation; Intelligent systems; Simulation framework; Cloud simulation; Batch jobs; Monte carlo methods; Monte Carlo methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2018","","","","","","","","","","","","","","",""
"AQ8QPMBA","journalArticle","2022","Su, G.; Liu, L.; Zhang, M.; Rosenblum, D.S.","Quantitative Verification for Monitoring Event-Streaming Systems","IEEE Transactions on Software Engineering","","","10.1109/TSE.2020.2996033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085761724&doi=10.1109%2fTSE.2020.2996033&partnerID=40&md5=8c9ece984385bccbae7ea1f83bc38e42","High-performance data streaming technologies are increasingly adopted in IT companies to support the integration of heterogeneous and possibly distributed applications. Compared with the traditional message queuing middleware, a streaming platform enables the implementation of event-streaming systems (ESS) which include not only complex queues but also pipelines that transform and react to the streams of data. By analysing the centralised data streams, one can evaluate the Quality-of-Service for other systems and components that produce or consume those streams. We consider the exploitation of probabilistic model checking as a performance monitoring technique for ESS systems. Probabilistic model checking is a mature, powerful verification technique with successful application in performance analysis. However, an ESS system may contain quantitative parameters that are determined by event streams observed in a certain period of time. In this paper, we present a novel theoretical framework called QV4M (meaning 'quantitative verification for monitoring') for monitoring ESS systems, which is based on two recent methods of probabilistic model checking. QV4M assumes the parameters in a probabilistic system model as random variables and infers the statistical significance for the probabilistic model checking output. We also present an empirical evaluation of computational time and data cost for QV4M.  © 1976-2012 IEEE.","2022","2025-10-22 19:07:43","2025-10-22 19:07:43","","538-550","","2","48","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Monitoring; Middleware; Multimedia systems; Performance monitoring; Quality control; Data streams; Model checking; Probabilistic model checking; Empirical evaluations; Verification techniques; Probabilistic systems; Quantitative verification; Discrete-time markov chain; Event stream; Parametric model checking; Quantitative parameters; Statistical confidence; Statistical inference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UFUVXKXF","journalArticle","2020","Imdoukh, M.; Ahmad, I.; Alfailakawi, M.G.","Machine learning-based auto-scaling for containerized applications","Neural Computing and Applications","","","10.1007/s00521-019-04507-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074476840&doi=10.1007%2fs00521-019-04507-z&partnerID=40&md5=86fd26d2f95eec826a8337d89a19ad52","Containers are shaping the new era of cloud applications due to their key benefits such as lightweight, very quick to launch, consuming minimum resources to run an application which reduces cost, and can be easily and rapidly scaled up/down as per workload requirements. However, container-based cloud applications require sophisticated auto-scaling methods that automatically and in a timely manner provision and de-provision cloud resources without human intervention in response to dynamic fluctuations in workload. To address this challenge, in this paper, we propose a proactive machine learning-based approach to perform auto-scaling of Docker containers in response to dynamic workload changes at runtime. The proposed auto-scaler architecture follows the commonly abstracted four steps: monitor, analyze, plan, and execute the control loop. The monitor component continuously collects different types of data (HTTP request statistics, CPU, and memory utilization) that are needed during the analysis and planning phase to determine proper scaling actions. We employ in analysis phase a concise yet fast, adaptive, and accurate prediction model based on long short-term memory (LSTM) neural network to predict future HTTP workload to determine the number of containers needed to handle requests ahead of time to eliminate delays caused by starting or stopping running containers. Moreover, in the planning phase, the proposed gradually decreasing strategy avoids oscillations which happens when scaling operations are too frequent. Experimental results using realistic workload show that the prediction accuracy of LSTM model is as accurate as auto-regression integrated moving average model but offers 600 times prediction speedup. Moreover, as compared with artificial neural network model, LSTM model performs better in terms of auto-scaler metrics related to provisioning and elastic speedup. In addition, it was observed that when LSTM model is used, the predicted workload helped in using the minimum number of replicas to handle future workload. In the experiments, the use of GDS showed promising results in keeping the desired performance at reduced cost to handle cases with sudden workload increase/decrease. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","9745-9760","","13","32","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Forecasting; Cloud applications; HTTP; Memory architecture; Containerization; Learning algorithms; Machine learning; Long short-term memory; Neural networks; Cost reduction; Prediction; Auto-scaling; Brain; Prediction accuracy; Human intervention; Frequency dividing circuits; Accurate prediction; Artificial neural network modeling; Moving average model; Neural network; Proactive controller","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"356AYIQJ","conferencePaper","2017","Dehnert, C.; Junges, S.; Katoen, J.-P.; Volk, M.","A storm is coming: A modern probabilistic model checker","","","","10.1007/978-3-319-63390-9_31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026765560&doi=10.1007%2f978-3-319-63390-9_31&partnerID=40&md5=bec40458d61e867317afa60deceea5f9","We launch the new probabilistic model checker Storm. It features the analysis of discrete- and continuous-time variants of both Markov chains and MDPs. It supports the Prism and JANI modeling languages, probabilistic programs, dynamic fault trees and generalized stochastic Petri nets. It has a modular set-up in which solvers and symbolic engines can easily be exchanged. It offers a Python API for rapid prototyping by encapsulating Storm’s fast and scalable algorithms. Experiments on a variety of benchmarks show its competitive performance. © Springer International Publishing AG 2017","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","592-600","","","10427 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Benchmarking; Modeling languages; Software prototyping; Stochastic systems; Markov processes; Petri nets; Model checking; Generalized Stochastic Petri nets; Storms; Continuous time systems; Competitive performance; Computer aided analysis; Computer simulation languages; Continuous-time; Dynamic fault trees; It supports; Probabilistic modeling; Probabilistic programs; Scalable algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"HDJVG74G","journalArticle","2020","Nguyen, T.-T.; Yeom, Y.-J.; Kim, T.; Park, D.-H.; Kim, S.","Horizontal pod autoscaling in kubernetes for elastic container orchestration","Sensors (Switzerland)","","","10.3390/s20164621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089612460&doi=10.3390%2fs20164621&partnerID=40&md5=0bd64ccc5e149c37898e1b3e4c197267","Kubernetes, an open-source container orchestration platform, enables high availability and scalability through diverse autoscaling mechanisms such as Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler and Cluster Autoscaler. Amongst them, HPA helps provide seamless service by dynamically scaling up and down the number of resource units, called pods, without having to restart the whole system. Kubernetes monitors default Resource Metrics including CPU and memory usage of host machines and their pods. On the other hand, Custom Metrics, provided by external software such as Prometheus, are customizable to monitor a wide collection of metrics. In this paper, we investigate HPA through diverse experiments to provide critical knowledge on its operational behaviors. We also discuss the essential difference between Kubernetes Resource Metrics (KRM) and Prometheus Custom Metrics (PCM) and how they affect HPA’s performance. Lastly, we provide deeper insights and lessons on how to optimize the performance of HPA for researchers, developers, and system administrators working with Kubernetes in the future. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","1-18","","16","20","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Containers; Docker; Kubernetes; Cloud computing; Edge computing; High availability; Container orchestration; Prometheus; Open sources; Resource units; System administrators; Customizable; Custom metrics; Horizontal Pod Autoscaling (HPA); Operational behavior; Resource metrics; Seamless services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2SSUHSA","journalArticle","2021","Mireslami, S.; Rakai, L.; Wang, M.; Far, B.H.","Dynamic Cloud Resource Allocation Considering Demand Uncertainty","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2019.2897304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114504298&doi=10.1109%2fTCC.2019.2897304&partnerID=40&md5=0fc86aa256c3a391a288f4e9e4eddfbd","Cloud computing provisions scalable resources for high performance industrial applications. Cloud providers usually offer two types of usage plans: reserved and on-demand. Reserved plans offer cheaper resources for long-term contracts while on-demand plans are available for short or long periods but are more expensive. To satisfy incoming user demands with reasonable costs, cloud resources should be allocated efficiently. Most existing works focus on either cheaper solutions with reserved resources that may lead to under-provisioning or over-provisioning, or costly solutions with on-demand resources. Since inefficiency of allocating cloud resources can cause huge provisioning costs and fluctuation in cloud demand, resource allocation becomes a highly challenging problem. In this paper, we propose a hybrid method to allocate cloud resources according to the dynamic user demands. This method is developed as a two-phase algorithm that consists of reservation and dynamic provision phases. In this way, we minimize the total deployment cost by formulating each phase as an optimization problem while satisfying quality of service. Due to the uncertain nature of cloud demands, we develop a stochastic optimization approach by modeling user demands as random variables. Our algorithm is evaluated using different experiments and the results show its efficiency in dynamically allocating cloud resources.  © 2013 IEEE.","2021","2025-10-22 19:07:44","2025-10-22 19:07:44","","981-994","","3","9","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; Cloud computing; Resource allocation; Over provisioning; Optimization problems; quality of service; Deployment costs; Its efficiencies; demand uncertainty; Demand uncertainty; Long-term contracts; pricing and resource allocation; Stochastic optimization approach; stochastic programming; Two phase algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTN5SJPT","journalArticle","2024","Araujo, G.; Barbosa, V.; Lima, L.N.; Sabino, A.; Brito, C.; Fe, I.; Rego, P.; Choi, E.; Min, D.; Nguyen, T.A.; Silva, F.A.","Energy Consumption in Microservices Architectures: A Systematic Literature Review","IEEE Access","","","10.1109/ACCESS.2024.3389064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190750888&doi=10.1109%2fACCESS.2024.3389064&partnerID=40&md5=4c9c1f346cd433aabcf7ef1bc610bb15","Cloud computing emerges as a paradigm that facilitates on-demand access to technological resources through the mechanism of service virtualization. This virtualization enables the partitioning of hardware resources among applications that are organized into distinct independent modules. The concept of microservice architecture takes advantage of virtualization capabilities to embrace a software architecture strategy focused on the development of applications as assemblies of several interdependent but loosely coupled modules. Nonetheless, the adoption of microservices architecture is accompanied by substantial energy demands to meet the desired standards of performance and availability. Existing research within the domain of microservices has explored various topics pertinent to energy consumption, including elasticity, reliability, performance, and availability. Yet, the diversity of challenges and solutions presents a complex landscape for identifying prevailing research trends and unaddressed gaps in the context of microservices. This study aims to methodically discern, evaluate, and juxtapose the existing research trends and voids concerning energy consumption within microservices. It elucidates a systematic review on the subject of energy consumption in microservices architectures, offering a compilation of references to facilitate more directed future investigations. The initial selection encompassed 3625 articles, which were subsequently narrowed down through three stages of refinement, resulting in 37 articles chosen for an exhaustive review. These selected studies were cataloged and analyzed based on various criteria, including metrics, evaluation methodologies, and architectural typologies, thus uncovering research gaps and emerging trends related to energy consumption in microservice architectures. Furthermore, this inquiry delineates significant research challenges and prospective directions, structured around the key metrics that underpin the reviewed studies: performance, elasticity, scalability, reliability, sustainability, and availability.  © 2013 IEEE.","2024","2025-10-22 19:07:44","2025-10-22 19:07:44","","186710-186729","","","12","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Microservice; Microservices; cloud computing; Cloud computing; Cloud-computing; Virtual reality; Virtualization; Energy utilization; Virtualizations; Computer architecture; Elasticity; Systematic mapping; Energy-consumption; Green computing; Security; Microservice architecture; energy consumption; container; Systematic; systematic mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N38UHV89","journalArticle","","Kinyae, N.","","Greedy Cloud Selection Deployment on Microservices. Kaggle.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213683134&partnerID=40&md5=c5263d02555422a85b15757a6032ea2f","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JK2UJD64","conferencePaper","2022","Merkouche, S.; Bouanaka, C.","A Proactive Formal Approach For Microservice-based Applications Auto-Scaling","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136200457&partnerID=40&md5=0a07dffe2c418ec6bc3ef8ec750cceaa","Due to the emergence of cloud and containers, microservices has become widely adopted to develop large-scale applications, since deploying on the cloud provides an unlimited amount of resources to the developers. However, an uncontrolled usage of these resources leads to unnecessary costs or a non-performant system. Therefore, several researches have been carried out around an efficient resources auto-scaling, coming out with several policies. Most of the existing policies follow a reactive approach that relies on the current state of the system to adapt it. On the counterpart, proactive approaches are based on resource future usage estimation to adapt the system before it reaches a non-performant state, yet, complex and expensive methodologies are needed to ensure proactivity such as reinforcement learning. In this work, we propose a proactive approach of resource auto-scaling. We use the weak and strong dependencies concept to expect the future state of the system. To formally model the proposed approach, we combine high-level PNs and plausible PNs. The plausible PNs are suitable for decision-making, when several adaptation plans are available, they allow identifying a compromise plan when the auto-scaling concerns different qualities of the system. © 2020 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2022","2025-10-22 19:07:44","2025-10-22 19:07:44","","15-28","","","3176","","","","","","","","","","","","","Scopus","","","","","","","","Containers; containers; Decision making; Large-scale applications; Reinforcement learning; Reinforcement learnings; 'current; Microservice architecture; Petri nets; formal methods; auto-scaling; Auto-scaling; Microservice architectures; Scalings; Formal methods; Decisions makings; Formal approach; Petri Nets; Pro-active approach; Proactivity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CEUR Workshop Proceedings","","","","","","","","","","","","","","",""
"2L3EZQDQ","journalArticle","2021","Santos, L.; Cunha, B.; Fé, I.; Vieira, M.; Silva, F.A.","Data Processing on Edge and Cloud: A Performability Evaluation and Sensitivity Analysis","Journal of Network and Systems Management","","","10.1007/s10922-021-09592-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102179880&doi=10.1007%2fs10922-021-09592-x&partnerID=40&md5=823415fbdfc2da072c7ecb1abed6d62e","Nowadays, the Internet of Things (IoT) allows monitoring and automation in diverse contexts, such as hospitals, homes, or even smart cities, just to name a few examples. IoT data processing may occur, at the edge of the network or in the cloud, but frequently the processing must be divided between the two layers. Aiming to guarantee that the IoT systems works efficiently, it is essential to evaluate the system even in initial design stages. However, evaluating hybrid systems composed by multiple layers is not an easy task as a myriad of parameters are involved in the process. Thus, this paper presents two SPN models (one base and extended one) that can represent an abstract distributed system composed of IoT, edge and cloud layers. The models are highly configurable to be used in diverse simulation scenarios. Besides a sensitivity analysis evidenced the most impacting components in the studied architecture and made it possible to optimize the base SPN model. Finally a case study explores multiple metrics of interest concurrently and works as a guide of the model utilization. Ultimately, the proposed approach can assist system designers to avoid unnecessary investment in original equipment. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2021","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","3","29","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Distributed systems; Internet of things; Edge computing; Data handling; Sensitivity analysis; Internet of Things (IoT); Distributed database systems; Internet of thing (IOT); Performability evaluation; System designers; Cloud layers; Hybrid systems; Initial design; Multiple layers; SPN model; Stochastic petri nets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QSFFWP4Y","conferencePaper","2022","Yang, B.; Zhang, F.; Khan, S.U.","Quantitative Evaluation of Cloud Elasticity based on Fuzzy Analytic Hierarchy Process","","","","10.1109/CloudSummit54781.2022.00022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145434517&doi=10.1109%2fCloudSummit54781.2022.00022&partnerID=40&md5=d502bf4882fbadd357f1230becb31c05","Elasticity is one of the most important cloud computing characteristics, which enables deployed applications to dynamically adapt to workload-changing demands by acquiring and releasing shared computing resources at runtime. However, the existing cloud elasticity metrics are either oversimplified or hard to use, thereby lacking a comprehensive evaluation mech-anism to properly compare the elastic feature among different cloud providers. To address this gap, we propose an assessment method for cloud elasticity based on fuzzy hierarchical analysis. We use a fuzzy hierarchical model to quantitatively assess the qualitative metrics with a unified standard model. We compare three public cloud providers (Ali Cloud, HUAWEI Cloud, Tencent Cloud) as case studies and measure their cloud elasticity based on the proposed model on a cluster. To verify the effectiveness of our method, we also measure three cloud platforms using auto scaling performance metrics proposed by SPEC Cloud Group. The results show that our proposed elasticity quantification method is feasible. © 2022 IEEE.","2022","2025-10-22 19:07:44","2025-10-22 19:07:44","","105-112","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud-computing; Hierarchical systems; Elasticity; Quantitative evaluation; Cloud providers; Cloud; Computing resource; Deployed applications; Cloud elasticities; Analytic hierarchy process; Fuzzy analytic hierarchy; Fuzzy analytic hierarchy process; Fuzzy analytic hierarchy process(FAHP); Quantify; Resource","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2022 IEEE Cloud Summit, Cloud Summit 2022","","","","","","","","","","","","","","",""
"M8T8VI6D","conferencePaper","2015","Naskos, A.; Stachtiari, E.; Gounaris, A.; Katsaros, P.; Tsoumakos, D.; Konstantinou, I.; Sioutas, S.","Dependable horizontal scaling based on probabilistic model checking","","","","10.1109/CCGrid.2015.91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941241984&doi=10.1109%2fCCGrid.2015.91&partnerID=40&md5=13dea36c1dc251271f7d864f4550dedf","The focus of this work is the on-demand resource provisioning in cloud computing, which is commonly referredto as cloud elasticity. Although a lot of effort has been invested in developing systems and mechanisms that enable elasticity, the elasticity decision policies tend to be designed without quantifying or guaranteeing the quality of their operation. We present an approach towards the development of more formalized and dependable elasticity policies. We make two distinct contributions. First, we propose an extensible approach to enforcing elasticity through the dynamic instantiation and online quantitative verification of Markov Decision Processes(MDP) using probabilistic model checking. Second, various concrete elasticity models and elasticity policies are studied. We evaluate the decision policies using traces from a realNoSQL database cluster under constantly evolving externalload. We reason about the behaviour of different modelling and elasticity policy options and we show that our proposal can improve upon the state-of-the-art in significantly decreasing under-provisioning while avoiding over-provisioning. © 2015 IEEE.","2015","2025-10-22 19:07:44","2025-10-22 19:07:44","","31-40","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cluster computing; Grid computing; Elasticity; Markov Decision Processes; Markov processes; Model checking; Probabilistic model checking; Prisms; Autonomic Computing; Horizontal scaling; Cloud elasticities; Quantitative verification; Autonomic computing; Cloud elasticity; Nosql database; NoSQL databases; On-demand resource provisioning; PRISM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 IEEE/ACM 15th International Symposium on Cluster, Cloud, and Grid Computing, CCGrid 2015","","","","","","","","","","","","","","",""
"UDP68VEL","journalArticle","2023","Kubernetes Documentation, J.","","Horizontal Pod Autoscaling","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180090258&partnerID=40&md5=30e92de62008d000f7fa6d5ea8b21963","","2023","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRCANFHN","conferencePaper","2015","Moreno, G.A.; Cámara, J.; Garlan, D.; Schmerl, B.","Proactive self-adaptation under uncertainty: A probabilistic model checking approach","","","","10.1145/2786805.2786853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960425213&doi=10.1145%2f2786805.2786853&partnerID=40&md5=75e2f31c3d3472005b19c2cc8c26407a","Self-adaptive systems tend to be reactive and myopic, adapting in response to changes without anticipating what the subsequent adaptation needs will be. Adapting reactively can result in inefficiencies due to the system performing a suboptimal sequence of adaptations. Furthermore, when adaptations have latency, and take some time to produce their effect, they have to be started with sufficient lead time so that they complete by the time their effect is needed. Proactive latency-aware adaptation addresses these issues by making adaptation decisions with a look-ahead horizon and taking adaptation latency into account. In this paper we present an approach for proactive latency-aware adaptation under uncertainty that uses probabilistic model checking for adaptation decisions. The key idea is to use a formal model of the adaptive system in which the adaptation decision is left underspecified through nondeterminism, and have the model checker resolve the nondeterministic choices so that the accumulated utility over the horizon is maximized. The adaptation decision is optimal over the horizon, and takes into account the inherent uncertainty of the environment predictions needed for looking ahead. Our results show that the decision based on a look-ahead horizon, and the factoring of both tactic latency and environment uncertainty, considerably improve the effectiveness of adaptation decisions. © 2015 ACM.","2015","2025-10-22 19:07:44","2025-10-22 19:07:44","","1-12","","","","","","","","","","","","","","","","Scopus","","","","","","","","Software engineering; Self adaptation; Model checking; Probabilistic model checking; Adaptive systems; Latency-aware; Environment predictions; Environment uncertainty; Nondeterministic choice; Proactive; Self-adaptive system; Selfadaptation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings","","","","","","","","","","","","","","",""
"3HY27KMI","journalArticle","2021","Burroughs, S.","","Towards Predictive Runtime Modelling of Kubernetes Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122396157&partnerID=40&md5=26d3196cfb1e537f4e4a0905fd7eb01f","","2021","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZV63ETZ","journalArticle","2018","Evangelidis, A.; Parker, D.; Bahsoon, R.","Performance modelling and verification of cloud-based auto-scaling policies","Future Generation Computer Systems","","","10.1016/j.future.2017.12.047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041570783&doi=10.1016%2fj.future.2017.12.047&partnerID=40&md5=9aed289bf5984ae13c67f66c71fc944f","Auto-scaling, a key property of cloud computing, allows application owners to acquire and release resources on demand. However, the shared environment, along with the exponentially large configuration space of available parameters, makes the configuration of auto-scaling policies a challenging task. In particular, it is difficult to quantify, a priori, the impact of a policy on Quality of Service (QoS) provision. To address this problem, we propose a novel approach based on performance modelling and formal verification to produce performance guarantees on particular rule-based auto-scaling policies. We demonstrate the usefulness and efficiency of our techniques through a detailed validation process on two public cloud providers, Amazon EC2 and Microsoft Azure, targeting two cloud computing models, Infrastructure as a Service (IaaS) and Platform as a Service (PaaS), respectively. Our experimental results show that the modelling process along with the model itself can be very effective in providing the necessary formal reasoning to cloud application owners with respect to the configuration of their auto-scaling policies, and consequently helping them to specify an auto-scaling policy which could minimise QoS violations. © 2018 Elsevier B.V.","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","629-638","","","87","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Platform as a Service (PaaS); Performance modelling; Cloud applications; Infrastructure as a service (IaaS); Performance guarantees; Windows operating system; Markov processes; Auto-scaling; Formal verification; Markov models; Configuration space; Markov model; Probabilistic verification; Validation process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X58IE9U5","conferencePaper","2020","Mendonca, N.; Mendes Aderaldo, C.; Camara, J.; Garlan, D.","Model-based analysis of microservice resiliency patterns","","","","10.1109/ICSA47634.2020.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085929653&doi=10.1109%2fICSA47634.2020.00019&partnerID=40&md5=a1038668e9f8f97d2bdbdf8258f415fa","Microservice application developers try to mitigate the impact of partial outages typically by implementing service-to-service interactions that use well-known resiliency patterns, such as Retry, Fail Fast, and Circuit Breaker. However, those resiliency patterns - as well as their available open-source implementations - are often documented informally, leaving it up to application developers to figure out when and how to use those patterns in the context of a particular microservice application. In this paper, we take a first step towards improving on this situation by introducing a model checking-based approach in which we use the PRISM probabilistic model checker to analyze the behavior of the Retry and Circuit Breaker resiliency patterns as continuous-time Markov chains (CTMC). This approach has enabled us to quantify the impact of applying each resiliency pattern on multiple quality attributes, as well as to determine how to best tune their parameters to deal with varying service availability conditions, in the context of a simple client-service interaction scenario. © 2020 IEEE.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","114-124","","","","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Software architecture; Application developers; Service interaction; Microservice architecture; Electric circuit breakers; Service availability; Model checking; Probabilistic model checking; Continuous time Markov chain; Continuous time systems; Markov chains; Probabilistic modeling; Model-based analysis; Multiple quality; Open source implementation; Resiliency patterns","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE 17th International Conference on Software Architecture, ICSA 2020","","","","","","","","","","","","","","",""
"LPEFNWJ6","journalArticle","2019","Kochovski, P.; Drobintsev, P.D.; Stankovski, V.","Formal Quality of Service assurances, ranking and verification of cloud deployment options with a probabilistic model checking method","Information and Software Technology","","","10.1016/j.infsof.2019.01.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059819610&doi=10.1016%2fj.infsof.2019.01.003&partnerID=40&md5=347c52a1b9e5ada9ff8c921d0e26eae4","Context: Existing software workbenches allow for the deployment of cloud applications across a variety of Infrastructure-as-a-Service (IaaS) providers. The expected workload, Quality of Service (QoS) and Non-Functional Requirements (NFRs) must be considered before an appropriate infrastructure is selected. However, this decision-making process is complex and time-consuming. Moreover, the software engineer needs assurances that the selected infrastructure will lead to an adequate QoS of the application. Objective: The goal is to develop a new method for selection of an optimal cloud deployment option, that is, an infrastructure and configuration for deployment and to verify that all hard and as many soft QoS requirements as possible will be met at runtime. Method: A new Formal QoS Assurances Method (FoQoSAM), which relies on stochastic Markov models is introduced to facilitate an automated decision-making process. For a given workload, it uses QoS monitoring data and a user-related metric in order to automatically generate a probabilistic model. The probabilistic model takes the form of a finite automaton. It is further used to produce a rank list of cloud deployment options. As a result, any of the cloud deployment options can be verified by applying a probabilistic model checking approach. Results: Testing was performed by ranking deployment options for two cloud applications, File Upload and Video-conferencing. The FoQoSAM method was compared to a baseline Analytic Hierarchy Process (AHP). The results show that the first ranked cloud deployment options satisfy all hard and at least one of the soft requirements for both methods, however, the FoQoSAM method always satisfies at least an additional QoS requirement compared to the baseline AHP method. Conclusions: The proposed new FoQoSAM method is appropriate and can be used in decision-making when ranking and verifying cloud deployment options. Due to its practical utility it was integrated into the SWITCH workbench. © 2019 Elsevier B.V.","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","14-25","","","109","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Application programs; Hierarchical systems; Infrastructure as a service (IaaS); Clouds; Software engineering; Decision making; Cloud; Stochastic systems; Markov processes; Stochastic models; Fog; Edge; Decision-making; Model checking; Probabilistic model checking; Non-functional requirements; Probabilistic modeling; Analytic hierarchy process; Analytic hierarchy process (ahp); Automated decision making; Decision making process; Equivalence classes; Quality of service assurances; Video conferencing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2S44CK4","journalArticle","2024","","","Kubernetes: Horizontal Pod Autoscaling Policies","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213679908&partnerID=40&md5=159a43ff5dfebf83ea1c995e1a4508f4","","2024","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFGFTUPZ","journalArticle","2018","Jamshidi, P.; Pahl, C.; Mendonca, N.C.; Lewis, J.; Tilkov, S.","Microservices: The journey so far and challenges ahead","IEEE Software","","","10.1109/MS.2018.2141039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046893906&doi=10.1109%2fMS.2018.2141039&partnerID=40&md5=b2913a1bc8e6dd75d8bc75e9f8feac8e","Microservices are an architectural approach emerging out of service-oriented architecture, emphasizing self-management and lightweightness as the means to improve software agility, scalability, and autonomy. This article examines microservice evolution from the technological and architectural perspectives and discusses key challenges facing future microservice developments. © 1984-2012 IEEE.","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","24-35","","3","35","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; microservices; Software design; software development; software engineering; Software engineering; Architectural approach; Legacy systems; Information services; Service oriented architecture (SOA); legacy systems; SOA; service-oriented architecture; model-driven development; Model driven development; Anti-patterns; architectural antipatterns; DDD; domain-driven design; Domain-driven designs; MDD; Self management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6XKCAKM","conferencePaper","2020","Jagadeesan, L.J.; Mendiratta, V.B.","When Failure is (Not) an Option: Reliability Models for Microservices Architectures","","","","10.1109/ISSREW51248.2020.00031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099866678&doi=10.1109%2fISSREW51248.2020.00031&partnerID=40&md5=02036281c8d341d90b2350c3db5cf12e","Modern application development and deployment is rapidly evolving to microservices based architectures, in which thousands of microservices communicate with one another and can be independently scaled and updated. While these architectures enable flexibility of deployment and frequency of upgrades, the naive use of thousands of communicating and frequently updated microservices can significantly impact the reliability of applications. To address these challenges, service meshes are used to rapidly detect and respond to microservices failures without necessitating changes to the microservices themselves. However, there are inherent tradeoffs that service meshes must make with regards to how quickly they assume a microservice has failed and the subsequent impact on overall application reliability. We present in this paper a modeling framework for microservices and service mesh reliability that takes these tradeoffs into account. Index Terms-microservices, service mesh, sidecars, circuit breakers, reliability, availability, resilience, reliability models, probabilistic model checking, PRISM.  © 2020 IEEE.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","19-24","","","","","","","","","","","","","","","","Scopus","","","","","","","","Commerce; Timing circuits; Mesh generation; Application deployment; Circuit-breakers; Electric circuit breakers; Availability; Reliability; Reliability modelling; Application reliabilities; Model checking; Probabilistic model checking; Probabilistic model-checking; Application development; Microservice, service mesh, sidecar, circuit breaker, reliability, availability, resilience, reliability model, probabilistic model checking, PRISM; microservices, service mesh, sidecars, circuit breakers, reliability, availability, resilience, reliability models, probabilistic model checking, PRISM; Modelling framework; Modern applications; Prisms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE 31st International Symposium on Software Reliability Engineering Workshops, ISSREW 2020","","","","","","","","","","","","","","",""
"ACX4BABP","conferencePaper","2011","Tsai, W.-T.; Huang, Y.; Shao, Q.","Testing the scalability of SaaS applications","","","","10.1109/SOCA.2011.6166245","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860008701&doi=10.1109%2fSOCA.2011.6166245&partnerID=40&md5=522b825395549d0d3ec73f5f8e3cc9c0","Cloud computing and SaaS (Software-as-a-Service) received significant attention recently. Testing SaaS applications is important because many mission-critical applications will be deployed on the cloud. However, to the best of our knowledge, testing framework designed specifically for SaaS applications is not developed. The issue of testing the scalability of SaaS applications remains untouched. This paper discusses the unique features and challenges in testing SaaS applications, and proposes scalability metrics that can be used to test the scalability of SaaS applications. © 2011 IEEE.","2011","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scalability; Mission critical applications; Software-as-a-Service; Testing framework; Unique features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2011 IEEE International Conference on Service-Oriented Computing and Applications, SOCA 2011","","","","","","","","","","","","","","",""
"49STVYNN","journalArticle","2009","Kwiatkowska, M.; Norman, G.; Parker, D.","PRISM: Probabilistic model checking for performance and reliability analysis","ACM SIGMETRICS Performance Evaluation Review","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349958924&partnerID=40&md5=d57648ded64df82b94f3ee2c21aa45d7","","2009","2025-10-22 19:07:44","2025-10-22 19:07:44","","40-45","","4","36","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQVXJGQV","journalArticle","2012","Beloglazov, A.; Abawajy, J.; Buyya, R.","Energy-aware resource allocation heuristics for efficient management of data centers for Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2011.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370722&doi=10.1016%2fj.future.2011.04.017&partnerID=40&md5=404d8a6f96e7208ce49f7fb3ffc699cd","Cloud computing offers utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of electrical energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only minimize operational costs but also reduce the environmental impact. In this paper, we define an architectural framework and principles for energy-efficient Cloud computing. Based on this architecture, we present our vision, open research challenges, and resource provisioning and allocation algorithms for energy-efficient management of Cloud computing environments. The proposed energy-aware allocation heuristics provision data center resources to client applications in a way that improves energy efficiency of the data center, while delivering the negotiated Quality of Service (QoS). In particular, in this paper we conduct a survey of research in energy-efficient computing and propose: (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering QoS expectations and power usage characteristics of the devices; and (c) a number of open research challenges, addressing which can bring substantial benefits to both resource providers and consumers. We have validated our approach by conducting a performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant cost savings and demonstrates high potential for the improvement of energy efficiency under dynamic workload scenarios. © 2011 Elsevier B.V. All rights reserved.","2012","2025-10-22 19:07:44","2025-10-22 19:07:44","","755-768","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Energy efficient; Virtualizations; Energy aware; Resource allocation; Energy-efficient resource allocation; Computing environments; Research challenges; Data centers; Client applications; Computer systems; Performance evaluation; Cost saving; Dynamic consolidation; Allocation algorithm; Architectural frameworks; Architectural principles; Business domain; Carbon footprint; Computing solutions; Electrical energy; Environmental impact; Green IT; High potential; IT services; Operational costs; Pay-as-you-go; Pervasive applications; Power usage; Research; Resource providers; Resource provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6J9H28Z","journalArticle","2004","Saltelli, A.","Global sensitivity analysis: An introduction","Sensitivity Analysis of Model Output","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247402449&partnerID=40&md5=b5b0c412c2b7c40fe40d767ec3228357","","2004","2025-10-22 19:07:44","2025-10-22 19:07:44","","27-43","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IKV4GSVY","journalArticle","2016","Akhter, N.; Othman, M.","Energy aware resource allocation of cloud data center: review and open issues","Cluster Computing","","","10.1007/s10586-016-0579-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976634782&doi=10.1007%2fs10586-016-0579-4&partnerID=40&md5=6ffeaf3095e13dd3504670dc628c9cbf","The demand for cloud computing is increasing dramatically due to the high computational requirements of business, social, web and scientific applications. Nowadays, applications and services are hosted on the cloud in order to reduce the costs of hardware, software and maintenance. To satisfy this high demand, the number of large-scale data centers has increased, which consumes a high volume of electrical power, has a negative impact on the environment, and comes with high operational costs. In this paper, we discuss many ongoing or implemented energy aware resource allocation techniques for cloud environments. We also present a comprehensive review on the different energy aware resource allocation and selection algorithms for virtual machines in the cloud. Finally, we come up with further research issues and challenges for future cloud environments. © 2016, Springer Science+Business Media New York.","2016","2025-10-22 19:07:44","2025-10-22 19:07:44","","1163-1182","","3","19","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Application programs; Electric power utilization; Energy efficiency; Cloud computing; Virtualization; Cloud data centers; Java programming language; Virtualizations; Computational requirements; Virtual machines; Resource allocation; Scientific applications; Resource allocation techniques; Power consumption; Allocation of virtual machine; Impact on the environment; Selection algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NG45NVQA","journalArticle","2024","","","Production-Grade Container Orchestration","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197847259&partnerID=40&md5=6b50c85c92a179d7478fa3ac80025dc7","","2024","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUBSZB2J","journalArticle","2021","Yan, M.; Liang, X.; Lu, Z.; Wu, J.; Zhang, W.","HANSEL: Adaptive horizontal scaling of microservices using Bi-LSTM","Applied Soft Computing","","","10.1016/j.asoc.2021.107216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102654500&doi=10.1016%2fj.asoc.2021.107216&partnerID=40&md5=6f43e967886f90ae8ff608ea83599d09","With the rapid development of 5G network, business scenarios such as intelligent service and new retail are becoming more and more popular. The demand for more flexible and scalable real-time data processing, in particular, the AI-related data processing has also increased in edge computing. Therefore, how to meet such business development has become a major challenge. Focusing on this requirement, microservice architecture, proposed and developed by some big cloud computing companies’ platform, such as Google Kubernetes platform, has gradually become a mainstream technology solution in edge computing. However, many microservices used in edge computing cannot achieve an even time distribution, which is random or sudden. Kubernetes built-in Horizontal POD Autoscaling (HPA) is unable to well handle the change of microservice load, which inevitably leads to the waste of system resources and affects the SLA of microservice. To solve this issue, this paper proposes a HANSEL system based on Kubernetes platform, which can optimize the horizontal elastic scaling policy of Kubernetes by accurately predicting the load of microservices based on the Bi-LSTM load prediction algorithm with attention mechanism. Furthermore, active elastic scaling is realized through reinforcement learning method, and we design a hybrid elastic scaling mechanism through combining reactive and active methods, so as to construct an elastic scaling system for automatic scheduling of working nodes. Our experimental results show that HANSEL system can improve the system resource utilization by about 20% when meeting the microservice SLA of edge computing. © 2021 Elsevier B.V.","2021","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","105","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Edge computing; 5G mobile communication systems; Data handling; Learning systems; Real-time data processing; Reinforcement learning; Long short-term memory; System resource utilization; Elastic scaling; Intelligent Services; Attention mechanisms; Automatic scheduling; Business development; Horizontal wells; LSTM; Reinforcement learning method; Technology solutions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BI5PJAK","conferencePaper","2014","Cámara, J.; Moreno, G.A.; Garlan, D.","Stochastic game analysis and latency awareness for proactive self-adaptation","","","","10.1145/2593929.2593933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903726367&doi=10.1145%2f2593929.2593933&partnerID=40&md5=3032e7301a89e4652795b29fbe20f513","Although different approaches to decision-making in self-adaptive systems have shown their effectiveness in the past by factoring in predictions about the system and its environment (e.g., resource availability), no proposal considers the latency associated with the execution of tactics upon the target system. However, different adaptation tactics can take different amounts of time until their effects can be observed. In reactive adaptation, ignoring adaptation tactic latency can lead to suboptimal adaptation decisions (e.g., activating a server that takes more time to boot than the transient spike in trafic that triggered its activation). In proactive adaptation, taking adaptation latency into account is necessary to get the system into the desired state to deal with an upcoming situation. In this paper, we introduce a formal analysis technique based on model checking of stochas- tic multiplayer games (SMGs) that enables us to quantify the potential benefits of employing different types of algorithms for self-adaptation. In particular, we apply this tech- nique to show the potential benefit of considering adaptation tactic latency in proactive adaptation algorithms. Our results show that factoring in tactic latency in decision making improves the outcome of adaptation. We also present an algorithm to do proactive adaptation that considers tactic latency, and show that it achieves higher utility than an algorithm that under the assumption of no latency is optimal.","2014","2025-10-22 19:07:44","2025-10-22 19:07:44","","155-164","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource availability; Algorithms; Software engineering; Decision making; Stochastic systems; Model checking; Latency; Potential benefits; Self-adaptive system; Adaptation decisions; Chemical activation; Formal analysis; Multiplayer games; Proactive adaptation; Proactive adaptations; Stochastic multiplayer games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems, SEAMS 2014 - Proceedings","","","","","","","","","","","","","","",""
"YULP8XVQ","journalArticle","2006","Kwiatkowska, M.; Norman, G.; Parker, D.","Quantitative Analysis With the Probabilistic Model Checker PRISM","Electronic Notes in Theoretical Computer Science","","","10.1016/j.entcs.2005.10.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646404908&doi=10.1016%2fj.entcs.2005.10.030&partnerID=40&md5=233a50c4369a035c621327726b4666af","Probabilistic model checking is a formal verification technique for establishing the correctness, performance and reliability of systems which exhibit stochastic behaviour. As in conventional verification, a precise mathematical model of a real-life system is constructed first, and, given formal specifications of one or more properties of this system, an analysis of these properties is performed. The exploration of the system model is exhaustive and involves a combination of graph-theoretic algorithms and numerical methods. In this paper, we give a brief overview of the probabilistic model checker PRISM (www.cs.bham.ac.uk/~dxp/prism) implemented at the University of Birmingham. PRISM supports a range of probabilistic models and specification languages based on temporal logic, and has been recently extended with costs and rewards. We describe our experience with using PRISM to analyse a number of case studies from a wide range of application domains. We demonstrate the usefulness of probabilistic model checking techniques in detecting flaws and unusual trends, focusing mainly on the quantitative analysis of a range of best, worst and average-case system characteristics. © 2006 Elsevier B.V. All rights reserved.","2006","2025-10-22 19:07:44","2025-10-22 19:07:44","","5-31","","2 SPEC. ISS.","153","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Algorithms; Real time systems; Mathematical models; Markov processes; Reliability; reliability; performability; dependability; Probabilistic model checking; Performability; Markov models; Probabilistic logics; Temporal logic; probabilistic model checking; Automatic verification; Numerical analysis; Stochastic programming; temporal logic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RS5UKEW","journalArticle","2014","Lorido-Botran, T.; Miguel-Alonso, J.; Lozano, J.A.","A Review of Auto-scaling Techniques for Elastic Applications in Cloud Environments","Journal of Grid Computing","","","10.1007/s10723-014-9314-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912530861&doi=10.1007%2fs10723-014-9314-7&partnerID=40&md5=2910478cbfc08e55ee6c8ebb60478a04","Cloud computing environments allow customers to dynamically scale their applications. The key problem is how to lease the right amount of resources, on a pay-as-you-go basis. Application re-dimensioning can be implemented effortlessly, adapting the resources assigned to the application to the incoming user demand. However, the identification of the right amount of resources to lease in order to meet the required Service Level Agreement, while keeping the overall cost low, is not an easy task. Many techniques have been proposed for automating application scaling. We propose a classification of these techniques into five main categories: static threshold-based rules, control theory, reinforcement learning, queuing theory and time series analysis. Then we use this classification to carry out a literature review of proposals for auto-scaling in the cloud. © 2014, Springer Science+Business Media Dordrecht.","2014","2025-10-22 19:07:44","2025-10-22 19:07:44","","559-592","","4","12","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud environments; Service Level Agreements; Computation theory; Cloud computing environments; Reinforcement learning; Literature reviews; Time series analysis; Queueing theory; Auto-scaling; Service level agreement; Elastic applications; Re-dimensioning; Scalable applications; Static thresholds","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUNIMZV9","journalArticle","2013","Barroso, L.A.; Clidaras, J.; Hölzle, U.","The datacenter as a computer: An introduction to the design of warehouse-scale machines, second edition","Synthesis Lectures on Computer Architecture","","","10.2200/S00516ED2V01Y201306CAC024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883331358&doi=10.2200%2fS00516ED2V01Y201306CAC024&partnerID=40&md5=23b188236b7201d7b8ae9aa8c056cdf8","As computation continues to move into the cloud, the computing platform of interest no longer resembles a pizza box or a refrigerator, but a warehouse full of computers. These new large datacenters are quite different from traditional hosting facilities of earlier times and cannot be viewed simply as a collection of co-located servers. Large portions of the hardware and software resources in these facilities must work in concert to efficiently deliver good levels of Internet service performance, something that can only be achieved by a holistic approach to their design and deployment. In other words, we must treat the datacenter itself as one massive warehouse-scale computer (WSC). We describe the architecture of WSCs, the main factors influencing their design, operation, and cost structure, and the characteristics of their software base. We hope it will be useful to architects and programmers of today's WSCs, as well as those of future many-core platforms which may one day implement the equivalent of today's WSCs on a single board. Notes for the Second Edition After nearly four years of substantial academic and industrial developments in warehouse-scale computing, we are delighted to present our first major update to this lecture. The increased popularity of public clouds has made WSC software techniques relevant to a larger pool of programmers since our first edition. Therefore, we expanded Chapter 2 to reflect our better understanding of WSC software systems and the toolbox of software techniques for WSC programming. In Chapter 3, we added to our coverage of the evolving landscape of wimpy vs. brawny server trade-offs, and we now present an overview of WSC interconnects and storage systems that was promised but lacking in the original edition. Thanks largely to the help of our new co-author, Google Distinguished Engineer Jimmy Clidaras, the material on facility mechanical and power distribution design has been updated and greatly extended (see Chapters 4 and 5). Chapters 6 and 7 have also been revamped significantly. We hope this revised edition continues to meet the needs of educators and professionals in this area. © 2013 by Morgan & Claypool.","2013","2025-10-22 19:07:44","2025-10-22 19:07:44","","1-156","","","24","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; cloud computing; Cloud computing; Distributed systems; Internet; Cluster computing; Computer architecture; Design; Computer software; Data centers; Warehouses; energy efficiency; Fault tolerant computer systems; Internet services; distributed systems; data centers; cluster computing; Computer organization; computer organization and design; fault-tolerant computing; Fault-tolerant computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WLA5Y5Q","journalArticle","2023","","","Resize CPU and Memory Resources Assigned to Containers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213688281&partnerID=40&md5=72f733c94aa6c06bcfad147f8c408491","","2023","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9GADRHR7","journalArticle","2024","Xu, H.; Jian, C.","A meta reinforcement learning-based virtual machine placement algorithm in mobile edge computing","Cluster Computing","","","10.1007/s10586-023-04030-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161367765&doi=10.1007%2fs10586-023-04030-w&partnerID=40&md5=fc8dfecc0133a12712abb775ba680264","Mobile edge computing requires more and more high-performance servers, resulting in increased energy consumption. As an effective means to reduce energy consumption, virtual machine placement (VMP) has been widely studied. In the edge computing environment, as the number of terminal device requests continues to increase, the scale of VMP becomes larger and larger, and existing research algorithms may take a long time to converge. The reason is that as the number of VMs increases, the search space of the policy becomes larger and the agent needs to interact with the environment for a longer time to make the best decision. In addition, existing research methods only consider reducing energy consumption, rarely consider the response latency of virtual machines, and almost ignore the dynamic changes of the edge environment. To overcome these drawbacks, we propose a virtual machine placement algorithm based on meta-reinforcement learning, which consists of an inner and outer loop. The inner loop designs a deep reinforcement learning algorithm combined with the order exchange and migration mechanism to generate the best decision, and the outer loop provides meta-strategy parameters for the inner loop based on meta-learning to accelerate the convergence capability of the inner loop, thereby obtaining efficient virtual machine placement decisions quickly from a new environment. Through simulation experiments, we demonstrate that our approach effectively reduces the energy consumption of the edge server and the response latency of VMs at different problem sizes compared to the three baseline algorithms. At the same time, it quickly adapts to the new environment with only a small number of gradient updates. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.","2024","2025-10-22 19:07:44","2025-10-22 19:07:44","","1883-1896","","2","27","","","","","","","","","","","","","Scopus","","","","","","","","Deep learning; Energy utilization; Energy-consumption; Green computing; Mobile edge computing; Virtual machine; Learning algorithms; Deep reinforcement learning; Reinforcement learning; Reinforcement learnings; Network security; Virtual machine placements; Placement algorithm; Virtual machine placement; E-learning; Best decision; Inner loops; Meta reinforcement learning; Outer loop","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q29QL65T","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201045593&partnerID=40&md5=8e8a223fd88601b90b7afe7c5a769e87","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZMVXZBT","journalArticle","2000","Deb, K.; Agrawal, S.; Pratap, A.; Meyarivan, T.","A fast elitist non-dominated sorting genetic algorithm for multi-objective optimization: NSGA-II","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/3-540-45356-3_83","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947926042&doi=10.1007%2f3-540-45356-3_83&partnerID=40&md5=48ed55dda6b441840a2f3c3fa46a1371","Multi-objective evolutionary algorithms which use non-dominated sorting and sharing have been mainly criticized for their (i) O(MN3) computational complexity (where M is the number of objectives and N is the population size), (ii) non-elitism approach, and (iii) the need for specifying a sharing parameter. In this paper, we suggest a non-dominated sorting based multi-objective evolutionary algorithm (we called it the Non-dominated Sorting GA-II or NSGA-II) which alleviates all the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN2) computational complexity is presented. Second, a selection operator is presented which creates a mating pool by combining the parent and child populations and selecting the best (with respect to fitness and spread) N solutions. Simulation results on five difficult test problems show that the proposed NSGA-II, in most problems, is able to find much better spread of solutions and better convergence near the true Pareto-optimal front compared to PAES and SPEA—two other elitist multi-objective EAs which pay special attention towards creating a diverse Pareto-optimal front. Because of NSGA-II's low computational requirements, elitist approach, and parameter-less sharing approach, NSGA-II should find increasing applications in the years to come. © Springer-Verlag Berlin Heidelberg 2000.","2000","2025-10-22 19:07:44","2025-10-22 19:07:44","","849-858","","","1917","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Algorithms; Computational requirements; Computational complexity; Problem solving; Multiobjective optimization; Evolutionary algorithms; Genetic algorithms; Multi objective; Pareto principle; Composite structures; Elitist non-dominated sorting genetic algorithms; Multi objective evolutionary algorithms; Non-dominated Sorting; Pareto-optimal front; Population sizes; Population statistics; Selection operators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JC7PFWHX","journalArticle","2022","Cortellessa, V.; Di Pompeo, D.; Eramo, R.; Tucci, M.","A model-driven approach for continuous performance engineering in microservice-based systems","Journal of Systems and Software","","","10.1016/j.jss.2021.111084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117098236&doi=10.1016%2fj.jss.2021.111084&partnerID=40&md5=47e70199c168eed6e6f288b9b64e7894","Microservices are quite widely impacting on the software industry in recent years. Rapid evolution and continuous deployment represent specific benefits of microservice-based systems, but they may have a significant impact on non-functional properties like performance. Despite the obvious relevance of this property, there is still a lack of systematic approaches that explicitly take into account performance issues in the lifecycle of microservice-based systems. In such a context of evolution and re-deployment, Model-Driven Engineering techniques can provide major support to various software engineering activities, and in particular they can allow managing the relationships between a running system and its architectural model. In this paper, we propose a model-driven integrated approach that exploits traceability relationships between the monitored data of a microservice-based running system and its architectural model to derive recommended refactoring actions that lead to performance improvement. The approach has been applied and validated on two microservice-based systems, in the domain of e-commerce and ticket reservation, respectively, whose architectural models have been designed in UML profiled with MARTE. © 2021 The Author(s)","2022","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","183","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Performance; Software engineering; Architectural modeling; Continuous deployment; Life cycle; Model driven approach; Model-driven engineering; Model-driven Engineering; Performance engineering; Running systems; Software evolution; Software Evolution; Software refactoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NH4ELK8F","conferencePaper","2011","Arcuri, A.; Briand, L.","A practical guide for using statistical tests to assess randomized algorithms in software engineering","","","","10.1145/1985793.1985795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959871222&doi=10.1145%2f1985793.1985795&partnerID=40&md5=059ab141072a983e9289c18ede5d03e8","Randomized algorithms have been used to successfully address many different types of software engineering problems. This type of algorithms employ a degree of randomness as part of their logic. Randomized algorithms are useful for difficult problems where a precise solution cannot be derived in a deterministic way within reasonable time. However, randomized algorithms produce different results on every run when applied to the same problem instance. It is hence important to assess the effectiveness of randomized algorithms by collecting data from a large enough number of runs. The use of rigorous statistical tests is then essential to provide support to the conclusions derived by analyzing such data. In this paper, we provide a systematic review of the use of randomized algorithms in selected software engineering venues in 2009. Its goal is not to perform a complete survey but to get a representative snapshot of current practice in software engineering research. We show that randomized algorithms are used in a significant percentage of papers but that, in most cases, randomness is not properly accounted for. This casts doubts on the validity of most empirical results assessing randomized algorithms. There are numerous statistical tests, based on different assumptions, and it is not always clear when and how to use these tests. We hence provide practical guidelines to support empirical research on randomized algorithms in software engineering © 2011 ACM.","2011","2025-10-22 19:07:44","2025-10-22 19:07:44","","1-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Software engineering; Surveys; Effect size; Software testing; Systematic Review; Random processes; survey; systematic review; Engineering; Parameter estimation; confidence interval; Statistical tests; bonferroni adjustment; Bonferroni adjustment; Confidence interval; effect size; non-parametric test; Non-parametric test; parametric test; Parametric test; statistical difference; Statistical differences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"7M7UA4FA","journalArticle","1994","Lai, Y.-J.; Liu, T.-Y.; Hwang, C.-L.","TOPSIS for MODM","European Journal of Operational Research","","","10.1016/0377-2217(94)90282-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028483495&doi=10.1016%2f0377-2217%2894%2990282-8&partnerID=40&md5=88a5244232099fb09b0a1fac28c87e43","In this study, we extend TOPSIS to solve a multiple objective decision making problem. The principle of compromise (of TOPSIS) for multiple criteria decision making is that the chosen solution should have the shortest distance from the positive ideal solution as well as the longest distance from the negative ideal solution. Thus, we reduce a k-dimensional objective space to a two-dimensional objective space by a first-order compromise procedure. We then use membership functions of fuzzy set theory to represent the satisfaction level for both criteria. We obtain a single-objective programming problem by using the max-min operator for the second-order compromise operation. To illustrate the procedure, the Bow River Valley water quality management problem is solved by use of TOPSIS. © 1994.","1994","2025-10-22 19:07:44","2025-10-22 19:07:44","","486-500","","3","76","","","","","","","","","","","","","Scopus","","","","","","","","Vectors; Mathematical programming; Constraint theory; Compromise operation; Decision theory; Fuzzy sets; Mathematical operators; Membership functions; Multiple objective decision making; Negative ideal solution; Positive ideal solution; Project management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJH6BFXU","journalArticle","","","","UML Profile for Modeling and Analysis of Real-Time and Embedded Systems (MARTE)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47749093851&partnerID=40&md5=a64362f7427f163a983bba268aac625f","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XE2UFZMQ","journalArticle","2022","Ram, S.D.K.; Srivastava, S.; Mishra, K.K.","A new meta-heuristic approach for load aware-cost effective workflow scheduling","Concurrency and Computation: Practice and Experience","","","10.1002/cpe.7112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130760464&doi=10.1002%2fcpe.7112&partnerID=40&md5=a77150a45168d7312481f660d9dbf35f","Workflow scheduling is an important way to manage the execution of a workflow. It introduces the concept of providing suitable resources to workflow tasks in order to finish workflow execution and meet the user's objectives. However, the problem becomes more complex when scheduling must balance two conflicting objectives, such as minimizing execution cost and maximizing load across all computing resources. A workflow has many interdependent tasks, and the cloud datacenter has many computing resources to execute the workflow. There can be an asymptotically infinite number of mappings of tasks-to-computing resources. Every mapping produces different execution costs with different workloads on computing resources. The main challenge for the researcher is to develop an intelligent scheduling algorithm to identify an optimal mapping that produces minimal execution cost with fair workload distribution on resources. We developed a novel meta-heuristic algorithm named Investment-Based Optimization (IBO) to identify an optimal mapping. The IBO algorithm was first tested on optimization benchmark functions and then simulated in CloudSim to see its performance for scheduling workflows. Finally, IBO was tested over Montage, Epigenomics, Sipht, and a sample workflow, and it was found that IBO reduces execution costs by 33%, 16%, 16.36%, and 20% with a fair workload distribution. © 2022 John Wiley & Sons, Ltd.","2022","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","21","34","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Optimization; cloud computing; Cloud-computing; Benchmarking; Mapping; Heuristic algorithms; Cost effectiveness; Scheduling algorithms; workflow scheduling; Workflow scheduling; Optimisations; Heuristic methods; Computing resource; Work-flows; Metaheuristic; workflow; meta-heuristic; Execution costs; Cloudsim; CloudSim; Optimal mapping; Work-load distribution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YMKD3KY3","journalArticle","2016","Xu, X.; Dou, W.; Zhang, X.; Chen, J.","EnReal: An Energy-Aware Resource Allocation Method for Scientific Workflow Executions in Cloud Environment","IEEE Transactions on Cloud Computing","","","10.1109/TCC.2015.2453966","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976588157&doi=10.1109%2fTCC.2015.2453966&partnerID=40&md5=08980cc191d10bca2dc09ef67c1074b4","Scientific workflows are often deployed across multiple cloud computing platforms due to their large-scale characteristic. This can be technically achieved by expanding a cloud platform. However, it is still a challenge to conduct scientific workflow executions in an energy-aware fashion across cloud platforms or even inside a cloud platform, since the cloud platform expansion will make the energy consumption a big concern. In this paper, we propose an Energy-aware Resource Allocation method, named EnReal, to address the above challenge. Basically, we leverage the dynamic deployment of virtual machines for scientific workflow executions. Specifically, an energy consumption model is presented for applications deployed across cloud computing platforms, and a corresponding energy-aware resource allocation algorithm is proposed for virtual machine scheduling to accomplish scientific workflow executions. Experimental evaluation demonstrates that the proposed method is both effective and efficient. © 2013 IEEE.","2016","2025-10-22 19:07:44","2025-10-22 19:07:44","","166-179","","2","4","","","","","","","","","","","","","Scopus","","","","","","","","Power management; cloud computing; Cloud computing; Energy utilization; Java programming language; Energy aware; Resource allocation; Experimental evaluation; resource allocation; Energy consumption model; Resource allocation algorithms; Scientific workflows; Dynamic deployment; Cloud computing platforms; Energy-aware method; scientific workflow; Virtual machine scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAP8GZU5","conferencePaper","2022","Di Pompeo, D.; Tucci, M.","Search Budget in Multi-Objective Refactoring optimization: a Model-Based Empirical Study","","","","10.1109/SEAA56994.2022.00070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146884337&doi=10.1109%2fSEAA56994.2022.00070&partnerID=40&md5=1dcd8d5fb8b83d67b23ffca1be5a28c7","Software model optimization is the task of automatically generate design alternatives, usually to improve quality aspects of software that are quantifiable, like performance and reliability. In this context, multi-objective optimization techniques have been applied to help the designer find suitable tradeoffs among several non-functional properties. In this process, design alternatives can be generated through automated model refactoring, and evaluated on non-functional models. Due to their complexity, this type of optimization tasks require considerable time and resources, often limiting their application in software engineering processes.In this paper, we investigate the effects of using a search budget, specifically a time limit, to the search for new solutions. We performed experiments to quantify the impact that a change in the search budget may have on the quality of solutions. Furthermore, we analyzed how different genetic algorithms (i.e., NSGh-II, SPEh2, and PESA2) perform when imposing different budgets. We experimented on two case studies of different size, complexity, and domain.We observed that imposing a search budget considerably deteriorates the quality of the generated solutions, but the specific algorithm we choose seems to play a crucial role. From our experiments, NSGh-II is the fastest algorithm, while PESA2 generates solutions with the highest quality. Differently, SPEh2 is the slowest algorithm, and produces the solutions with the lowest quality. © 2022 IEEE.","2022","2025-10-22 19:07:44","2025-10-22 19:07:44","","406-413","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Performance; Refactorings; Model-driven Engineering; Empirical studies; Budget control; Multiobjective optimization; Optimisations; Genetic algorithms; Model-based OPC; Software reliability; performance; non-functional properties; model-driven engineering; refactoring; Multi objective; Design alternatives; multi-objective; Non functional properties; Software modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 48th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2022","","","","","","","","","","","","","","",""
"JA8VY8XG","journalArticle","2000","Boehm, B.W.","","Software Cost Estimation with COCOMO II","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003567818&partnerID=40&md5=cd091e62c66f44e210bbfa7ffcb15652","","2000","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADLK3DSP","conferencePaper","2011","Arcuri, A.; Fraser, G.","On parameter tuning in search based software engineering","","","","10.1007/978-3-642-23716-4_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052895933&doi=10.1007%2f978-3-642-23716-4_6&partnerID=40&md5=3f92d4cb44dadf12e21ec2d3ebf7796e","When applying search-based software engineering (SBSE) techniques one is confronted with a multitude of different parameters that need to be chosen: Which population size for a genetic algorithm? Which selection mechanism to use? What settings to use for dozens of other parameters? This problem not only troubles users who want to apply SBSE tools in practice, but also researchers performing experimentation - how to compare algorithms that can have different parameter settings? To shed light on the problem of parameters, we performed the largest empirical analysis on parameter tuning in SBSE to date, collecting and statistically analysing data from more than a million experiments. As case study, we chose test data generation, one of the most popular problems in SBSE. Our data confirm that tuning does have a critical impact on algorithmic performance, and over-fitting of parameter tuning is a dire threat to external validity of empirical analyses in SBSE. Based on this large empirical evidence, we give guidelines on how to handle parameter tuning. © 2011 Springer-Verlag.","2011","2025-10-22 19:07:44","2025-10-22 19:07:44","","33-47","","","6956 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Data communication systems; Algorithms; Software engineering; Object oriented; Experiments; Search-based software engineering; Engineering; Parameter estimation; Population sizes; Population statistics; Empirical analysis; Empirical evidence; object-oriented; Overfitting; Parameter setting; Parameter-tuning; Search based software engineering; Selection mechanism; test data generation; Test data generation; unit testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"82N7I4HD","conferencePaper","2010","Bortolussi, L.; Galpin, V.; Hillston, J.; Tribastone, M.","Hybrid semantics for PEPA","","","","10.1109/QEST.2010.31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649461070&doi=10.1109%2fQEST.2010.31&partnerID=40&md5=0bbbdb7275b92bc953c909ce0eb5397e","In order to circumvent the problem of statespace explosion of large-scale Markovian models, the stochastic process algebra PEPA has been given a fluid semantics based on ordinary differential equations, treating all entities as continuous. However, low numbers of instances and/or relatively slow dynamics may make such approximation too coarse for some parts of the system. To deal with such situations, we propose an hybrid semantics lying between these two extremes, treating parts of the system as discrete and stochastic and others as continuous and deterministic. The underlying mathematical object for the quantitative evaluation is a stochastic hybrid automaton. A case study of a client/server system with breakdowns and repairs is used to discuss the accuracy and the cost of this hybrid analysis. © 2010 IEEE.","2010","2025-10-22 19:07:44","2025-10-22 19:07:44","","181-190","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quantitative evaluation; Stochastic systems; Markov processes; Stochastic models; Breakdowns and repairs; Client/server systems; Hybrid analysis; Hybrid automatons; Markovian model; Mathematical objects; Ordinary differential equations; Slow dynamics; State-space explosion; Stochastic process algebras","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 7th International Conference on the Quantitative Evaluation of Systems, QEST 2010","","","","","","","","","","","","","","",""
"T4KQVUL9","journalArticle","2013","Trendowicz, A.","Software Cost Estimation, Benchmarking, and Risk Assessment: The Software Decision-Makers’","Guide to Predictable Software Development.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169391889&partnerID=40&md5=afcb1c1fca4c430d45380796f1d8fe4d","","2013","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPTGH38P","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201046609&partnerID=40&md5=44bf75ed1c094157bdd91143600e899d","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UHW5V4N7","journalArticle","2021","Houssein, E.H.; Gad, A.G.; Wazery, Y.M.; Suganthan, P.N.","Task Scheduling in Cloud Computing based on Meta-heuristics: Review, Taxonomy, Open Challenges, and Future Trends","Swarm and Evolutionary Computation","","","10.1016/j.swevo.2021.100841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100086183&doi=10.1016%2fj.swevo.2021.100841&partnerID=40&md5=8aab29bab18b62b064d7742b362fb40e","Cloud computing is a recently looming-evoked paradigm, the aim of which is to provide on-demand, pay-as-you-go, internet-based access to shared computing resources (hardware and software) in a metered, self-service, dynamically scalable fashion. A related hot topic at the moment is task scheduling, which is well known for delivering critical cloud service performance. However, the dilemmas of resources being underutilized (underloaded) and overutilized (overloaded) may arise as a result of improper scheduling, which in turn leads to either wastage of cloud resources or degradation in service performance, respectively. Thus, the idea of incorporating meta-heuristic algorithms into task scheduling emerged in order to efficiently distribute complex and diverse incoming tasks (cloudlets) across available limited resources, within a reasonable time. Meta-heuristic techniques have proven very capable of solving scheduling problems, which is fulfilled herein from a cloud perspective by first providing a brief on traditional and heuristic scheduling methods before diving deeply into the most popular meta-heuristics for cloud task scheduling followed by a detailed systematic review featuring a novel taxonomy of those techniques, along with their advantages and limitations. More specifically, in this study, the basic concepts of cloud task scheduling are addressed smoothly, as well as diverse swarm, evolutionary, physical, emerging, and hybrid meta-heuristic scheduling techniques are categorized as per the nature of the scheduling problem (i.e., single- or multi-objective), the primary objective of scheduling, task-resource mapping scheme, and scheduling constraint. Armed with these methods, some of the most recent relevant literature are surveyed, and insights into the identification of existing challenges are presented, along with a trail to potential solutions. Furthermore, guidelines to future research directions drawn from recently emerging trends are outlined, which should definitely contribute to assisting current researchers and practitioners as well as pave the way for newbies excited about cloud task scheduling to pursue their own glory in the field. © 2021 Elsevier B.V.","2021","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","62","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Multitasking; Optimization; Cloud computing; Cloud-computing; Quality-of-service; Taxonomies; Heuristic algorithms; Scheduling algorithms; Optimisations; Systematic Review; Heuristic methods; Metaheuristic; Task scheduling; Tasks scheduling; Simulation tools; Systematic review; Future trends; Meta-heuristics; Open challenge; Open challenges; Quality of Service (QoS); Simulation tool","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJIFGTZU","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201060421&partnerID=40&md5=927160d8f227e689dbd8726ac21cd41a","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGKSL4CZ","conferencePaper","2017","Hahnel, M.; Arega, F.M.; Dargie, W.; Khasanov, R.; Castrillon, J.","Application interference analysis: Towards energy-efficient workload management on heterogeneous micro-server architectures","","","","10.1109/INFCOMW.2017.8116415","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041308410&doi=10.1109%2fINFCOMW.2017.8116415&partnerID=40&md5=f93e550bb1af29e947fee389263c47aa","The ever increasing demand for Internet traffic, storage and processing requires an ever increasing amount of hardware resources. In addition to this, infrastructure providers over-provision system architectures to serve users at peak times without performance delays. Over-provisioning leads to underutilization and thus to unnecessary power consumption. Therefore, there is a need for workload management strategies to map and schedule different services simultaneously in an energy-efficient manner without compromising performance, specially for heterogeneous micro-server architectures. This requires statistical models of how services interfere with each other, thereby affecting both performance and energy consumption. Indeed, the performance-energy behavior when mixing workloads is not well understood. This paper presents an interference analysis for heterogeneous workloads (i.e., CPU- and memory-intensive) on a big.LITTLE MPSoC architecture. We employ state-of-the-art tools to generate multiple single-application mappings and characterize the interference among two different services. We observed a performance degradation factor between 1.1 and 2.5. For some configurations, executing on different clusters resulted in reduced energy consumption with no performance penalty. This kind of detailed analysis give us first insights towards more general models for future workload management systems. © 2017 IEEE.","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","432-437","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Energy efficiency; Performance degradation; Energy utilization; Mapping; System-on-chip; Heterogeneous workloads; Energy efficient computing; Interference; Performance penalties; Infrastructure providers; Multiprocessing systems; Energy-efficient computing; Heterogeneous; Interference analysis; MPSoCs; Wave interference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2017","","","","","","","","","","","","","","",""
"WZCXIBFE","journalArticle","2023","Cortellessa, V.; Di Pompeo, D.; Stoico, V.; Tucci, M.","Many-objective optimization of non-functional attributes based on refactoring of software models","Information and Software Technology","","","10.1016/j.infsof.2023.107159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147547137&doi=10.1016%2fj.infsof.2023.107159&partnerID=40&md5=1e209abdb3cc33fb8cb5dbab48c5e223","Context: Software quality estimation is a challenging and time-consuming activity, and models are crucial to face the complexity of such activity on modern software applications. In this context, software refactoring is a crucial activity within development life-cycles where requirements and functionalities rapidly evolve. Objective: One main challenge is that the improvement of distinctive quality attributes may require contrasting refactoring actions on software, as for trade-off between performance and reliability (or other non-functional attributes). In such cases, multi-objective optimization can provide the designer with a wider view on these trade-offs and, consequently, can lead to identify suitable refactoring actions that take into account independent or even competing objectives. Method: In this paper, we present an approach that exploits the NSGA-II as the genetic algorithm to search optimal Pareto frontiers for software refactoring while considering many objectives. We consider performance and reliability variations of a model alternative with respect to an initial model, the amount of performance antipatterns detected on the model alternative, and the architectural distance, which quantifies the effort to obtain a model alternative from the initial one. Results: We applied our approach on two case studies: a Train Ticket Booking Service, and CoCoME. We observed that our approach is able to improve performance (by up to 42%) while preserving or even improving the reliability (by up to 32%) of generated model alternatives. We also observed that there exists an order of preference of refactoring actions among model alternatives. Conclusion: Based on our analysis, we can state that performance antipatterns confirmed their ability to improve performance of a subject model in the context of many-objective optimization. In addition, the metric that we adopted for the architectural distance seems to be suitable for estimating the refactoring effort. © 2023 Elsevier B.V.","2023","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","157","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Performance; Software architecture; Economic and social effects; Refactorings; Life cycle; Model-driven engineering; Model-driven Engineering; Software refactoring; Multi-objectives optimization; Multiobjective optimization; Search-based; Search-based software engineering; Genetic algorithms; Reliability; Software reliability; Multi-objective optimization; Refactoring; Computer software selection and evaluation; Functional attribute; Many-objective optimizations; Non-functional","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7ZZXKSF","journalArticle","2019","Rodríguez-Gracia, D.; Piedra-Fernández, J.A.; Iribarne, L.; Criado, J.; Ayala, R.; Alonso-Montesinos, J.; de las Mercedes, C.-U.M.","Microservices and machine learning algorithms for adaptive green buildings","Sustainability (Switzerland)","","","10.3390/su11164320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070712595&doi=10.3390%2fsu11164320&partnerID=40&md5=547ebabe27f2f4e288d0a8b65e03a6b6","In recent years, the use of services for Open Systems development has consolidated and strengthened. Advances in the Service Science and Engineering (SSE) community, promoted by the reinforcement ofWeb Services and SemanticWeb technologies and the presence of new Cloud computing techniques, such as the proliferation of microservices solutions, have allowed software architects to experiment and develop new ways of building open and adaptable computer systems at runtime. Home automation, intelligent buildings, robotics, graphical user interfaces are some of the social atmosphere environments suitable in which to apply certain innovative trends. This paper presents a schema for the adaptation of Dynamic Computer Systems (DCS) using interdisciplinary techniques on model-driven engineering, service engineering and soft computing. The proposal manages an orchestrated microservices schema for adapting component-based software architectural systems at runtime. This schema has been developed as a three-layer adaptive transformation process that is supported on a rule-based decision-making service implemented by means of Machine Learning (ML) algorithms. The experimental development was implemented in the Solar Energy Research Center (CIESOL) applying the proposed microservices schema for adapting home architectural atmosphere systems on Green Buildings. © 2019 by the authors.","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","16","11","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; automation; Machine learning; algorithm; machine learning; software; World Wide Web; Adaptive systems; Smart building; building; innovation; computer system; adaptive management; interdisciplinary approach; robotics; trend analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCGLC84R","conferencePaper","2016","Ponsard, C.; De Landtsheer, R.; Ospina, G.; Deprez, J.-C.","Towards design-time simulation support for energy-aware cloud application development","","","","10.5220/0005933503980404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979518755&doi=10.5220%2f0005933503980404&partnerID=40&md5=bcca5ad71ffaceec4c170c45ec152ac1","Cloud application deployment is becoming increasingly popular for the removal of upfront hardware costs, the pay-per-use cost model and their ability to scale. However, deploying software on the Cloud carries both opportunities and threats regarding energy efficiency. In order to help Cloud application developers learn and reason about the energy consumption of their application on the server-side, we have developed a framework centred on a UML profile for relating energy goals, requirements and associated KPI metrics to application design and deployment elements. Our previous work has focused on the use of such a framework to carry out our run-time experiments in order to select the best approach. In this paper, we explore the feasibility of a complementary approach for providing support at design time based on finer grained deployment models, the specification of Cloud and energy adaptation policies and the use of a discrete event simulator for reasoning on key performance indicators such as energy but also overall performance, delay and costs. The goal is to support the Cloud developer in pre-selecting the best trade-off that can be further tuned at run-time. Copyright © 2016 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","2016","2025-10-22 19:07:44","2025-10-22 19:07:44","","398-404","","","2","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Cloud computing; Cloud applications; Deployment models; Energy utilization; Economic and social effects; Clouds; Benchmarking; Green computing; Cloud; Sustainable development; Application design; Adaptation policies; Self adaptation; Self-adaptation; Sustainability; Key performance indicators; Discrete-event simulators; Discrete event simulation; Green-it; Hardware cost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CLOSER 2016 - Proceedings of the 6th International Conference on Cloud Computing and Services Science","","","","","","","","","","","","","","",""
"DRE3CAMJ","conferencePaper","2007","Fan, X.; Weber, W.-D.; Barroso, L.A.","Power provisioning for a warehouse-sized computer","","","","10.1145/1250662.1250665","https://www.scopus.com/inward/record.uri?eid=2-s2.0-35348835964&doi=10.1145%2f1250662.1250665&partnerID=40&md5=0ba10bc53962f2321e9062dec64e3177","Large-scale Internet services require a computing infrastructure that can beappropriately described as a warehouse-sized computing system. The cost ofbuilding datacenter facilities capable of delivering a given power capacity tosuch a computer can rival the recurring energy consumption costs themselves.Therefore, there are strong economic incentives to operate facilities as closeas possible to maximum capacity, so that the non-recurring facility costs canbe best amortized. That is difficult to achieve in practice because ofuncertainties in equipment power ratings and because power consumption tends tovary significantly with the actual computing activity. Effective powerprovisioning strategies are needed to determine how much computing equipmentcan be safely and efficiently hosted within a given power budget. In this paper we present the aggregate power usage characteristics of largecollections of servers (up to 15 thousand) for different classes ofapplications over a period of approximately six months. Those observationsallow us to evaluate opportunities for maximizing the use of the deployed powercapacity of datacenters, and assess the risks of over-subscribing it. We findthat even in well-tuned applications there is a noticeable gap (7 - 16%)between achieved and theoretical aggregate peak power usage at the clusterlevel (thousands of servers). The gap grows to almost 40% in wholedatacenters. This headroom can be used to deploy additional compute equipmentwithin the same power budget with minimal risk of exceeding it. We use ourmodeling framework to estimate the potential of power management schemes toreduce peak power and energy usage. We find that the opportunities for powerand energy savings are significant, but greater at the cluster-level (thousandsof servers) than at the rack-level (tens). Finally we argue that systems needto be power efficient across the activity range, and not only at peakperformance levels. Copyright 2007 ACM.","2007","2025-10-22 19:07:44","2025-10-22 19:07:44","","13-23","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Power modeling; Internet; Telecommunication services; Mathematical models; Warehouses; Power provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"HG6T6RVF","conferencePaper","2017","Rago, A.; Vidal, S.; Andres Diaz-Pace, J.; Frank, S.; Van Hoorn, A.","Distributed qality-atribute optimization of sofware architectures","","","","10.1145/3132498.3132509","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037813858&doi=10.1145%2f3132498.3132509&partnerID=40&md5=caeff8b75f9a1add3268059c459d1ad7","A key challenge of software architecture design is how to satisfy quality-attribute requirements, which often confict with each other. This is usually a complex task, because there are several candidates for architectural solutions meeting the same requirements, and quality-attribute tradeofs of those solutions need to be considered by the architects. In this context, we present the SQuAT framework to assist architects in the exploration of design solutions and their tradeofs. This framework provides a modular approach for integrating quality-attribute analyzers and solvers, and also features a distributed search-based optimization. In this paper, we report on an experience using SQuAT with Palladio architectural models, which integrates third-party tools for performance and modifability, and shows the tradeofs among candidate solutions to the architect. Furthermore, we enhance the standard search schema of SQuAT with a distributed negotiation technique based on monotonic concession, in order to provide better tradeofs for the architect's decision making. © 2017 Association for Computing Machinery.","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","Part F130660","","","","","","","","","","","","","Scopus","","","","","","","","Software architecture; Decision making; Commerce; Software architectures; Agents; Computer software reusability; Software agents; Quality attributes; Architectural models; Architectural solutions; Distributed negotiations; Distributed search; Modular approach; Software architecture design; Third-party tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"EI8JKVIR","journalArticle","1993","Cliff, N.","Dominance statistics: Ordinal analyses to answer ordinal questions","Psychological Bulletin","","","10.1037/0033-2909.114.3.494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-12044258480&doi=10.1037%2f0033-2909.114.3.494&partnerID=40&md5=2ca6ac7262d59edf80475edaf25c7f18","Much behavioral research involves comparing the central tendencies of different groups, or of the same subjects under different conditions, and the usual analysis is some form of mean comparison. This article suggests that an ordinal statistic, d, is often more appropriate. d compares the number of times a score from one group or condition is higher than one from the other, compared with the reverse. Compared to mean comparisons, d is more robust and equally or more powerful; it is invariant under transformation: and it often conforms more closely to the experimenter's research hypothesis. It is suggested that inferences from d be based on sample estimates of its variance rather than on the more traditional assumption of identical distributions. The statistic is extended to simple repeated measures designs, and ways of extending its use to more complex designs are suggested.","1993","2025-10-22 19:07:44","2025-10-22 19:07:44","","494-509","","3","114","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKIIUZ8T","conferencePaper","2014","Procaccianti, G.; Lago, P.; Lewis, G.A.","A catalogue of green architectural tactics for the cloud","","","","10.1109/MESOCA.2014.12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933047019&doi=10.1109%2fMESOCA.2014.12&partnerID=40&md5=fb46ca5da4f70055aa3a5818986d6d68","Energy efficiency is a primary concern for the ICTsector. In particular, the widespread adoption of cloud computing technologies has drawn attention to the massive energy consumption of data centers. Although hardware constantly improves with respect to energy efficiency, this should also be a main concern for software. In previous work we analyzed the literature and elicited a set of techniques for addressing energy efficiency in cloud-based software architectures. In this work we codified these techniques in the form of Green Architectural Tactics. These tactics will help architects extend their design reasoning towards energy efficiency and to apply reusable solutions for greener software. © 2014 IEEE.","2014","2025-10-22 19:07:44","2025-10-22 19:07:44","","29-36","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Software architecture; Cloud Computing; Energy Efficiency; Energy utilization; Computer architecture; Green computing; Data centers; Software Architecture; Cloud-based; Computer software reusability; Cloud computing technologies; Architectural Tactics; Design reasonings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2014 IEEE 8th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Systems, MESOCA 2014","","","","","","","","","","","","","","",""
"N5T5KE57","journalArticle","2012","Beloglazov, A.; Abawajy, J.; Buyya, R.","Energy-aware resource allocation heuristics for efficient management of data centers for Cloud computing","Future Generation Computer Systems","","","10.1016/j.future.2011.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370722&doi=10.1016%2fj.future.2011.04.017&partnerID=40&md5=404d8a6f96e7208ce49f7fb3ffc699cd","Cloud computing offers utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of electrical energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only minimize operational costs but also reduce the environmental impact. In this paper, we define an architectural framework and principles for energy-efficient Cloud computing. Based on this architecture, we present our vision, open research challenges, and resource provisioning and allocation algorithms for energy-efficient management of Cloud computing environments. The proposed energy-aware allocation heuristics provision data center resources to client applications in a way that improves energy efficiency of the data center, while delivering the negotiated Quality of Service (QoS). In particular, in this paper we conduct a survey of research in energy-efficient computing and propose: (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering QoS expectations and power usage characteristics of the devices; and (c) a number of open research challenges, addressing which can bring substantial benefits to both resource providers and consumers. We have validated our approach by conducting a performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant cost savings and demonstrates high potential for the improvement of energy efficiency under dynamic workload scenarios. © 2011 Elsevier B.V. All rights reserved.","2012","2025-10-22 19:07:44","2025-10-22 19:07:44","","755-768","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Energy efficient; Virtualizations; Energy aware; Resource allocation; Energy-efficient resource allocation; Computing environments; Research challenges; Data centers; Client applications; Computer systems; Performance evaluation; Cost saving; Dynamic consolidation; Allocation algorithm; Architectural frameworks; Architectural principles; Business domain; Carbon footprint; Computing solutions; Electrical energy; Environmental impact; Green IT; High potential; IT services; Operational costs; Pay-as-you-go; Pervasive applications; Power usage; Research; Resource providers; Resource provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHSD56FJ","journalArticle","1947","Mann, H.B.; Whitney, D.R.","On a test of whether one of two random variables is stochastically larger than the other","Ann Math Stat","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002322469&partnerID=40&md5=f23859b7c1d2de39e8b4212b062c6aac","","1947","2025-10-22 19:07:44","2025-10-22 19:07:44","","50-60","","1","18","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FXWVUXUJ","journalArticle","2017","Chauhan, M.A.; Babar, M.A.; Benatallah, B.","Architecting cloud-enabled systems: a systematic survey of challenges and solutions","Software - Practice and Experience","","","10.1002/spe.2409","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969961838&doi=10.1002%2fspe.2409&partnerID=40&md5=444a5cf7af46567a0eb7e0dbaefe59b2","The literature on the challenges of and potential solutions to architecting cloud-based systems is rapidly growing but is scattered. It is important to systematically analyze and synthesize the existing research on architecting cloud-based software systems in order to build a cohesive body of knowledge of the reported challenges and solutions. We have systematically identified and reviewed 133 papers that report architecture-related challenges and solutions for cloud-based software systems. This paper reports the methodological details, findings, and implications of a systematic review that has enabled us to identify 44 unique categories of challenges and associated solutions for architecting cloud-based software systems. We assert that the identified challenges and solutions classified into the categories form a body of knowledge that can be leveraged for designing or evaluating software architectures for cloud-based systems. Our key conclusions are that a large number of primary studies focus on middleware services aimed at achieving scalability, performance, response time, and efficient resource optimization. Architecting cloud-based systems presents unique challenges as the systems to be designed range from pervasive embedded systems and enterprise applications to smart devices with Internet of Things. We also conclude that there is a huge potential of research on architecting cloud-based systems in areas related to green computing, energy efficient systems, mobile cloud computing, and Internet of Things. Copyright © 2016 John Wiley & Sons, Ltd. Copyright © 2016 John Wiley & Sons, Ltd.","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","599-644","","4","47","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Energy efficiency; cloud computing; Cloud computing; Software architecture; Distributed computer systems; Internet; Internet of things; Computer architecture; Middleware; Mobile cloud computing; Systematic literature review; Computer software; Systematic Review; software architecture; Enterprise applications; Knowledge management; systematic literature review; Resource optimization; Body of knowledge; Energy efficient systems; Evaluating software architectures; Middleware services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S8K2RVSH","conferencePaper","2011","Koziolek, A.; Koziolek, H.; Reussner, R.","PerOpteryx: Automated application of tactics in multi-objective software architecture optimization","","","","10.1145/2000259.2000267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960492145&doi=10.1145%2f2000259.2000267&partnerID=40&md5=54812b352d28340283f65291e844a43b","Designing software architectures that exhibit a good trade-off between multiple quality attributes is hard. Even with a given functional design, many degrees of freedom in the software architecture (e.g. component deployment or server configuration) span a large design space. In current practice, software architects try to find good solutions manually, which is time-consuming, can be error-prone and can lead to suboptimal designs. We propose an automated approach guided by architectural tactics to search the design space for good solutions. Our approach applies multi-objective evolutionary optimization to software architectures modelled with the Palladio Component Model. Software architects can then make well-informed trade-off decisions and choose the best architecture for their situation. To validate our approach, we applied it to the architecture models of two systems, a business reporting system and an industrial control system from ABB. The approach was able to find meaningful trade-offs leading to significant performance improvements or costs savings. The novel use of tactics decreased the time needed to find good solutions by up to 80%. © 2011 ACM.","2011","2025-10-22 19:07:44","2025-10-22 19:07:44","","33-42","","","","","","","","","","","","","","","","Scopus","","","","","","","","Software architecture; Economic and social effects; Design; Software architects; Commerce; Multiobjective optimization; optimization; Error prones; software architecture; Automated approach; reliability; Software reliability; performance; multi-objective optimization; Multi objective; Architecture optimization; Evolutionary optimizations; Multiple quality; architectural tactics; Architecture models; Automated applications; Component deployment; Component model; costs; Design spaces; Functional design; Industrial control systems; Large designs; Performance improvements; Reporting systems; Sub-optimal designs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CompArch'11 - Proceedings of the 2011 Federated Events on Component-Based Software Engineering and Software Architecture - QoSA+ISARCS'11","","","","","","","","","","","","","","",""
"6LQDDL2S","conferencePaper","2004","Franks, G.; Woodside, M.","Multiclass multiservers with deferred operations in layered queueing networks, with software system applications","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-16244417188&partnerID=40&md5=434310e665917ab5616e60cd53fca0e8","Layered queueing networks describe the simultaneous-resource behaviour of servers that request lower-layer services and wait for them to complete. Layered software systems often follow this model, with messages to request service and receive the results. Their performance has been computed successfully using mean-value queueing approximations. Such systems also have multiservers (which model multi-threaded software processes), multiple classes of service, and what we call deferred operations or ""second phases"", which are executed after sending the reply message to the requester. In this paper, three established MVA approximations for multiclass multiservers were extended to include deferred service, and evaluated within the layered queueing context. Errors ranged from 1% up to about 15%. These servers were then used to model the Network File System, as implemented on Linux, to show that the method scales up and gives good accuracy on typical systems, with computation times of a few seconds to a few minutes. This is hundreds of times faster than simulation. © 2004 IEEE.","2004","2025-10-22 19:07:44","2025-10-22 19:07:44","","239-245","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer operating systems; Computer software; Servers; Telecommunication services; Approximation theory; World Wide Web; Queueing networks; Layered queueing networks; Layered software systems; Multiservers; Poisson equation; Queueing context","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS","","","","","","","","","","","","","","",""
"E9GHRHVQ","conferencePaper","2018","Zhou, X.; Peng, X.; Xie, T.; Sun, J.; Xu, C.; Ji, C.; Zhao, W.","Benchmarking microservice systems for software engineering research","","","","10.1145/3183440.3194991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049690447&doi=10.1145%2f3183440.3194991&partnerID=40&md5=1f766836a80991cd78e34ddc73c8c69e","Despite the prevalence and importance of microservices in industry, there exists limited research on microservices, partly due to lacking a benchmark system that reflects the characteristics of industrial microservice systems. To fill this gap, we conduct a review of literature and open source systems to identify the gap between existing benchmark systems and industrial microservice systems. Based on the results of the gap analysis, we then develop and release a medium-size benchmark system of microservice architecture. © 2018 Authors.","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","323-324","","","","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Microservice; Microservices; Tracing; Open systems; Benchmarking; Industrial research; Benchmark; Computer debugging; Visualization; Benchmark system; debugging; Failure diagnosis; Failure Diagnosis; Flow visualization; Gap analysis; Medium size; Open source system; Program diagnostics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"X8S2MIT7","journalArticle","2011","Baliga, J.; Ayre, R.W.A.; Hinton, K.; Tucker, R.S.","Green cloud computing: Balancing energy in processing, storage, and transport","Proceedings of the IEEE","","","10.1109/JPROC.2010.2060451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019514248&doi=10.1109%2fJPROC.2010.2060451&partnerID=40&md5=299067989510e27cb90035020153aaeb","Network-based cloud computing is rapidly expanding as an alternative to conventional office-based computing. As cloud computing becomes more widespread, the energy consumption of the network and computing resources that underpin the cloud will grow. This is happening at a time when there is increasing attention being paid to the need to manage energy consumption across the entire information and communications technology (ICT) sector. While data center energy use has received much attention recently, there has been less attention paid to the energy consumption of the transmission and switching networks that are key to connecting users to the cloud. In this paper, we present an analysis of energy consumption in cloud computing. The analysis considers both public and private clouds, and includes energy consumption in switching and transmission as well as data processing and data storage. We show that energy consumption in transport and switching can be a significant percentage of total energy consumption in cloud computing. Cloud computing can enable more energy-efficient use of computing power, especially when the computing tasks are of low intensity or infrequent. However, under some circumstances cloud computing can consume more energy than conventional computing where each user performs all computing on their own personal computer (PC). © 2010 IEEE.","2011","2025-10-22 19:07:44","2025-10-22 19:07:44","","149-167","","1","99","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Energy utilization; Green computing; Energy consumption; Computing power; Digital storage; Data centers; Data handling; Computing resource; Core networks; Balancing energy; Personal computers; Total energy consumption; Energy efficient use; Information and communications technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBBEYHZV","conferencePaper","2015","Willnecker, F.; Dlugi, M.; Brunnert, A.; Spinner, S.; Kounev, S.; Gottesheim, W.; Krcmar, H.","Comparing the accuracy of resource demand measurement and estimation techniques","","","","10.1007/978-3-319-23267-6_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944728289&doi=10.1007%2f978-3-319-23267-6_8&partnerID=40&md5=64bde25b287b84a76f9e8f3a6e723fad","Resource demands are a core aspect of performance models. They describe how an operation utilizes a resource and therefore influence the systems performance metrics: response time, resource utilization and throughput. Such demands can be determined by two extraction classes: direct measurement or demand estimation. Selecting the best suited technique depends on available tools, acceptable measurement overhead and the level of granularity necessary for the performance model. This work compares two direct measurement techniques and an adaptive estimation technique based on multiple statistical approaches to evaluate strengths and weaknesses of each technique. We conduct a series of experiments using the SPECjEnterprise2010 industry benchmark and an automatic performance model generator for architecture level performance models based on the Palladio Component Model. To compare the techniques we conduct two experiments with different levels of granularity on a standalone system, followed by one experiment using a distributed SPECjEnterprise2010 deployment combining both extraction classes for generating a full-stack performance model. © Springer International Publishing Switzerland 2015.","2015","2025-10-22 19:07:44","2025-10-22 19:07:44","","115-129","","","9272","","","","","","","","","","","","","Scopus","","","","","","","","Benchmarking; Resource utilizations; Resource demands; Extraction; Performance Model; Statistical approach; Adaptive estimation techniques; Estimation techniques; Performance model generation; Resource demand estimations; Resource demand measurements; Specjenterprise2010; Systems performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"YTIUJAIC","journalArticle","2017","Armstrong, D.; Djemame, K.; Kavanagh, R.","Towards energy aware cloud computing application construction","Journal of Cloud Computing","","","10.1186/s13677-017-0083-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021422050&doi=10.1186%2fs13677-017-0083-2&partnerID=40&md5=aeb11874807a0abce526302a62459200","The energy consumption of cloud computing continues to be an area of significant concern as data center growth continues to increase. This paper reports on an energy efficient interoperable cloud architecture realised as a cloud toolbox that focuses on reducing the energy consumption of cloud applications holistically across all deployment models. The architecture supports energy efficiency at service construction, deployment and operation. We discuss our practical experience during implementation of an architectural component, the Virtual Machine Image Constructor (VMIC), required to facilitate construction of energy aware cloud applications. We carry out a performance evaluation of the component on a cloud testbed. The results show the performance of Virtual Machine construction, primarily limited by available I/O, to be adequate for agile, energy aware software development. We conclude that the implementation of the VMIC is feasible, incurs minimal performance overhead comparatively to the time taken by other aspects of the cloud application construction life-cycle, and make recommendations on enhancing its performance. © 2017, The Author(s).","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","1","6","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Cloud computing; Virtualization; Energy utilization; Computer architecture; Software design; Software engineering; Virtual machine; Performance evaluation; Network security; Cloud architectures; Architectural components; Cloud engineering; Cloud engineerings; Cloud interoperability; Construction life cycles; Machine construction; Practical experience; Service construction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZLVPXB4","journalArticle","2006","Romano, J.; Kromrey, J.D.; Coraggio, J.; Skowronek, J.","Appropriate statistics for ordinal level data: Should we really be using t-test and Cohen's d for evaluating group differences on the NSSE and other surveys?","Annual Meeting of the Florida Association of Institutional Research","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960837892&partnerID=40&md5=97f4aa2643d0ecbcd14a9aad2f79763a","","2006","2025-10-22 19:07:44","2025-10-22 19:07:44","","1-33","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94KKUKXI","journalArticle","2015","Zhan, Z.-H.; Liu, X.-F.; Gong, Y.-J.; Zhang, J.; Chung, H.S.-H.; Li, Y.","Cloud computing resource scheduling and a survey of its evolutionary approaches","ACM Computing Surveys","","","10.1145/2788397","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939803867&doi=10.1145%2f2788397&partnerID=40&md5=51dd07826ce6c544fd26df28f90068de","A disruptive technology fundamentally transforming the way that computing services are delivered, cloud computing offers information and communication technology users a new dimension of convenience of resources, as services via the Internet. Because cloud provides a finite pool of virtualized on-demand resources, optimally scheduling them has become an essential and rewarding topic, where a trend of using Evolutionary Computation (EC) algorithms is emerging rapidly. Through analyzing the cloud computing architecture, this survey first presents taxonomy at two levels of scheduling cloud resources. It then paints a landscape of the scheduling problem and solutions. According to the taxonomy, a comprehensive survey of state-of-the-art approaches is presented systematically. Looking forward, challenges and potential future research directions are investigated and invited, including real-time scheduling, adaptive dynamic scheduling, large-scale scheduling, multiobjective scheduling, and distributed and parallel scheduling. At the dawn of Industry 4.0, cloud computing scheduling for cyber-physical integration with the presence of big data is also discussed. Research in this area is only in its infancy, but with the rapid fusion of information and data technology, more exciting and agenda-setting topics are likely to emerge on the horizon.","2015","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","4","47","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Big data; Cloud computing; Cloud-computing; Computer architecture; Surveys; Information and Communication Technologies; Computing resource; Genetic algorithms; Computing services; Genetic algorithm; Resource scheduling; Resource-scheduling; Ant colony optimization; Particle swarm optimization (PSO); Particle swarm optimization; Disruptive technology; Evolutionary approach; Evolutionary Computation; Particle swarm; Swarm optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7FGM7XJ","conferencePaper","2005","Hiroyasu, T.; Nakayama, S.; Miki, M.","Comparison study of SPEA2+, SPEA2, and NSGA-II in diesel engine emissions and fuel economy problem","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-27144546968&partnerID=40&md5=3591cd640cb6ac4b4d69c85d76e5bd57","Recently, the technology that can control NOx and Soot values of diesel engines by changing the electronically controllable parameters has been developed. However, there is a trade-off relationship between fuel economy and NOx values. Therefore, the diesel engines that can change their characteristics with along to the driving environment should be emerged in the future. For designing these kinds of engines, the Pareto solutions that can express the trade-off between fuel economy and NOx values are needed. In that case, the derived non dominated solutions should have the diversity not only in the objective space but also in the design variable space. SPEA2+ is one of multi objective genetic algorithms and is developed based on SPEA2. The derived non dominated solutions by SPEA2+ have the diversity in both objective space and design variable space. In this study, the diesel engines that have high fuel economy and small amounts of NOx and Soot are designed by SEPA2+. The results are compared with those of SPEA2 and NSGA-II. From the discussions, it is found that the solutions of SPEA2+ have the diversity not only in the objective space but also in the design variable space. These characteristics are very suitable for designing diesel engines whose parameters are changing against the driving environment. © 2005 IEEE.","2005","2025-10-22 19:07:44","2025-10-22 19:07:44","","236-242","","","1","","","","","","","","","","","","","Scopus","","","","","","","","Problem solving; Gas emissions; Genetic algorithms; Pareto principle; Multi-objective genetic algorithm; Diesel engines; Fuel economy; Pareto solution; Variable space","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2005 IEEE Congress on Evolutionary Computation, IEEE CEC 2005. Proceedings","","","","","","","","","","","","","","",""
"8H2VSQK4","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201055291&partnerID=40&md5=4dc631039e4fd76e74a0abe06f2bb29b","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQ9V47ES","conferencePaper","2023","Funke, M.; Lago, P.","Carving Sustainability into Architecture Knowledge Practice","","","","10.1007/978-3-031-42592-9_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172106147&doi=10.1007%2f978-3-031-42592-9_4&partnerID=40&md5=d235c63d9a95293e3bc79852916eb398","In the daily work of a software architect, knowledge is ubiquitous. In addition to technical expertise, architecture knowledge (AK) also requires practical experience in the representation, communication, and management of architectural decisions. However, there is a pressing need to also incorporate sustainability aspects, i.e., capturing decisions towards software systems that are environmentally, economically, and socially balanced in the long term. With this study, we aim to provide a review of AK concepts and their representation and communication from a practical point of view. Having this understanding, we explore where sustainability can be applied in daily practice and how we can address sustainability in architecture processes in the future. The paper presents an empirical study conducted in an industrial context encompassing a questionnaire survey with 32 participants and semi-structured interviews with 15 practitioners; both groups are from a major bank in the Netherlands. Based on the insights gained from combining our findings, we (i) provide a map of applied concepts for communicating and representing AK in a large enterprise, and (ii) discuss potential avenues for carving sustainability into current software architecture practice. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2023","2025-10-22 19:07:44","2025-10-22 19:07:44","","54-69","","","14212 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Software architecture; Decision making; Empirical studies; Software architects; Sustainable development; Practical experience; Architectural decision; Industrial context; Pressung; Questionnaire surveys; Semi structured interviews; Software-systems; Technical expertise","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"YFZSEPMR","journalArticle","2021","Katoch, S.; Chauhan, S.S.; Kumar, V.","A review on genetic algorithm: past, present, and future","Multimedia Tools and Applications","","","10.1007/s11042-020-10139-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094857903&doi=10.1007%2fs11042-020-10139-6&partnerID=40&md5=8c8ff133775d41c1500375a41f4b0ab5","In this paper, the analysis of recent advances in genetic algorithms is discussed. The genetic algorithms of great interest in research community are selected for analysis. This review will help the new and demanding researchers to provide the wider vision of genetic algorithms. The well-known algorithms and their implementation are presented with their pros and cons. The genetic operators and their usages are discussed with the aim of facilitating new researchers. The different research domains involved in genetic algorithms are covered. The future research directions in the area of genetic operators, fitness function and hybrid algorithms are discussed. This structured review will be helpful for research and graduate teaching. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2021","2025-10-22 19:07:44","2025-10-22 19:07:44","","8091-8126","","5","80","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Multimedia systems; Genetic algorithms; Research communities; Genetic algorithm; Metaheuristic; Fitness functions; Future research directions; Selection; Crossover; Evolution; Genetic operators; Graduate teachings; Hybrid algorithms; Mutation; Research domains; Structured review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAZPJJV8","conferencePaper","2005","Huppes, G.; Ishikawa, M.","A framework for quantified eco-efficiency analysis","","","","10.1162/108819805775247882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646251728&doi=10.1162%2f108819805775247882&partnerID=40&md5=f2d17e16fa66a3e7b9f7443c70250a71","Eco-efficiency is an instrument for sustainability analysis, indicating an empirical relation in economic activities between environmental cost or value and environmental impact. This empirical relation can be matched against normative considerations as to how much environmental quality or improvement society would like to offer in exchange for economic welfare, or what the trade-off between the economy and the environment should be if society is to realize a certain level of environmental quality. Its relevance lies in the fact that relations between economy and environment are not self-evident, not at a micro level and not at the macro level resulting from micro-level decisions for society as a whole. Clarifying the why and what of eco-efficiency is a first step toward decision support on these two aspects of sustainability. With the main analytic framework established, filling in the actual economic and environmental relations requires further choices in modeling. Also, the integration of different environmental effects into a single score requires a clear definition of approach, because several partly overlapping methods exist. Some scaling problems accompany the specification of numerator and denominator, which need a solution and some standardization before eco-efficiency analysis can become more widely used. With a method established, the final decision is how to embed it in practical decision making. In getting the details of eco-efficiency better specified, its strengths, but also its weaknesses and limitations, need to be indicated more clearly. © 2005 by the Massachusetts Institute of Technology and Yale University.","2005","2025-10-22 19:07:44","2025-10-22 19:07:44","","25-41","","","9","","","","","","","","","","","","","Scopus","","","","","","","","Economic and social effects; Cost effectiveness; Environmental impact; Economics; Sustainable development; sustainability; environmental impact; Industrial engineering; Ecology; economic relations; Environmental cost-effectiveness; environmental economics; environmental effect; Environmental effect score; Environmental intensity; Environmental productivity; environmental quality; Industrial ecology; Productivity; trade-off; Win-win","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Journal of Industrial Ecology","","","","","","","","","","","","","","",""
"3EDDJ46P","conferencePaper","2018","Mazkatli, M.; Koziolek, A.","Continuous integration of performance model","","","","10.1145/3185768.3186285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052026661&doi=10.1145%2f3185768.3186285&partnerID=40&md5=d08ae752ef84d0c0cfc16ed5542e028e","Applying model-based performance prediction requires that an up-to-date Performance Model (PM) is available throughout the development process. Creating such a model manually is an expensive process that is unsuitable for agile software development aiming to produce rapid releases in short cycles. Existing approaches automate the extraction of a PM based on reverse engineering and/or measurements techniques. However, these approaches require to monitor and analyse the whole application. Thus, they are too costly to be applied frequently, up to after each code change. Moreover, keeping potential manual changes of the PM is another challenge as long the PM is regenerated from scratch every time. To address these problems, this paper envisions an approach for efficient continuous integration of a parametrised performance model in an agile development process. Our work will combine static code analysis with adaptive, automatic, dynamic analysis covering updated parts of code to update the PM with parameters, like resource demands and branching probabilities. The benefit of our approach will be to automatically keep the PM up-to-date throughout the development process which enables the proactive identification of upcoming performance problems and provides a foundation for evaluating design alternatives at low costs. © 2018 Association for Computing Machinery.","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","153-158","","","2018-January","","","","","","","","","","","","","Scopus","","","","","","","","Codes (symbols); Software design; Performance engineering; Continuous integrations; Performance management; Performance prediction; Performance problems; Reverse engineering; Agile software development; Branching probability; Continuous/incremental performance management; Incremental reverse engineering; Model-based performance engineering; Parametric performance; Parametric performance model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2018 - Companion of the 2018 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"IAMCR8C4","journalArticle","2018","Belkhir, L.; Elmeligi, A.","Assessing ICT global emissions footprint: Trends to 2040 & recommendations","Journal of Cleaner Production","","","10.1016/j.jclepro.2017.12.239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041215618&doi=10.1016%2fj.jclepro.2017.12.239&partnerID=40&md5=c91dee0ffd32a303af9af58776c4c37e","In light of the concerted efforts to reduce global greenhouse gas emissions (GHGE) per the so-called Paris Agreement, the Information and Communication Industry (ICT) has received little attention as a significant contributor to GHGE and if anything is often highly praised for enabling efficiencies that help reduce other industry sectors footprint. In this paper, we aim at assessing the global carbon footprint of the overall ICT industry, including the contribution from the main consumer devices, the data centers and communication networks, and compare it with the to the total worldwide GHGE. We conduct a detailed and rigorous analysis of the ICT global carbon footprint, including both the production and the operational energy of ICT devices, as well as the operational energy for the supporting ICT infrastructure. We then compare this contribution to the global 2016-level GHGE. We have found that, if unchecked, ICT GHGE relative contribution could grow from roughly 1–1.6% in 2007 to exceed 14% of the 2016-level worldwide GHGE by 2040, accounting for more than half of the current relative contribution of the whole transportation sector. Our study also highlights the contribution of smart phones and shows that by 2020, the footprint of smart phones alone would surpass the individual contribution of desktops, laptops and displays. Finally, we offer some actionable recommendations on how to mitigate and curb the ICT explosive GHGE footprint, through a combination of renewable energy use, tax policies, managerial actions and alternative business models. © 2018 Elsevier Ltd","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","448-463","","","177","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Smartphones; Carbon footprint; Gas emissions; Greenhouse gases; ICT infrastructures; Information and communication; Managerial actions; Operational energy; Relative contribution; Renewable energy use; Rigorous analysis; Telephone sets; Transportation sector","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DE742D79","journalArticle","2020","Mytton, D.","Assessing the suitability of the Greenhouse Gas Protocol for calculation of emissions from public cloud computing workloads","Journal of Cloud Computing","","","10.1186/s13677-020-00185-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089199506&doi=10.1186%2fs13677-020-00185-8&partnerID=40&md5=df5dbc3b8be6be2c638643bf9ec5fc74","Efficiency improvements over the past decade have meant that data center energy usage has decoupled from the growth in IT workloads. Much of this efficiency improvement has been attributed to innovations made by “hyperscale” public cloud vendors, where a large proportion of new IT workloads are now being deployed. However, the move to the cloud is making it more difficult to assess the environmental impact of workloads deployed there. Although the large cloud vendors are amongst the largest purchasers of renewable electricity, customers do not have access to the data they need to complete emissions assessments under the Greenhouse Gas Protocol. Data such as Power Usage Effectiveness, emissions factors and equipment embodied energy are not available from public cloud vendors. This paper demonstrates how the Greenhouse Gas Protocol method of assessment of IT emissions does not work for public cloud environments and suggests how this can be tackled by the cloud vendors themselves. © 2020, The Author(s).","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","1","9","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Efficiency; Data centers; Environmental impact; Gas emissions; Greenhouse gases; Public clouds; Efficiency improvement; Energy usage; Cloud environmental impact; Data center emissions; Embodied energy; Emissions factors; Greenhouse gas Protocol; Greenhouse gas protocols; IT emissions; Renewable electricity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAXQUZV8","conferencePaper","2017","Li, C.; Altamimi, T.; Zargari, M.H.; Casale, G.; Petriu, D.","Tulsa: a tool for transforming UML to layered queueing networks for performance analysis of data intensive applications","","","","10.1007/978-3-319-66335-7_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028647070&doi=10.1007%2f978-3-319-66335-7_18&partnerID=40&md5=a3ad50822e49b3a39a1b0a9d081ab16b","Motivated by the problem of detecting software performance anti-patterns in data-intensive applications (DIAs), we present a tool, Tulsa, for transforming software architecture models specified through UML into Layered Queueing Networks (LQNs), which are analytical performance models used to capture contention across multiple software layers. In particular, we generalize an existing transformation based on the Epsilon framework to generate LQNs from UML models annotated with the DICE profile, which extends UML to modelling DIAs based on technologies such as Apache Storm. © 2017, Springer International Publishing AG.","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","295-299","","","10503 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Application programs; Software architecture; Network layers; Unified Modeling Language; Metadata; Queueing networks; Software performance; Anti-patterns; Layered queueing networks; Analytical performance model; Data-intensive application; Software architecture model; Transformation based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"B9TPV4PY","journalArticle","2017","Ouni, A.; Kessentini, M.; Ó Cinnéide, M.; Sahraoui, H.; Deb, K.; Inoue, K.","MORE: A multi-objective refactoring recommendation approach to introducing design patterns and fixing code smells","Journal of Software: Evolution and Process","","","10.1002/smr.1843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014656546&doi=10.1002%2fsmr.1843&partnerID=40&md5=9a7e0b9b3103399b1cc81a6c5fedfab1","Refactoring is widely recognized as a crucial technique applied when evolving object-oriented software systems. If applied well, refactoring can improve different aspects of software quality including readability, maintainability, and extendibility. However, despite its importance and benefits, recent studies report that automated refactoring tools are underused much of the time by software developers. This paper introduces an automated approach for refactoring recommendation, called MORE, driven by 3 objectives: (1) to improve design quality (as defined by software quality metrics), (2) to fix code smells, and (3) to introduce design patterns. To this end, we adopt the recent nondominated sorting genetic algorithm, NSGA-III, to find the best trade-off between these 3 objectives. We evaluated the efficacy of our approach using a benchmark of 7 medium and large open-source systems, 7 commonly occurring code smells (god class, feature envy, data class, spaghetti code, shotgun surgery, lazy class, and long parameter list), and 4 common design pattern types (visitor, factory method, singleton, and strategy). Our approach is empirically evaluated through a quantitative and qualitative study to compare it against 3 different state-of-the art approaches, 2 popular multiobjective search algorithms, and random search. The statistical analysis of the results confirms the efficacy of our approach in improving the quality of the studied systems while successfully fixing 84% of code smells and introducing an average of 6 design patterns. In addition, the qualitative evaluation shows that most of the suggested refactorings (an average of 69%) are considered by developers to be relevant and meaningful. Copyright © 2017 John Wiley & Sons, Ltd.","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","5","29","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Codes (symbols); Economic and social effects; Open systems; Refactorings; Quality control; Search-based software engineering; Genetic algorithms; search-based software engineering; Design Patterns; refactoring; Object oriented programming; Computer software selection and evaluation; Code smell; code smells; design patterns; Odors; software quality; Software Quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6TI4GR7","journalArticle","2012","Hodges, J.L.; Lehmann, E.L.","Estimates of location based on rank tests","Selected Works of EL Lehmann","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042883472&partnerID=40&md5=ebabf115b3f394c5be08e435b4ae99df","","2012","2025-10-22 19:07:44","2025-10-22 19:07:44","","287-300","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VQ2D8WEU","journalArticle","2004","","","Enhanced Intel SpeedStep Technology for the Intel Pentium M Processor","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746279684&partnerID=40&md5=caf5513fb73ecdf14a9b669e30ddc5b4","","2004","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZX2C99U9","conferencePaper","2019","Valera, H.H.L.; Dalmau, M.; Roose, P.; Herzog, C.","The Architecture of Kaligreen V2: A Middleware Aware of Hardware Opportunities to Save Energy","","","","10.1109/IOTSMS48152.2019.8939237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077969153&doi=10.1109%2fIOTSMS48152.2019.8939237&partnerID=40&md5=7b937f6435a19d89b288227377d059e7","Nowadays, energy saving in the use of information technologies is a very important issue both from the economic and sustainability point of view. Many scientists investigate methods to save energy at different application levels (cloud: i.e., architectures, grid: i.e., middlewares and frameworks and hardware management: i.e., operating systems) and many of them agree on the strategy of executing programs, processes or virtual machines only using the time and resources that are strictly necessary. For this, it is necessary to plan strategies for deployment and relocation of processes; but always taking into account hardware repercussions and the knowledge of the architecture and applications behavior. On the other hand, it has already been demonstrated that the use of microservices brings numerous advantages in availability and efficiency; but we do not find many jobs that exploit this technique on the energy level. In this article, we present the architecture of a middleware for distributed microservices-based applications, which allows any negotiation-based scheduling algorithm to duplicate or move microservices from one device to another in a non-centralized way for energy savings, taking into account the consumption characteristics of the microservices and the capabilities that the hardware components offer. © 2019 IEEE.","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","79-86","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; microservices; Program processors; Internet of things; Network architecture; Networks (circuits); Middleware; Energy conservation; CPU; Scheduling algorithms; Application level; energy; middleware; consumption; hard disk; network; Hard disk storage; Hardware components; Hardware management; Information use; Save energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 6th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2019","","","","","","","","","","","","","","",""
"9QQ34GR8","journalArticle","2015","Bongers, E.; Pouwelse, J.","","A Survey of P2P Multidimensional Indexing Structures","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009829721&partnerID=40&md5=2af19d476143121dc7585daaf730226d","","2015","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJ73GF9X","conferencePaper","2016","Azmy, N.M.; El-Maddah, I.A.M.; Mohamed, H.K.","Adaptive power panel of cloud computing controlling cloud power consumption","","","","10.1145/2944165.2944167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985990751&doi=10.1145%2f2944165.2944167&partnerID=40&md5=c5b64478913d045dc22f54d9b7cff5fa","Cloud computing had created a new era of network design, where end-users can get their required services without having to purchase expensive infrastructure or even to care about troubleshooting. Power consumption is a challenge facing the Cloud Providers to operate their Datacenters. One solution to overcome this is the Virtual Machine (VM) migration, which is a technique used to switch under-utilized hosts to sleep mode in order to save power, and to avoid over-utilized hosts from Service Level Agreement (SLA) violation. But still the problem is that the Cloud Service Provider apply a single policy on all nodes. Our proposed solution is an adaptive power panel where different policies can be applied based on both of the nature of the tasks running on hosts, and the Cloud Provider decision. © 2016 ACM.","2016","2025-10-22 19:07:44","2025-10-22 19:07:44","","9-14","","","28-29-May-2016","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Cloud computing; Distributed computer systems; Software engineering; Virtual machines; Migration; Green computing; Virtual Machine; Placement; Green Computing; Adaptive; Allocation; Cloudsim; Selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"286FFB6L","conferencePaper","2018","Lvarez-Valera, H.H.; Roose, P.; Dalmau, M.; Herzog, C.; Respicio, K.","Kali green: A distributed scheduler for energy saving","","","","10.1016/j.procs.2018.10.172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058349351&doi=10.1016%2fj.procs.2018.10.172&partnerID=40&md5=762a84024c90ed200594143af3fc90ed","A commonplace issue with portable technology is battery efficiency. While many industries are trying their best to improve battery life without sacrificing a products quality and efficiency, we believe that further can be done to improve battery consumption on ones mobile devicefrom tablets to smartphones to laptops to everything else. Many applications on these devices are based on a microservice architecture. In this article, we introduce a new algorithm KaliGreen that can maneuver the microservices within a network of devices in order to maximize the run-time of a microservice-based application; moreover, KaliGreen allows a 54% increase in the average run-time of an application by shifting microservices from 6 devices (as example) with low battery or inefficient processing ratios to devices in better conditions. To achieve this, KaliGreen utilizes KaliMucho middleware, which is able manipulate microservices in run-time. This algorithm provides a plausible solution to maximizing energy consumption within a network of devices. © 2018 The Authors. Published by Elsevier Ltd.","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","223-230","","","141","","","","","","","","","","","","","Scopus","","","","","","","","Electric batteries; Microservices; Energy utilization; Middleware; Smartphones; Green computing; Energy conservation; Distributed schedulers; Green Computing; Battery consumption; Battery efficiencies; Battery life; Distributed applicatioggns; mHealth; Portable technologies; Products quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Procedia Computer Science","","","","","","","","","","","","","","",""
"8TDAE6RD","journalArticle","2018","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136077897&partnerID=40&md5=6f8b6fa55ae8d49e7d0f78e4572b6a90","","2018","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FSCNHWMX","journalArticle","2019","Services, A.W.","","Implementing Microservices on Aws","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136057210&partnerID=40&md5=de73f910ba756e078d87fc9e1f204cc3","","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","2019","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N32ENMF7","journalArticle","2020","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135986128&partnerID=40&md5=eebf7fe0a0d0c66b94426e2f44020f52","","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63N2Y3YH","journalArticle","2016","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136055906&partnerID=40&md5=2d8ee1e2e32a32ca49e573cdc786c5a6","","2016","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6X6ZBLX","conferencePaper","2014","Da, K.; Dalmau, M.; Roose, P.","Kalimucho: Middleware for mobile applications","","","","10.1145/2554850.2554883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905652787&doi=10.1145%2f2554850.2554883&partnerID=40&md5=c88b567dba93ee6384b57b3bbd3ba1ee","Developing ubiquitous applications is particularly complex. Beyond the dynamic aspect of such applications, the evolution of computing towards the multiplication of mobile access terminals is not making things easier. One solution to simplifying the development and use of such applications is to use software platforms dedicated to deployment and adaptation of applications and handling the heterogeneity of peripherals. They allow designers to focus on business aspects and facilitate reuse. The Kalimucho platform was designed and developed against this background. It executes and supervises applications based on software components. Copyright 2014 ACM.","2014","2025-10-22 19:07:44","2025-10-22 19:07:44","","413-419","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Performance; Software component; Design; Middleware; Mobile applications; Query languages; Reliability; Measurement; Measurements; Business aspects; Dynamic aspects; Languages; Mobile access; Software platforms; Ubiquitous application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Symposium on Applied Computing","","","","","","","","","","","","","","",""
"5P7DQEHS","conferencePaper","2019","Gan, Y.; Zhang, Y.; Cheng, D.; Shetty, A.; Rathi, P.; Katarki, N.; Bruno, A.; Hu, J.; Ritchken, B.; Jackson, B.; Hu, K.; Pancholi, M.; He, Y.; Clancy, B.; Colen, C.; Wen, F.; Leung, C.; Wang, S.; Zaruvinsky, L.; Espinosa, M.; Lin, R.; Liu, Z.; Padilla, J.; Delimitrou, C.","An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud & Edge Systems","","","","10.1145/3297858.3304013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064688619&doi=10.1145%2f3297858.3304013&partnerID=40&md5=b9f662fba2a35d83eb40d32009cf7676","Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present Death- StarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","3-18","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Open source software; Datacenter; Microservice; cloud computing; Cloud-computing; microservices; QoS; acceleration; Benchmark suites; Cloud systems; Cluster computing; cluster management; Cluster management; datacenters; Economic and social effects; Field programmable gate arrays (FPGA); fpga; Fpgum; Open systems; Open-source; Quality-of-service; serverless; Serverless","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"543GSLRM","journalArticle","2017","Gujarati, A.; Elnikety, S.; He, Y.; McKinley, K. S.; Brandenburg, B. B.","Swayam: Distributed Autoscaling to Meet SLAs of Machine Learning Inference Services with Resource Efficiency","USENIX Middleware Conference","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095484895&partnerID=40&md5=220c1fa5fda624b6df2f84c7fcf6f4e0","","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NMJXG29D","journalArticle","2019","","","Provisioned Concurrency.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119298797&partnerID=40&md5=dbaf19089c1c29634d0a5f1f317f1cba","","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SPP9W9Z","conferencePaper","2019","Mohan, A.; Sane, H.; Doshi, K.; Edupuganti, S.; Nayak, N.; Sukhomlinov, V.","Agile cold starts for scalable serverless","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084160535&partnerID=40&md5=78d805902ca3dc9483d26084f74a76cf","The Serverless or Function-as-a-Service (FaaS) model capitalizes on lightweight execution by packaging code and dependencies together for just-in-time dispatch. Often a container environment has to be set up afresh– a condition called “cold start"", and in such cases, performance suffers and overheads mount, both deteriorating rapidly under high concurrency. Caching and reusing previously employed containers ties up memory and risks information leakage. Latency for cold starts is frequently due to work and wait-times in setting up various dependencies – such as in initializing networking elements. This paper proposes a solution that pre-crafts such resources and then dynamically reassociates them with baseline containers. Applied to networking, this approach demonstrates an order of magnitude gain in cold starts, negligible memory consumption, and flat startup time under rising concurrency. © 2019 USENIX Association. All rights reserved.","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud computing; Wait time; Cold start; High concurrencies; Information leakage; Just in time; Memory consumption; Startup time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019, co-located with USENIX ATC 2019","","","","","","","","","","","","","","",""
"XWWV24PA","conferencePaper","2020","Tariq, A.; Pahl, A.; Nimmagadda, S.; Rozner, E.; Lanka, S.","Sequoia: Enabling quality-of-service in serverless computing","","","","10.1145/3419111.3421306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095439090&doi=10.1145%2f3419111.3421306&partnerID=40&md5=04b3111d11f1056b8d800b2feb8089c4","Serverless computing is a rapidly growing paradigm that easily harnesses the power of the cloud. With serverless computing, developers simply provide an event-driven function to cloud providers, and the provider seamlessly scales function invocations to meet demands as event-triggers occur. As current and future serverless offerings support a wide variety of serverless applications, effective techniques to manage serverless workloads becomes an important issue. This work examines current management and scheduling practices in cloud providers, uncovering many issues including inflated application run times, function drops, inefficient allocations, and other undocumented and unexpected behavior. To fix these issues, a new quality-of-service function scheduling and allocation framework, called Sequoia, is designed. Sequoia allows developers or administrators to easily def ne how serverless functions and applications should be deployed, capped, prioritized, or altered based on easily configured, flexible policies. Results with controlled and realistic workloads show Sequoia seamlessly adapts to policies, eliminates mid-chain drops, reduces queuing times by up to 6.4X, enforces tight chain-level fairness, and improves run-time performance up to 25X.  © 2020 ACM.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","311-327","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Cloud computing; Run-time performance; Drops; Cloud providers; serverless computing; quality-of-service; measurement; Event-driven; Event trigger","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2020 - Proceedings of the 2020 ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"T4LUG9YD","conferencePaper","2017","Yang, H.; Chen, Q.; Riaz, M.; Luan, Z.; Tang, L.; Mars, J.","PowerChief: Intelligent power allocation for multi-stage applications to improve responsiveness on power constrained CMP","","","","10.1145/3079856.3080224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025619452&doi=10.1145%2f3079856.3080224&partnerID=40&md5=1b3762d3742b803bb5b2ea594b587a90","Modern user facing applications consist of multiple processing stages with a number of service instances in each stage. The latency profle of these multi-stage applications is intrinsically variable, making it challenging to provide satisfactory responsiveness. Given a limited power budget, improving the end-to-end latency requires intelligently boosting the bottleneck service across stages using multiple boosting techniques. However, prior work fail to acknowledge the multi-stage nature of user-facing applications and perform poorly in improving responsiveness on power constrained CMP, as they are unable to accurately identify bottleneck service and apply the boosting techniques adaptively. In this paper, we present PowerChief, a runtime framework that 1) provides joint design of service and query to monitor the latency statistics across service stages and accurately identifes the bottleneck service during runtime; 2) adaptively chooses the boosting technique to accelerate the bottleneck service with improved responsiveness; 3) dynamically reallocates the constrained power budget across service stages to accommodate the chosen boosting technique. Evaluated with real world multi-stage applications, PowerChief improves the average latency by 20.3× and 32.4× (99% tail latency by 13.3× and 19.4×) for Sirius and Natural Language Processing applications respectively compared to stage-agnostic power allocation. In addition, for the given QoS target, PowerChief reduces the power consumption of Sirius and Web Search applications by 23% and 33% respectively over prior work. © 2017 Association for Computing Machinery.","2017","2025-10-22 19:07:44","2025-10-22 19:07:44","","133-146","","","Part F128643","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Computer architecture; Budget control; Natural language processing systems; Power allocations; End to end latencies; Facings; Intelligent Service Boosting; Intelligent Services; Multi stage; Multi-Stage Application; Multiple processing; Number of services; Power Constrained CMP; Runtime frameworks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on Computer Architecture","","","","","","","","","","","","","","",""
"TLKVR6J4","journalArticle","","","","Twitter Stream Traces.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119276526&partnerID=40&md5=203329d27a78f1756272a26527d66aba","","","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CGMCWA4","journalArticle","2009","Urdaneta, G.; Pierre, G.; van Steen, M.","Wikipedia workload analysis for decentralized hosting","Computer Networks","","","10.1016/j.comnet.2009.02.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349226826&doi=10.1016%2fj.comnet.2009.02.019&partnerID=40&md5=b5fc02e0d8213494d9a714f5be814510","We study an access trace containing a sample of Wikipedia's traffic over a 107-day period aiming to identify appropriate replication and distribution strategies in a fully decentralized hosting environment. We perform a global analysis of the whole trace, and a detailed analysis of the requests directed to the English edition of Wikipedia. In our study, we classify client requests and examine aspects such as the number of read and save operations, significant load variations and requests for nonexisting pages. We also review proposed decentralized wiki architectures and discuss how they would handle Wikipedia's workload. We conclude that decentralized architectures must focus on applying techniques to efficiently handle read operations while maintaining consistency and dealing with typical issues on decentralized systems such as churn, unbalanced loads and malicious participating nodes. © 2009 Elsevier B.V. All rights reserved.","2009","2025-10-22 19:07:44","2025-10-22 19:07:44","","1830-1845","","11","53","","","","","","","","","","","","","Scopus","","","","","","","","Internet; Websites; Distribution strategies; P2P; Decentralized architecture; Decentralized hosting; Decentralized system; Global analysis; Unbalanced loads; Wikipedia; Workload analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GWPS8ECK","conferencePaper","2020","Taibi, D.; El Ioini, N.; Pahl, C.; Niederkofler, J.R.S.","Patterns for serverless functions (Function-as-a-Service): A multivocal literature review","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088373702&partnerID=40&md5=9c4430d886b446d7ae8f3ecc8b5c3fcc","[Context] Serverless is a recent technology that enables companies to reduce the overhead for provisioning, scaling and in general managing the infrastructure. Companies are increasingly adopting Serverless, by migrating existing applications to this new paradigm. Different practitioners proposed patterns for composing and managing serverless functions. However, some of these patterns offer different solutions to solve the same problem, which makes it hard to select the most suitable solution for each problem. [Goal] In this work, we aim at supporting practitioners in understanding the different patterns, by classifying them and reporting possible benefits and issues. [Method]We adopted a multivocal literature review process, surveying peer-reviewed and grey literature and classifying patterns (common solutions to solve common problems), together with benefits and issues. [Results] Among 24 selected works, we identified 32 patterns that we classified as orchestration, aggregation, event-management, availability, communication, and authorization. [Conclusion] Practitioners proposed a list of fairly consistent patterns, even if a small number of patterns proposed different solutions to similar problems. Some patterns emerged to circumvent some serverless limitations, while others for some classical technical problems (e.g. publisher/subscriber). © Copyright 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","181-192","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Serverless; Computer science; Function as a Service; Computer programming; Cloud; Grey literature; Literature reviews; Suitable solutions; Event management; Publisher/subscriber; Serverless Functions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CLOSER 2020 - Proceedings of the 10th International Conference on Cloud Computing and Services Science","","","","","","","","","","","","","","",""
"CYHBPKLP","journalArticle","2019","","","Airbnb AWS Case Study.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119272406&partnerID=40&md5=b2c15946f9d4ab9a841339b5693a0926","","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBJ3S5YQ","conferencePaper","2020","Shahrad, M.; Fonseca, R.; Goiri, Í.; Chaudhry, G.; Batum, P.; Cooke, J.; Laureano, E.; Tresness, C.; Russinovich, M.; Bianchini, R.","Serverless in the wild: Characterizing and optimizing the serverless workload at a large cloud provider","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091934381&partnerID=40&md5=16dd6343f7a2bb6ef374f99e1bb924da","Function as a Service (FaaS) has been gaining popularity as a way to deploy computations to serverless backends in the cloud. This paradigm shifts the complexity of allocating and provisioning resources to the cloud provider, which has to provide the illusion of always-available resources (i.e., fast function invocations without cold starts) at the lowest possible resource cost. Doing so requires the provider to deeply understand the characteristics of the FaaS workload. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we first characterize the entire production FaaS workload of Azure Functions. We show for example that most functions are invoked very infrequently, but there is an 8-order-of-magnitude range of invocation frequencies. Using observations from our characterization, we then propose a practical resource management policy that significantly reduces the number of function cold starts, while spending fewer resources than state-of-the-practice policies. Copyright © Proc. of the 2020 USENIX Annual Technical Conference, ATC 2020. All rights reserved.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","205-218","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud providers; Resource costs; Cold start; Paradigm shifts; Public information; Resource management policy; State of the practice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2020 USENIX Annual Technical Conference, ATC 2020","","","","","","","","","","","","","","",""
"3HUGDMLG","conferencePaper","2020","Silva, P.; Fireman, D.; Pereira, T.E.","Prebaking functions to warm the serverless cold start","","","","10.1145/3423211.3425682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098482026&doi=10.1145%2f3423211.3425682&partnerID=40&md5=a504f228433628dd70e0d3a74365fdba","Function-as-service (FaaS) platforms promise a simpler programming model for cloud computing, in which the developers concentrate on writing its applications. In contrast, platform providers take care of resource management and administration. As FaaS users are billed based on the execution of the functions, platform providers have a natural incentive not to keep idle resources running at the platform's expense. However, this strategy may lead to the cold start issue, in which the execution of a function is delayed because there is no ready resource to host the execution. Cold starts can take hundreds of milliseconds to seconds and have been a prohibitive and painful disadvantage for some applications. This work describes and evaluates a technique to start functions, which restores snapshots from previously executed function processes. We developed a prototype of this technique based on the CRIU process checkpoint/restore Linux tool. We evaluate this prototype by running experiments that compare its start-up time against the standard Unix process creation/start-up procedure. We analyze the following three functions: i) a ""do-nothing"" function, ii) an Image Resizer function, and iii) a function that renders Markdown files. The results attained indicate that the technique can improve the start-up time of function replicas by 40% (in the worst case of a ""do-nothing"" function) and up to 71% for the Image Resizer one. Further analysis indicates that the runtime initialization is a key factor, and we confirmed it by performing a sensitivity analysis based on synthetically generated functions of different code sizes. These experiments demonstrate that it is critical to decide when to create a snapshot of a function. When one creates the snapshots of warm functions, the speed-up achieved by the prebaking technique is even higher: the speed-up increases from 127.45% to 403.96%, for a small, synthetic function; and for a bigger, synthetic function, this ratio increases from 121.07% to 1932.49%. © 2020 Association for Computing Machinery.","2020","2025-10-22 19:07:44","2025-10-22 19:07:44","","1-13","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource management; Computer operating systems; Serverless; Middleware; Image enhancement; Cold start; Startup time; Cloud; Faas; Generated function; ITS applications; Key factors; Performance evaluation; Process creation; Programming models; Sensitivity analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Middleware 2020 - Proceedings of the 2020 21st International Middleware Conference","","","","","","","","","","","","","","",""
"VHW4BZZK","journalArticle","2012","Awad, M.A.; Khalil, I.","Prediction of user's web-browsing behavior: Application of markov model","IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics","","","10.1109/TSMCB.2012.2187441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864147184&doi=10.1109%2fTSMCB.2012.2187441&partnerID=40&md5=bb189370cf038d274340441c686eaec4","Web prediction is a classification problem in which we attempt to predict the next set of Web pages that a user may visit based on the knowledge of the previously visited pages. Predicting user's behavior while serving the Internet can be applied effectively in various critical applications. Such application has traditional tradeoffs between modeling complexity and prediction accuracy. In this paper, we analyze and study Markov model and all- K th Markov model in Web prediction. We propose a new modified Markov model to alleviate the issue of scalability in the number of paths. In addition, we present a new two-tier prediction framework that creates an example classifier EC, based on the training examples and the generated classifiers. We show that such framework can improve the prediction time without compromising prediction accuracy. We have used standard benchmark data sets to analyze, compare, and demonstrate the effectiveness of our techniques using variations of Markov models and association rule mining. Our experiments show the effectiveness of our modified Markov model in reducing the number of paths without compromising accuracy. Additionally, the results support our analysis conclusions that accuracy improves with higher orders of all- K th model. © 2012 IEEE.","2012","2025-10-22 19:07:44","2025-10-22 19:07:44","","1131-1142","","4","42","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Forecasting; Critical applications; Markov processes; Prediction accuracy; Markov model; All-K th Markov; association rule mining (ARM); Benchmark data; Modeling complexity; N-gram; Training example; two-tier architecture; Two-tier architecture; Web prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYLA6RR5","conferencePaper","2019","Gunasekaran, J.R.; Thinakaran, P.; Kandemir, M.T.; Urgaonkar, B.; Kesidis, G.; Das, C.","Spock: Exploiting serverless functions for SLO and cost aware resource procurement in public cloud","","","","10.1109/CLOUD.2019.00043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069531622&doi=10.1109%2fCLOUD.2019.00043&partnerID=40&md5=db3951b69899a434967f97105d5a7d07","We are witnessing the emergence of elastic web services which are hosted in public cloud infrastructures. For reasons of cost-effectiveness, it is crucial for the elasticity of these web services to match the dynamically-evolving user demand. Traditional approaches employ clusters of virtual machines (VMs) to dynamically scale resources based on application demand. However, they still face challenges such as higher cost due to over-provisioning or incur service level objective (SLO) violations due to under-provisioning. Motivated by this observation, we propose Spock, a new scalable and elastic control system that exploits both VMs and serverless functions to reduce cost and ensure SLO for elastic web services. We show that under two different scaling policies, Spock reduces SLO violations of queries by up to 74\% when compared to VM-based resource procurement schemes. Further, Spock yields significant cost savings, by up to 33\% compared to traditional approaches which use only VMs. © 2019 IEEE.","2019","2025-10-22 19:07:44","2025-10-22 19:07:44","","199-208","","","2019-July","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Serverless; Web services; FaaS; Websites; Costs; Cost effectiveness; Autoscaling; Cost-aware; Lambda; SLO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"J966Z8RM","journalArticle","2020","","","Amazon States Language.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119282135&partnerID=40&md5=10e725392a15d10448c1f8d29bb49d8c","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMJYLNAN","journalArticle","2004","Begleiter, R.; El-Yaniv, R.; Yona, G.","On prediction using variable order Markov models","Journal of Artificial Intelligence Research","","","10.1613/jair.1491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-27344458404&doi=10.1613%2fjair.1491&partnerID=40&md5=d197c0fdad570b2edf2397794023188e","This paper is concerned with algorithms for prediction of discrete sequences over a finite alphabet, using variable order Markov models. The class of such algorithms is large and in principle includes any lossless compression algorithm. We focus on six prominent prediction algorithms, including Context Tree Weighting (CTW), Prediction by Partial Match (PPM) and Probabilistic Suffix Trees (PSTs). We discuss the properties of these algorithms and compare their performance using real life sequences from three domains: proteins, English text and music pieces. The comparison is made with respect to prediction quality as measured by the average log-loss. We also compare classification algorithms based on these predictors with respect to a number of large protein classification tasks. Our results indicate that a ""decomposed"" CTW (a variant of the CTW algorithm) and PPM outperform all other algorithms in sequence prediction tasks. Somewhat surprisingly, a different algorithm, which is a modification of the Lempel-Ziv compression algorithm, significantly outperforms all algorithms on the protein classification problems. © 2004 AI Access Foundation. All rights reserved.","2004","2025-10-22 19:07:45","2025-10-22 19:07:45","","385-421","","","22","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Trees (mathematics); Classification (of information); Problem solving; Markov processes; Context Tree Weighting (CTW); Data compression; Prediction by Partial Match (PPM); Probabilistic Suffix Trees (PSTs); Protein classification problems; Proteins","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5EIB2SF","conferencePaper","2019","Carver, B.; Zhang, J.; Wang, A.; Cheng, Y.","In search of a fast and efficient serverless DAG engine","","","","10.1109/PDSW49588.2019.00005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078949158&doi=10.1109%2fPDSW49588.2019.00005&partnerID=40&md5=1161fc1d68b475b3cc851d5b17b805bc","Python-written data analytics applications can be modeled as and compiled into a directed acyclic graph (DAG) based workflow, where the nodes are fine-grained tasks and the edges are task dependencies.Such analytics workflow jobs are increasingly characterized by short, fine-grained tasks with large fan-outs. These characteristics make them well-suited for a new cloud computing model called serverless computing or Function-as-a-Service (FaaS), which has become prevalent in recent years. The auto-scaling property of serverless computing platforms accommodates short tasks and bursty workloads, while the pay-per-use billing model of serverless computing providers keeps the cost of short tasks low. In this paper, we thoroughly investigate the problem space of DAG scheduling in serverless computing. We identify and evaluate a set of techniques to make DAG schedulers serverless-aware. These techniques have been implemented in WUKONG, a serverless, DAG scheduler attuned to AWS Lambda. WUKONG provides decentralized scheduling through a combination of static and dynamic scheduling. We present the results of an empirical study in which WUKONG is applied to a range of microbenchmark and real-world DAG applications. Results demonstrate the efficacy of WUKONG in minimizing the performance overhead introduced by AWS Lambda-WUKONG achieves competitive performance compared to a serverful DAG scheduler, while improving the performance of real-world DAG jobs by as much as 4.1x at larger scale. © 2019 IEEE.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","1-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Empirical studies; Data Analytics; Digital storage; Computing platform; Directed graphs; Directed acyclic graph (DAG); Competitive performance; Bursty workloads; Decentralized scheduling; Scaling properties; Static and dynamic scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of PDSW 2019: IEEE/ACM 4th International Parallel Data Systems Workshop - Held in conjunction with SC 2019: The International Conference for High Performance Computing, Networking, Storage and Analysis","","","","","","","","","","","","","","",""
"TLZ4ZXB8","journalArticle","2020","","","Microsoft Azure Serverless Functions.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119253679&partnerID=40&md5=5485c727227fed8133b9e069656d8d16","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQ6VCC3P","journalArticle","2020","Brooker, M.; Florescu, A.; Popa, D.-M.; Neugebauer, R.; Agache, A.; Iordache, A.; Liguori, A.; Piwonka, P.","Firecracker: Lightweight Virtualization for Serverless Applications","NSDI","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095497238&partnerID=40&md5=acdd7c262baa0e03669c6c09ec95784f","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HKSQZPZ","journalArticle","2019","Prasad Buddha, J.; Beesetty, R.","Step functions","The Definitive Guide to AWS Application Integration.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119251379&partnerID=40&md5=a98c3777553fa985b616acf66c99b03d","","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XNCWVPJI","conferencePaper","2020","Keahey, K.; Anderson, J.; Zhen, Z.; Riteau, P.; Ruth, P.; Stanzione, D.; Cevik, M.; Colleran, J.; Gunawi, H.S.; Hammock, C.; Mambretti, J.; Barnes, A.; Halbach, F.; Rocha, A.; Stubbs, J.","Lessons learned from the chameleon testbed","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089064296&partnerID=40&md5=8eb1b29a826fb2b99aa478bc52588580","The Chameleon testbed is a case study in adapting the cloud paradigm for computer science research. In this paper, we explain how this adaptation was achieved, evaluate it from the perspective of supporting the most experiments for the most users, and make a case that utilizing mainstream technology in research testbeds can increase efficiency without compromising on functionality. We also highlight the opportunity inherent in the shared digital artifacts generated by testbeds and give an overview of the efforts we've made to develop it to foster reproducibility. Copyright © Proc. of the 2020 USENIX Annual Technical Conference, ATC 2020. All rights reserved.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","219-233","","","","","","","","","","","","","","","","Scopus","","","","","","","","Testbeds; Reproducibilities; Computer science research; Digital artifacts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2020 USENIX Annual Technical Conference, ATC 2020","","","","","","","","","","","","","","",""
"BZTNUWH7","conferencePaper","2020","Cadden, J.; Unger, T.; Awad, Y.; Dong, H.; Krieger, O.; Appavoo, J.","SEUSS: Skip redundant paths to make serverless fast","","","","10.1145/3342195.3392698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087107959&doi=10.1145%2f3342195.3392698&partnerID=40&md5=7c393950590d0b7cd76c31891e4148d7","This paper presents a system-level method for achieving the rapid deployment and high-density caching of serverless functions in a FaaS environment. For reduced start times, functions are deployed from unikernel snapshots, bypassing expensive initialization steps. To reduce the memory footprint of snapshots we apply page-level sharing across the entire software stack that is required to run a function. We demonstrate the effects of our techniques by replacing Linux on the compute node of a FaaS platform architecture. With our prototype OS, the deployment time of a function drops from 100s of milliseconds to under 10 ms. Platform throughput improves by 51x on workload composed entirely of new functions. We are able to cache over 50,000 function instances in memory as opposed to 3,000 using standard OS techniques. In combination, these improvements give the FaaS platform a new ability to handle large-scale bursts of requests. © 2020 ACM.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer operating systems; Memory footprint; Cache memory; Deployment time; Initialization step; New functions; Platform architecture; Rapid deployments; Redundant paths; Software stacks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 15th European Conference on Computer Systems, EuroSys 2020","","","","","","","","","","","","","","",""
"CFKFT9EE","conferencePaper","2019","Thinakaran, P.; Gunasekaran, J.R.; Sharma, B.; Kandemir, M.T.; Das, C.R.","Kube-Knots: Resource Harvesting through Dynamic Container Orchestration in GPU-based Datacenters","","","","10.1109/CLUSTER.2019.8891040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075268776&doi=10.1109%2fCLUSTER.2019.8891040&partnerID=40&md5=c15599158265a13428a55a593c69384d","Compute heterogeneity is increasingly gaining prominence in modern datacenters due to the addition of accelerators like GPUs and FPGAs. We observe that datacenter schedulers are agnostic of these emerging accelerators, especially their resource utilization footprints, and thus, not well equipped to dynamically provision them based on the application needs. We observe that the state-of-the-art datacenter schedulers fail to provide fine-grained resource guarantees for latency-sensitive tasks that are GPU-bound. Specifically for GPUs, this results in resource fragmentation and interference leading to poor utilization of allocated GPU resources. Furthermore, GPUs exhibit highly linear energy efficiency with respect to utilization and hence proactive management of these resources is essential to keep the operational costs low while ensuring the end-to-end Quality of Service (QoS) in case of user-facing queries.Towards addressing the GPU orchestration problem, we build Knots, a GPU-aware resource orchestration layer and integrate it with the Kubernetes container orchestrator to build Kube-Knots. Kube-Knots can dynamically harvest spare compute cycles through dynamic container orchestration enabling co-location of latency-critical and batch workloads together while improving the overall resource utilization. We design and evaluate two GPU-based scheduling techniques to schedule datacenter-scale workloads through Kube-Knots on a ten node GPU cluster. Our proposed Correlation Based Prediction (CBP) and Peak Prediction (PP) schemes together improves both average and 99th percentile cluster-wide GPU utilization by up to 80% in case of HPC workloads. In addition, CBP+PP improves the average job completion times (JCT) of deep learning workloads by up to 36% when compared to state-of-the-art schedulers. This leads to 33% cluster-wide energy savings on an average for three different workloads compared to state-of-the-art GPU-agnostic schedulers. Further, the proposed PP scheduler guarantees the end-to-end QoS for latency-critical queries by reducing QoS violations by up to 53% when compared to state-of-the-art GPU schedulers. © 2019 IEEE.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","2019-September","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Containers; Energy efficiency; Deep learning; Program processors; Cluster computing; Computer architecture; State of the art; Graphics processing unit; Resource utilizations; Batch workloads; End-to-end QoS; End-to-end quality of service; Job completion; Proactive management; Scheduling techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE International Conference on Cluster Computing, ICCC","","","","","","","","","","","","","","",""
"WCK7MRN9","journalArticle","2020","","AWS Lambda","Serverless Functions.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119282869&partnerID=40&md5=cd40c8bad8633c32da6d4d08288097d9","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9WNK8IDB","conferencePaper","2020","Zhang, Y.; Crowcroft, J.; Li, D.; Zhang, C.; Li, H.; Wang, Y.; Yu, K.; Xiong, Y.; Chen, G.","KylinX: A dynamic library operating system for simplified and efficient cloud virtualization","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077459733&partnerID=40&md5=ce16e0d3fd31f98b9e0dacc83a6f3a1a","Unikernel specializes a minimalistic LibOS and a target application into a standalone single-purpose virtual machine (VM) running on a hypervisor, which is referred to as (virtual) appliance. Compared to traditional VMs, Unikernel appliances have smaller memory footprint and lower overhead while guaranteeing the same level of isolation. On the downside, Unikernel strips off the process abstraction from its monolithic appliance and thus sacrifices flexibility, efficiency, and applicability. This paper examines whether there is a balance embracing the best of both Unikernel appliances (strong isolation) and processes (high flexibility/efficiency). We present KylinX, a dynamic library operating system for simplified and efficient cloud virtualization by providing the pVM (process-like VM) abstraction. A pVM takes the hypervisor as an OS and the Unikernel appliance as a process allowing both page-level and library-level dynamic mapping. At the page level, KylinX supports pVM fork plus a set of API for inter-pVM communication (IpC). At the library level, KylinX supports shared libraries to be linked to a Unikernel appliance at runtime. KylinX enforces mapping restrictions against potential threats. KylinX can fork a pVM in about 1.3 ms and link a library to a running pVM in a few ms, both comparable to process fork on Linux (about 1 ms). Latencies of KylinX IpCs are also comparable to that of UNIX IPCs. © Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018. All rights reserved.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","173-185","","","","","","","","","","","","","","","","Scopus","","","","","","","","Hypervisor; Virtual reality; Virtualization; Computer operating systems; Runtimes; Mapping; Abstracting; Virtual machine; Dynamic mapping; High flexibility; Memory footprint; Potential threats; Shared libraries; Target application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2018 USENIX Annual Technical Conference, USENIX ATC 2018","","","","","","","","","","","","","","",""
"9M4VRNXS","journalArticle","2021","","","Expedia Case Study - Amazon AWS.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119267908&partnerID=40&md5=18841b5e363b1e2e6f8ef11cb26a8cf9","","2021","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U5RQ5TMH","conferencePaper","2019","Kannan, R.S.; Subramanian, L.; Raju, A.; Ahn, J.; Mars, J.; Tang, L.","GrandSLAm: Guaranteeing SLAs for jobs in microservices execution frameworks","","","","10.1145/3302424.3303958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063902706&doi=10.1145%2f3302424.3303958&partnerID=40&md5=3421b52ef10bf2d471d82be441436ba2","The microservice architecture has dramatically reduced user effort in adopting and maintaining servers by providing a catalog of functions as services that can be used as building blocks to construct applications. This has enabled datacenter operators to look at managing datacenter hosting microservices quite differently from traditional infrastructures. Such a paradigm shift calls for a need to rethink resource management strategies employed in such execution environments. We observe that the visibility enabled by a microservices execution framework can be exploited to achieve high throughput and resource utilization while still meeting Service Level Agreements, especially in multi-tenant execution scenarios. In this study, we present GrandSLAm, a microservice execution framework that improves utilization of datacenters hosting microservices. GrandSLAm estimates time of completion of requests propagating through individual microservice stages within an application. It then leverages this estimate to drive a runtime system that dynamically batches and reorders requests at each microservice in a manner where individual jobs meet their respective target latency while achieving high throughput. GrandSLAm significantly increases throughput by up to 3× compared to the our baseline, without violating SLAs for a wide range of real-world AI and ML applications. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Resource management; Service Level Agreements; Learning systems; Building blockes; Computer systems; Execution environments; Execution framework; Execution scenario; Machine Learning; Resource utilizations; Systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 14th EuroSys Conference 2019","","","","","","","","","","","","","","",""
"NTCBGJ3L","journalArticle","2020","","","Azure Durable Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091921373&partnerID=40&md5=429fb2a6809c7c1f4ec2d3f0368f5a27","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNS5DMPI","journalArticle","2018","Akkus, I.E.; Chen, R.; Rimac, I.; Stein, M.; Satzke, K.; Beck, A.; Aditya, P.; Hilt, V.","SAND: Towards High-Performance Serverless Computing","USENIX ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062596504&partnerID=40&md5=69803d1ae53e00a17efa1267107cd265","","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","923-935","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7EHIUDHD","conferencePaper","2020","Kuhlenkamp, J.; Werner, S.; Tai, S.","The Ifs and Buts of Less is More: A Serverless Computing Reality Check","","","","10.1109/IC2E48712.2020.00023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086010587&doi=10.1109%2fIC2E48712.2020.00023&partnerID=40&md5=017b80e2713eedd1b56287f83399c448","Serverless computing defines a pay-as-you-go cloud execution model, where the unit of computation is a function that a cloud provider executes and auto-scales on behalf of a cloud consumer. Serverless suggests not (or less) caring about servers but focusing (more) on business logic expressed in functions. Server'less' may be 'more' when getting developer expectations and platform propositions right and when engineering solutions that take specific behavior and constraints of (current) Function-as-a-Service platforms into account. To this end, in this invited paper, we present a summary of findings and lessons learned from a series of research experiments conducted over the past two years. We argue that careful attention must be placed on the promises associated with the serverless model, provide a reality-check for five common assumptions, and suggest ways to mitigate unwanted effects. Our findings focus on application workload distribution and computational processing complexity, the specific auto-scaling mechanisms in place, the behavior and strategies implemented with operational tasks, the constraints and limitations existing when composing functions, and the costs of executing functions. © 2020 IEEE.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","154-161","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud providers; serverless computing; function-as-a-service (FaaS); Engineering; Industrial engineering; Work-load distribution; Cloud consumers; Computational processing; Engineering solutions; FaaS experimentation; FaaS platforms; Operational tasks; Scaling mechanism; Service platforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE International Conference on Cloud Engineering, IC2E 2020","","","","","","","","","","","","","","",""
"ISFG29JB","journalArticle","2020","","","Prometheus","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093068583&partnerID=40&md5=14a90c15a85c08ba691cf0d0d4f660b1","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYIXB4RW","journalArticle","2019","Jonas, E.","Cloud programming simplified: A Berkeley view on serverless computing","Cloud Programming Simplified: A Berkeley View on Serverless Computing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067433472&partnerID=40&md5=85287d7260661386b411bc1efadbde9b","","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCXRTQXF","conferencePaper","2019","Carreira, J.; Fonseca, P.; Tumanov, A.; Zhang, A.; Katz, R.","Cirrus: A Serverless Framework for End-To-end ML Workflows","","","","10.1145/3357223.3362711","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086244066&doi=10.1145%2f3357223.3362711&partnerID=40&md5=93d14acd78be426e6b2361507438ea14","Machine learning (ML) workflows are extremely complex. The typical workflow consists of distinct stages of user interaction, such as preprocessing, training, and tuning, that are repeatedly executed by users but have heterogeneous computational requirements. This complexity makes it challenging for ML users to correctly provision and manage resources and, in practice, constitutes a significant burden that frequently causes over-provisioning and impairs user productivity. Serverless computing is a compelling model to address the resource management problem, in general, but there are numerous challenges to adopt it for existing ML frameworks due to significant restrictions on local resources. This work proposes Cirrus-An ML framework that automates the end-To-end management of datacenter resources for ML workflows by efficiently taking advantage of serverless infrastructures. Cirrus combines the simplicity of the serverless interface and the scalability of the serverless infrastructure (AWS Lambdas and S3) to minimize user effort. We show a design specialized for both serverless computation and iterative ML training is needed for robust and efficient ML training on serverless infrastructure. Our evaluation shows that Cirrus outperforms frameworks specialized along a single dimension: Cirrus is 100x faster than a general purpose serverless system [36] and 3.75x faster than specialized ML frameworks for traditional infrastructures [49]. © 2019 ACM.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","13-24","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Serverless; Computer science; Computational requirements; Over provisioning; Computer programming; Machine Learning; Distributed Computing; End-to-End management; Local resources; Resource management problems; Serverless systems; User interaction; User productivity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2019 - Proceedings of the ACM Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"SZJT7ZF3","journalArticle","2021","","","AWS Lambda Cold Starts.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119294537&partnerID=40&md5=5686c5a1d2e3e8964b3a6e6e2a16076f","","2021","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYP4IJQP","book","2017","Gagniuc, P.A.","Markov chains: From theory to implementation and experimentation","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006461119&partnerID=40&md5=fcd942eb4ae1d63da5a68748376f5d30","A fascinating and instructive guide to Markov chains for experienced users and newcomers alike. This unique guide to Markov chains approaches the subject along the four convergent lines of mathematics, implementation, simulation, and experimentation. It introduces readers to the art of stochastic modeling, shows how to design computer implementations, and provides extensive worked examples with case studies. Markov Chains: From Theory to Implementation and Experimentation begins with a general introduction to the history of probability theory in which the author uses quantifiable examples to illustrate how probability theory arrived at the concept of discrete-time and the Markov model from experiments involving independent variables. An introduction to simple stochastic matrices and transition probabilities is followed by a simulation of a two-state Markov chain. The notion of steady state is explored in connection with the long-run distribution behavior of the Markov chain. Predictions based on Markov chains with more than two states are examined, followed by a discussion of the notion of absorbing Markov chains. Also covered in detail are topics relating to the average time spent in a state, various chain configurations, and n-state Markov chain simulations used for verifying experiments involving various diagram configurations. • Fascinating historical notes shed light on the key ideas that led to the development of the Markov model and its variants • Various configurations of Markov Chains and their limitations are explored at length • Numerous examples-from basic to complex-are presented in a comparative manner using a variety of color graphics • All algorithms presented can be analyzed in either Visual Basic, Java Script, or PHP • Designed to be useful to professional statisticians as well as readers without extensive knowledge of probability theory. Covering both the theory underlying the Markov model and an array of Markov chain implementations, within a common conceptual framework, Markov Chains: From Theory to Implementation and Experimentation is a stimulating introduction to and a valuable reference for those wishing to deepen their understanding of this extremely valuable statistical tool. © 2017 John Wiley & Sons, Inc. All rights reserved.","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","","1","","","","","","Markov Chains: From Theory to Implementation and Experimentation","","","","","","","","","Scopus","","","","","","","","Distribution functions; Stochastic models; Stochastic-modeling; Statistics; Case-studies; Markov chains; Random variables; Markov modeling; Computer implementations; Discrete time; Higher order statistics; Independent variables; Markov chain approaches; Probability theory; Simple stochastic; Worked examples","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYJWC6LP","journalArticle","2020","","","OpenFaaS.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119284680&partnerID=40&md5=94302faef6f70fe60792580f1a2846a3","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSB7KZ8J","conferencePaper","2020","Qiu, H.; Banerjee, S.S.; Jha, S.; Kalbarczyk, Z.T.; Iyer, R.K.","Firm: An intelligent fine-grained resource management framework for SLO-Oriented microservices","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096750460&partnerID=40&md5=b6f58ba9bf20eadf724e1ad34566cc29","User-facing latency-sensitive web services include numerous distributed, intercommunicating microservices that promise to simplify software development and operation. However, multiplexing of compute resources across microservices is still challenging in production because contention for shared resources can cause latency spikes that violate the service-level objectives (SLOs) of user requests. This paper presents FIRM, an intelligent fine-grained resource management framework for predictable sharing of resources across microservices to drive up overall utilization. FIRM leverages online telemetry data and machine-learning methods to adaptively (a) detect/localize microservices that cause SLO violations, (b) identify low-level resources in contention, and (c) take actions to mitigate SLO violations via dynamic reprovisioning. Experiments across four microservice benchmarks demonstrate that FIRM reduces SLO violations by up to 16× while reducing the overall requested CPU limit by up to 62%. Moreover, FIRM improves performance predictability by reducing tail latencies by up to 11×. © 2020 Proceedings of the 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020. All rights reserved.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","805-825","","","","","","","","","","","","","","","","Scopus","","","","","","","","Compute resources; Software design; Systems analysis; Web services; Natural resources management; Resource allocation; Digital storage; Learning systems; Service level objective; Machine learning methods; Development and operations; Re-provisioning; Resource management framework; Shared resources; Telemetry data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020","","","","","","","","","","","","","","",""
"2TEWHFCD","conferencePaper","2020","Gunasekaran, J.R.; Thinakaran, P.; Nachiappan, N.C.; Kandemir, M.T.; Das, C.R.","Fifer: Tackling resource underutilization in the serverless era","","","","10.1145/3423211.3425683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098501448&doi=10.1145%2f3423211.3425683&partnerID=40&md5=5b7c61544291abbc88128e4805963129","Datacenters are witnessing a rapid surge in the adoption of serverless functions for microservices-based applications. A vast majority of these microservices typically span less than a second, have strict SLO requirements, and are chained together as per the requirements of an application. The aforementioned characteristics introduce a new set of challenges, especially in terms of container provisioning and management, as the state-of-the-art resource management frameworks, employed in serverless platforms, tend to look at microservice-based applications similar to conventional monolithic applications. Hence, these frameworks suffer from microservice agnostic scheduling and colossal container over-provisioning, especially during workload fluctuations, thereby resulting in poor resource utilization. In this work, we quantify the above shortcomings using a variety of workloads on a multi-node cluster managed by the Kubernetes and Brigade serverless framework. To address them, we propose Fifer Ð an adaptive resource management framework to efficiently manage function-chains on serverless platforms. The key idea is to make Fifer (i) utilization conscious by efficiently bin packing jobs to fewer containers using function-aware container scaling and intelligent request batching, and (ii) at the same time, SLO-compliant by proactively spawning containers to avoid cold-starts, thus minimizing the overall response latency. Combining these benefits, Fifer improves container utilization and cluster-wide energy consumption by 4× and 31%, respectively, without compromising on SLO's, when compared to the state-of-the-art schedulers employed by serverless platforms. © 2020 Association for Computing Machinery.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","280-295","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Energy utilization; Serverless; Middleware; State of the art; Natural resources management; Resource allocation; Data centers; Over provisioning; Resource utilizations; Bin packing; Bins; Resource management framework; Adaptive Resource Management; Multi-nodes; Queuing; Resource-management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Middleware 2020 - Proceedings of the 2020 21st International Middleware Conference","","","","","","","","","","","","","","",""
"IWYMUQDD","journalArticle","2018","","","Google Cloud Functions","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058988852&partnerID=40&md5=3754edb5c4abbd9a67b401f83d0d33ec","","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRMAS926","journalArticle","2008","Awad, M.; Khan, L.; Thuraisingham, B.","Predicting WWW surfing using multiple evidence combination","VLDB Journal","","","10.1007/s00778-006-0014-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-43249090136&doi=10.1007%2fs00778-006-0014-1&partnerID=40&md5=af9bab42c29f9c96a245340d1460e98a","The improvement of many applications such as web search, latency reduction, and personalization/ recommendation systems depends on surfing prediction. Predicting user surfing paths involves tradeoffs between model complexity and predictive accuracy. In this paper, we combine two classification techniques, namely, the Markov model and Support Vector Machines (SVM), to resolve prediction using Dempster's rule. Such fusion overcomes the inability of the Markov model in predicting the unseen data as well as overcoming the problem of multiclassification in the case of SVM, especially when dealing with large number of classes. We apply feature extraction to increase the power of discrimination of SVM. In addition, during prediction we employ domain knowledge to reduce the number of classifiers for the improvement of accuracy and the reduction of prediction time. We demonstrate the effectiveness of our hybrid approach by comparing our results with widely used techniques, namely, SVM, the Markov model, and association rule mining. © 2006 Springer-Verlag.","2008","2025-10-22 19:07:45","2025-10-22 19:07:45","","401-417","","3","17","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7A2SUUV","journalArticle","2021","","","Azure Functions Cold Starts.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119286758&partnerID=40&md5=3512821f3bc6954e98ac682cfc3fd1aa","","2021","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QC7ILVYS","journalArticle","2018","Korte, B.; Vygen, J.","Bin-Packing","Combinatorial Optimization: Theory and Algorithms","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047991612&partnerID=40&md5=3d0d49cd65ec37194d0d2edb77cc99df","","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","489-507","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJ3FQ2BD","journalArticle","2018","Oakes, E.; Yang, L.; Zhou, D.; Houck, K.; Harter, T.; Arpaci-Dusseau, A.; Arpaci-Dusseau, R.","SOCK: Rapid task provisioning with serverless-optimized containers","USENIX ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062616330&partnerID=40&md5=9b225926df24cf1dbc5436bcf966f5ca","","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","57-70","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HF53NNK3","conferencePaper","2019","Shahrad, M.; Balkind, J.; Wentzlaff, D.","Architectural implications of function-as-a-service computing","","","","10.1145/3352460.3358296","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074454583&doi=10.1145%2f3352460.3358296&partnerID=40&md5=a1c5e1ae40346c4b02458962a3f50a50","Serverless computing is a rapidly growing cloud application model, popularized by Amazon's Lambda platform. Serverless cloud services provide fine-grained provisioning of resources, which scale automatically with user demand. Function-as-a-Service (FaaS) applications follow this serverless model, with the developer providing their application as a set of functions which are executed in response to a user- or system-generated event. Functions are designed to be short-lived and execute inside containers or virtual machines, introducing a range of system-level overheads. This paper studies the architectural implications of this emerging paradigm. Using the commercial-grade Apache OpenWhisk FaaS platform on real servers, this work investigates and identifies the architectural implications of FaaS serverless computing. The workloads, along with the way that FaaS inherently interleaves short functions from many tenants frustrates many of the locality-preserving architectural structures common in modern processors. In particular, we find that: FaaS containerization brings up to 20x slowdown compared to native execution, cold-start can be over 10x a short function's execution time, branch mispredictions per kilo-instruction are 20x higher for short functions, memory bandwidth increases by 6x due to the invocation pattern, and IPC decreases by as much as 35% due to inter-function interference. We open-source FaaSProfiler, the FaaS testing and profiling platform that we developed for this work. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","1063-1075","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Cloud applications; Serverless; Computer architecture; Architecture; Clouds; Architectural structure; Branch mispredictions; Cloud; Faas; Function-as-a-service; Locality-preserving; Modern processors; Open whisk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual International Symposium on Microarchitecture, MICRO","","","","","","","","","","","","","","",""
"VQ2R49RR","journalArticle","2020","","","IBM-Composer.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119298686&partnerID=40&md5=34666b790668eccc66f781770b3ee29c","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y29IMRCA","journalArticle","2018","Wang, L.; Li, M.; Zhang, Y.; Ristenpart, T.; Swift, M.","Peeking behind the curtains of serverless platforms","ATC","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059031873&partnerID=40&md5=caa34109dbbbd9ed3461168088924e09","","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","133-146","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SEKV564G","journalArticle","2020","","","Kubernetes.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119261837&partnerID=40&md5=992895f474fb0a5a71e423ec1cb3feaf","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSJAF3XA","journalArticle","2020","","","Intel Power Gadget.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119296266&partnerID=40&md5=c05731643c70baae9737c00730903f6b","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XEFZTHPZ","journalArticle","2020","","","Hey HTTP Load Testing Tool.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119274614&partnerID=40&md5=a42b90c12d54952d0cbea13b84823610","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94U2I9PR","journalArticle","2019","Singhvi, A.; Houck, K.; Balasubramanian, A.; Shaikh, M.D.; Venkataraman, S.; Akella, A.","","Archipelago: A Scalable Low-Latency Serverless Platform","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086275868&partnerID=40&md5=74375a642a1e604dccda8238e9406f1a","","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NVTWSSL6","conferencePaper","2020","Daw, N.; Bellur, U.; Kulkarni, P.","Xanadu: Mitigating cascading cold starts in serverless function chain deployments","","","","10.1145/3423211.3425690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098485885&doi=10.1145%2f3423211.3425690&partnerID=40&md5=8e4776490ec08205556e8edaac0873a7","Organization of tasks as workflows are an essential feature to expand the applicability of the serverless computing framework. Existing serverless platforms are either agnostic to function chains (workflows as a composition of functions) or rely on naive provisioning and management mechanisms of the serverless framework-an example is that they provision resources after the trigger to each function in a workflow arrives thereby forcing a setup latency for each function in the workflow. In this work, we focus on mitigating the cascading cold start problem- the latency overheads in triggering a sequence of serverless functions according to a workflow specification. We first establish the nature and extent of the cascading effects in cold start situations across multiple commercial server platforms and cloud providers. Towards mitigating these cascading overheads, we design and develop several optimizations, that are built into our tool Xanadu. Xanadu offers multiple instantiation options based on the desired runtime isolation requirements and supports function chaining with or without explicit workflow specifications. Xanadu's optimizations to address the cascading cold start problem are built on speculative and just-in-time provisioning of resources. Our evaluation of the Xanadu system reveals almost complete elimination of cascading cold starts at minimal cost overheads, outperforming the available state of the art platforms. For even relatively short workflows, Xanadu reduces platform overheads by almost 18x compared to Knative and 10x compared to Apache Openwhisk. © 2020 Association for Computing Machinery.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","356-370","","","","","","","","","","","","","","","","Scopus","","","","","","","","Middleware; State of the art; Computing frameworks; Cascading effects; Specifications; Cold start problems; Essential features; Just-in-time scheduling; Management mechanisms; Server platform; Serverless workflows; Speculative deployment; Workflow specification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Middleware 2020 - Proceedings of the 2020 21st International Middleware Conference","","","","","","","","","","","","","","",""
"JYZKU8EE","conferencePaper","2017","Thinakaran, P.; Gunasekaran, J.R.; Sharma, B.; Kandemir, M.T.; Das, C.R.","Phoenix: A Constraint-Aware Scheduler for Heterogeneous Datacenters","","","","10.1109/ICDCS.2017.262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027243807&doi=10.1109%2fICDCS.2017.262&partnerID=40&md5=ac206f4e869dd2cd31958088b9a24366","Today's datacenters are increasingly becoming diverse with respect to both hardware and software architectures in order to support a myriad of applications. These applications are also heterogeneous in terms of job response times and resource requirements (eg., Number of Cores, GPUs, Network Speed) and they are expressed as task constraints. Constraints are used for ensuring task performance guarantees/Quality of Service(QoS) by enabling the application to express its specific resource requirements. While several schedulers have recently been proposed that aim to improve overall application and system performance, few of these schedulers consider resource constraints across tasks while making the scheduling decisions. Furthermore, latencycritical workloads and short-lived jobs that typically constitute about 90% of the total jobs in a datacenter have strict QoS requirements, which can be ensured by minimizing the tail latency through effective scheduling. In this paper, we propose Phoenix, a constraint-aware hybrid scheduler to address both these problems (constraint awareness and ensuring low tail latency) by minimizing the job response times at constrained workers. We use a novel Constraint Resource Vector (CRV) based scheduling, which in turn facilitates reordering of the jobs in a queue to minimize tail latency. We have used the publicly available Google traces to analyze their constraint characteristics and have embedded these constraints in Cloudera and Yahoo cluster traces for studying the impact of traces on system performance. Experiments with Google, Cloudera and Yahoo cluster traces across 15,000 worker node cluster shows that Phoenix improves the 99th percentile job response times on an average by 1.9× across all three traces when compared against a state-of-the-art hybrid scheduler. Further, in comparison to other distributed scheduler like Hawk, it improves the 90th and 99th percentile job response times by 4.5× and 5× respectively. © 2017 IEEE.","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","977-987","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Application programs; Information management; Performance; Resource management; Program processors; Distributed computer systems; Response time (computer systems); Resource Management; Constraint-aware; Heterogeneous Data Center; Heterogeneous data centers; Hybrid","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Distributed Computing Systems","","","","","","","","","","","","","","",""
"9LA9BTQ8","journalArticle","2004","","","Enhanced Intel SpeedStep Technology for the Intel Pentium M Processor","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746279684&partnerID=40&md5=caf5513fb73ecdf14a9b669e30ddc5b4","","2004","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3AYZWR5M","journalArticle","2017","","","Samsung V-NAND Ssd 860 Evo","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100738579&partnerID=40&md5=6cfd312038f753ade131473f69c87c38","","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9CVF5J7P","journalArticle","2017","","","Understanding Load Capacitance and Access Time","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104993806&partnerID=40&md5=24740d5b79e49ffef0b36ffda50b7d28","","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VDWQKYR","conferencePaper","2012","Seo, D.","A study of workload consolidation and power consumption on a multi-core processor","","","","10.1145/2401603.2401702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871635925&doi=10.1145%2f2401603.2401702&partnerID=40&md5=d0166c177d5ddfb205890a2e5a06b2cc","Workload consolidation based on virtualization techniques has been widely adopted in most Cloud Computing platforms to improve energy efficiency. However, workload consolidation comes with performance degradation due to the contention in shared resources, such as CPU cache, memory controller, etc. In this paper, we study the change of performance and power consumption with various mixes of workloads. We performed experiments with SPEC CPU2006 benchmark suite on an Intel's quad-core processor, and observed that there is noticeable relationship among characteristics of workloads, performance interference and power consumption. Copyright 2012 ACM.","2012","2025-10-22 19:07:45","2025-10-22 19:07:45","","457-458","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Performance degradation; Virtualizations; Benchmark suites; Benchmarking; Computing platform; Server consolidation; Green IT; Workload consolidation; Multi-core processor; Shared resources; Memory controller; Performance interference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceeding of the 2012 ACM Research in Applied Computation Symposium, RACS 2012","","","","","","","","","","","","","","",""
"2H4WXSA9","conferencePaper","2020","Valera, H.H.A.; Dalmau, M.; Roose, P.; Larracoechea, J.; Herzog, C.","DRACeo: A smart simulator to deploy energy saving methods in microservices based networks","","","","10.1109/WETICE49692.2020.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100714002&doi=10.1109%2fWETICE49692.2020.00026&partnerID=40&md5=6dde8162ca929d1cfeb833956e56d257","Nowadays, many researchers work to identify microservices-based application deployments and scheduling solutions to save energy without decreasing functional QoS. In this work, we present DRACeo: A simulator that allows facing this challenge in a simple and efficient way, enabling its users to focus uniquely on microservices deployment/scheduling algorithms and its hardware/software repercussions (load vs. energy consumption) without worrying about low-level network configurations or operating system issues. DRACeo is able to deploy and schedule (move, duplicate, start/stop) microservices and their dependencies on various devices with software and hardware heterogeneity (CPU, bandwidth, RAM, Battery, etc.), taking into account various scheduling heuristics algorithms: centralized vs non-centralized. To do this, DRACeo allows deploying custom network topologies based on client-server schemes or p2p distributions, where devices can (dis)appear, turn on/off obeying random circumstances or user strategies. Finally, the simulator performs relevant operations such as QoS definition, resource monitoring, calculation of energy saved and consumption tracking (at device and network level). We tested some ideas based on our previous work 'Kaligreen' to demonstrate the effectiveness of DRACeo. © 2020 IEEE.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","94-99","","","2020-September","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Scheduling; microservices; Energy utilization; Energy conservation; CPU; Software and hardwares; Application deployment; energy; middleware; Network topology; consumption; hard disk; network; prototype; simulator; Energy saving methods; Hardware/software; Network configuration; Resource monitoring; Scheduling heuristics; Simulators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE","","","","","","","","","","","","","","",""
"ZALPYAFD","journalArticle","2019","","","Implementing Microservices on AWS","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104984254&partnerID=40&md5=e5ebc8c03310646cb19ef4f6136c7fbd","","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","2019","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"76F9X4NS","conferencePaper","2018","Bucek, J.; Lange, K.-D.; Kistowski, J.V.","SPEC CPU2017 – next-generation compute benchmark","","","","10.1145/3185768.3185771","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052022982&doi=10.1145%2f3185768.3185771&partnerID=40&md5=11d0c231ad2092a4e4df6e3067486f6b","Description of the new features of the SPEC CPU2017 industry standard benchmark and its metric calculations. © 2018 Association of Computing Machinery.","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","41-42","","","2018-January","","","","","","","","","","","","","Scopus","","","","","","","","Power; Performance; Program processors; Energy; CPU; Speed; Engineering; Industrial engineering; Compiler; Rate; Rating; SPEC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2018 - Companion of the 2018 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"E54GEDI6","conferencePaper","2014","Zhan, K.; Lung, C.-H.; Srivastava, P.","A green analysis of mobile cloud computing applications","","","","10.1145/2554850.2555069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905637579&doi=10.1145%2f2554850.2555069&partnerID=40&md5=a1b9a6bbb272621e55d54e65fd49f773","With the widespread of rich mobile applications, the usage of mobile devices, especially smart phones and tablets, has become popular nowadays. However, battery in the mobile devices often limits continuous usages with its small size and capacity. Therefore, power consumption of mobile devices is a critical issue, not only for extending lifetime use of mobile devices, but also for creating a green IT which is a raising concern in academic and industrial communities. The goal of this paper is to investigate the power consumption of mobile devices and resource usages for various applications. To meet the goal, we have performed a number of experiments and detailed evaluations of resource usages and power consumption for various applications using a number of tools. In addition, we have measured performance metrics for applications either using a mobile device or running in the Amazon cloud. We examine the impact of various factors and provide insights on power consumption for different mobile applications. Copyright 2014 ACM.","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","357-362","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Performance metrics; Mobile devices; Mobile applications; Mobile computing; Mobile cloud computing; Green computing; Resource usage; CPU; Power consumption; Amazon; Critical issues; Industrial communities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Symposium on Applied Computing","","","","","","","","","","","","","","",""
"3R7FN5AV","journalArticle","1998","Gaede, V.; Günther, O.","Multidimensional Access Methods","ACM Computing Surveys","","","10.1145/280277.280279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032083561&doi=10.1145%2f280277.280279&partnerID=40&md5=cb89e29b44053485060d3f9c03a2890c","Search operations in databases require special support at the physical level. This is true for conventional databases as well as spatial databases, where typical search operations include the point query (find all objects that contain a given search point) and the region query (find all objects that overlap a given search region). More than ten years of spatial database research have resulted in a great variety of multidimensional access methods to support such operations. We give an overview of that work. After a brief survey of spatial data management in general, we first present the class of point access methods, which are used to search sets of points in two or more dimensions. The second part of the paper is devoted to spatial access methods to handle extended objects, such as rectangles or polyhedra. We conclude with a discussion of theoretical and experimental results concerning the relative performance of various approaches.","1998","2025-10-22 19:07:45","2025-10-22 19:07:45","","170-231","","2","30","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Data structures; Database systems; Query languages; Online searching; Computer aided design; World Wide Web; Information retrieval; Constraint databases; Geographic information systems; H.2.2 [Database Management]: Physical Design - access methods; H.2.4 [Database Management]: Systems; H.2.8 [Database Management]: Database Applications - spatial databases and GIS; Indexing (of information); Management information systems; Multidimensional access methods; Spatial data management; Spatial databases; Spatial variables control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CAANM57H","journalArticle","2020","","","Cpu-frequency","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104949099&partnerID=40&md5=528703faff6ba19a8a777d50e5a4e6dc","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FNEPXFAR","conferencePaper","2016","Bao, K.; Mauser, I.; Kochanneck, S.; Xu, H.; Schmeck, H.","A microservice architecture for the Intranet of Things and energy in smart buildings","","","","10.1145/3007203.3007215","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010375308&doi=10.1145%2f3007203.3007215&partnerID=40&md5=730b0a142140f2e954d073b1476e68bd","This paper presents challenges and issues in smart buildings and the Internet of Things (IoT), which we identified in years of research in real buildings. To tackle these challenges, a decentralized service-oriented architecture based on a message-oriented middleware has been implemented for the domain of smart buildings. It uses a network-transparent IoT message bus and provides the means for composing applications from auxiliary services, which facilitate device abstraction, protocol adaption, modularity, and maintainability. We demonstrate the flexibility of our architecture by describing how three distinct applications - privacy-enhancing energy data visualization, automated building energy management, and a generic user interface - can be integrated and operated simultaneously in our real smart building laboratory. We compare the advantages of our architecture to conventional ones and provide a best-practice solution for the Intranet of Things and Energy in smart buildings. © 2016 ACM.","2016","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Internet of things; Network architecture; Architecture; User interfaces; Middleware; Energy management; Buildings; Information services; Internet of Things; Intelligent buildings; Visualization; Service oriented architecture (SOA); Smart energies; Smart building; Internet of thing (IOT); Energy informatics; Flow visualization; Automated buildings; Auxiliary services; Data visualization; Device abstractions; Ge-neric user interfaces; Message oriented middleware; Smart energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 1st International Workshop on Mashups of Things and APIs, MOTA 2016","","","","","","","","","","","","","","",""
"3QR7VH7N","journalArticle","2025","Blog, N.T.","","Netflix Conductor: A Microservices Orchestrator","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088595149&partnerID=40&md5=4e2096496f24a0abd19ff8a02142cc5f","","2025","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMJLJ9LN","conferencePaper","2003","Cai, M.; Frank, M.; Chen, J.; Szekely, P.","MAAN: A multi-attribute addressable network for grid information services","","","","10.1109/GRID.2003.1261714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892599957&doi=10.1109%2fGRID.2003.1261714&partnerID=40&md5=3cf0588a11da0435e274cf5a9448e651","Recent structured peer-to-peer (P2P) systems such as distributed hash tables (DHTs) offer scalable key-based lookup for distributed resources. However, they cannot be simply applied to grid information services because grid resources need to be registered and searched using multiple attributes. We propose a multiattribute addressable network (MAAN) which extends chord to support multiattribute and range queries. MAAN addresses range queries by mapping attribute values to the chord identifier space via uniform locality preserving hashing. It uses an iterative or single attribute dominated query routing algorithm to resolve multiattribute based queries. Each node in MAAN only has O(logN) neighbors for N nodes. The number of routing hops to resolve a multiattribute range query is O(logN+N×smin), where smin is the minimum range selectivity on all attributes. When smin=ε, it is logarithmic to the number of nodes, which is scalable to a large number of nodes and attributes. We also measured the performance of our MAAN implementation and the experimental results are consistent with our theoretical analysis. © 2003 IEEE.","2003","2025-10-22 19:07:45","2025-10-22 19:07:45","","184-191","","","2003-January","","","","","","","","","","","","","Scopus","","","","","","","","Performance analysis; Large scale systems; Algorithms; Distributed computer systems; Grid computing; Iterative methods; Query languages; Information services; Distributed computing; Routing; Business; Distributed hash tables; Distributed resources; Grid information services; Industry; Iterative algorithm; Iterative algorithms; Large-scale systems; Maintainability; Maintenance engineering; Peer to peer computing; Peer to peer networks; Peer-to-peer computing; Query processing; Structured peer-to-peer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE/ACM International Workshop on Grid Computing","","","","","","","","","","","","","","",""
"GUMJINVA","journalArticle","2011","Chiaravalloti, S.; Idzikowski, F.; Budzisz, L.","Power consumption of WLAN network elements","Power Consumption of WLAN Network Elements","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865796739&partnerID=40&md5=c02a2b7082d8f28c1c0b3914d64daff3","","2011","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBMPBF42","conferencePaper","2007","Du Mouza, C.; Litwin, W.; Rigaux, P.","SD-Rtree: A scalable distributed Rtree","","","","10.1109/ICDE.2007.367875","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548718163&doi=10.1109%2fICDE.2007.367875&partnerID=40&md5=6f091d3d94643d71d150f2c2769946c6","We propose a scalable distributed data structure (SDDS) called SD-Rtree. We intend our structure for point and window queries over possibly large spatial dataseis distributed on clusters of interconnected servers. SD-Rtree generalizes the well-known Rtree structure. It uses a distributed balanced binary spatial tree that scales with insertions to potentially any number of storage servers through splits of the overloaded ones. A user/application manipulates the structure from a client node. The client addresses the tree through its image that the splits can make outdated. This may generate addressing errors, solved by the forwarding among the servers. Specific messages towards the clients incrementally correct the outdated images. © 2007 IEEE.","2007","2025-10-22 19:07:45","2025-10-22 19:07:45","","296-305","","","","","","","","","","","","","","","","Scopus","","","","","","","","Data structures; Servers; Problem solving; Cluster analysis; Query processing; Binary spatial tree; Binary trees; SD-Rtree; Window queries","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Data Engineering","","","","","","","","","","","","","","",""
"T2HW3HCC","journalArticle","2018","","","Creating Composite UI Based on Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105008681&partnerID=40&md5=fd80828b306b6fb971484df909431cd2","","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JWYCGQDP","journalArticle","2020","","","Memory Benchmarks","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104986422&partnerID=40&md5=7612f2e2a692c5fd8ae99c4e2ba8c167","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFHPV2QC","journalArticle","2014","Lewis, J.; Fowler, M.","Microservices: A definition of this new architectural term","Microservices: A Definition of This New Architectural Term","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964234114&partnerID=40&md5=fd3de0bd7b34545e47485cf075757737","","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PEAUNYVZ","conferencePaper","2012","Hao, S.; Li, D.; Halfond, W.G.J.; Govindan, R.","Estimating Android applications' CPU energy usage via bytecode profiling","","","","10.1109/GREENS.2012.6224263","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864260968&doi=10.1109%2fGREENS.2012.6224263&partnerID=40&md5=0396ef1cac05481c30d150b8a7f8f7a0","Optimizing the energy efficiency of mobile applications can greatly increase user satisfaction. However, developers lack easily applied tools for estimating the energy consumption of their applications. This paper proposes a new approach, eCalc, that is lightweight in terms of its developer requirements and provides code-level estimates of energy consumption. The approach achieves this using estimation techniques based on program analysis of the mobile application. In evaluation, eCalc is able to estimate energy consumption within 9.5% of the ground truth for a set of mobile applications. Additionally, eCalc provides useful and meaningful feedback to the developer that helps to characterize energy consumption of the application. © 2012 IEEE.","2012","2025-10-22 19:07:45","2025-10-22 19:07:45","","1-7","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy utilization; Mobile applications; Robots; Mobile telecommunication systems; Energy estimation; Estimation; Ground truth; Program analysis; User satisfaction; Energy usage; energy estimation; Bytecodes; Estimation techniques; Android apps; bytecode profiling; eCalc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2012 1st International Workshop on Green and Sustainable Software, GREENS 2012 - Proceedings","","","","","","","","","","","","","","",""
"7XGEBHWN","journalArticle","2002","Maymounkov, P.; Mazières, D.","Kademlia: A peer-to-peer information system based on the XOR metric","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","10.1007/3-540-45748-8_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947235017&doi=10.1007%2f3-540-45748-8_5&partnerID=40&md5=ce04a5a23535595758b18f88f1546304","We describe a peer-to-peer distributed hash table with provable consistency and performance in a fault-prone environment. Our system routes queries and locates nodes using a novel XOR-based metric topology that simplifies the algorithm and facilitates our proof. The topology has the property that every message exchanged conveys or reinforces useful contact information. The system exploits this information to send parallel, asynchronous query messages that tolerate node failures without imposing timeout delays on users. © 2002 Springer-Verlag Berlin Heidelberg.","2002","2025-10-22 19:07:45","2025-10-22 19:07:45","","53-65","","","2429","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Topology; Property; Peer to peer networks; Distributed Hash Table; Fault-prone; Kademlia; Metric topology; Peer to peer; Peer-to-peer information; Query message; Route queries; Structured Query Language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P97S78Y9","journalArticle","2006","Krajewski, J.; Lozano, J.; Driver, J.; Escandon, E.; Kumar, S.; Malatini, S.; Lozano Hinojosa, J.","","PASTRY: The Third Generation of Peer-to-peer Networks","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104980207&partnerID=40&md5=a612dbb515e68c5dde35ca04bd676e6b","","2006","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HH3G3DMS","conferencePaper","2014","Procaccianti, G.; Lago, P.; Lewis, G.A.","Green architectural tactics for the cloud","","","","10.1109/WICSA.2014.30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903736056&doi=10.1109%2fWICSA.2014.30&partnerID=40&md5=05d70982b487d6efcb5f7e23da19ca94","Energy efficiency is a primary concern for the ICT sector. In particular, the widespread adoption of cloud computing technologies has drawn attention to the massive energy consumption of data centers. Although hardware constantly improves with respect to energy efficiency, this should also be a main concern for software. In previous work we analyzed the literature and elicited a set of techniques for addressing energy efficiency in cloud-based software architectures. In this work we codified these techniques in the form of Green Architectural Tactics. These tactics will help architects extend their design reasoning towards energy efficiency and to apply reusable solutions for greener software. © 2014 IEEE.","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","41-44","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Software architecture; Cloud Computing; Energy Efficiency; Energy utilization; Data centers; Software Architecture; Cloud-based; Computer software reusability; Cloud computing technologies; Architectural Tactics; Design reasonings; Ict sectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - Working IEEE/IFIP Conference on Software Architecture 2014, WICSA 2014","","","","","","","","","","","","","","",""
"A56WJAI3","conferencePaper","2011","Neumann, D.; Bodenstein, C.; Rana, O.F.; Krishnaswamy, R.","STACEE: Enhancing storage clouds using edge devices","","","","10.1145/1998561.1998567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960117962&doi=10.1145%2f1998561.1998567&partnerID=40&md5=f0fcfad372abe313f6dd9ce55834e657","The explosion of user generated data along with the evolution of web 2.0 applications (e.g. social networks, blogs, podcasts, etc.) has resulted in a tremendous demand for storage. With cloud computing posing as a possible all-in-one solution, ""storage clouds"" focus on providing distributed storage capability. We discuss the creation of a storage cloud using edge devices, based on Peer-to-Peer resource provisioning. In this approach, mobile phones, PCs/Media Centers, Set-top-boxes, modems and networked storage devices can all contribute as storage within these storage clouds. Combining all end-user edge devices may result in a scalable, very flexible storage capability that keeps the data comparatively close to the user, increasing availability, while reducing latency. This work addresses the issue of Quality of Service (QoS)-aware scheduling in a P2P storage cloud, built with edge devices by designing an optimization scheme that minimizes energy from a system perspective and simultaneously maximizing user satisfaction from the individual user perspective. © 2011 ACM.","2011","2025-10-22 19:07:45","2025-10-22 19:07:45","","19-26","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Optimization; Cloud computing; resource management; Resource management; Clouds; User interfaces; Green IT; Resource provisioning; Social Networks; green it; Distributed storage; User satisfaction; End users; Telecommunication equipment; Peer to peer networks; Peer to peer; Flexible storage; Optimization scheme; peer-to-peer; Podcasts; Set top box; storage optimization; Virtual storage; Web 2.0 applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","8th International Conference on Autonomic Computing, ICAC 2011 Co-located Workshops - Proceedings of the 1st ACM/IEEE Workshop on Autonomic Computing in Economics, ACE'11","","","","","","","","","","","","","","",""
"JRPAWNX4","journalArticle","2001","Chávez, E.; Navarro, G.; Baeza-Yates, R.; Marroquín, J.L.","Searching in metric spaces","ACM Computing Surveys","","","10.1145/502807.502808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345043999&doi=10.1145%2f502807.502808&partnerID=40&md5=4f5dc577f5c13d03370609b56123afae","The problem of searching the elements of a set that are close to a given query element under some similarity criterion has a vast number of applications in many branches of computer science, from pattern recognition to textual and multimedia information retrieval. We are interested in the rather general case where the similarity criterion defines a metric space, instead of the more restricted case of a vector space. Many solutions have been proposed in different areas, in many cases without cross-knowledge. Because of this, the same ideas have been reconceived several times, and very different presentations have been given for the same approaches. We present some basic results that explain the intrinsic difficulty of the search problem. This includes a quantitative definition of the elusive concept of ""intrinsic dimensionality."" We also present a unified Categories and Subject Descriptors: F.2.2 [Analysis of algorithms and problem complexity]: Nonnumerical algorithms and problems-computations on discrete structures, geometrical problems and computations, sorting and searching; H.2.1 [Database management]: Physical design-access methods; H.3.1 [Information storage and retrieval]: Content analysis and indexing-indexing methods; H.3.2 [Information storage and retrieval]: Information storage-file organization; H.3.3 [Information storage and retrieval]: Information search and retrieval-clustering, search process; 1.5.1 [Pattern recognition]: Models-geometric; 1.5.3 [Pattern recognition]: Clustering General Terms: Algorithms. ©2001 ACM.","2001","2025-10-22 19:07:45","2025-10-22 19:07:45","","273-321","","3","33","","","","","","","","","","","","","Scopus","","","","","","","","Data mining; Algorithms; Computational complexity; Data storage equipment; Vectors; Curse of dimensionality; Vector spaces; Information retrieval; Clustering search process; Computational geometry; Metric spaces; Nearest neighbors; Pattern matching; Similarity searching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YP4LRK69","journalArticle","2020","","","How to Overclock Your Unlocked Intel Core™ Processor","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104999899&partnerID=40&md5=c9ce7bb19797cdbcfd874a103b82e27d","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZMW9UG7","conferencePaper","2015","Kiertscher, S.; Schnor, B.","Scalability evaluation of an energy-aware resource management system for clusters of web servers","","","","10.1109/SPECTS.2015.7285285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992036358&doi=10.1109%2fSPECTS.2015.7285285&partnerID=40&md5=8fde33c6f96f037481f6dcf2f4c96100","For green cluster computing resource management systems have to be energy-aware. CHERUB is such an energy-aware resource management system which works together with the Linux Virtual Server. Experiments in a small cluster setup with two nodes have shown the benefit of CHERUB. This paper presents necessary design changes to make CHERUB also work in big cluster setups. Our methodological approach is two-fold. First, we present unit measurements to evaluate the scaling of the re-implemented functions. Second, a cluster simulator is presented and validated which makes it possible to test CHERUB for backend clusters of arbitrary size. © 2015 Society for Modeling and Simulation International.","2015","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Computer operating systems; Energy Efficiency; Cluster computing; Computer architecture; Natural resources management; Resource allocation; Scalability; Green IT; Simulation; Energy management systems; Green-IT; Computing resource management; Resource management systems; Energy awareness; Cluster Computing; Energy Awareness; Integrated modeling; Integrated Modeling and Measurement; Methodological approach; Scalability evaluation; Scalability Studies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2015 International Symposium on Performance Evaluation of Computer and Telecommunication Systems, SPECTS 2015 - Part of SummerSim 2015 Multiconference","","","","","","","","","","","","","","",""
"NSGBH6GP","conferencePaper","2019","Valera, H.H.L.; Dalmau, M.; Roose, P.; Herzog, C.","The Architecture of Kaligreen V2: A Middleware Aware of Hardware Opportunities to Save Energy","","","","10.1109/IOTSMS48152.2019.8939237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077969153&doi=10.1109%2fIOTSMS48152.2019.8939237&partnerID=40&md5=7b937f6435a19d89b288227377d059e7","Nowadays, energy saving in the use of information technologies is a very important issue both from the economic and sustainability point of view. Many scientists investigate methods to save energy at different application levels (cloud: i.e., architectures, grid: i.e., middlewares and frameworks and hardware management: i.e., operating systems) and many of them agree on the strategy of executing programs, processes or virtual machines only using the time and resources that are strictly necessary. For this, it is necessary to plan strategies for deployment and relocation of processes; but always taking into account hardware repercussions and the knowledge of the architecture and applications behavior. On the other hand, it has already been demonstrated that the use of microservices brings numerous advantages in availability and efficiency; but we do not find many jobs that exploit this technique on the energy level. In this article, we present the architecture of a middleware for distributed microservices-based applications, which allows any negotiation-based scheduling algorithm to duplicate or move microservices from one device to another in a non-centralized way for energy savings, taking into account the consumption characteristics of the microservices and the capabilities that the hardware components offer. © 2019 IEEE.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","79-86","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; microservices; Program processors; Internet of things; Network architecture; Networks (circuits); Middleware; Energy conservation; CPU; Scheduling algorithms; Application level; energy; middleware; consumption; hard disk; network; Hard disk storage; Hardware components; Hardware management; Information use; Save energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 6th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2019","","","","","","","","","","","","","","",""
"JEZKCJWT","conferencePaper","2018","Lvarez-Valera, H.H.; Roose, P.; Dalmau, M.; Herzog, C.; Respicio, K.","Kali green: A distributed scheduler for energy saving","","","","10.1016/j.procs.2018.10.172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058349351&doi=10.1016%2fj.procs.2018.10.172&partnerID=40&md5=762a84024c90ed200594143af3fc90ed","A commonplace issue with portable technology is battery efficiency. While many industries are trying their best to improve battery life without sacrificing a products quality and efficiency, we believe that further can be done to improve battery consumption on ones mobile devicefrom tablets to smartphones to laptops to everything else. Many applications on these devices are based on a microservice architecture. In this article, we introduce a new algorithm KaliGreen that can maneuver the microservices within a network of devices in order to maximize the run-time of a microservice-based application; moreover, KaliGreen allows a 54% increase in the average run-time of an application by shifting microservices from 6 devices (as example) with low battery or inefficient processing ratios to devices in better conditions. To achieve this, KaliGreen utilizes KaliMucho middleware, which is able manipulate microservices in run-time. This algorithm provides a plausible solution to maximizing energy consumption within a network of devices. © 2018 The Authors. Published by Elsevier Ltd.","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","223-230","","","141","","","","","","","","","","","","","Scopus","","","","","","","","Electric batteries; Microservices; Energy utilization; Middleware; Smartphones; Green computing; Energy conservation; Distributed schedulers; Green Computing; Battery consumption; Battery efficiencies; Battery life; Distributed applicatioggns; mHealth; Portable technologies; Products quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Procedia Computer Science","","","","","","","","","","","","","","",""
"DESPW38R","journalArticle","2014","Pawlish, M.; Varde, A.S.; Robila, S.A.; Ranganathan, A.","A call for energy efficiency in data centers","SIGMOD Record","","","10.1145/2627692.2627703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901660119&doi=10.1145%2f2627692.2627703&partnerID=40&md5=41566c91c3f43607ba45eadfab151955","In this paper, we explore a data center's performance with a call for energy efficiency through green computing. Some performance metrics we examine in data centers are server energy usage, Power Usage Effectiveness and utilization rate, i.e., the extent to which data center servers are being used. Recent literature indicates that utilization rates at many internal data centers are quite low, resulting in poor usage of resources such as energy and materials. Based on our study, we attribute these low utilization rates to not fully taking advantage of virtualization, and not retiring phantom (unused) servers. This paper describes our initiative corroborated with real data in a university setting. We suggest that future data centers will need to increase their utilization rates for better energy efficiency, and moving towards a cloud provider would help. However, we argue that neither a pure in-house data center or cloud model is the best solution. Instead we recommend, from a decision support perspective, a hybrid model in data center management to lower costs and increase services, while also providing greater energy efficiency.","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","45-51","","1","43","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Performance metrics; Energy Efficiency; Virtualizations; Clouds; Data centers; Cloud; Green IT; Data center management; Utilization rates; Decision support systems; Data Centers; Decision supports; University settings; Utilization Rates","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I4SB35VD","conferencePaper","2011","Orgerie, A.-C.; Lefèvre, L.; Guérin-Lassous, I.; Lopez Pacheco, D.M.","ECOFEN: An end-to-end energy cost model and simulator for evaluating power consumption in large-scale networks","","","","10.1109/WoWMoM.2011.5986203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052698432&doi=10.1109%2fWoWMoM.2011.5986203&partnerID=40&md5=59543a30d002fd0aae1815e186a1e3f4","Wired networks are increasing in size and their power consumption is becoming a matter of concern. Evaluating the end-to-end electrical cost of new network architectures and protocols is difficult due to the lack of monitored realistic infrastructures. We propose an End-to-End energy Cost mOdel and simulator For Evaluating power consumption in large-scale Networks (ECOFEN) whose user's entries are the network topology and traffic. Based on configurable measurement of different network components (routers, switches, NICs, etc.), it provides the power consumption of the overall network including the end-hosts as well as the power consumption of each equipment over time. © 2011 IEEE.","2011","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Network architecture; Wireless networks; Costs; Topology; Energy cost; Network topology; Power consumption; Simulators; Network simulator; Wired networks; Configurable; Electric network topology; Electrical costs; Energy cost model; Large-scale network; Switches; Time switches","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks, WoWMoM 2011 - Digital Proceedings","","","","","","","","","","","","","","",""
"GNPICXSL","conferencePaper","2017","Karyakin, A.; Salem, K.","An analysis of memory power consumption in database systems","","","","10.1145/3076113.3076117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021733217&doi=10.1145%2f3076113.3076117&partnerID=40&md5=c604b7a1774dffc452900871b6efa76e","The growing appetite for in-memory computing is increasing memory's share of total server power consumption. However, memory power consumption in database management systems is not well understood. This paper presents an empirical characterization of memory power consumption in database systems, for both analytical and transactional workloads. Our results indicate that memory power optimization will be effective only if it can reduce background power through more aggressive use of low power memory idle states. ©2017 ACM.","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Electric power utilization; Information management; Database systems; Power Optimization; Background power; Low-power memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 13th International Workshop  on Data Management on New Hardware, DAMON 2017","","","","","","","","","","","","","","",""
"DBJQLNXT","conferencePaper","2010","Jaiantilal, A.; Jiang, Y.; Mishra, S.","Modeling CPU energy consumption for energy efficient scheduling","","","","10.1145/1925013.1925015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952339536&doi=10.1145%2f1925013.1925015&partnerID=40&md5=41f46a8723ae0d9bff6b8739ae223d9b","In the past few years, we have seen the rising popularity of multi-core systems, including the 4, 6, and 8-cores present in i7 processors from Intel, and the 8 and 12 cores present in Magny-Cours processors from AMD. There is a general trend that newer processors have more and more number of cores. A study [6] showed that, in data centers, the CPU load is around 10-50%; thus, when multi-core processors are used in data centers, many of the cores will be unused for a majority of the time. Such a scenario is also true for a casual desktop PC user. As an idle core still consumes energy, from the perspective of saving energy, it is important to ensure that the idle cores are put in the lowest energy state and unnecessary wakeups for these idle cores are avoided. This will ensure the lowest energy consumption for a given set of tasks. The precursor step towards developing an energy efficient CPU scheduler requires an understanding of the relation between the type of tasks and their corresponding power profile. In this paper, we show that the power profile of a task is dependent on the type of processor cycles executed by the task. We further develop a model that can predict the power consumption based on the processor cycles executed by the task. We conclude our paper showing initial results on how such a model can be used to schedule tasks and save energy. Copyright © 2010 ACM.","2010","2025-10-22 19:07:45","2025-10-22 19:07:45","","10-15","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Energy efficient; Energy utilization; Middleware; Energy consumption; Data centers; Microprocessor chips; Energy-Efficient Scheduling; Save energy; Power Consumption; Multi-core systems; Multi-core processor; Saving energy; General trends; Lowest energy state; Power profile","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","1st International Workshop on Green Computing Middleware 2010, GCM 2010","","","","","","","","","","","","","","",""
"5RB369FM","journalArticle","2014","Lu, Y.-F.; Wu, J.; Kuo, C.-F.","A path generation scheme for real-time green internet of things","SIGAPP Appl. Comput. Rev.","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926450845&partnerID=40&md5=3c2e07eaf7deec34698397f5aa7597d8","","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","45-58","","2","14","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7MRLR55Y","conferencePaper","2012","Mandal, S.; Chakraborty, S.; Karmakar, S.","Deterministic 1-2 skip list in distributed system","","","","10.1109/PDGC.2012.6449835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874425885&doi=10.1109%2fPDGC.2012.6449835&partnerID=40&md5=c6457017be28deab73b5fd55df515e08","Searching data efficiently in distributed applications like peer-to-peer system is a challenging task due to the random distribution of data among several participating nodes. Efficient data structures are designed and implemented to reduce the complexity of data searching in such an environment. In this paper a data structure called deterministic 1-2 skip list has been proposed as a solution for search problems in distributed environment. The data structure has three main operations viz. search, insert, and delete. The detailed description of the insertion, deletion and search operations are given in this paper. It is found that the message complexity of the insertion, deletion and search algorithm is O(log n) where n is the total number of nodes in the skip-list. © 2012 IEEE.","2012","2025-10-22 19:07:45","2025-10-22 19:07:45","","296-301","","","","","","","","","","","","","","","","Scopus","","","","","","","","Data structures; Distributed systems; Grid computing; Distributed applications; Random distribution; Search engines; Data searching; Distributed environments; Efficient data structures; Message complexity; Peer-to-Peer system; Search Algorithms; Search operations; Search problem; Skip listes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of 2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing, PDGC 2012","","","","","","","","","","","","","","",""
"R583ZASR","conferencePaper","2004","Ganesan, P.; Yang, B.; Garcia-Molina, H.","One torus to rule them all: Multi-dimensional queries in P2P systems","","","","10.1145/1017074.1017081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954435659&doi=10.1145%2f1017074.1017081&partnerID=40&md5=9ae45db4a31a58e8b4a18af759ab6c84","Peer-to-peer systems enable access to data spread over an extremely large number of machines. Most P2P systems support only simple lookup queries. However, many new applications, such as P2P photo sharing and massively multi-player games, would benefit greatly from support for multidimensional range queries. We show how such queries may be supported in a P2P system by adapting traditional spatial-database technologies with novel P2P routing networks and load-balancing algorithms. We show how to adapt two popular spatial-database solutions - kd-trees and space-filling curves - and experimentally compare their effectiveness.","2004","2025-10-22 19:07:45","2025-10-22 19:07:45","","19-24","","","67","","","","","","","","","","","","","Scopus","","","","","","","","Trees (mathematics); New applications; Simple++; Peer to peer networks; Structured Query Language; Peer-to-Peer system; Lookups; Massively multiplayer games; Multi-dimensional queries; P2P system; Photo sharing; Spatial database; Systems support; Table lookup","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"J7VW6QQH","journalArticle","2016","","","Desktop Hdd Product Manual","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100813024&partnerID=40&md5=689610d04b90f0283edb78919307b376","","2016","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3B73U3JR","journalArticle","2019","","","Orquestacion de Contenedores Explicada","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104928973&partnerID=40&md5=6a764979e92e99a1bcea45f6966d2906","","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RX9DTHN9","conferencePaper","2011","Siddavatam, I.; Johri, E.; Patole, D.","Optimization of load balancing algorithm for green IT","","","","10.1145/1980022.1980321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958720139&doi=10.1145%2f1980022.1980321&partnerID=40&md5=b375d694610f5c51b7ce515e32c3cc5f","This paper is focused on calculating the processor utilization of various machines having different types of processor configurations employed in data centers by providing solutions to reduce the energy cost component of companies total IT budget. In this paper different parameters like CPU Utilization and Power Utilization on different machines installed in data centers have been analyzed. Also calculation of power required by different machines of different configurations in different modes of operations like active mode, hibernation mode and standby mode is been performed. Here an algorithm has been developed that will calculate the processor utilization by different machines according to the Load Distribution in a network and propose a strategy to utilize minimum possible energy by optimal resource utilization. Copyright © 2011 ACM.","2011","2025-10-22 19:07:45","2025-10-22 19:07:45","","1344-1346","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Optimization; Algorithms; Information technology; Energy consumption; Wireless sensor networks; Data centers; Load balancing algorithms; Resource utilizations; Green IT; Energy cost; CPU utilization; Active mode; Different modes; IT budgets; Load distributions; Processor sharing; Processor sharing computer systems; Processor utilization; Standby mode; Standby power systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference and Workshop on Emerging Trends in Technology 2011, ICWET 2011 - Conference Proceedings","","","","","","","","","","","","","","",""
"QERYFHP7","conferencePaper","2014","Da, K.; Dalmau, M.; Roose, P.","Kalimucho: Middleware for mobile applications","","","","10.1145/2554850.2554883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905652787&doi=10.1145%2f2554850.2554883&partnerID=40&md5=c88b567dba93ee6384b57b3bbd3ba1ee","Developing ubiquitous applications is particularly complex. Beyond the dynamic aspect of such applications, the evolution of computing towards the multiplication of mobile access terminals is not making things easier. One solution to simplifying the development and use of such applications is to use software platforms dedicated to deployment and adaptation of applications and handling the heterogeneity of peripherals. They allow designers to focus on business aspects and facilitate reuse. The Kalimucho platform was designed and developed against this background. It executes and supervises applications based on software components. Copyright 2014 ACM.","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","413-419","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Performance; Software component; Design; Middleware; Mobile applications; Query languages; Reliability; Measurement; Measurements; Business aspects; Dynamic aspects; Languages; Mobile access; Software platforms; Ubiquitous application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Symposium on Applied Computing","","","","","","","","","","","","","","",""
"6EMVTSFZ","conferencePaper","2011","Kang, S.; Choi, H.J.; Kim, C.H.; Chung, S.W.; Kwon, D.; Na, J.C.","Exploration of CPU/GPU co-execution: From the perspective of performance, energy, and temperature","","","","10.1145/2103380.2103388","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863119763&doi=10.1145%2f2103380.2103388&partnerID=40&md5=47baf701aecd532d1795b9604448ed9c","In recent computing systems, CPUs have encountered the situations in which they cannot meet the increasing throughput demands. To overcome the limits of CPUs in processing heavy tasks, especially for computer graphics, GPUs have been widely used. Therefore, the performance of up-to-date computing systems can be maximized when the task scheduling between the CPU and the GPU is optimized. In this paper, we analyze the system in the perspective of performance, energy efficiency, and temperature according to the execution methods between the CPU and the GPU. Experimental results show that the GPU leads to better efficiency compared to the CPU when single application is executed. However, when two applications are executed, the GPU does not guarantee superior efficiency than the CPU depending on the application characteristics. © 2011 ACM.","2011","2025-10-22 19:07:45","2025-10-22 19:07:45","","38-43","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Energy efficiency; Program processors; GPU; CPU; scheduling; Computing system; Computer graphics; Task-scheduling; High-performance computing; Computer software selection and evaluation; CUDA; high-performance computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2011 ACM Research in Applied Computation Symposium, RACS 2011","","","","","","","","","","","","","","",""
"XJBRYCAH","journalArticle","2020","","","IntelR Core i5-8400 Processor","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104999405&partnerID=40&md5=1fd1276d941aa330413801d7bd0b2ddb","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WKRXMBXW","conferencePaper","2013","Chen, Q.; Li, J.","The balance mechanism of power and performance in the virtualization","","","","10.1145/2556871.2556912","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899567061&doi=10.1145%2f2556871.2556912&partnerID=40&md5=97358bea132fd7f6d17117e96d2e7815","Energy has become an important resource for computer system. In multicore systems, shared resource can lead to contention between tasks running on different cores, which also will give rise to poor power efficiency. The system with dynamic voltage and frequency scaling(DVFS) capability provide support for dynamic energy management to make a better energy efficiency. However, the coming of the virtualization technology make different in energy management. In this paper, we present the policies into a virtualization system, to improve the performance and energy efficiency by avoiding the resource contention of virtual CPU, which the application run on it, and use frequency scaling. Our evaluation based on Xen virtualization environment shows that our policies reduce the energy delay product considerably. © 2013 ACM.","2013","2025-10-22 19:07:45","2025-10-22 19:07:45","","189-192","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Energy efficiency; Cloud computing; Virtual reality; Energy; Energy management; Computer systems; Resource contention; Dynamic voltage and frequency scaling; Virtualization technologies; DVFS; Multi-core systems; Dynamic energy managements; Energy delay product; Schedule","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"DFLNX9VF","conferencePaper","2012","Yaacoub, E.; Kadri, A.; Abu-Dayya, A.","Cooperative wireless sensor networks for green internet of things","","","","10.1145/2387218.2387235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870372973&doi=10.1145%2f2387218.2387235&partnerID=40&md5=d83272830a260c4b0f1d7c18ad4ca982","Green internet of things are investigated by studying energy efficiency in wireless sensor networks. A cooperative multihop data transmission approach is presented and analyzed. Significant energy savings are achieved with the proposed approach compared to the non cooperative scenario, in addition to better delay results. Copyright 2012 ACM.","2012","2025-10-22 19:07:45","2025-10-22 19:07:45","","79-80","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Data communication systems; Internet; Internet of things; Internet of Things (IOT); Sensor networks; Wireless sensor networks; Green internets; Energy minimization; Green communications; Multihop; Non-cooperative","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Q2SWinet'12 - Proceedings of the 8th ACM Symposium on QoS and Security for Wireless and Mobile Networks","","","","","","","","","","","","","","",""
"I2MCD52B","conferencePaper","2010","Malik, T.; Nistor, L.; Gehani, A.","Middleware for managing provenance metadata","","","","10.1145/1930028.1930033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957978511&doi=10.1145%2f1930028.1930033&partnerID=40&md5=a129ebacb8a6a18c92f922d89481abb9","Current provenance collection systems typically gather metadata on remote hosts and submit it to a central server. We describe middleware for managing distributed provenance metadata, where each host maintains an authoritative local repository of the provenance metadata gathered on it. The approach provides several advantages - the system can scale to handle the large amounts of metadata generated when auditing occurs at fine granularity; users retain control over their provenance records; and the middleware transparently queries remote provenance stores to reconstruct distributed lineage. © 2010 ACM.","2010","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Middleware; Metadata; Central servers; Collection systems; Fine granularity; Remote host","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Middleware'10 Posters and Demos Track, Middleware Posters'10","","","","","","","","","","","","","","",""
"K8ASWSQL","journalArticle","2010","Leverich, J.; Monchiero, M.; Talwar, V.; Ranganathan, P.; Kozyrakis, C.","Power management of datacenter workloads using per-core power gating","IEEE Computer Architecture Letters","","","10.1109/L-CA.2009.46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75449089335&doi=10.1109%2fL-CA.2009.46&partnerID=40&md5=304d051da79cd6d61a1c620c517769c7","While modern processors offer a wide spectrum of software-controlled power modes, most datacenters only rely on Dynamic Voltage and Frequency Scaling (DVFS, a.k.a. P-states) to achieve energy efficiency. This paper argues that, in the case of datacenter workloads, DVFS is not the only option for processor power management. We make the case for per-core power gating (PCPG) as an additional power management knob for multi-core processors. PCPG is the ability to cut the voltage supply to selected cores, thus reducing to almost zero the leakage power for the gated cores. Using a testbed based on a commercial 4-core chip and a set of real-world application traces from enterprise environments, we have evaluated the potential of PCPG. We show that PCPG can significantly reduce a processor's energy consumption (up to 40%) without significant performance overheads. When compared to DVFS, PCPG is highly effective saving up to 30% more energy than DVFS. When DVFS and PCPG operate together they can save up to almost 60%. © 2009 Published by the IEEE Computer Society.","2010","2025-10-22 19:07:45","2025-10-22 19:07:45","","48-51","","2","8","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy management; Energy consumption; Electric power measurement; Data centers; Modern processors; Power managements; Leakage power; Real-world application; Multi-core processor; Energy-aware systems; Enterprise environment; Integration and modeling; ON dynamics; Power gatings; Power modes; Processor power; System architectures; Voltage supply; Wide spectrum","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9DC5H75M","conferencePaper","2018","de Lange, P.; Göschlberger, B.; Farrell, T.; Klamma, R.","A Microservice Infrastructure for Distributed Communities of Practice","","","","10.1007/978-3-319-98572-5_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053214292&doi=10.1007%2f978-3-319-98572-5_14&partnerID=40&md5=2f36018faf5f3fa55203f0b2866ed8d4","Non-formal learning in Communities of Practice (CoPs) makes up a significant portion of today’s knowledge gain. However, only little technological support is tailored specifically towards CoPs and their particular strengths and challenges. Even worse, CoPs often do not possess the resources to host or even develop a software ecosystem to support their activities. In this paper, we describe a distributed, microservice-based Web infrastructure for non-formal learning in CoPs. It mitigates the need for central infrastructures, coordination or facilitation and takes into account the constant change of these communities. As a real use case, we implement an inquiry-based learning application on-top of our infrastructure. Our evaluation results indicate the usefulness of this learning application, which shows promise for future work in the domain of community-hosted, microservice-based Web infrastructures for learning outside of formal settings. © 2018, Springer Nature Switzerland AG.","2018","2025-10-22 19:07:45","2025-10-22 19:07:45","","172-186","","","11082 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Engineering education; Central infrastructure; Communities of Practice; Computer aided instruction; Distributed Communities of Practice; Inquiry-based learning; Learning infrastructures; Software ecosystems; Technological supports","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"VUKS4DBX","conferencePaper","2014","Cornea, B.F.; Orgerie, A.-C.; Lefèvre, L.","Studying the energy consumption of data transfers in Clouds: The Ecofen approach","","","","10.1109/CloudNet.2014.6968983","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925859008&doi=10.1109%2fCloudNet.2014.6968983&partnerID=40&md5=dcd337cdf783b075b4254c04e9ecb48b","Energy consumption is one of the main limiting factors for designing large scale Clouds. Evaluating the energy consumption of Clouds networking architectures and providing multi-level views required by providers and users, is a challenging issue. In this paper, we show how to evaluate and understand network choices (protocols, topologies) in terms of contributions to the energy consumption of the global Cloud infrastructures. By applying the ECOFEN model (Energy Consumption mOdel For End-to-end Networks) and the corresponding simulation framework, we profile and analyze the energy consumption of data transfers in Clouds. © 2014 IEEE.","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","143-148","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Green computing; simulation; energy consumption; Energy consumption model; Data transfer; Simulation framework; Cloud data; Networking architecture; Cloud data transfers; End-to-end network; ethernet networks; Ethernet networks; Global clouds","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2014 IEEE 3rd International Conference on Cloud Networking, CloudNet 2014","","","","","","","","","","","","","","",""
"AWPIVV3L","journalArticle","2019","","","SSD Vs HDD Tested: What's the Difference and Which Is Better?","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105000819&partnerID=40&md5=5f84c97958557f877009954f0215fb8f","","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2SWG3VKD","journalArticle","2001","Stoica, I.; Morris, R.; Karger, D.; Kaashoek, M.; Balakrishnan, H.","","Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952555588&partnerID=40&md5=2ee655b409f55c87e4c6862799cf2152","","2001","2025-10-22 19:07:45","2025-10-22 19:07:45","","149-160","","","149-160","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZ73TAEY","journalArticle","2003","Stoica, I.; Morris, R.; Liben-Nowell, D.; Karger, D.R.; Kaashoek, M.F.; Dabek, F.; Balakrishnan, H.","Chord: A scalable peer-to-peer lookup protocol for Internet applications","IEEE/ACM Transactions on Networking","","","10.1109/TNET.2002.808407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037298256&doi=10.1109%2fTNET.2002.808407&partnerID=40&md5=b789f15b0c5af2961f6a6532fa59419f","A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.","2003","2025-10-22 19:07:45","2025-10-22 19:07:45","","17-32","","1","11","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Internet; Data reduction; Iterative methods; Network protocols; Costs; Computer simulation; Distributed scalable algorithms; Lookup protocols; Peer-to-peer networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHQTN64Q","bookSection","2017","Maevsky, D.A.; Maevskaya, E.J.; Stetsuyk, E.D.","Evaluating the RAM energy consumption at the stage of software development","Studies in Systems, Decision and Control","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028990231&doi=10.1007%2f978-3-319-44162-7_6&partnerID=40&md5=3c430799c139e365f2e8863f5f638572","A method of absolute value estimation of the computer energy consumption in performing the programs is proposed in the chapter. The evaluation is made on the basis of the program source code and can help to choose the most optimal solution from the viewpoint of energy saving at the Software development stage. The method is based on the indication of energy consumption by the computer Random Access Memory (RAM) depending upon how intensive the RAM is used by Software. Selection of RAM due to the fact that it is a necessary equipment, and any computing device cannot function without it. Evaluation of energy consumed by RAM is made in using the two proposed mathematical models. The method for computer’s estimating power consumption based on assembler source code was made on the basis of the proposed models. This allows you to create a green software with the control of “green” degree on all stages of its development. © Springer International Publishing Switzerland 2017.","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","101-121","","","74","","","","","","","","","","","","","Scopus","","","","","","","","Software engineering; Green computing; Energy consumption; Green software; Energy-efficient software development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5MXTFXMW","journalArticle","2020","","","Calculating Network Data Transfer Speeds","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105002315&partnerID=40&md5=a1a386cdd31dd70458fb6e0a1367c3e6","","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD9QHYVB","conferencePaper","2016","Azmy, N.M.; El-Maddah, I.A.M.; Mohamed, H.K.","Adaptive power panel of cloud computing controlling cloud power consumption","","","","10.1145/2944165.2944167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985990751&doi=10.1145%2f2944165.2944167&partnerID=40&md5=c5b64478913d045dc22f54d9b7cff5fa","Cloud computing had created a new era of network design, where end-users can get their required services without having to purchase expensive infrastructure or even to care about troubleshooting. Power consumption is a challenge facing the Cloud Providers to operate their Datacenters. One solution to overcome this is the Virtual Machine (VM) migration, which is a technique used to switch under-utilized hosts to sleep mode in order to save power, and to avoid over-utilized hosts from Service Level Agreement (SLA) violation. But still the problem is that the Cloud Service Provider apply a single policy on all nodes. Our proposed solution is an adaptive power panel where different policies can be applied based on both of the nature of the tasks running on hosts, and the Cloud Provider decision. © 2016 ACM.","2016","2025-10-22 19:07:45","2025-10-22 19:07:45","","9-14","","","28-29-May-2016","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Cloud computing; Distributed computer systems; Software engineering; Virtual machines; Migration; Green computing; Virtual Machine; Placement; Green Computing; Adaptive; Allocation; Cloudsim; Selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","",""
"P8BU5AB4","conferencePaper","2015","Esfahani, N.P.; Cerpa, A.E.","Poster abstract: Energy optimization framework in wireless sensor network","","","","10.1145/2809695.2817904","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962909447&doi=10.1145%2f2809695.2817904&partnerID=40&md5=5b17645e6efcdf2f1c9b7d9be1212204","We present a holistic architecture for energy management in sensor networks. Our architecture is based on a modeldriven approach which attempts to (a) establish functional relationships across different components of the software stack and the interrelated parameters based on empirical data, (b) use the maximum sensor value and time-synchronization errors acceptable by the users of the sensor network application as input to establish minimum quality of service requirements, and (c) optimize the parameter values of all the software modules within the node's application stack to minimize total energy consumption for each sensor node. We explore the trade-offs of the design space by using a non-trivial application that includes sensing, time synchronization and routing modules and show that when using our architecture, we can provide energy savings in the average of 37% to 76% while still maintaining quality of service both in terms of the expected sensing and time-synchronization errors. We further show that even when using modules that perform significantly better than others with default values (e.g. ORW ∗ CTP), we can still reduce overall energy consumption by properly adjusting the parameters of lowest performance modules and provide energy savings in the average of 30% to 43%.","2015","2025-10-22 19:07:45","2025-10-22 19:07:45","","441-442","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Application programs; Embedded systems; Optimization; Energy utilization; Economic and social effects; Network architecture; Energy; Model driven approach; Energy conservation; Wireless sensor networks; Sensor nodes; Synchronization; C (programming language); Total energy consumption; Component; Functional relationship; Sensor network applications; Time synchronization; Time synchronization errors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SenSys 2015 - Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems","","","","","","","","","","","","","","",""
"K9JNPLXG","conferencePaper","2022","Patrou, M.; Kent, K.B.; Siu, J.; Dawson, M.","Optimizing Energy Efficiency of Node.js Applications with CPU DVFS Awareness","","","","10.1109/IGSC55832.2022.9969367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145440659&doi=10.1109%2fIGSC55832.2022.9969367&partnerID=40&md5=c768dcfc730f42b7b97d1f2ae74e6b74","Node.js applications can incorporate CPU Dynamic Voltage and Frequency Scaling (DVFS) to adjust their energy consumption and runtime performance. Thus, we build a CPU frequency scaling policy that promotes 'green' and high-performing requests and enables customizations of their execution profile. Our technique requires a profiling step to classify the web requests based on the CPU frequency impact on their energy consumption and runtime performance and on their code syntax/paradigm. We also include the case of concurrent request execution in our model to select an appropriate CPU frequency. We enable priority-based requests to work along with this model for users to customize and formulate a policy based on their goals. Finally, we perform an energy-runtime analysis, which shows that our policy with the proposed configurations is an energy-efficient approach compared to the Linux scaling governors.  © 2022 IEEE.","2022","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Computer operating systems; Energy utilization; Energy-consumption; Dynamic frequency scaling; Dynamic voltage and frequency scaling; Frequency-scaling; Concurrent requests; Customisation; Optimizing energy; Policy-based; Priority-based; Runtime performance; Web requests","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2022 IEEE 13th International Green and Sustainable Computing Conference, IGSC 2022","","","","","","","","","","","","","","",""
"TXCK9KK6","conferencePaper","2022","Tang, W.; Ke, Y.; Fu, S.; Jiang, H.; Wu, J.; Peng, Q.; Gao, F.","Demeter: QoS-Aware CPU Scheduling to Reduce Power Consumption of Multiple Black-Box Workloads","","","","10.1145/3542929.3563476","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143256886&doi=10.1145%2f3542929.3563476&partnerID=40&md5=86f69997bef090db61a3eb01f41c1bb7","Energy consumption in cloud data centers has become an increasingly important contributor to greenhouse gas emissions and operation costs. To reduce energy-related costs and improve environmental sustainability, most modern data centers consolidate Virtual Machine (VM) workloads belonging to different application classes, some being latency-critical (LC) and others being more tolerant to performance changes, known as best-effort (BE). However, in public cloud scenarios, the real classes of applications are often opaque to data center operators. The heterogeneous applications from different cloud tenants are usually consolidated onto the same hosts to improve energy efficiency, but it is not trivial to guarantee decent performance isolation among colocated workloads. We tackle the above challenges by introducing Demeter, a QoS-aware power management controller for heterogeneous black-box workloads in public clouds. Demeter is designed to work without offline profiling or prior knowledge about black-box workloads. Through the correlation analysis between network throughput and CPU resource utilization, Demeter automatically classifies black-box workloads as either LC or BE. By provisioning differentiated CPU management strategies (including dynamic core allocation and frequency scaling) to LC and BE workloads, Demeter achieves considerable power savings together with a minimum impact on the performance of all workloads. We discuss the design and implementation of Demeter in this work, and conduct extensive experimental evaluations to reveal its effectiveness. Our results show that Demeter not only meets the performance demand of all workloads, but also responds quickly to dynamic load changes in our cloud environment. In addition, Demeter saves an average of 10.6% power consumption than state of the art mechanisms.  © 2022 ACM.","2022","2025-10-22 19:07:45","2025-10-22 19:07:45","","31-46","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Electric power utilization; Energy efficiency; Datacenter; Black boxes; cloud computing; Cloud-computing; Performance; Quality-of-service; Memory architecture; Green computing; Dynamic frequency scaling; Scheduling algorithms; power management; Best-effort; Gas emissions; Greenhouse gases; quality of service; Sustainable development; Public clouds; workload characterization; QoS-aware; Workload characterization; Dynamic loads; Demeter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2022 - Proceedings of the 13th Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"HWVQHZCE","conferencePaper","2020","Gouicem, R.; Carver, D.; Lozi, J.-P.; Sopena, J.; Lepers, B.; Zwaenepoel, W.; Palix, N.; Lawall, J.; Muller, G.","Fewer cores, more hertz: Leveraging high-frequency cores in the OS scheduler for improved application performance","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091917647&partnerID=40&md5=e4f1c220f6d833f03fd82d5696b87618","In modern server CPUs, individual cores can run at different frequencies, which allows for fine-grained control of the performance/energy tradeoff. Adjusting the frequency, however, incurs a high latency. We find that this can lead to a problem of frequency inversion, whereby the Linux scheduler places a newly active thread on an idle core that takes dozens to hundreds of milliseconds to reach a high frequency, just before another core already running at a high frequency becomes idle. In this paper, we first illustrate the significant performance overhead of repeated frequency inversion through a case study of scheduler behavior during the compilation of the Linux kernel on an 80-core Intel™ Xeon-based machine. Following this, we propose two strategies to reduce the likelihood of frequency inversion in the Linux scheduler. When benchmarked over 60 diverse applications on the Intel™ Xeon, the better performing strategy, Smove, improves performance by more than 5% (at most 56% with no energy overhead) for 23 applications, and worsens performance by more than 5% (at most 8%) for only 3 applications. On a 4-core AMD Ryzen we obtain performance improvements up to 56%. Copyright © Proc. of the 2020 USENIX Annual Technical Conference, ATC 2020. All rights reserved.","2020","2025-10-22 19:07:45","2025-10-22 19:07:45","","435-448","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Program processors; Linux; Application performance; Diverse applications; Different frequency; Energy overheads; Fine-grained control; High frequency HF; Linux schedulers; Repeated frequencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2020 USENIX Annual Technical Conference, ATC 2020","","","","","","","","","","","","","","",""
"4EEFCJIU","conferencePaper","2019","Novaković, D.; Vasić, N.; Novaković, S.; Kostić, D.; Bianchini, R.","DeepDive: Transparently identifying and managing performance interference in virtualized environments","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077182637&partnerID=40&md5=9e5bed2125480098d4735afef7666ac9","We describe the design and implementation of DeepDive, a system for transparently identifying and managing performance interference between virtual machines (VMs) co-located on the same physical machine in Infrastructure-as-a-Service cloud environments. DeepDive successfully addresses several important challenges, including the lack of performance information from applications, and the large overhead of detailed interference analysis. We first show that it is possible to use easily-obtainable, low-level metrics to clearly discern when interference is occurring and what resource is causing it. Next, using realistic workloads, we show that DeepDive quickly learns about interference across co-located VMs. Finally, we show DeepDive's ability to deal efficiently with interference when it is detected, by using a low-overhead approach to identifying a VM placement that alleviates interference. © USENIX Annual Technical Conference, USENIX ATC 2013. All rights reserved.","2019","2025-10-22 19:07:45","2025-10-22 19:07:45","","219-230","","","","","","","","","","","","","","","","Scopus","","","","","","","","Design and implementations; Virtualized environment; Virtual reality; Infrastructure as a service (IaaS); Co-located; Interference analysis; Low overhead; VM placements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2013 USENIX Annual Technical Conference, USENIX ATC 2013","","","","","","","","","","","","","","",""
"DWGJ9MQ4","journalArticle","2014","Mazouz, A.; Laurent, A.; Pradelle, B.; Jalby, W.","Evaluation of CPU frequency transition latency","Computer Science - Research and Development","","","10.1007/s00450-013-0240-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904734533&doi=10.1007%2fs00450-013-0240-x&partnerID=40&md5=0752ca4094777b00087c3d2f87138cbd","Dynamic Voltage and Frequency Scaling (DVFS) has appeared as one of the most important techniques to reduce energy consumption in computing systems. The main idea exploited by DVFS controllers is to reduce the CPU frequency in memory-bound phases, usually significantly reducing the energy consumption. However, depending on the CPU model, transitions between CPU frequencies may imply varying delays. Such delays are often optimistically ignored in DVFS controllers, whereas their knowledge could enhance the quality of frequency setting decisions. The current article presents an experimental study on the measurement of frequency transition latencies. The measurement methodology is presented accompanied with evaluations on three Intel machines, reflecting three distinct micro-architectures. In overall, we show for our experimental setup that, while changing CPU frequency upward leads to higher transition delays, changing it downward leads to smaller or similar transition delays across the set of available frequencies. © 2013 Springer-Verlag Berlin Heidelberg.","2014","2025-10-22 19:07:45","2025-10-22 19:07:45","","187-195","","3-4","29","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy utilization; Computer architecture; Dynamic frequency scaling; Reduce energy consumption; Dynamic voltage and frequency scaling; Computing system; DVFS; Performances evaluation; Frequency transition; Frequency transition latency; Memory bounds; Statistical performance; Statistical performance evaluation; Transition delays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BEUKES3Z","journalArticle","2021","Mei, X.; Wang, Q.; Chu, X.; Liu, H.; Leung, Y.-W.; Li, Z.","","Energy-aware Task Scheduling with Deadline Constraint in DVFSenabled Heterogeneous Clusters","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115721976&partnerID=40&md5=ade44e244f438a038493806d2c3bc8b9","","2021","2025-10-22 19:07:45","2025-10-22 19:07:45","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HHR2ZMEG","conferencePaper","2017","Singh, T.; Rangarajan, S.; John, D.; Henrion, C.; Southard, S.; McIntyre, H.; Novak, A.; Kosonocky, S.; Jotwani, R.; Schaefer, A.; Chang, E.; Bell, J.; Co, M.","Zen: A next-generation high-performance ×86 core","","","","10.1109/ISSCC.2017.7870256","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016245760&doi=10.1109%2fISSCC.2017.7870256&partnerID=40&md5=8bfadf9ab8cd6f2f84b95a8715830368","Codenamed 'Zen', AMD's next-generation, high-performance ×86 core targets server, desktop, and mobile client applications. Utilizing Global Foundries' energy-efficient 14nm LPP FinFET process, the 44mm2 Zen core complex unit (CCX) has 1.4B transistors and contains a shared 8MB L3 cache and four cores (Fig. 3.2.7). The 7mm2 Zen core contains a dedicated 0.5MB L2 cache, 32KB L1 data cache, and 64KB L1 instruction cache. Each core has a digital low drop-out (LDO) voltage regulator and digital frequency synthesizer (DFS) to independently vary frequency and voltage across power states. © 2017 IEEE.","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","52-53","","","60","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy efficient; Cache memory; Mobile client; Voltage regulators; Power state; Core complex; Data caches; Digital frequency synthesizer; Instruction caches; Low drop outs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Digest of Technical Papers - IEEE International Solid-State Circuits Conference","","","","","","","","","","","","","","",""
"DH9GSV3X","journalArticle","2012","Etinski, M.; Corbalan, J.; Labarta, J.; Valero, M.","Understanding the future of energy-performance trade-off via DVFS in HPC environments","Journal of Parallel and Distributed Computing","","","10.1016/j.jpdc.2012.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857792797&doi=10.1016%2fj.jpdc.2012.01.006&partnerID=40&md5=e3add416ae41fa32d7afa62b6b82d459","DVFS is a ubiquitous technique for CPU power management in modern computing systems. Reducing processor frequency/voltage leads to a decrease of CPU power consumption and an increase in the execution time. In this paper, we analyze which application/platform characteristics are necessary for a successful energy-performance trade-off of large scale parallel applications. We present a model that gives an upper bound on performance loss due to frequency scaling using the application parallel efficiency. The model was validated with performance measurements of large scale parallel applications. Then we track how application sensitivity to frequency scaling evolved over the last decade for different cluster generations. Finally, we study how cluster power consumption characteristics together with application sensitivity to frequency scaling determine the energy effectiveness of the DVFS technique. © 2012 Elsevier Inc. All rights reserved.","2012","2025-10-22 19:07:45","2025-10-22 19:07:45","","579-590","","4","72","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Execution time; Energy management; Parallel application; High performance computing; Computing system; Performance loss; DVFS; Frequency-scaling; CPU power; Energy effectiveness; Parallel efficiency; Performance measurements; Upper Bound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUAFTUW2","conferencePaper","2013","Zhang, W.; Wen, Y.; Wu, D.O.","Energy-efficient scheduling policy for collaborative execution in mobile cloud computing","","","","10.1109/INFCOM.2013.6566761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883123478&doi=10.1109%2fINFCOM.2013.6566761&partnerID=40&md5=454691d41b512fabc758b416770a60f8","In this paper, we investigate the scheduling policy for collaborative execution in mobile cloud computing. A mobile application is represented by a sequence of fine-grained tasks formulating a linear topology, and each of them is executed either on the mobile device or offloaded onto the cloud side for execution. The design objective is to minimize the energy consumed by the mobile device, while meeting a time deadline. We formulate this minimum-energy task scheduling problem as a constrained shortest path problem on a directed acyclic graph, and adapt the canonical 'LARAC' algorithm to solving this problem approximately. Numerical simulation suggests that a one-climb offloading policy is energy efficient for the Markovian stochastic channel, in which at most one migration from mobile device to the cloud is taken place for the collaborative task execution. Moreover, compared to standalone mobile execution and cloud execution, the optimal collaborative execution strategy can significantly save the energy consumed on the mobile device. © 2013 IEEE.","2013","2025-10-22 19:07:45","2025-10-22 19:07:45","","190-194","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Computer applications; Mobile devices; Mobile applications; Mobile cloud computing; mobile cloud computing; Graph theory; Problem solving; Energy-Efficient Scheduling; Directed acyclic graph (DAG); Scheduling policies; collaborative execution; Collaborative execution; Collaborative tasks; Constrained shortest path; scheduling policy; Task scheduling problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"HZP9EBP8","conferencePaper","2017","Alzahrani, E.J.; Tari, Z.; Zeephongsekul, P.; Lee, Y.C.; Alsadie, D.; Zomaya, A.Y.","SLA-Aware Resource Scaling for Energy Efficiency","","","","10.1109/HPCC-SmartCity-DSS.2016.0123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013638445&doi=10.1109%2fHPCC-SmartCity-DSS.2016.0123&partnerID=40&md5=42c81357f55b228e276a061a511a2352","Cloud data centers (CDCs) with abundant resource capacities have prevailed in the past decade. However, these CDCs often struggle to efficiently deal with resource provisioning in terms of performance and energy efficiency. In this paper, we present Energy-Based Auto Scaling (EBAS) as a new resource auto-scaling approach - that takes into account Service Level Agreement (SLA) - for CDCs. EBAS proactively scales resources at the CPU core level in terms of both the number and frequency of cores. It incorporates the dynamic voltage and frequency scaling (DVFS) technique to dynamically adjust CPU frequencies. The proactive decisions on resource scaling are enabled primarily by the CPU usage prediction model and the workload consolidation model of EBAS. The experimental results show that EBAS can save energy on average by 14% compared with the Linux governor. In particular, EBAS contributes to enhancing DVFS by making it aware of SLA conditions, which leads to savings of computing power and in turn energy. © 2016 IEEE.","2017","2025-10-22 19:07:45","2025-10-22 19:07:45","","852-859","","","","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Energy efficiency; Computer operating systems; Cloud data centers; Energy Efficiency; Smart city; Dynamic frequency scaling; Dynamic voltage and frequency scaling; Workload consolidation; Abundant resources; Account services; Auto-Scaling; Cloud Data Centers; Docker Containers; Prediction model; Resource Provisioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 18th IEEE International Conference on High Performance Computing and Communications, 14th IEEE International Conference on Smart City and 2nd IEEE International Conference on Data Science and Systems, HPCC/SmartCity/DSS 2016","","","","","","","","","","","","","","",""
"Q6NJ7XBK","conferencePaper","2023","Khazen, M.W.E.; Amor, S.B.; Kougblenou, K.; Gogonel, A.; Cucu-Grosjean, L.","Work in progress: Towards a statistical worst-case energy consumption model","","","","10.1109/RTAS58335.2023.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164535166&doi=10.1109%2fRTAS58335.2023.00034&partnerID=40&md5=7a51a77564066ee8dbcdb472f842ac66","In this paper, we provide first results introducing the impact of both software and hardware events on the estimation of worst-case energy consumption of programs on embedded processors. We build a framework to better understand the representativeness of measurements with respect to both software and hardware events. We test this framework on execution times and energy consumption data for 5 existing benchmarks as a step towards a statistical worst-case energy consumption model. © 2023 IEEE.","2023","2025-10-22 19:07:45","2025-10-22 19:07:45","","333-336","","","2023-May","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Energy-consumption; CPU; Software and hardwares; Energy consumption model; Measurement-based; Bad-case energy consumption; Measurement-based benchmark; measurement-based benchmarks; SDRAM; statistical estimator; Statistical estimators; WCET; worst-case energy consumption","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the IEEE Real-Time and Embedded Technology and Applications Symposium, RTAS","","","","","","","","","","","","","","",""
"AEA43LD4","conferencePaper","2022","Wang, Z.; Zhu, S.; Li, J.; Jiang, W.; Ramakrishnan, K.K.; Zheng, Y.; Yan, M.; Zhang, X.; Liu, A.X.","DeepScaling: Microservices AutoScaling for Stable CPU Utilization in Large Scale Cloud Systems","","","","10.1145/3542929.3563469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143253714&doi=10.1145%2f3542929.3563469&partnerID=40&md5=988111d2dde96d83e5b770974715fc93","Cloud service providers conservatively provision excessive resources to ensure service level objectives (SLOs) are met. They often set lower CPU utilization targets to ensure service quality is not degraded, even when the workload varies significantly. Not only does this potentially waste resources, but it can also consume excessive power in large-scale cloud deployments. This paper aims to minimize resource costs while ensuring SLO requirements are met in a dynamically varying, large-scale production microservice environment. We propose DeepScaling, which introduces three innovative components to adaptively refine the target CPU utilization to a level that is maintained at a stable value to meet SLO constraints while using minimum resources. First, DeepScaling forecasts the workload for each service using a Spatio-temporal Graph Neural Network. Second, DeepScaling estimates the CPU utilization by mapping the workload intensity to an estimated CPU utilization with a Deep Neural Network, while taking into account multiple factors in the cloud environment (e.g., periodic tasks and traffic). Third, DeepScaling generates an autoscaling policy for each service based on an improved Deep Q Network (DQN). The adaptive autoscaling policy updates the target CPU utilization to be a maximum, stable value, while ensuring SLOs is not violated. We compare DeepScaling with state-of-the-art autoscaling approaches in the large-scale production cloud environment of the Ant Group. It shows that DeepScaling outperforms other approaches both in terms of maintaining stable service performance, and saving resources, by a significant margin. The deployment of DeepScaling in Ant Group's real production environment with 135 microservices saves the provisioning of over 30,000 CPU cores per day, on average.  © 2022 ACM.","2022","2025-10-22 19:07:45","2025-10-22 19:07:45","","16-30","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud environments; Cloud systems; Large-scales; Service Quality; Service level objective; Autoscaling; Deep neural networks; Cloud service providers; Graph neural networks; CPU utilization; Large scale productions; Waste resources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SoCC 2022 - Proceedings of the 13th Symposium on Cloud Computing","","","","","","","","","","","","","","",""
"CK2Z92UT","conferencePaper","1990","Macken, Peter; Degrauwe, Marc; Van Paemel, Mark; Oguey, Henri","A voltage reduction technique for digital systems","","","","10.1109/isscc.1990.110213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025450394&doi=10.1109%2fisscc.1990.110213&partnerID=40&md5=d65e292cf943991ec9743940617f47ba","A self-regulating on-chip voltage-reduction circuit that adjusts the internal supply voltage to the lowest value compatible with chip speed requirements is described. Besides enhancing reliability, this technique allows power savings. The technique is based on regulation of the supply voltage of an equivalent critical path, a small circuit with delay Vdd properties proportional to those of the actual critical path. The output of this equivalent critical path is compared with the output of a second identical equivalent critical path which is connected to the full supply voltage and serves as a reference. In a first-order approximation, the ratio of the delay of a critical path to the period of a ring oscillator is a constant that depends only on the number of gates, the dimensions of the transistors, and the load capacitances. This means that a ring oscillator can be used as an equivalent critical path for all digital circuits. Moreover, when the supply voltage of a ring oscillator (VCO) is changed, the frequency changes. The voltage regulator principle can be implemented with a phase-locked loop (PLL). By adjusting the VCO supply voltage, the PLL causes the VCO to oscillate at N × fin. If the dimensions of the VCO transistors and the division ratio N are such that the critical path functions correctly at the regulated voltage, it will always function correctly, as changing parameters, temperature, or frequency fin affect the VCO in the same way as the circuitry.","1990","2025-10-22 19:07:46","2025-10-22 19:07:46","","238-239","","","","","","","","","","","","","","","","Scopus","","","","","","","","Chip Speed; Control, Electric variables; Digital Chips; Integrated Circuits, Digital--Design; Phase locked loops; Power Savings; Voltage Reduction Circuit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Digest of Technical Papers - IEEE International Solid-State Circuits Conference","","","","","","","","","","","","","","",""
"AGWLGVKM","journalArticle","2022","Law, M.","Energy efficiency predictions for data centres in 2023","Energy Efficiency Predictions for Data Centres in 2023","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207340176&partnerID=40&md5=fd2f209a56117b5a53940d9849b2fc76","","2022","2025-10-22 19:07:46","2025-10-22 19:07:46","","1-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9478B3QU","journalArticle","2024","Yang, W.; Zhao, M.; Li, J.; Zhang, X.","Energy-efficient DAG scheduling with DVFS for cloud data centers","Journal of Supercomputing","","","10.1007/s11227-024-06035-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188812348&doi=10.1007%2fs11227-024-06035-7&partnerID=40&md5=71a9884080839772edf0a241deaa3244","With the growth of the cloud computing market, the number and scale of cloud data centers are expanding rapidly. While cloud data centers provide a large amount of computing power, generating tremendous energy consumption has become a fundamental issue in the financial and environmental fields. Improving quality of service and reducing energy costs are fundamental challenges for next-generation cloud data centers. Task scheduling in cloud data centers grows increasingly complex due to the heterogeneity of computing resources, intricate dependencies of jobs and rising expenses resulting from high energy consumption. Efficiently utilizing computing resources is crucial, so it is necessary to develop optimal strategies for job scheduling. This paper proposes a reinforcement learning-based task scheduler (E2DSched) for online scheduling of randomly arriving directed acyclic graph jobs in cloud data centers. E2DSched divides the scheduling process into three layers: task selection layer, server selection layer and frequency control layer. It achieves joint optimization of energy consumption and quality of service through three-layer cooperation. Finally, we compare E2DSched with various other algorithms, and the results show that E2DSched can provide excellent service with less energy consumption. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","2024","2025-10-22 19:07:46","2025-10-22 19:07:46","","14799-14823","","10","80","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud data centers; Energy efficient; Energy utilization; Quality-of-service; Energy-consumption; Green computing; Computing power; Scheduling algorithms; Directed graphs; Reinforcement learning; Reinforcement learnings; Computing resource; Cloud data center; DAG scheduling; DAG job; Task schedule; Three-layer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84Q7UFCF","journalArticle","2016","Masip-Bruin, X.; Marín-Tordera, E.; Tashakor, G.; Jukan, A.; Ren, G.-J.","Foggy clouds and cloudy fogs: A real need for coordinated management of fog-to-cloud computing systems","IEEE Wireless Communications","","","10.1109/MWC.2016.7721750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012170641&doi=10.1109%2fMWC.2016.7721750&partnerID=40&md5=2679523a2a25e9e75cc2e84900cb7253","The recent advances in cloud services technology are fueling a plethora of information technology innovation, including networking, storage, and computing. Today, various flavors have evolved of IoT, cloud computing, and so-called fog computing, a concept referring to capabilities of edge devices and users' clients to compute, store, and exchange data among each other and with the cloud. Although the rapid pace of this evolution was not easily foreseeable, today each piece of it facilitates and enables the deployment of what we commonly refer to as a smart scenario, including smart cities, smart transportation, and smart homes. As most current cloud, fog, and network services run simultaneously in each scenario, we observe that we are at the dawn of what may be the next big step in the cloud computing and networking evolution, whereby services might be executed at the network edge, both in parallel and in a coordinated fashion, as well as supported by the unstoppable technology evolution. As edge devices become richer in functionality and smarter, embedding capacities such as storage or processing, as well as new functionalities, such as decision making, data collection, forwarding, and sharing, a real need is emerging for coordinated management of fog-to-cloud (F2C) computing systems. This article introduces a layered F2C architecture, its benefits and strengths, as well as the arising open and research challenges, making the case for the real need for their coordinated management. Our architecture, the illustrative use case presented, and a comparative performance analysis, albeit conceptual, all clearly show the way forward toward a new IoT scenario with a set of existing and unforeseen services provided on highly distributed and dynamic compute, storage, and networking resources, bringing together heterogeneous and commodity edge devices, emerging fogs, as well as conventional clouds. Introduction: The Scenario © 2016 IEEE.","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","120-128","","5","23","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Information management; Automation; Distributed computer systems; Internet of things; Network architecture; Decision making; Digital storage; Smart city; Network services; Research challenges; Intelligent buildings; Computing system; Fog; Cloud computing and networkings; Comparative performance analysis; Embedding capacity; Information technology innovation; Technology evolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8CV8VTIZ","journalArticle","1997","De, P.; Dunne, E.J.; Ghosh, J.B.; Wells, C.E.","Complexity of the discrete time-cost tradeoff problem for project networks","Operations Research","","","10.1287/opre.45.2.302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031102411&doi=10.1287%2fopre.45.2.302&partnerID=40&md5=a2bdd7f0964f2856908e1847bb2c220a","This note addresses the discrete version of the well-known time-cost tradeoff problem for project networks, which has been studied previously in the standard project management literature as well as in the related literature on Decision-CPM. All the algorithms proposed thus far for the solution of the general problem exhibit exponential worst-case complexity, with the notable exception of the pseudo-polynomial dynamic program due to Hindelang and Muth. We first demonstrate that this algorithm is flawed, and that when we correct it, it no longer remains pseudo-polynomial. Continuing on in the main result of the note, we show that this is not at all surprising, since the problem is strongly NP-hard. Finally, we discuss the complexities of various network structures and validate an old conjecture that certain structures are necessarily more difficult to solve.","1997","2025-10-22 19:07:46","2025-10-22 19:07:46","","302-306","","2","45","","","","","","","","","","","","","Scopus","","","","","","","","Algorithms; Computational complexity; Costs; Problem solving; Dynamic programming; Computational methods; Project management; Critical path analysis; Operations research; Pseudo-polynomial dynamic program; Statistical methods; Time-cost tradeoff problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6Q7I796C","journalArticle","2016","Falk, H.","TACLeBench: A benchmark collection to support worst-case execution time research","16th International Workshop on Worst-Case Execution Time Analysis","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031420216&partnerID=40&md5=b20a6495de47bcd1fe8bab13dd736cec","","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","1-10","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ATGIY28Q","conferencePaper","2016","Zhang, Y.; Wang, Y.; Hu, C.","CloudFreq: Elastic energy-efficient bag-of-tasks scheduling in DVFS-enabled clouds","","","","10.1109/ICPADS.2015.79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964626489&doi=10.1109%2fICPADS.2015.79&partnerID=40&md5=49519800d25b87c7e9a1a3e09c29c6e4","Energy consumption imposes a significant cost for data centers in providing cloud services. Many studies explore the opportunities to save power by energy-efficient task scheduling based on the technique of dynamic voltage and frequency scaling (DVFS). However, most of them assume that energy budgets and/or deadline constraints are known in advance. But these information can hardly be acquired in general computing environments, such as cloud computing, and job rejections caused by restricted constraints are intolerable to guarantee the service-level agreement (SLA). Moreover, previous works prefer to provide &ldquo;black-box&rdquo; algorithms with little consideration on adjustability, and cannot satisfy runtime requirements in performance and energy-saving. This paper proposes an elastic energy-efficient algorithm called CloudFreq for bag-of-tasks scheduling in DVFS-enabled clouds. Cloud-Freq enables a model of elastic, adjustable energy-efficient scheduling without any prior knowledge of constraints, and then eliminates job rejections accordingly. CloudFreq also provides an entry for operators to scale system performance at runtime. Experimental results demonstrate that the proposed algorithm can effectively perform energy-efficient scheduling without constraints, and has the capability of making an appropriate tradeoff to improve the weighted balance between schedule length and energy-saving. © 2015 IEEE.","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","585-592","","","2016-January","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Voltage scaling; Energy efficiency; Cloud computing; Energy efficient; Energy utilization; Service Level Agreements; Elasticity; Green computing; Dynamic frequency scaling; Computing environments; Budget control; Dynamic voltage and frequency scaling; Energy-Efficient Scheduling; Bag of tasks; Bag-of-tasks; Deadline constraint; Elastic; Energy-efficient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS","","","","","","","","","","","","","","",""
"WCXEYRFD","journalArticle","2023","","","Linux Kernel Scaling Governors","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218193265&partnerID=40&md5=ecba8e61ffdc1477e3da33f622112e6c","","2023","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R2MD4VVE","journalArticle","2019","Beyer, D.; Löwe, S.; Wendler, P.","Reliable benchmarking: requirements and solutions","International Journal on Software Tools for Technology Transfer","","","10.1007/s10009-017-0469-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032816422&doi=10.1007%2fs10009-017-0469-y&partnerID=40&md5=389f40c9f8dbaf6d6a725493a324edd7","Benchmarking is a widely used method in experimental computer science, in particular, for the comparative evaluation of tools and algorithms. As a consequence, a number of questions need to be answered in order to ensure proper benchmarking, resource measurement, and presentation of results, all of which is essential for researchers, tool developers, and users, as well as for tool competitions. We identify a set of requirements that are indispensable for reliable benchmarking and resource measurement of time and memory usage of automatic solvers, verifiers, and similar tools, and discuss limitations of existing methods and benchmarking tools. Fulfilling these requirements in a benchmarking framework can (on Linux systems) currently only be done by using the cgroup and namespace features of the kernel. We developed BenchExec, a ready-to-use, tool-independent, and open-source implementation of a benchmarking framework that fulfills all presented requirements, making reliable benchmarking and resource measurement easy. Our framework is able to work with a wide range of different tools, has proven its reliability and usefulness in the International Competition on Software Verification, and is used by several research groups worldwide to ensure reliable benchmarking. Finally, we present guidelines on how to present measurement results in a scientifically valid and comprehensible way. © 2017, Springer-Verlag GmbH Germany.","2019","2025-10-22 19:07:46","2025-10-22 19:07:46","","1-29","","1","21","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Containers; Container; Computer operating systems; Benchmarking; Benchmarking tools; Software reliability; Competition; Open source implementation; Comparative evaluations; International competitions; Linux systems; Process control; Process isolation; Ready to use; Research groups; Resource measurement; Software verification; Verification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XEAF92I","conferencePaper","2020","Beyer, D.; Wendler, P.","CPU Energy Meter: A Tool for Energy-Aware Algorithms Engineering","","","","10.1007/978-3-030-45237-7_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083986675&doi=10.1007%2f978-3-030-45237-7_8&partnerID=40&md5=a0a7196e4c0afc8fdd40e5f2086400ac","Verification algorithms are among the most resource-intensive computation tasks. Saving energy is important for our living environment and to save cost in data centers. Yet, researchers compare the efficiency of algorithms still in terms of consumption of CPU time (or even wall time). Perhaps one reason for this is that measuring energy consumption of computational processes is not as convenient as measuring the consumed time and there is no sufficient tool support. To close this gap, we contribute CPU Energy Meter, a small tool that takes care of reading the energy values that Intel CPUs track inside the chip. In order to make energy measurements as easy as possible, we integrated CPU Energy Meter into BenchExec, a benchmarking tool that is already used by many researchers and competitions in the domain of formal methods. As evidence for usefulness, we explored the energy consumption of some state-of-the-art verifiers and report some interesting insights, for example, that energy consumption is not necessarily correlated with CPU time. © 2020, The Author(s).","2020","2025-10-22 19:07:46","2025-10-22 19:07:46","","126-133","","","12079 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Program processors; Energy utilization; Benchmarking; Energy-consumption; RAPL; Electric power measurement; Energy Measurement; Saving energy; Algorithm engineering; Benchexec; BenchExec; Computation tasks; CPU time; Energy aware algorithms; Energy meters; Verification algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science","","","","","","","","","","","","","","",""
"MB2MQZCH","journalArticle","2017","Doweck, J.; Kao, W.-F.; Lu, A.K.-Y.; Mandelblat, J.; Rahatekar, A.; Rappoport, L.; Rotem, E.; Yasin, A.; Yoaz, A.","Inside 6th-Generation Intel Core: New Microarchitecture Code-Named Skylake","IEEE Micro","","","10.1109/MM.2017.38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019228010&doi=10.1109%2fMM.2017.38&partnerID=40&md5=103537d56ce36287619a8b7670ce206f","Skylake's core, processor graphics, and system on chip were designed to meet a demanding set of requirements for a wide range of power-performance points. Its coherent fabric was designed to provide high-memory bandwidth from multiple memory sources. Skylake's power management, which includes Intel Speed Shift technology, was designed to provide the largest dynamic power range among prior Intel processors. The Intel Architecture core delivers higher power efficiency, higher frequency, and a wider dynamic power range, supporting smaller form factors. Skylake's Gen9 graphics provides new features designed to maximize energy efficiency and bring the best visual experience for gaming and media. Skylake offers a rich performance monitoring unit that enhances software developers' ability to optimize their applications. © 1981-2012 IEEE.","2017","2025-10-22 19:07:46","2025-10-22 19:07:46","","52-62","","2","37","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Application programs; Energy efficiency; Computer architecture; Energy management; GPU; Graphics processing unit; System-on-chip; Micro architectures; power management; Performance monitoring; performance monitoring; Performance measurements; eDRAM; Intel Speed Shift; microarchitecture; performance measurements; Skylake; Turbo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDQKE9XF","journalArticle","2023","","","ODROID XU3","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218190892&partnerID=40&md5=72e6500ad037419354549a5a9d1a8e95","","2023","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMZ77CDV","conferencePaper","2021","Ermolenko, D.; Kilicheva, C.; Muthanna, A.; Khakimov, A.","Internet of Things Services Orchestration Framework Based on Kubernetes and Edge Computing","","","","10.1109/ElConRus51938.2021.9396553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104714605&doi=10.1109%2fElConRus51938.2021.9396553&partnerID=40&md5=29c89717b94344a84352f846729a8419","Presented work is fanalysis of how the microservices paradigm can be used to design and implement distributed edge services for Internet of Things (IoT) applications. Basically, IoT is a platform where integrated services are associated with the common network, thus all devices are able to gather and exchange data among each other. Typically, monolithic user mobility research services are developed for the unified ETSI MEC system reference architecture centers. ETSI MEC considers microservices as a tool for breaking monolithic applications into a set of loosely coupled distributed components. It is expected that this architecture will facilitate the dynamic adaptation during the application execution. However, increased modularity can also increase the burden on orchestration and system management. In MEC, user hardware is connected through gateways to microservices running on the edge host.There are three levels in each of the edge systems: 1) microservices perform a logical operation with components for motion track analysis, 2) movement foresight and 3) outcome visualization. The distributed service is realized with Docker containers and calculated on actual world adjustment with low capacity edge servers and real user mobility information. The results demonstrate the fact that the edge perspective of low latency may be encountered in this sort of implementation. The integration of a software creation technology with a standardized edge system supplies respectable basis for subsequent development. The paper considers the application of the boundary computing architecture and Kubernetes as an orchestration and management of network applications. © 2021 IEEE.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","12-17","","","","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; Internet of things; Computer architecture; Network architecture; Edge computing; Internet of Things (IOT); Web services; Design and implements; IoT; Orchestration; Computing architecture; Application execution; Clustering; Network applications; Distributed components; Reference architecture; User mobility information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2021 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2021","","","","","","","","","","","","","","",""
"Q7G4URGZ","conferencePaper","2018","Lin, C.-C.; Chen, J.-J.; Liu, P.; Wu, J.-J.","Energy-Efficient Core Allocation and Deployment for Container-Based Virtualization","","","","10.1109/PADSW.2018.8644537","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063352888&doi=10.1109%2fPADSW.2018.8644537&partnerID=40&md5=f4ffdb4480d6d1d5f6e2f148ddb36059","Infrastructure-as-a-Service (IaaS) is a popular form of cloud computing that provides virtualized computing resources. The current trend of IaaS is moving from virtual machine-based into container-based. In this paper, we study the energy-efficient resource allocation problem for container-based virtualization in a data center. Our goal is to minimize the energy consumption by determining 1) the number of cores allocated to a container, 2) the operating frequency of the container, and 3) the deployment of the container to server. Every container has to meet its service level agreement (SLA). We propose dynamic programming algorithms that can be used under different scenarios, depending on the affordable time complexity. The performance of the proposed algorithms is evaluated with energy consumption data collected from experiments. © 2018 IEEE.","2018","2025-10-22 19:07:46","2025-10-22 19:07:46","","93-101","","","2018-December","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Energy efficiency; Datacenter; Cloud-computing; Container; Virtual reality; Virtualization; Cloud Computing; Energy efficient; Energy utilization; Infrastructure as a service (IaaS); Virtualizations; Energy-consumption; Green computing; Resource allocation; Energy-efficient resource allocation; 'current; Dynamic programming; Computing resource; Resources allocation; Resource allocation problem; Resource Allocation; Dynamic Programming; Energy-Efficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS","","","","","","","","","","","","","","",""
"3XES9WZJ","journalArticle","2023","","","Nvidia jetson","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193760557&partnerID=40&md5=04b692e4e005441b08c2ca0a0216bf11","","2023","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJE4MWE7","conferencePaper","2015","Pietri, I.; Sakellariou, R.","Energy-Aware Workflow Scheduling Using Frequency Scaling","","","","10.1109/ICPPW.2014.26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946568373&doi=10.1109%2fICPPW.2014.26&partnerID=40&md5=78127246419cc2193a6bbad390d1d0fb","Dynamic Voltage and Frequency Scaling (DVFS) is a power management technique used to decrease the processor frequency and minimize power consumption in modern computing systems. This may lead to higher energy savings for large-scale computational problems, with scientific workflows comprising an important category of applications among these. However, as frequency scaling may result in increased execution time overall, idle time on the processors may also increase, to such a degree that any gains in power are annulled, this depends on the system and workflow characteristics. In this paper, we propose a scheduling algorithm that adopts frequency scaling to reduce overall energy consumption of scientific workflows given an allocation of tasks onto machines and a deadline to complete the execution. Based on the observation that using the lowest possible frequency may not necessarily be energy-efficient, the proposed algorithm works iteratively to scale the frequency further and distribute any slack time, only when overall energy consumption can be decreased. Synthetic data based on parameters of real scientific workflows are used in the evaluation. The results show that the proposed algorithm can achieve energy savings, sometimes at the expense of execution time to reduce the idle time of the processors and decrease overall energy consumption. © 2014 IEEE.","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","104-113","","","2015-May","","","","","","","","","","","","","Scopus","","","","","","","","Energy-aware scheduling; Scheduling; Voltage scaling; Energy efficiency; Parallel processing systems; Energy utilization; Green computing; Dynamic frequency scaling; Iterative methods; Scheduling algorithms; workflow; DAG scheduling; DVFS; Frequency-scaling; energy-aware scheduling; frequency scaling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel Processing Workshops","","","","","","","","","","","","","","",""
"D4ANZXYK","journalArticle","2023","","","CPU frequency trace low","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218215321&partnerID=40&md5=f06f5dcfa50f57dd2099aa68a11caa2a","","2023","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZL6JGIC","conferencePaper","2021","Jia, X.; Zhao, L.","RAEF: Energy-efficient Resource Allocation through Energy Fungibility in Serverless","","","","10.1109/ICPADS53394.2021.00060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129871862&doi=10.1109%2fICPADS53394.2021.00060&partnerID=40&md5=1b3811b7386c38d53c0767e62f2d8bb2","Datacenters' excessive energy consumption has become an increasingly significant pain point to cloud service providers. However, existing research usually tends to focus on the server power cap to increase application throughput and do not address the rapid growth in the energy consumption of datacenters. Although the serverless architecture makes it more difficult to improve datacenter energy efficiency due to its high density and high dynamic nature, we observe that the emerging serverless workloads bring new opportunities for energy reduction. First, the energy consumption of serverless workloads during their execution time can be divided into three stages with clear boundaries: startup, runtime and idle. As the three stages have quite different energy usage patterns, we are able to reduce overall energy consumption through orchestrating the energy consumption of the stages. Second, we observe the energy fungibility phenomenon, i.e., the different combinations of multidimensional resource allocations may lead to the same latency but different energy consumption. Exploiting the balanced combination of energy consumption and performance, we can reduce the overall energy consumption without violating the latency service level agreement (SLA). Based on this, we propose RAEF, a function-level resource allocator that proactively adjusts the resources of the functions for minimizing the energy consumption with SLA guarantees. Evaluation results demonstrate that RAEF reduces energy consumption by up to 21.2 % compared to the state-of-the-art technique while guaranteeing the SLA.  © 2021 IEEE.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","434-441","","","2021-December","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Datacenter; Power; Energy utilization; serverless; Serverless; Energy; Energy-consumption; Green computing; Resource allocation; Energy-efficient resource allocation; Cloud service providers; resource allocation; Resources allocation; energy consumption; Servicelevel agreement (SLA); Excessive energy; system design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS","","","","","","","","","","","","","","",""
"9QBMC56Z","bookSection","2016","Sampaio, A.M.; Barbosa, J.G.","Energy-Efficient and SLA-Based Resource Management in Cloud Data Centers","Advances in Computers","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953272973&doi=10.1016%2fbs.adcom.2015.11.002&partnerID=40&md5=e9f4663c941c897974bec1ec541ae910","Nowadays, cloud data centers play an important role in modern Information Technology (IT) infrastructures, being progressively adopted in different scenarios. The proliferation of cloud has led companies and resource providers to build large warehouse-sized data centers, in an effort to respond to costumers demand for computing resources. Operating with powerful data centers requires a significant amount of electrical power, which translates into more heat to dissipate, possible thermal imbalances, and increased electricity bills. On the other hand, as data centers grow in size and in complexity, failure events become norms instead of exceptions. However, failures contribute to the energy waste as well, since preceding work of terminated tasks is lost. Therefore, today's cloud data centers are faced with the challenge of reducing operational costs through improved energy utilization while provisioning dependable service to customers. This chapter discusses the causes of power and energy consumption in data centers. The advantages brought by cloud computing on the management of data center resources are discussed, and the state of the art on schemes and strategies to improve power and energy efficiency of computing resources is reviewed. A practical case of energy-efficient and service-level agreement (SLA)-based management of resources, which analyzes and discusses the performance of three state-of-the-art scheduling algorithms to improve energy efficiency, is also included. This chapter concludes with a review of open challenges on strategies to improve power and energy efficiency in data centers. © 2016 Elsevier Inc.","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","103-159","","","100","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Virtualization; Interference; Power and energy efficiency; Proactive fault tolerance; Service-level agreement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7J3M7KIH","conferencePaper","2021","Patrou, M.; Kent, K.B.; Siu, J.; Dawson, M.","Energy and Runtime Performance Optimization of Node.js Web Requests","","","","10.1109/IC2E52221.2021.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123217432&doi=10.1109%2fIC2E52221.2021.00021&partnerID=40&md5=bce669e715fcf15767034795a52f4062","The Node.js framework uses an event-driven model with a single-threaded event loop and provides asynchronous and non-blocking I/O operations. As with other programs, Node.js web applications take advantage of underlying resources, including CPUs, which can incorporate the dynamic voltage and frequency scaling (DVFS) technique. Using CPU DVFS, the applications can increase their runtime performance, at the expense of the system's energy consumption. Thus, software code that utilizes the CPU DVFS technique efficiently should lead to 'green' and high-performing applications with respect to the business logic. To this end, we build a CPU frequency scaling/energy aware system to enable CPU frequency control within Node.js applications and measure the energy consumption of specific tasks. We also build a benchmark suite to analyze the energy consumption and runtime performance of different requests based on the CPU frequency impact and collect information and patterns, as we scale the CPU frequency. The analysis aims to provide data and knowledge on the CPU frequency 'suitability' and impact in order to create a model for CPU frequency scaling on Node.js web applications and achieve an efficient and sustainable runtime performance.  © 2021 IEEE.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","71-82","","","","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Application programs; Program processors; Energy utilization; Benchmarking; Energy-consumption; Green computing; Dynamic frequency scaling; Dynamic voltage and frequency scaling; WEB application; Energy performance; green energy; Green energy; Web applications; Runtime performance; CPU DVFS; CPU dynamic voltage and frequency scaling; efficiency; Js; Node.; Node.js","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2021 IEEE International Conference on Cloud Engineering, IC2E 2021","","","","","","","","","","","","","","",""
"DU777EF9","journalArticle","1998","Skutella, M.","Approximation algorithms for the discrete Time-Cost Tradeoff Problem","Mathematics of Operations Research","","","10.1287/moor.23.4.909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032208139&doi=10.1287%2fmoor.23.4.909&partnerID=40&md5=60c1c941907d02476b4396113983e8ce","Due to its obvious practical relevance, the Time-Cost Tradeoff Problem has attracted the attention of many researchers over the last forty years. While the Linear Time-Cost Tradeoff Problem can be solved in polynomial time, its discrete variant is known to be NP-hard. We present the first approximation algorithms for the Discrete Time-Cost Tradeoff Problem. Specifically, given a fixed budget we consider the problem of finding a shortest schedule for a project. We give an approximanon algorithm with performance ratio 3/2 for the class of projects where all feasible durations of activities are either 0, 1, or 2. We extend our result by giving approximation algorithms with performance guarantee O( log I), where I is the ratio of the maximum duration of any activity to the minimum nonzero duration of any activity. Finally, we discuss bicriteria approximation algorithms which compute schedules for a given deadline or budget such that both project duration and cost are within a constant factor of the duration and cost of an optimum schedule for the given deadline or budget.","1998","2025-10-22 19:07:46","2025-10-22 19:07:46","","909-929","","4","23","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Optimization; Algorithms; Computational complexity; Costs; Problem solving; Approximation theory; Bicriteria optimization; Polynomials; Approximation algorithm; Bicriteria approximation algorithms; Discrete time-cost tradeoffs; Time-cost tradeoff","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AV9MNACF","journalArticle","2024","Rastegar, S.H.; Shafiei, H.; Khonsari, A.","EneX: An Energy-Aware Execution Scheduler for Serverless Computing","IEEE Transactions on Industrial Informatics","","","10.1109/TII.2023.3290985","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163532892&doi=10.1109%2fTII.2023.3290985&partnerID=40&md5=473905e516b7bc293804e36a17dd8bf0","The emerging serverless computing paradigm has recently attracted huge attention from both academia and industry. It brings benefits, such as less operational complexity, high scalability and availability, and lower costs. Serverless applications are usually partitioned into several chains of functions. The serverless provider should schedule functions for execution per customers' requests considering their chained nature. Also, the existing scheduling mechanisms for serverless platforms pay little attention to the reduction of energy consumption during functions' execution. To fill this gap, we present an energy-aware execution scheduler for serverless service providers named EneX. To do so, we formulate the minimization of energy consumption for executing the incoming chains of functions with specified computational loads and deadlines. Due to the intractability of the problem, we introduce a linear programming reformulation based on which, we propose an online scheduler. Finally, our experiments demonstrate the significant improvement of EneX in terms of energy efficiency.  © 2005-2012 IEEE.","2024","2025-10-22 19:07:46","2025-10-22 19:07:46","","2342-2353","","2","20","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Scheduling; Energy efficiency; Energy utilization; Cloud services; Energy-consumption; Green computing; Web services; Serverless computing; Chains; serverless computing; Function-as-a-service; Job shop scheduling; Job-Shop scheduling; Processor scheduling; scheduling; Delay; energy consumption; function-as-a-service (FaaS); Linear programming; Chain of function; Chain of functions; cloud services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LH8X2MRG","journalArticle","2023","Tzenetopoulos, A.; Masouros, D.; Soudris, D.; Xydis, S.","DVFaaS: Leveraging DVFS for FaaS Workflows","IEEE Computer Architecture Letters","","","10.1109/LCA.2023.3288089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162865040&doi=10.1109%2fLCA.2023.3288089&partnerID=40&md5=7cedf4684268ea2184a1e90e6f079c40","In this letter, we propose DVFaaS, a per-core DVFS framework that utilizes control systems theory to assign just-enough frequency for the purpose of addressing the QoS requirements on serverless workflows comprising unseen functions. DVFaaS exploits the intermittent nature of serverless workflows, which enables staged control on distinguishable functions, which jointly contribute to the end-to-end latency. Our results show that DVFaaS considerably outperforms related work, reducing power consumption by up to 22%, with 2x fewer QoS violations.  © 2002-2011 IEEE.","2023","2025-10-22 19:07:46","2025-10-22 19:07:46","","85-88","","2","22","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Voltage scaling; Electric power utilization; Performance; Quality-of-service; Fine grained; Computation theory; Computing power; Dynamic frequency scaling; Power demands; Timing circuits; power management; Quality control; Work-flows; distributed systems; Frequency measurements; QoS requirements; emerging technologies; Frequency control; Quality of Services; Time-frequency Analysis; Timing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR78CV27","journalArticle","2023","","","CPU frequency trace high","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218192387&partnerID=40&md5=75b760bb0876a97aab8e7c811d47e95e","","2023","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZARLJ2LY","conferencePaper","2011","Chang, M.-F.; Liang, W.-Y.","Learning-directed dynamic voltage and frequency scaling for computation time prediction","","","","10.1109/TrustCom.2011.140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856157361&doi=10.1109%2fTrustCom.2011.140&partnerID=40&md5=34e71eebac01ca39db64af1adaa2a5dc","Dynamic voltage and frequency scaling (DVFS) is an effective technique for reducing power consumption. A number of DVFS researches apply learning methods in an attempt to approach the DVFS prediction model instead of using complicated mathematical models. In this paper, we propose a lightweight learning-directed DVFS technique using Counter Propagation Networks (CPN) to identify the task behavior and predict the corresponding voltage/frequency setting precisely. An adjustable performance mechanism is also provided to users that have diverse performance requirement. The algorithm has been implemented on the Linux operating system and used a PXA270 development board. The results show that the learning-directed DVFS method could accurately predict the suitable frequency, given runtime statistics information of a running program. In this way, the user can easily control the energy consumption by specifying allowable performance loss factor. © 2011 IEEE.","2011","2025-10-22 19:07:46","2025-10-22 19:07:46","","1023-1029","","","","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Forecasting; Computer operating systems; Energy utilization; Software design; Runtimes; Performance requirements; Mathematical models; Neural networks; Low Power; Dynamic voltage and frequency scaling; Performance loss; neural network; DVFS; Embedded software; Prediction model; Computation time; Counter propagation networks; CPN; Embedded System; Learning methods; LINUX- operating system; Low Power Software Design; Reducing power","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proc. 10th IEEE Int. Conf. on Trust, Security and Privacy in Computing and Communications, TrustCom 2011, 8th IEEE Int. Conf. on Embedded Software and Systems, ICESS 2011, 6th Int. Conf. on FCST 2011","","","","","","","","","","","","","","",""
"Q364IMPJ","conferencePaper","1994","Weiser, M.; Welch, B.; Demers, A.; Shenker, S.","Scheduling for reduced cpu energy","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029600625&partnerID=40&md5=6346948850b6d57af72221896fafb9b5","The energy usage of computer systems is becoming more important, especially for battery operated systems. Displays, disks, and cpus, in that order, use the most energy. Reducing the energy used by displays and disks has been studied elsewhere; this paper considers a new method for reducing the energy used by the cpu. We introduce a new metric for cpu energy performance, millions-of-instructions-per-joule (MIPJ). We examine a class of methods to reduce MIPJ that are characterized by dynamic control of system clock speed by the operating system scheduler. Reducing clock speed alone does not reduce MIPJ, since to do the same work the system must run longer. However, a number of methods are available for reducing energy with reduced clock-speed, such as reducing the voltage [Chandrakasan et al 1992] [Horowitz 1993] or using reversible [Younis and Knight 1993] or adiabatic logic [Athas et al 1994]. What are the right scheduling algorithms for taking advantage of reduced clock-speed, especially in the presence of applications demanding ever more instructions-per-second? We consider several methods for varying the clock speed dynamically under control of the operating system, and examine the performance of these methods against workstation traces. The primary result is that by adjusting the clock speed at a fine grain, substantial CPU energy can be saved with a limited impact on performance.","1994","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Systems analysis; Scheduling algorithms; Energy performance; Speed; Dynamic controls; Energy usage; Adiabatic logic; Battery-operated systems; Class of methods; Clocks; Instructions per seconds; Number of methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 1st USENIX Conference on Operating Systems Design and Implementation, OSDI 1994","","","","","","","","","","","","","","",""
"A7ELALPE","conferencePaper","2021","Kumbhare, A.; Azimi, R.; Manousakis, I.; Bonde, A.; Frujeri, F.; Mahalingam, N.; Misra, P.A.; Javadi, S.A.; Schroeder, B.; Fontoura, M.; Bianchini, R.","Prediction-based power oversubscription in cloud platforms","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111731471&partnerID=40&md5=404c2325683a9ccae00f90bd01ac22c0","Prior work has used power capping to shave rare power peaks and add more servers to a datacenter, thereby oversubscribing its resources and lowering capital costs. This works well when the workloads and their server placements are known. Unfortunately, these factors are unknown in public clouds, forcing providers to limit the oversubscription and thus the potential performance loss from power capping. In this paper, we argue that providers can use predictions of workload performance criticality and virtual machine (VM) resource utilization to increase oversubscription. This poses many challenges, such as identifying the performance-critical workloads from opaque VMs, creating support for criticalityaware power management, and increasing oversubscription while limiting the impact of capping. We address these challenges for the hardware and software of Microsoft Azure. The results show that we enable a 2× increase in oversubscription with minimum impact to critical workloads. We describe lessons from deploying our work in production. © 2021 USENIX Annual Technical Conference. All rights reserved.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","65-79","","","","","","","","","","","","","","","","Scopus","","","","","","","","Power capping; Cloud platforms; Hardware and software; Windows operating system; Resource utilizations; Public clouds; Performance loss; Prediction-based; Server placements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2021 USENIX Annual Technical Conference","","","","","","","","","","","","","","",""
"6YGBQZGK","conferencePaper","2021","Fieni, G.; Rouvoy, R.; Seiturier, L.","SelfWatts: On-the-fly selection of performance events to optimize software-defined power meters","","","","10.1109/CCGrid51090.2021.00042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114877010&doi=10.1109%2fCCGrid51090.2021.00042&partnerID=40&md5=573bb938fa5dda851d1986875a5c0bc7","Fine-grained power monitoring of software-defined infrastructures is unavoidable to maximize the power usage efficiency of data centers. However, the design of the underlying power models that estimate the power consumption of the monitored software components keeps being a long and fragile process that remains tightly coupled to the host machine and prevents a wider adoption by the industry beyond the rich literature on this topic.To overcome these limitations, this paper introduces SELFWATTS: a lightweight power monitoring system that explores and selects the relevant performance events to automatically optimize the power models to the underlying architecture. Unlike state-of-the-art techniques, SELFWATTS does not require any a priori training phase or specific hardware to configure the power models and can be deployed on a wide range of machines, including heterogeneous environments. © 2021 IEEE.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","324-333","","","","","","","","","","","","","","","","Scopus","","","","","","","","Software component; Cluster computing; Computer science; Heterogeneous environments; Computer programming; energy; Fine-grained power; State-of-the-art techniques; Power monitoring; Tightly-coupled; performance events; power meter; Specific hardware; Training phase","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2021","","","","","","","","","","","","","","",""
"XJM58MVS","journalArticle","2022","Ma, H.; Huang, P.; Zhou, Z.; Zhang, X.; Chen, X.","GreenEdge: Joint Green Energy Scheduling and Dynamic Task Offloading in Multi-Tier Edge Computing Systems","IEEE Transactions on Vehicular Technology","","","10.1109/TVT.2022.3147027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124190337&doi=10.1109%2fTVT.2022.3147027&partnerID=40&md5=295d0ee2d641b0309259034423aa7ffa","As mobile edge computing (MEC) emerges as a paradigm to meet the ever-increasing computation demands from real-time Internet of Things (IoT) applications in 5 G era, the development trends of which are mainly divided into two, with one being MEC with advanced computing architectures, and the other being MEC with high efficiency for sustainable operations. We are committed to taking advantage of these two trends to explore a novel multi-tier edge computing scenario with hierarchical task offloading and green energy provisioning via leveraging the energy harvesting (EH) technique. Specifically, we focus on the key problem of joint task offloading and energy scheduling in such green multi-tier edge computing systems. We aim to minimize the task execution cost by jointly considering the system cost that covers latency, energy consumption, and cloud rental fees. By formulating the problem as a stochastic optimization problem, we invoke the Lyapunov technique to decompose the long-term optimization problem into a series of one-slot optimization problems which only use the current system information. To solve the one-slot optimization problem which is a mixed-integer linear problem (MILP) proved to be NP-hard, we first relax the integer variables into real ones to obtain the optimal fractional solutions. Considering the capacity of the physical resources of each edge server, we propose a resource-constrained randomized dependent rounding algorithm to properly round up or down the fractional variables to get a feasible yet near-optimal solution. We conduct rigorous theoretical analysis and extensive simulations to verify the superior performance of the proposed schemes.  © 1967-2012 IEEE.","2022","2025-10-22 19:07:46","2025-10-22 19:07:46","","4322-4335","","4","71","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Multitasking; Energy utilization; Internet of things; Computer architecture; Real time systems; Edge computing; Green computing; Mobile edge computing; 5G mobile communication systems; Integer programming; Costs; Scheduling algorithms; Cost benefit analysis; Job analysis; Task analysis; Optimisations; task offloading; Green products; Green energy; Energy harvesting; Task offloading; Multi-tier; green energy scheduling; Green energy scheduling; Multi-tier edge computing; randomized dependent rounding; Randomized dependent rounding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QC5C3A86","conferencePaper","2008","Kim, W.; Gupta, M.S.; Wei, G.-Y.; Brooks, D.","System level analysis of fast, per-core DVFS using on-chip switching regulators","","","","10.1109/HPCA.2008.4658633","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57749178620&doi=10.1109%2fHPCA.2008.4658633&partnerID=40&md5=832af2f38e87f730477a26c97dc68c55","Portable, embedded systems place ever-increasing demands on high-performance, low-power microprocessor design. Dynamic voltage and frequency scaling (DVFS) is a well-known technique to reduce energy in digital systems, but the effectiveness of DVFS is hampered by slow voltage transitions that occur on the order of tens of microseconds. In addition, the recent trend towards chip-multiprocessors (CMP) executing multi-threaded workloads with heterogeneous behavior motivates the need for per-core DVFS control mechanisms. Voltage regulators that are integrated onto the same chip as the microprocessor core provide the benefit of both nanosecond-scale voltage switching and per-core voltage control. We show that these characteristics provide significant energy-saving opportunities compared to traditional off-chip regulators. However, the implementation of on-chip regulators presents many challenges including regulator efficiency and output voltage transient characteristics, which are significantly impacted by the system-level application of the regulator. In this paper, we describe and model these costs, and perform a comprehensive analysis of a CMP system with on-chip integrated regulators. We conclude that on-chip regulators can significantly improve DVFS effectiveness and lead to overall system energy savings in a CMP, but architects must carefully account for overheads and costs when designing next-generation DVFS systems and algorithms. ©2008 IEEE.","2008","2025-10-22 19:07:46","2025-10-22 19:07:46","","123-134","","","","","","","","","","","","","","","","Scopus","","","","","","","","Embedded systems; Computer architecture; Computers; Energy conservation; Cost benefit analysis; Microprocessor chips; Comprehensive analysis; System levels; Electric potential; Nanotechnology; Dynamic Voltage and Frequency Scaling; Voltage control; Voltage regulators; And models; Control mechanisms; Digital systems; DVFS systems; Integrated circuits; Low powers; Microprocessor cores; Microprocessor designs; Multi-processors; Nano-seconds; On chips; Output voltages; Overall systems; Recent trends; Switching regulators; Voltage switching; Voltage transitions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Symposium on High-Performance Computer Architecture","","","","","","","","","","","","","","",""
"G6NAX896","journalArticle","2020","Ibrahim, A.; Noshy, M.; Ali, H.A.; Badawy, M.","PAPSO: A power-aware VM placement technique based on particle swarm optimization","IEEE Access","","","10.1109/ACCESS.2020.2990828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084951357&doi=10.1109%2fACCESS.2020.2990828&partnerID=40&md5=a4dc399316fb336a11ffc8cee200afa1","With the widespread usage of cloud computing to benefit from its services, cloud service providers have invested in constructing large scale data centers. Consequently, a tremendous increase in energy consumption has arisen in conjunction with its results, including a remarkable rise in costs of operating and cooling servers. Besides, increasing energy consumption has a significant impact on the environment due to emissions of carbon dioxide. Dynamic consolidation of Virtual Machines (VMs) into the minimal number of Physical Machines (PMs) is considered as one of the magic solutions to manage power consumption. The virtual machine placement problem is a critical issue for good VM consolidation. This paper proposes a Power-Aware technique depending on Particle Swarm Optimization (PAPSO) to determine the near-optimal placement for the migrated VMs. A discrete version of Particle Swarm Optimization (PSO) is adopted based on a decimal encoding to map the migrated VMs to the best appropriate PMs. Furthermore, an effective minimization fitness function is employed to reduce power consumption without violating the Service Level Agreement (SLA). Specifically, PAPSO consolidates the migrated VMs into the minimum number of PMs with a major constraint to decrease the number of overloaded hosts as much as possible. Therefore, the number of VM migrations can be reduced drastically by taking into consideration the main sources for VM migrations; overloaded hosts and underloaded ones. PAPSO is implemented in CloudSim and the experimental results on random workloads with different sizes of VMs and PMs show that PAPSO does not violate SLA and outperforms the Power-Aware Best Fit Decreasing algorithm (PABFD). It can reduce about 8.01%, 39.65%, 66.33%, and 11.87% on average in terms of consumed energy, number of VM migrations, number of host shutdowns and the combined metric Energy SLA Violation (ESV), respectively. © 2013 IEEE.","2020","2025-10-22 19:07:46","2025-10-22 19:07:46","","81747-81764","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Electric power utilization; Cloud computing; Energy utilization; Service Level Agreements; Green computing; Virtual machine; Cloud service providers; Network security; Dynamic consolidation; Large scale data; Virtual machine placements; Fitness functions; energy consumption; Particle swarm optimization (PSO); service level agreement; Carbon dioxide; Impact on the environment; CloudSim; Best fit decreasing; dynamic VM consolidation; live VM migration; particle swarm optimization; virtual machine placement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MW9JRWH8","conferencePaper","2014","Li, X.; Wu, J.; Tang, S.; Lu, S.","Let's stay together: Towards traffic aware virtual machine placement in data centers","","","","10.1109/INFOCOM.2014.6848123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904410744&doi=10.1109%2fINFOCOM.2014.6848123&partnerID=40&md5=190bfa601d28767ded4e6c03542d56e4","As tenants take networked virtual machines (VMs) as their requirements, effective placement of VMs is needed to reduce the network cost in cloud data centers. The cost is one of the major concerns for the cloud providers. In addition to the cost caused by network traffics (N-cost), the cost caused by the utilization of physical machines (PM-cost) is also non-negligible. In this paper, we focus on the optimized placement of VMs to minimize the cost, the combination of N-cost and PM-cost. We define N-cost by various functions, according to different communication models. We formulate the placement problem, and prove it to be NP-hard. We investigate the problem from two aspects. Firstly, we put a special emphasis on minimizing the N-cost with fixed PM-cost. For the case that tenants request the same amount of VMs, we present optimal algorithms under various definitions of N-cost. For the case that tenants require different numbers of VMs, we propose an approximation algorithm. Also, a greedy algorithm is implemented as the baseline to evaluate the performance. Secondly, we study the general case of the VM placement problem, in which both N-cost and PM-cost are taken into account. We present an effective binary-search-based algorithm to determine how many PMs should be used, which makes a tradeoff between PM-cost and N-cost. For all of the algorithms, we conduct theoretical analysis and extensive simulations to evaluate their performance and efficiency. © 2014 IEEE.","2014","2025-10-22 19:07:46","2025-10-22 19:07:46","","1842-1850","","","","","","","","","","","","","","","","Scopus","","","","","","","","Clouds; Costs; Data centers; Approximation algorithms; Bin packing; Computer simulation; data center; Virtual machine placements; virtual machine placement; cost optimization; Cost optimization; subset-sum problem; Subset-sum problem; vector bin packing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"55NTEPDK","conferencePaper","2012","Alicherry, M.; Lakshman, T.V.","Network aware resource allocation in distributed clouds","","","","10.1109/INFCOM.2012.6195847","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861624273&doi=10.1109%2fINFCOM.2012.6195847&partnerID=40&md5=31970cf23ffaac4e2e4952ea8cd59047","We consider resource allocation algorithms for distributed cloud systems, which deploy cloud-computing resources that are geographically distributed over a large number of locations in a wide-area network. This distribution of cloud-computing resources over many locations in the network may be done for several reasons, such as to locate resources closer to users, to reduce bandwidth costs, to increase availability, etc. To get the maximum benefit from a distributed cloud system, we need efficient algorithms for resource allocation which minimize communication costs and latency. In this paper, we develop efficient resource allocation algorithms for use in distributed clouds. Our contributions are as follows: Assuming that users specify their resource needs, such as the number of virtual machines needed for a large computational task, we develop an efficient 2-approximation algorithm for the optimal selection of data centers in the distributed cloud. Our objective is to minimize the maximum distance, or latency, between the selected data centers. Next, we consider use of a similar algorithm to select, within each data center, the racks and servers where the requested virtual machines for the task will be located. Since the network inside a data center is structured and typically a tree, we make use of this structure to develop an optimal algorithm for rack and server selection. Finally, we develop a heuristic for partitioning the requested resources for the task amongst the chosen data centers and racks. We use simulations to evaluate the performance of our algorithms over example distributed cloud systems and find that our algorithms provide significant gains over other simpler allocation algorithms. © 2012 IEEE.","2012","2025-10-22 19:07:46","2025-10-22 19:07:46","","963-971","","","","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Distributed computer systems; Trees (mathematics); Cloud systems; Virtual machines; Resource allocation; Data centers; Approximation algorithms; Wide area networks; Allocation algorithm; Computer simulation; Optimal algorithm; Efficient resource allocation; Resource allocation algorithms; Telecommunication systems; Communication cost; Computational task; Maximum distance; Optimal selection; Server selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"EI9IL43Z","journalArticle","2013","Fang, W.; Liang, X.; Li, S.; Chiaraviglio, L.; Xiong, N.","VMPlanner: Optimizing virtual machine placement and traffic flow routing to reduce network power costs in cloud data centers","Computer Networks","","","10.1016/j.comnet.2012.09.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873718586&doi=10.1016%2fj.comnet.2012.09.008&partnerID=40&md5=80f7be905016a1de95b7f47972923382","In recent years, the power costs of cloud data centers have become a practical concern and have attracted significant attention from both industry and academia. Most of the early works on data center energy efficiency have focused on the biggest power consumers (i.e., computer servers and cooling systems), yet without taking the networking part into consideration. However, recent studies have revealed that the network elements consume 10-20% of the total power in the data center, which poses a great challenge to effectively reducing network power cost without adversely affecting overall network performance. Based on the analysis on topology characteristics and traffic patterns of data centers, this paper presents a novel approach, called VMPlanner, for network power reduction in the virtualization-based data centers. The basic idea of VMPlanner is to optimize both virtual machine placement and traffic flow routing so as to turn off as many unneeded network elements as possible for power saving. We formulate the optimization problem, analyze its hardness, and solve it by designing VMPlanner as a stepwise optimization approach with three approximation algorithms. VMPlanner is implemented and evaluated in a simulated environment with traffic traces collected from a data center test-bed, and the experiment results illustrate the efficacy and efficiency of this approach.© 2012 Elsevier B.V. All rights reserved.","2013","2025-10-22 19:07:46","2025-10-22 19:07:46","","179-196","","1","57","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Network performance; Cloud data centers; Data center; Data centers; Approximation algorithms; Computer simulation; Optimization problems; Cost reduction; Virtual machine placements; Network element; Green networking; Traffic flow; Data center energy efficiencies; Power costs; VM placements; Computer servers; Green networkings; Network power; Power consumers; Power savings; Simulated environment; Stepwise optimization; Topology characteristics; Total power; Traffic pattern; Traffic traces; Turn offs; VM placement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LIUNQ2GP","conferencePaper","2019","Kayal, P.; Liebeherr, J.","Autonomic service placement in fog computing","","","","10.1109/WoWMoM.2019.8792989","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071463867&doi=10.1109%2fWoWMoM.2019.8792989&partnerID=40&md5=97b416bacc08e8335c5cb7d795e26846","Fog computing recently emerged as novel distributed virtualized computing paradigm, where cloud services are extended to the edge of the network, thereby increasing network capacity and reducing latencies. In fog computing, applications are composed of building blocks, called microservices, that are mapped to edge computing and communication devices, referred to as fog nodes. A crucial component in fog computing are placement algorithms that assign microservices to fog nodes, since they determine the overall system performance in terms of energy consumption, communication costs, load balancing, and others. Placement strategies for virtual machines in cloud computing abound, but are generally centralized and therefore not well suited for decentralized fog systems. In this paper, we develop a fully distributed placement strategy that jointly optimizes energy consumption of fog nodes and communication costs of applications. We follow a Markov approximation approach for the design of a fully distributed autonomic service placement strategy without central coordination or global state information. Using numerical examples, we show that our placement algorithm finds solutions that are comparable to existing centralized solutions. © 2019 IEEE.","2019","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Green computing; Fog computing; Balancing; Computing paradigm; Placement algorithm; Placement strategy; Fog; Service placements; Markov approximation; Communication cost; Communication device; Global state information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","20th IEEE International Symposium on A World of Wireless, Mobile and Multimedia Networks, WoWMoM 2019","","","","","","","","","","","","","","",""
"FZGBG9KD","conferencePaper","2012","Gao, P.X.; Curtis, A.R.; Wong, B.; Keshav, S.","It's not easy being green","","","","10.1145/2342356.2342398","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866480667&doi=10.1145%2f2342356.2342398&partnerID=40&md5=4538e816034604c9cf1a659eef1d291d","Large-scale Internet applications, such as content distribution networks, are deployed across multiple datacenters and consume massive amounts of electricity. To provide uniformly low access latencies, these datacenters are geographically distributed and the deployment size at each location reflects the regional demand for the application. Consequently, an application's environmental impact can vary significantly depending on the geographical distribution of end-users, as electricity cost and carbon footprint per watt is location specific. In this paper, we describe FORTE: Flow Optimization based framework for request-Routing and Traffic Engineering. FORTE dynamically controls the fraction of user traffic directed to each datacenter in response to changes in both request workload and carbon footprint. It allows an operator to navigate the three-way tradeoff between access latency, carbon footprint, and electricity costs and to determine an optimal datacenter upgrade plan in response to increases in traffic load. We use FORTE to show that carbon taxes or credits are impractical in incentivizing carbon output reduction by providers of large-scale Internet applications. However, they can reduce carbon emissions by 10% without increasing the mean latency nor the electricity bill. © 2012 ACM.","2012","2025-10-22 19:07:46","2025-10-22 19:07:46","","211-222","","","","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Internet; Computer architecture; Network architecture; Communication; End-users; green computing; Data centers; Carbon footprint; Environmental impact; Carbon emissions; energy; Emission control; Access latency; Electricity costs; Carbon taxes; Content distribution networks; Electricity; Electricity bill; Flow optimization; Internet application; Traffic Engineering; Traffic loads; User traffics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SIGCOMM'12 - Proceedings of the ACM SIGCOMM 2012 Conference Applications, Technologies, Architectures, and Protocols for Computer Communication","","","","","","","","","","","","","","",""
"4X8MUWP2","journalArticle","2003","Russell, S.; Norvig, P.","","Artificial Intelligence: A Modern Approach","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003584577&partnerID=40&md5=c41115534547c9393cf4dbff88045f7b","","2003","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWHISITR","journalArticle","2018","Chen, M.; Hao, Y.; Hu, L.; Hossain, M.S.; Ghoneim, A.","Edge-CoCaCo: Toward Joint Optimization of Computation, Caching, and Communication on Edge Cloud","IEEE Wireless Communications","","","10.1109/MWC.2018.1700308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049616274&doi=10.1109%2fMWC.2018.1700308&partnerID=40&md5=f19ceafb34d8b8a0917f9fdcbb1def30","With the development of recent innovative applications (e.g., augmented reality, natural language processing, and various cognitive applications), more and more computation-intensive and rich-media tasks are delay-sensitive. Edge cloud computing is expected to be an effective solution to meet the demand for low latency. By the use of content offloading and/or computation offloading, users' quality of experience is improved with shorter delay. Compared to existing edge computing solutions, this article introduces a new concept of computing task caching and gives the optimal computing task caching policy. Furthermore, joint optimization of computation, caching, and communication on the edge cloud, dubbed Edge-CoCaCo, is proposed. Then we give the solution to that optimization problem. Finally, the simulation experimental results show that compared to the other schemes, Edge-CoCaCo has shorter delay. © 2002-2012 IEEE.","2018","2025-10-22 19:07:46","2025-10-22 19:07:46","","21-27","","3","25","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Computation offloading; Augmented reality; Natural language processing systems; Joint optimization; Computing solutions; Optimization problems; Quality of experience (QoE); Effective solution; Computation intensives; Optimal computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7XCXE6H","conferencePaper","2013","You, K.; Tang, B.; Ding, F.","Near-optimal virtual machine placement with product traffic pattern in data centers","","","","10.1109/ICC.2013.6655130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891368786&doi=10.1109%2fICC.2013.6655130&partnerID=40&md5=d2ea0a91dcd4a5b454d5bbe4d0a56a50","This paper focuses on optimizing the virtual machine (VM) placement to reduce the bandwidth usage in modern virtualization based data centers. Existing solutions require all the traffic rates between any pair of VMs to be known beforehand, which may incur significant overhead or even be impossible. To reduce such overhead, we adopt the product traffic pattern model to characterize the traffic rates. In this model, each VM is associated with an activity level, and the normalized traffic rate between each pair of VMs is approximated by the product of their activity levels. Specifically, we consider the VM placement problem with product traffic in data centers that follow the Clique or VL2 architecture. We then present an optimal solution for the special case where all the physical machines (PMs) connect to the same switch. By extending the intrinsic idea of such solution, we further develop a simple yet efficient algorithm for the general case. We prove its optimality in a common case where the PMs are homogeneous, and also derive its approximation ratio in the general case. Finally, we demonstrate via simulations that the performance of our algorithm is near-optimal under practical settings. © 2013 IEEE.","2013","2025-10-22 19:07:46","2025-10-22 19:07:46","","3705-3709","","","","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Algorithms; Virtualizations; Virtual machines; Computer simulation; Virtual machine placements; Optimal solutions; Approximation ratios; Traffic pattern; Activity levels; Bandwidth usage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Communications","","","","","","","","","","","","","","",""
"74NIRLNI","conferencePaper","2010","Beloglazov, A.; Buyya, R.","Energy efficient allocation of virtual machines in cloud data centers","","","","10.1109/ccgrid.2010.45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954925596&doi=10.1109%2fccgrid.2010.45&partnerID=40&md5=1b74a6f3da49fc382b17010bea034f14","Rapid growth of the demand for computational power has led to the creation of large-scale data centers. They consume enormous amounts of electrical power resulting in high operational costs and carbon dioxide emissions. Moreover, modern Cloud computing environments have to provide high Quality of Service (QoS) for their customers resulting in the necessity to deal with power-performance trade-off. We propose an efficient resource management policy for virtualized Cloud data centers. The objective is to continuously consolidate VMs leveraging live migration and switch off idle nodes to minimize power consumption, while providing required Quality of Service. We present evaluation results showing that dynamic reallocation of VMs brings substantial energy savings, thus justifying further development of the proposed policy. © 2010 IEEE.","2010","2025-10-22 19:07:46","2025-10-22 19:07:46","","577-578","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Virtualizations; Cluster computing; Economic and social effects; Grid computing; Virtual machines; Energy consumption; Natural resources management; Resource allocation; Energy conservation; Green IT; Computer simulation; Quality control; Carbon dioxide; Global warming; Allocation of virtual machines; Live migration of virtual machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CCGrid 2010 - 10th IEEE/ACM International Conference on Cluster, Cloud, and Grid Computing","","","","","","","","","","","","","","",""
"WLCMBMNM","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106672919&partnerID=40&md5=9ef6859905dca20d1a6b38f0a19a2431","","","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A64AY4AI","conferencePaper","2012","Singla, A.; Hong, C.-Y.; Popa, L.; Godfrey, P.B.","Jellyfish: Networking data centers randomly","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043480267&partnerID=40&md5=7dda5fa40c9c357fa6c6c9799ea3fbc5","Industry experience indicates that the ability to incrementally expand data centers is essential. However, existing high-bandwidth network designs have rigid structure that interferes with incremental expansion. We present Jellyfish, a high-capacity network interconnect which, by adopting a random graph topology, yields itself naturally to incremental expansion. Somewhat surprisingly, Jellyfish is more cost-efficient than a fat-tree, supporting as many as 25% more servers at full capacity using the same equipment at the scale of a few thousand nodes, and this advantage improves with scale. Jellyfish also allows great flexibility in building networks with different degrees of oversubscription. However, Jellyfish's unstructured design brings new challenges in routing, physical layout, and wiring. We describe approaches to resolve these challenges, and our evaluation suggests that Jellyfish could be deployed in today's data centers. © 2012 by The USENIX Association. All Rights Reserved.","2012","2025-10-22 19:07:46","2025-10-22 19:07:46","","225-238","","","","","","","","","","","","","","","","Scopus","","","","","","","","Systems analysis; Data centers; Topology; High-bandwidth networks; Expansion; Cost-efficient; High capacity networks; In-building network; Industry experience; Physical layout; Random graph topology; Rigid structures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of NSDI 2012: 9th USENIX Symposium on Networked Systems Design and Implementation","","","","","","","","","","","","","","",""
"7UC8WH8S","conferencePaper","2019","Pallewatta, S.; Kostakos, V.; Buyya, R.","Microservices-based IoT application placement within heterogeneous and resource constrained fog computing environments","","","","10.1145/3344341.3368800","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078454708&doi=10.1145%2f3344341.3368800&partnerID=40&md5=b99c5eccd2b311a7d66f0b4f73c80c63","Fog computing paradigm has created innovation opportunities within Internet of Things (IoT) domain by extending cloud services to the edge of the network. Due to the distributed, heterogeneous and resource constrained nature of the Fog computing nodes, Fog applications need to be developed as a collection of interdependent, lightweight modules. Since this concept aligns with the goals of microservices architecture, efficient placement of microservices-based IoT applications within Fog environments has the potential to fully leverage capabilities of Fog devices. In this paper, we propose a decentralized microservices-based IoT application placement policy for heterogeneous and resource constrained Fog environments. The proposed policy utilizes the independently deployable and scalable nature of microservices to place them as close as possible to the data source to minimize latency and network usage. Moreover, it aims to handle service discovery and load balancing related challenges of the microservices architecture. We implement and evaluate our policy using iFogSim simulated Fog environment. Results of the simulations show around 85% improvement in latency and network usage for the proposed microservice placement policy when compared with Cloud-only placement approach and around 40% improvement over an alternative Fog application placement method known as Edge-ward placement policy. Moreover, the decentralized placement approach proposed in this paper demonstrates significant reduction in microservice placement delay over centralized placement. © 2019 Association for Computing Machinery.","2019","2025-10-22 19:07:46","2025-10-22 19:07:46","","71-81","","","","","","","","","","","","","","","","Scopus","","","","","","","","Internet of things; Network architecture; Internet of Things (IOT); Fog computing; Computing environments; Computing paradigm; Microservices architecture; Application deployment; Service discovery; Fog; Application placement; Application placements; IOT applications; Internet of things (IoT); Simulated fog environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","UCC 2019 - Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing","","","","","","","","","","","","","","",""
"JG9JZFDP","journalArticle","2018","Pan, J.; McElhannon, J.","Future Edge Cloud and Edge Computing for Internet of Things Applications","IEEE Internet of Things Journal","","","10.1109/JIOT.2017.2767608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032725533&doi=10.1109%2fJIOT.2017.2767608&partnerID=40&md5=2db2b2f116b1799fb73a775280903e5d","The Internet is evolving rapidly toward the future Internet of Things (IoT) which will potentially connect billions or even trillions of edge devices which could generate huge amount of data at a very high speed and some of the applications may require very low latency. The traditional cloud infrastructure will run into a series of difficulties due to centralized computation, storage, and networking in a small number of datacenters, and due to the relative long distance between the edge devices and the remote datacenters. To tackle this challenge, edge cloud and edge computing seem to be a promising possibility which provides resources closer to the resource-poor edge IoT devices and potentially can nurture a new IoT innovation ecosystem. Such prospect is enabled by a series of emerging technologies, including network function virtualization and software defined networking. In this survey paper, we investigate the key rationale, the state-of-the-art efforts, the key enabling technologies and research topics, and typical IoT applications benefiting from edge cloud. We aim to draw an overall picture of both ongoing research efforts and future possible research directions through comprehensive discussions. © 2014 IEEE.","2018","2025-10-22 19:07:46","2025-10-22 19:07:46","","439-449","","1","5","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Virtual reality; Virtualization; Distributed computer systems; Internet of things; Edge computing; Surveys; Edge clouds; Digital storage; Transfer functions; Network function virtualization; edge computing; Internet of Things (IoT); survey; Edge cloud; Software defined networking; network function virtualization (NFV); Computational model; software defined networking (SDN); Software defined networking (SDN); Surveying; HomeCloud","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VQKR5J3D","conferencePaper","2013","Xu, Z.; Liang, W.","Minimizing the operational cost of data centers via geographical electricity price diversity","","","","10.1109/CLOUD.2013.94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897707284&doi=10.1109%2fCLOUD.2013.94&partnerID=40&md5=eae6c91f8b104a0d37916a4d1c768811","Data centers, serving as infrastructures for cloud services, are growing in both number and scale. However, they usually consume enormous amounts of electric power, which lead to high operational costs of cloud service providers. Reducing the operational cost of data centers thus has been recognized as a main challenge in cloud computing. In this paper we study the minimum operational cost problem of fair request rate allocations in a distributed cloud environment by incorporating the diversity of time-varying electricity prices in different regions, with an objective to fairly allocate requests to different data centers for processing while keeping the negotiated Service Level Agreements (SLAs) between request users and the cloud service provider to be met, where the data centers and web portals of a cloud service provider are geographically located in different regions. To this end, we first propose an optimization framework for the problem. We then devise a fast approximation algorithm with a provable approximation ratio by exploiting combinatorial properties of the problem. We finally evaluate the performance of the proposed algorithm through experimental simulation on real-life electricity price data sets. Experimental results demonstrate that the proposed algorithm is very promising, which not only outperforms other existing heuristics but also is highly scalable. © 2013 IEEE.","2013","2025-10-22 19:07:46","2025-10-22 19:07:46","","99-106","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Costs; Approximation algorithms; Cloud service providers; Distributed database systems; Service level agreement (SLAs); Approximation ratios; Optimization framework; Experimental simulations; Distributed clouds; Electricity; Combinatorial properties; Time-varying electricity prices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"25EY5FB8","conferencePaper","2008","Al-Fares, M.; Loukissas, A.; Vahdat, A.","A scalable, commodity data center network architecture","","","","10.1145/1402946.1402967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-65249121271&doi=10.1145%2f1402946.1402967&partnerID=40&md5=79c74fac447868845b283d0dacd9469b","Today's data centers may contain tens of thousands of computers with significant aggregate bandwidth requirements. The network architecture typically consists of a tree of routing and switching elements with progressively more specialized and expensive equipment moving up the network hierarchy. Unfortunately, even when deploying the highest-end IP switches/routers, resulting topologies may only support 50% of the aggregate bandwidth available at the edge of the network, while still incurring tremendous cost. Non-uniform bandwidth among data center nodes complicates application design and limits overall system performance. In this paper, we show how to leverage largely commodity Ethernet switches to support the full aggregate bandwidth of clusters consisting of tens of thousands of elements. Similar to how clusters of commodity computers have largely replaced more specialized SMPs and MPPs, we argue that appropriately architected and interconnected commodity switches may deliver more performance at less cost than available from today's higher-end solutions. Our approach requires no modifications to the end host network interface, operating system, or applications; critically, it is fully backward compatible with Ethernet, IP, and TCP. Copyright 2008 ACM.","2008","2025-10-22 19:07:46","2025-10-22 19:07:46","","63-74","","","38","","","","","","","","","","","","","Scopus","","","","","","","","Internet protocols; Network architecture; Bandwidth; Costs; Topology; Satellite communication systems; Operating systems; Ethernet; Backward compatible; Application designs; Bandwidth requirements; Commodity ethernets; Convolutional codes; Data center topology; Equal-cost routing; Network hierarchies; Network interfaces; Non-uniform; Shape memory effect; Switching elements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Computer Communication Review","","","","","","","","","","","","","","",""
"Q9FIIHUF","journalArticle","2018","Pahlevan, A.; Qu, X.; Zapater, M.; Atienza, D.","Integrating Heuristic and Machine-Learning Methods for Efficient Virtual Machine Allocation in Data Centers","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","","10.1109/TCAD.2017.2760517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031774157&doi=10.1109%2fTCAD.2017.2760517&partnerID=40&md5=ed06c75529660919029ceb200d260493","Modern cloud data centers (DCs) need to tackle efficiently the increasing demand for computing resources and address the energy efficiency challenge. Therefore, it is essential to develop resource provisioning policies that are aware of virtual machine (VM) characteristics, such as CPU utilization and data communication, and applicable in dynamic scenarios. Traditional approaches fall short in terms of flexibility and applicability for large-scale DC scenarios. In this paper, we propose a heuristic- and a machine learning (ML)-based VM allocation method and compare them in terms of energy, quality of service (QoS), network traffic, migrations, and scalability for various DC scenarios. Then, we present a novel hyper-heuristic algorithm that exploits the benefits of both methods by dynamically finding the best algorithm, according to a user-defined metric. For optimality assessment, we formulate an integer linear programming (ILP)-based VM allocation method to minimize energy consumption and data communication, which obtains optimal results, but is impractical at runtime. Our results demonstrate that the ML approach provides up to 24% server-to-server network traffic improvement and reduces execution time by up to 480 × compared to conventional approaches, for large-scale scenarios. On the contrary, the heuristic outperforms the ML method in terms of energy and network traffic for reduced scenarios. We also show that the heuristic and ML approaches have up to 6% energy consumption overhead compared to ILP-based optimal solution. Our hyper-heuristic integrates the strengths of both the heuristic and the ML methods by selecting the best one during runtime. © 1982-2012 IEEE.","2018","2025-10-22 19:07:46","2025-10-22 19:07:46","","1667-1680","","8","37","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Information management; Resource management; Distributed computer systems; Cloud data centers; Energy utilization; Economic and social effects; Green computing; Servers; Integer programming; Heuristic algorithms; Virtual machine; Artificial intelligence; Learning systems; Trade off; Scalability; Network security; Correlation methods; Heuristic methods; Integer Linear Programming; machine learning (ML); E-learning; Inductive logic programming (ILP); quality of service (QoS); Convolutional codes; Cloud data centers (DCs); Data-communication; energy-network traffic tradeoffs; greedy heuristic; Greedy heuristics; Heuristic programming; hyper heuristic; Hyperheuristic; integer linear programming (ILP); scalability assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G89DZJMT","conferencePaper","2013","Zhou, Z.; Liu, F.; Xu, Y.; Zou, R.; Xu, H.; Lui, J.C.S.; Jin, H.","Carbon-aware load balancing for geo-distributed cloud services","","","","10.1109/MASCOTS.2013.31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894559511&doi=10.1109%2fMASCOTS.2013.31&partnerID=40&md5=279e1af21c2d4e31b5d44d917ec7ae6c","Recently, data center carbon emission has become an emerging concern for the cloud service providers. Previous works are limited on cutting down the power consumption of the data centers to defuse such a concern. In this paper, we show how the spatial and temporal variabilities of the electricity carbon footprint can be fully exploited to further green the cloud running on top of geographically distributed data centers. We jointly consider the electricity cost, service level agreement (SLA) requirement, and emission reduction budget. To navigate such a three-way tradeoff, we take advantage of Lyapunov optimization techniques to design and analyze a carbon-aware control framework, which makes online decisions on geographical load balancing, capacity right-sizing, and server speed scaling. Results from rigorous mathematical analyses and real-world trace-driven empirical evaluation demonstrate its effectiveness in both minimizing electricity cost and reducing carbon emission. © 2013 IEEE.","2013","2025-10-22 19:07:46","2025-10-22 19:07:46","","232-241","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS","","","","","","","","","","","","","","",""
"5Z4XQR3W","journalArticle","2021","Omer, S.; Azizi, S.; Shojafar, M.; Tafazolli, R.","A priority, power and traffic-aware virtual machine placement of IoT applications in cloud data centers","Journal of Systems Architecture","","","10.1016/j.sysarc.2021.101996","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099224758&doi=10.1016%2fj.sysarc.2021.101996&partnerID=40&md5=b374e01d36d4eb1725d6c8a964d362c6","Recent telecommunication paradigms, such as big data, Internet of Things (IoT), ubiquitous edge computing (UEC), and machine learning, are encountering with a tremendous number of complex applications that require different priorities and resource demands. These applications usually consist of a set of virtual machines (VMs) with some predefined traffic load between them. The efficiency of a cloud data center (CDC) as prominent component in UEC significantly depends on the efficiency of its VM placement algorithm applied. However, VM placement is an NP-hard problem and thus there exist practically no optimal solution for this problem. In this paper, motivated by this, we propose a priority, power and traffic-aware approach for efficiently solving the VM placement problem in a CDC. Our approach aims to jointly minimize power consumption, network consumption and resource wastage in a multi-dimensional and heterogeneous CDC. To evaluate the performance of the proposed method, we compared it to the state-of-the-art on a fat-tree topology under various experiments. Results demonstrate that the proposed method is capable of reducing the total network consumption up to 29%, the consumption of power up to 18%, and the wastage of resources up to 68%, compared to the second-best results. © 2021 Elsevier B.V.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","115","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Virtual reality; Cloud data centers; Internet of things; Ubiquitous computing; Internet of Things (IOT); Complex applications; Efficiency; Virtual machine; Resource demands; Network security; Virtual machine placements; Optimal solutions; Power consumption; NP-hard; IOT applications; Cloud data center (CDC); Internet of Thing (IoT); Multi dimensional; Priority-aware; Traffic-aware; Virtual machine placement (VMP)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQCJXYEW","journalArticle","2019","Mustafa, S.; Sattar, K.; Shuja, J.; Sarwar, S.; Maqsood, T.; Madani, S.A.; Guizani, S.","Sla-aware best fit decreasing techniques for workload consolidation in clouds","IEEE Access","","","10.1109/ACCESS.2019.2941145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077992627&doi=10.1109%2fACCESS.2019.2941145&partnerID=40&md5=57d27bf40881c3a3920cdfca6e8fc80f","Cloud computing emerged as one of the leading computational paradigms due to elastic resource provisioning and pay-as-you-go model. Large data centers are used by the service providers to host the various services. These data centers consume enormous energy, which leads to increase in operating costs and carbon footprints. Therefore, green cloud computing is a necessity, which not only reduces energy consumption, but also affects the environment positively. In order to reduce the energy consumption, workload consolidation approach is used that consolidates the tasks in minimum possible servers. However, workload consolidation may lead to service level agreement (SLA) violations due to non-availability of resources on the server. Therefore, workload consolidation techniques should consider the aforementioned problem. In this paper, we present two consolidation based energy-efficient techniques that reduce energy consumption along with resultant SLA violations. In addition to that, we also enhanced the existing Enhanced-Conscious Task Consolidation (ECTC) and Maximum Utilization (MaxUtil) techniques that attempt to reduce energy consumption and SLA violations. Experimental results show that the proposed techniques perform better than the selected heuristic based techniques in terms of energy, SLA, and migrations. © 2013 IEEE.","2019","2025-10-22 19:07:46","2025-10-22 19:07:46","","135256-135267","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Resource management; Energy utilization; Service Level Agreements; Green computing; Operating costs; Reduce energy consumption; Carbon footprint; Workload consolidation; Best fit decreasing; Computational paradigm; Energy-efficient techniques; SLA violation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RS9E8U7V","conferencePaper","2011","Moreno, I.S.; Xu, J.","Customer-aware resource overallocation to improve energy efficiency in realtime Cloud Computing data centers","","","","10.1109/SOCA.2011.6166239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859959080&doi=10.1109%2fSOCA.2011.6166239&partnerID=40&md5=b89950e2fb0cdc6b863a714c157f2c03","Energy efficiency is becoming a very important concern for Cloud Computing environments. These are normally composed of large and power consuming data centers to provide the required elasticity and scalability to their customers. In this context, many efforts have been developed to balance the loads at host level. However, determining how to maximize the resources utilization at Virtual Machine (VM) level still remains as a big challenge. This is mainly driven by very dynamic workload behaviors and a wide variety of customers' resource utilization patterns. This paper introduces a dynamic resource provisioning mechanism to overallocate the capacity of real-time Cloud data centers based on customer utilization patterns. Furthermore, its impact on the trade-off between energy efficiency and SLA fulfillment is analyzed. The main idea is to exploit the resource utilization patterns of each customer to decrease the waste produced by resource request overestimations. This creates the opportunity to allocate additional VMs in the same host incrementing its energy efficiency. Nevertheless, this also increases the risk of QoS affectations. The proposed model considers SLA deadlines, predictions based on historical data, and dynamic occupation to determine the amount of resources to overallocate for each host. In addition, a compensation mechanism to adjust resource allocation in cases of underestimation is also described. In order to evaluate the model, simulation experimentation was conducted. Results demonstrate meaningful improvements in energy-efficiency while SLA-deadlines are slightly impacted. However, they also point the importance of strongest compensation policies to reduce availability violations especially during peak utilization periods. © 2011 IEEE.","2011","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; cloud computing; Cloud computing; Dynamics; Elasticity; Energy aware; green computing; Computer systems; Computer simulation; Sales; energy-efficiency; Customer satisfaction; customer-aware; energy-aware provisioning; overallocation; overbooking; real-time cloud computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2011 IEEE International Conference on Service-Oriented Computing and Applications, SOCA 2011","","","","","","","","","","","","","","",""
"QV2LDCPL","conferencePaper","2014","Vishwanath Member, A.; Hinton, K.; Ayre, R.W.A.; Tucker, R.S.","Modeling energy consumption in high-capacity routers and switches","","","","10.1109/JSAC.2014.2335312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907518813&doi=10.1109%2fJSAC.2014.2335312&partnerID=40&md5=a3fb7906516c99cc244b3ebfa2605bdf","Routers and switches are major contributors to the energy consumption of modern networks. Today, many energy efficiency metrics for these high-capacity devices are coarse-grained, i.e., based upon a single energy per bit value given at peak load or averaged over several specific loads. In this paper, we develop a new power model and a vendor-agnostic methodology that permits quantifying the energy efficiency of Internet equipment at a more fundamental level, i.e., at the granularity of per-packet processing, and per-byte store and forward packet handling operations. We demonstrate the efficacy of the proposed technique by applying it to various types of routers and switches. We describe how our technique can be used to accurately estimate the network-wide energy footprint incurred when accessing different applications. We offer our method as a valuable framework against which the energy efficiency of current and future generation of load-proportional Internet equipment can be benchmarked. © 2014 IEEE.","2014","2025-10-22 19:07:46","2025-10-22 19:07:46","","1524-1532","","","32","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; energy efficiency; ethernet switches; Ethernet switches; High-capacity; IP routers; per-byte store and forward energy; per-packet processing energy; Store and forward","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE Journal on Selected Areas in Communications","","","","","","","","","","","","","","",""
"LA5IQUFG","conferencePaper","2015","Gu, C.; Liu, C.; Zhang, J.; Huang, H.; Jia, X.","Green scheduling for cloud data centers using renewable resources","","","","10.1109/INFCOMW.2015.7179410","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943273501&doi=10.1109%2fINFCOMW.2015.7179410&partnerID=40&md5=b6293b303d3adf85046443386838d332","Cloud data centers provide all kinds of service using hundreds of thousands of servers. This naturally leads to concerns about the effect on environment such as carbon emissions and global warming. Huge amounts of effort have been devoted to power-aware scheduling using renewable energy. However, the intermittent availability of the renewable energy brings us a new challenge: how to dynamically distribute the requests to the data centers that are powered by renewable energy, while minimizing carbon emissions under a fixed electricity budget. In this paper, we model our problem as a constraint optimization problem. The goal is to minimize the carbon emissions of the data centers by using renewable energy while satisfying: (1) the request processing time constraint; (2) the total electricity budget in each time slot; (3) the intermittent supply of the renewable resources; (4) the maximal number of servers in each data center. We solve the problem by ingeniously transforming it into an integer linear programming model, and calculate the decision variables using existed method. Experiments show that our scheduler can minimize carbon emissions using renewable resources, while satisfying the constraints mentioned above. © 2015 IEEE.","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","354-359","","","2015-August","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Scheduling; Optimization; cloud computing; Cloud computing; Cloud data centers; Integer programming; Data centers; Budget control; Problem solving; data center; Constrained optimization; Renewable energies; Integer linear programming models; Emission control; renewable energy; Global warming; carbon emission reduction; Carbon emission reductions; Constraint optimization problems; green; Power-aware scheduling; schedule","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - IEEE INFOCOM","","","","","","","","","","","","","","",""
"SQDK24UE","journalArticle","2022","Nabavi, S.S.; Gill, S.S.; Xu, M.; Masdari, M.; Garraghan, P.","TRACTOR: Traffic-aware and power-efficient virtual machine placement in edge-cloud data centers using artificial bee colony optimization","International Journal of Communication Systems","","","10.1002/dac.4747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100093763&doi=10.1002%2fdac.4747&partnerID=40&md5=44823c05fc64adacf3a2674e83ffbe98","Technology providers heavily exploit the usage of edge-cloud data centers (ECDCs) to meet user demand while the ECDCs are large energy consumers. Concerning the decrease of the energy expenditure of ECDCs, task placement is one of the most prominent solutions for effective allocation and consolidation of such tasks onto physical machine (PM). Such allocation must also consider additional optimizations beyond power and must include other objectives, including network-traffic effectiveness. In this study, we present a multi-objective virtual machine (VM) placement scheme (considering VMs as fog tasks) for ECDCs called TRACTOR, which utilizes an artificial bee colony optimization algorithm for power and network-aware assignment of VMs onto PMs. The proposed scheme aims to minimize the network traffic of the interacting VMs and the power dissipation of the data center's switches and PMs. To evaluate the proposed VM placement solution, the Virtual Layer 2 (VL2) and three-tier network topologies are modeled and integrated into the CloudSim toolkit to justify the effectiveness of the proposed solution in mitigating the network traffic and power consumption of the ECDC. Results indicate that our proposed method is able to reduce power energy consumption by 3.5% while decreasing network traffic and power by 15% and 30%, respectively, without affecting other QoS parameters. © 2021 John Wiley & Sons Ltd.","2022","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","1","35","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; cloud computing; Energy utilization; Virtual machine; Network security; cloud data centers; power consumption; Virtual machine placements; Network topology; network traffic; Power efficient; VM placement; artificial bee colony; Artificial bee colony optimization algorithms; Artificial bee colony optimizations; Energy expenditure; Placement scheme; Technology providers; Tractors (agricultural); Tractors (truck)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84U6ZHJC","journalArticle","1965","Zadeh, L.A.","Fuzzy sets","Information and Control","","","10.1016/S0019-9958(65)90241-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248666540&doi=10.1016%2fS0019-9958%2865%2990241-X&partnerID=40&md5=52dbe1d1e74f322d2c9f6532ac332a8c","A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint. © 1965 Academic Press, Inc.","1965","2025-10-22 19:07:46","2025-10-22 19:07:46","","338-353","","3","8","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XVWLRK7","conferencePaper","2015","Kabir, M.H.; Shoja, G.C.; Ganti, S.","VM placement algorithms for hierarchical cloud infrastructure","","","","10.1109/CloudCom.2014.53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937900728&doi=10.1109%2fCloudCom.2014.53&partnerID=40&md5=d67933241ad8a0f444537a61c79dca09","A hierarchical cloud infrastructure involving cloud, cluster, and node controllers is the most preferred deployment architecture by the cloud providers since it helps them to achieve the desired scalability and geographical distribution. In this architecture, the cloud controller indirectly controls a large number of node controllers through a few cluster controllers. A Virtual Machine (VM) placement algorithm, therefore, should provide for intelligent cluster selection before node selection. To the best of our knowledge, there is no VM placement algorithm available that has addressed this issue. In this paper, we propose a new VM placement algorithm that intelligently selects the appropriate cluster, and then a node inside the cluster. We use multi-criteria-decision-analysis (MCDA) technique for this purpose. Simulation results have confirmed the superior performance of our algorithm. © 2014 IEEE.","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","656-659","","","2015-February","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Virtual machine; Data center; Cloud platforms; Cloud infrastructures; Cloud computing architecture; Virtual machine placements; Placement algorithm; Deployment architecture; VM placement; Cloud clusters; Cloud controller; Cluster controller; Hierarchical; Node controller; Node controllers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom","","","","","","","","","","","","","","",""
"2B3DIG7X","conferencePaper","2013","Tziritas, N.; Xu, C.-Z.; Loukopoulos, T.; Khan, S.U.; Yu, Z.","Application-Aware workload consolidation to minimize both energy consumption and network load in cloud environments","","","","10.1109/ICPP.2013.54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893266411&doi=10.1109%2fICPP.2013.54&partnerID=40&md5=bda7a99f28d013c2bdb7fbd431636ee3","In this paper we tackle the problem of virtual machine (VM) placement onto physical servers to jointly optimize two objective functions. The first objective is to minimize the total energy spent within a cloud due to the servers that are commissioned to satisfy the computational demands of VMs. The second objective is to minimize the total network overhead incurred due to: (a) communicational dependencies between VMs, and (b) the VM migrations performed for the transition from an old assignment scheme to a new one. We study different methodologies for solving the aforementioned problem. The first approach is based on VM packing algorithms that optimize the above objective functions separately, reaching a single solution. The other approach is to tackle simultaneously the two optimization targets and define a set of non-dominating solutions. Performance evaluation using simulation experiments reveals interesting trade-offs between energy consumption and network load. © 2013 IEEE.","2013","2025-10-22 19:07:46","2025-10-22 19:07:46","","449-457","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Energy utilization; Economic and social effects; Green computing; Virtual machine; Multiobjective optimization; Network security; Virtual machine placements; Virtual machine placement; Performance evaluations; Workload consolidation; Pareto principle; Objective functions; Computational demands; Network load minimization; Network load minimizations; Packing algorithms; Pareto optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel Processing","","","","","","","","","","","","","","",""
"HWS4J645","journalArticle","2018","Li, X.; Garraghan, P.; Jiang, X.; Wu, Z.; Xu, J.","Holistic Virtual Machine Scheduling in Cloud Datacenters towards Minimizing Total Energy","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2017.2688445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041005035&doi=10.1109%2fTPDS.2017.2688445&partnerID=40&md5=db168e86d80d672a81aa80fbff35123f","Energy consumed by Cloud datacenters has dramatically increased, driven by rapid uptake of applications and services globally provisioned through virtualization. By applying energy-aware virtual machine scheduling, Cloud providers are able to achieve enhanced energy efficiency and reduced operation cost. Energy consumption of datacenters consists of computing energy and cooling energy. However, due to the complexity of energy and thermal modeling of realistic Cloud datacenter operation, traditional approaches are unable to provide a comprehensive in-depth solution for virtual machine scheduling which encompasses both computing and cooling energy. This paper addresses this challenge by presenting an elaborate thermal model that analyzes the temperature distribution of airflow and server CPU. We propose GRANITE-a holistic virtual machine scheduling algorithm capable of minimizing total datacenter energy consumption. The algorithm is evaluated against other existing workload scheduling algorithms MaxUtil, TASA, IQR and Random using real Cloud workload characteristics extracted from Google datacenter tracelog. Results demonstrate that GRANITE consumes 4.3-43.6 percent less total energy in comparison to the state-of-the-art, and reduces the probability of critical temperature violation by 99.2 with 0.17 percent SLA violation rate as the performance penalty. © 1990-2012 IEEE.","2018","2025-10-22 19:07:46","2025-10-22 19:07:46","","1317-1331","","6","29","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Scheduling; Energy efficiency; Datacenter; Cloud computing; Energy utilization; Green computing; Servers; Virtual machine; Scheduling algorithms; Processor scheduling; Network security; energy efficiency; Cooling; Traditional approaches; virtual machine; workload scheduling; Virtual machining; Computational model; Data center operations; Virtual machine scheduling; datacenter modeling; Granite; Machinery; Thermal management (electronics); Workload characteristics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULJWUHSK","conferencePaper","2010","Beloglazov, A.; Buyya, R.","Energy efficient resource management in virtualized cloud data centers","","","","10.1109/CCGRID.2010.46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954894902&doi=10.1109%2fCCGRID.2010.46&partnerID=40&md5=d50cafe5405862095a10731080802148","Rapid growth of the demand for computational power by scientific, business and web-applications has led to the creation of large-scale data centers consuming enormous amounts of electrical power. We propose an energy efficient resource management system for virtualized Cloud data centers that reduces operational costs and provides required Quality of Service (QoS). Energy savings are achieved by continuous consolidation of VMs according to current utilization of resources, virtual network topologies established between VMs and thermal state of computing nodes. We present first results of simulation-driven evaluation of heuristics for dynamic reallocation of VMs using live migration according to current requirements for CPU performance. The results show that the proposed technique brings substantial energy savings, while ensuring reliable QoS. This justifies further investigation and development of the proposed resource management system. © 2010 IEEE.","2010","2025-10-22 19:07:46","2025-10-22 19:07:46","","826-831","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud computing; Resource management; Virtualization; Virtualizations; Cluster computing; Grid computing; Virtual machines; Energy consumption; Natural resources management; Resource allocation; Energy conservation; Green IT; Computer simulation; Cost reduction; Electric network topology; Allocation of virtual machines; Live migration of virtual machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CCGrid 2010 - 10th IEEE/ACM International Conference on Cluster, Cloud, and Grid Computing","","","","","","","","","","","","","","",""
"NA3IS63G","journalArticle","2015","Mann, Z.A.","Modeling the virtual machine allocation problem","Proceedings of the International Conference on Mathematical Methods, Mathematical Models, and Simulation in Science and Engineering","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939793788&partnerID=40&md5=dd81ad675d04cd59c13886a4daebef0e","","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","102-106","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSJAJY7I","journalArticle","","","","Eurostat Electricity Price Statistics","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878872475&partnerID=40&md5=3bc157a761d10ef71040d1a994594319","","","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HM45EVN","conferencePaper","2013","Zhang, X.; Lu, J.; Qin, X.","BFEPM: Best fit energy prediction modeling based on CPU utilization","","","","10.1109/NAS.2013.12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893220699&doi=10.1109%2fNAS.2013.12&partnerID=40&md5=6d74344dc699b3a17fc82ad2a98acbb8","Energy cost becomes a major part of data center operational cost. Computer system consume more power when it runs under high workload. Many past studies focused on how to predict power consumption by performance counters. Some models retrieve performance counters from chips. Some models query performance counters from OS. Most of these researches were verified on several machines and claimed their models were accurate under the test. We found different servers have different energy consumption characters even with same CPU. In this paper, we present BFEPM, a best fit energy prediction model. It choose best model based on the power consumption benchmark result. We illustrate how to use benchmark result to find a best fit model. Then we validate the viability and effectiveness of model on all published results. At last, we apply the best fit model on two different machines to estimate the real-time energy consumption. The results show our model can get better results than single model. © 2013 IEEE.","2013","2025-10-22 19:07:46","2025-10-22 19:07:46","","41-49","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Green computing; Digital storage; Data center management; Performance counters; CPU utilization; Best-fit models; Energy consumption mode; Energy prediction; Query performance; Single models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2013 IEEE 8th International Conference on Networking, Architecture and Storage, NAS 2013","","","","","","","","","","","","","","",""
"LR35ULXJ","journalArticle","2010","Beloglazov, A.; Buyya, R.","Energy and carbon-efficient placement of virtual machines in distributed cloud data centers","Euro-Par 2013 Parallel Processing","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106686887&partnerID=40&md5=fe53b8d123d4f1ceb1f0a2428d160fe3","","2010","2025-10-22 19:07:46","2025-10-22 19:07:46","","317-328","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ECK7EPG","journalArticle","2015","Mann, Z.Á.","Allocation of virtual machines in cloud data centers-a survey of problem models and optimization algorithms","ACM Computing Surveys","","","10.1145/2797211","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939815146&doi=10.1145%2f2797211&partnerID=40&md5=c4ecc3d47a2edb7743e909e4ceef49fb","Data centers in public, private, and hybrid cloud settings make it possible to provision virtual machines (VMs) with unprecedented flexibility. However, purchasing, operating, and maintaining the underlying physical resources incurs significant monetary costs and environmental impact. Therefore, cloud providers must optimize the use of physical resources by a careful allocation of VMs to hosts, continuously balancing between the conflicting requirements on performance and operational costs. In recent years, several algorithms have been proposed for this important optimization problem. Unfortunately, the proposed approaches are hardly comparable because of subtle differences in the used problem models. This article surveys the used problem formulations and optimization algorithms, highlighting their strengths and limitations, and pointing out areas that need further research. © 2015 ACM 0360-0300/2015/08-ART11 $15.00.","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","1","48","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Optimization; Cloud computing; Cloud-computing; Cloud data centers; Virtual machine consolidations; Surveys; Green computing; Virtual machine; Data center; Network security; VM consolidation; Environmental impact; Modeling and optimization; Virtual machine placements; Physical resources; Live migrations; Optimization algorithms; VM placement; Live migration; Problem models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAJ2EM4I","journalArticle","2019","Hu, Y.; de Laat, C.; Zhao, Z.","Optimizing service placement for microservice architecture in clouds","Applied Sciences (Switzerland)","","","10.3390/app9214663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075245058&doi=10.3390%2fapp9214663&partnerID=40&md5=d1693884b287c76d75abd11a561f6b05","As microservice architecture is becoming more popular than ever, developers intend to transform traditional monolithic applications into service-based applications (composed by a number of services). To deploy a service-based application in clouds, besides the resource demands of each service, the traffic demands between collaborative services are crucial for the overall performance. Poor handling of the traffic demands can result in severe performance degradation, such as high response time and jitter. However, current cluster schedulers fail to place services at the best possible machine, since they only consider the resource constraints but ignore the traffic demands between services. To address this problem, we propose a new approach to optimize the placement of service-based applications in clouds. The approach first partitions the application into several parts while keeping overall traffic between different parts to a minimum and then carefully packs the different parts into machines with respect to their resource demands and traffic demands. We implement a prototype scheduler and evaluate it with extensive experiments on testbed clusters. The results show that our approach outperforms existing container cluster schedulers and representative heuristics, leading to much less overall inter-machine traffic. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","2019","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","21","9","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Resource management; Microservice architecture; Cluster scheduling; service placement; Network optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SS9SZZ2E","journalArticle","2021","Goudarzi, M.; Wu, H.; Palaniswami, M.; Buyya, R.","An Application Placement Technique for Concurrent IoT Applications in Edge and Fog Computing Environments","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2020.2967041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102372700&doi=10.1109%2fTMC.2020.2967041&partnerID=40&md5=e561893f3f533f283de0dc79a1949604","Fog/Edge computing emerges as a novel computing paradigm that harnesses resources in the proximity of the Internet of Things (IoT) devices so that, alongside with the cloud servers, provide services in a timely manner. However, due to the ever-increasing growth of IoT devices with resource-hungry applications, fog/edge servers with limited resources cannot efficiently satisfy the requirements of the IoT applications. Therefore, the application placement in the fog/edge computing environment, in which several distributed fog/edge servers and centralized cloud servers are available, is a challenging issue. In this article, we propose a weighted cost model to minimize the execution time and energy consumption of IoT applications, in a computing environment with multiple IoT devices, multiple fog/edge servers and cloud servers. Besides, a new application placement technique based on the Memetic Algorithm is proposed to make batch application placement decision for concurrent IoT applications. Due to the heterogeneity of IoT applications, we also propose a lightweight pre-scheduling algorithm to maximize the number of parallel tasks for the concurrent execution. The performance results demonstrate that our technique significantly improves the weighted cost of IoT applications up to 65 percent in comparison to its counterparts.  © 2002-2012 IEEE.","2021","2025-10-22 19:07:46","2025-10-22 19:07:46","","1298-1311","","4","20","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Internet of things; Green computing; Fog computing; Computing environments; edge computing; Internet of Things (IoT); optimization; Computing paradigm; Fog; application placement; Internet of thing (IOT); Application placements; IOT applications; New applications; application partitioning; Concurrent execution; Memetic algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JX8NE79A","conferencePaper","2012","Gosselin, S.; Saliou, F.; Bourgart, F.; Rouzic, E.L.; Masson, S.L.; Gati, A.","Energy consumption of ICT infrastructures: An operator's viewpoint","","","","10.1364/ECEOC.2012.We.1.G.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882650992&doi=10.1364%2fECEOC.2012.We.1.G.4&partnerID=40&md5=ddd6c0d16e332bb473ff175861972d0b","The digital revolution has resulted up to now in the need for increasingly powerful and energy-hungry infrastructures. This paper provides an operator's viewpoint on how to face this challenge, including some intermediate results of France Telecom Orange energy action plan and some expected technological and architectural evolutions of ICT infrastructures.© 2012 OSA.","2012","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; ICT infrastructures; Action plan; Architectural evolution; Digital revolution; Exhibitions; France telecom; Intermediate results; Optical communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","European Conference and Exhibition on Optical Communication, ECEOC 2012","","","","","","","","","","","","","","",""
"NH5FJ8LW","conferencePaper","2015","Zheng, X.; Cai, Y.","Dynamic Virtual Machine Placement for Cloud Computing Environments","","","","10.1109/ICPPW.2014.28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946541227&doi=10.1109%2fICPPW.2014.28&partnerID=40&md5=2f0a333a1961c53ecf7a2a11b6a337ff","With the increasing application of large scale cloud computing platforms, how to place virtual machine (VM) requests into available computing servers to reduce energy consumption has become a hot research subject. However, the current VM placement approaches are still not effective for live migrations with dynamic characters. In this paper, we proposed a dynamic VM placement scheme for energy efficient resource allocation in a cloud platform. Our dynamic VM placement scheme supports VM requests scheduling and live migration to minimize the number of active nodes in order to save the overall energy in a virtualized data center. Specifically, the proposed VM placement scheme is built on a statistical mathematic framework, and it incorporates all the virtualization overheads in the dynamic migration process. In addition, our scheme considers other important factors in related to power consumption, and it is ready to be extended with more considerations on users demand. We conduct extensive evaluations based on HPC jobs in a simulated environment. The results prove the effectiveness of our scheme. © 2014 IEEE.","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","121-128","","","2015-May","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Energy utilization; Green computing; Energy-efficient resource allocation; Virtual machine; Cloud computing environments; Network security; Reduce energy consumption; Dynamic consolidation; Virtualized data centers; dynamic consolidation; energy efficiency; Virtual machine placements; virtual machine; Cloud computing platforms; Simulated environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the International Conference on Parallel Processing Workshops","","","","","","","","","","","","","","",""
"B8VI7ABV","conferencePaper","2012","Warkozek, G.; Drayer, E.; Debusschere, V.; Bacha, S.","A new approach to model energy consumption of servers in data centers","","","","10.1109/ICIT.2012.6209940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863895161&doi=10.1109%2fICIT.2012.6209940&partnerID=40&md5=02e0d3298ca5f771077b6991984e2100","Electricity consumption of data centers increases continuously. Beside of the IT industry which tries to reduce this consumption by improving efficiency of components in data centers, there are research solutions based on an optimized energy management of data centers by acting on the IT load placement, then on cooling, start-up and shut down. In this context, this paper focus on energetic modeling of servers in data centers. In the state of art, the IT load is usually presented as a whole unit by means of the percentage CPU, while in this work, the percentage CPU is separated in two parts. The first one is the percentage CPU due to server self applications (for example a virtual machine manager), while the second part is due to services turning on the server. This classification led to a new linear model which shows that electricity consumption of data centers can be modeled as accumulated layers depending on what kind of software is running on the servers. The model is developed and then validated with experimental measurements on actual server conduct with the help of industrial partners. This modeling presents the first step of further works aim to optimize the energy consumption of data centers by knowing the IT load that is held on its servers. © 2012 IEEE.","2012","2025-10-22 19:07:46","2025-10-22 19:07:46","","211-216","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Energy efficiency; Datacenter; New approaches; Energy-consumption; Green computing; Virtual machine; Network security; Modeling; energy efficiency; data center; energy consumption; IT industry; modeling; virtual machine; Electricity-consumption; CPU usage; Improving efficiency; Is researches; Optimized energy managements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2012 IEEE International Conference on Industrial Technology, ICIT 2012, Proceedings","","","","","","","","","","","","","","",""
"7CCI2WM8","conferencePaper","2016","Ahvar, E.; Ahvar, S.; Crespi, N.; Garcia-Alfaro, J.; Mann, Z.A.","NACER: A network-aware cost-efficient resource allocation method for processing-intensive tasks in distributed clouds","","","","10.1109/NCA.2015.37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963542034&doi=10.1109%2fNCA.2015.37&partnerID=40&md5=6975b2bdca6a360ac93b06ff947e0d65","In the distributed cloud paradigm, data centers are geographically dispersed and interconnected over a wide-area network. Due to the geographical distribution of data centers, communication networks play an important role in distributed clouds in terms of communication cost and QoS. Large-scale, processing-intensive tasks require the cooperation of many VMs, which may be distributed in more than one data center and should communicate with each other. In this setting, the number of data enters serving the given task and the network distance among those data centers have critical impact on the communication cost, traffic and even completion time of the task. In this paper, we present the NACER algorithm, a Network-Aware Cost-Efficient Resource allocation method for optimizing the placement of largemulti-VM tasks in distributed clouds. NACER builds on ideas of the A∗ search algorithm from Artificial Intelligence research in order to obtain better results than typical greedy heuristics. We present extensive simulation results to compare the performance of NACER with competing heuristics and show its effectiveness. © 2015 IEEE.","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","90-97","","","","","","","","","","","","","","","","Scopus","","","","","","","","Resource allocation; Costs; Extensive simulations; Artificial intelligence; Wide area networks; Geographical distribution; Distributed clouds; Search Algorithms; VM placements; Communication cost; VM placement; Cost-efficient; Greedy heuristics; Artificial intelligence research; Distributed cloud","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 IEEE 14th International Symposium on Network Computing and Applications, NCA 2015","","","","","","","","","","","","","","",""
"Q3Y2XSH2","conferencePaper","2010","Heller, B.; Seetharaman, S.; Mahadevan, P.; Yiakoumis, Y.; Sharma, P.; Banerjee, S.; McKeown, N.","Elastictree: Saving energy in data center networks","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885109587&partnerID=40&md5=9481fd77a3fc956f2b2428be0f9e780f","Networks are a shared resource connecting critical IT infrastructure, and the general practice is to always leave them on. Yet, meaningful energy savings can result from improving a network's ability to scale up and down, as traffic demands ebb and flow. We present ElasticTree, a network-wide power1 manager, which dynamically adjusts the set of active network elements - links and switches - to satisfy changing data center traffic loads. We first compare multiple strategies for finding minimum-power network subsets across a range of traffic patterns. We implement and analyze ElasticTree on a prototype testbed built with production OpenFlow switches from three network vendors. Further, we examine the trade-offs between energy efficiency, performance and robustness, with real traces from a production e-commerce website. Our results demonstrate that for data center workloads, ElasticTree can save up to 50% of network energy, while maintaining the ability to handle traffic surges. Our fast heuristic for computing network subsets enables ElasticTree to scale to data centers containing thousands of nodes. We finish by showing how a network admin might configure ElasticTree to satisfy their needs for performance and fault tolerance, while minimizing their network power bill. © Proceedings of NSDI 2010: 7th USENIX Symposium on Networked Systems Design and Implementation. All rights reserved.","2010","2025-10-22 19:07:46","2025-10-22 19:07:46","","249-264","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Economic and social effects; Systems analysis; Data center networks; Fault tolerance; IT infrastructures; Network element; Shared resources; Traffic pattern; E-commerce websites; Multiple strategy; Openflow switches","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of NSDI 2010: 7th USENIX Symposium on Networked Systems Design and Implementation","","","","","","","","","","","","","","",""
"VWEWCUR2","conferencePaper","2016","Ahvar, E.; Ahvar, S.; Mann, Z.A.; Crespi, N.; Garcia-Alfaro, J.; Glitho, R.","CACEV: A cost and carbon emission-efficient virtual machine placement method for green distributed clouds","","","","10.1109/SCC.2016.43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989840666&doi=10.1109%2fSCC.2016.43&partnerID=40&md5=79736e6b152742d02ad4c4fadd766ae4","Distributed clouds have recently attracted many cloud providers and researchers as a topic of intensive interest. High energy costs and carbon emissions are two significant problems in distributed clouds. Due to the geographic distribution of data centers (DCs), there are a variety of resources, energy prices and carbon emission rates to consider in a distributed cloud, which makes the placement of virtual machines (VMs) for cost and carbon efficiency even more critical than in centralized clouds. Most previous work in this field investigated either optimizing cost without considering the amount of produced carbon or vice versa. This paper presents a cost and carbon emission-efficient VM placement method (CACEV) in distributed clouds. CACEV considers geographically varying energy prices and carbon emission rates as well as optimizing both network and server resources at the same time. By combining prediction-based A∗ algorithm with Fuzzy Sets technique, CACEV makes an intelligent decision to optimize cost and carbon emission for providers. Simulation results show the applicability and performance of CACEV. © 2016 IEEE.","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","275-282","","","","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Java programming language; Energy; Costs; Carbon emissions; Virtual machine placements; Geographical distribution; Data center (DCs); Distributed clouds; VM placements; VM placement; Distributed cloud; Carbon efficiency; Carbon emission; Cost; Intelligent decisions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2016 IEEE International Conference on Services Computing, SCC 2016","","","","","","","","","","","","","","",""
"339P3IYB","journalArticle","2018","Liu, X.-F.; Zhan, Z.-H.; Deng, J.D.; Li, Y.; Gu, T.; Zhang, J.","An Energy Efficient Ant Colony System for Virtual Machine Placement in Cloud Computing","IEEE Transactions on Evolutionary Computation","","","10.1109/TEVC.2016.2623803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041323218&doi=10.1109%2fTEVC.2016.2623803&partnerID=40&md5=0bc23775671f54d3ee44222d97082fcd","Virtual machine placement (VMP) and energy efficiency are significant topics in cloud computing research. In this paper, evolutionary computing is applied to VMP to minimize the number of active physical servers, so as to schedule underutilized servers to save energy. Inspired by the promising performance of the ant colony system (ACS) algorithm for combinatorial problems, an ACS-based approach is developed to achieve the VMP goal. Coupled with order exchange and migration (OEM) local search techniques, the resultant algorithm is termed an OEMACS. It effectively minimizes the number of active servers used for the assignment of virtual machines (VMs) from a global optimization perspective through a novel strategy for pheromone deposition which guides the artificial ants toward promising solutions that group candidate VMs together. The OEMACS is applied to a variety of VMP problems with differing VM sizes in cloud environments of homogenous and heterogeneous servers. The results show that the OEMACS generally outperforms conventional heuristic and other evolutionary-based approaches, especially on VMP with bottleneck resource characteristics, and offers significant savings of energy and more efficient use of different resources. © 1997-2012 IEEE.","2018","2025-10-22 19:07:46","2025-10-22 19:07:46","","113-128","","1","22","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Program compilers; cloud computing; Cloud computing; Distributed computer systems; Green computing; Virtual machine; Network security; Evolutionary algorithms; Virtual machine placements; Ant colony optimization; Ant colony system (ACS); Ant colony system algorithms; Ant colony systems; Bottleneck resources; Combinatorial problem; Evolutionary computing; Global optimization; Heterogeneous servers; Local search techniques; virtual machine placement (VMP)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QYM63MTW","conferencePaper","2016","Rahnamay-Naeini, M.; Baidya, S.S.; Siavashi, E.; Ghani, N.","A traffic and resource-aware energy-saving mechanism in software defined networks","","","","10.1109/ICCNC.2016.7440553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966570570&doi=10.1109%2fICCNC.2016.7440553&partnerID=40&md5=b2cd0db5729db83444365e8c21d2c7e5","Energy-saving mechanisms are crucial in reducing the environmental impact and energy costs of ICT network infrastructures. Integration of renewable energy resources to ICT infrastructures and dynamic energy pricing suggest that not only traffic demands and communication resources but also energy resources should be taken into account in designing energy-saving mechanisms for network infrastructures. With the introduction of Software Defined Networking (SDN) paradigm with a logically centralized controller architecture and programmability of network elements new opportunities have emerged for improving the energy efficiency of the networks. In this paper, by exploiting the SDN features and adopting the idea of powering down unnecessary links to save energy, we formulate an optimization problem for identifying the optimum set of active links that reduces the energy cost of the network while satisfying traffic demands and respecting communication and energy resources. To solve this optimization problem we introduce a computationally efficient heuristic algorithm. Using simulation results, we show that the solutions of the heuristic algorithm reduce the energy cost of the network up to 34% while satisfying the constraints of the problem. © 2016 IEEE.","2016","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Energy Efficiency; Energy conservation; Heuristic algorithms; Costs; Problem solving; Communication resources; Environmental impact; Energy resources; Cost reduction; Computationally efficient; Transportation; Software defined networking; Renewable energy resources; Software defined networking (SDN); Centralized controllers; Constraint satisfaction problems; Energy Price; Energy prices; Energy saving mechanism; Heuristic Algorithm; Integration of renewable energies; Software Defined Networks; Traffic Demand; Traffic demands","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2016 International Conference on Computing, Networking and Communications, ICNC 2016","","","","","","","","","","","","","","",""
"CSPLLYBN","journalArticle","2020","Hassan, H.O.; Azizi, S.; Shojafar, M.","Priority, network and energy-aware placement of IoT-based application services in fog-cloud environments","IET Communications","","","10.1049/iet-com.2020.0007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090241606&doi=10.1049%2fiet-com.2020.0007&partnerID=40&md5=b0ab2d79e10932812521254937d7946a","Fog computing is a decentralised model which can help cloud computing for providing high quality-of-service (QoS) for the Internet of Things (IoT) application services. Service placement problem (SPP) is the mapping of services among fog and cloud resources. It plays a vital role in response time and energy consumption in fog–cloud environments. However, providing an efficient solution to this problem is a challenging task due to difficulties such as different requirements of services, limited computing resources, different delay, and power consumption profile of devices in fog domain. Motivated by this, in this study, we propose an efficient policy, called MinRE, for SPP in fog–cloud systems. To provide both QoS for IoT services and energy efficiency for fog service providers, we classify services into two categories: critical services and normal ones. For critical services, we propose MinRes, which aims to minimise response time, and for normal ones, we propose MinEng, whose goal is reducing the energy consumption of fog environment. Our extensive simulation experiments show that our policy improves the energy consumption up to 18%, the percentage of deadline satisfied services up to 14% and the average response time up to 10% in comparison with the second-best results. © The Institution of Engineering and Technology 2020","2020","2025-10-22 19:07:46","2025-10-22 19:07:46","","2117-2129","","13","14","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Energy efficiency; Cloud environments; Energy utilization; Internet of things; Green computing; Power management (telecommunication); Fog computing; Extensive simulations; Critical service; Computing resource; Energy policy; Fog; Internet of thing (IOT); Service placements; Application services; Service provider","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"75UU7GVW","journalArticle","2015","Zhou, Z.; Hu, Z.-G.; Song, T.; Yu, J.-Y.","A novel virtual machine deployment algorithm with energy efficiency in cloud computing","Journal of Central South University","","","10.1007/s11771-015-2608-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924804281&doi=10.1007%2fs11771-015-2608-5&partnerID=40&md5=525a3fe1e6068ff9427f5b215974925f","In order to improve the energy efficiency of large-scale data centers, a virtual machine (VM) deployment algorithm called three-threshold energy saving algorithm (TESA), which is based on the linear relation between the energy consumption and (processor) resource utilization, is proposed. In TESA, according to load, hosts in data centers are divided into four classes, that is, host with light load, host with proper load, host with middle load and host with heavy load. By defining TESA, VMs on lightly loaded host or VMs on heavily loaded host are migrated to another host with proper load; VMs on properly loaded host or VMs on middling loaded host are kept constant. Then, based on the TESA, five kinds of VM selection policies (minimization of migrations policy based on TESA (MIMT), maximization of migrations policy based on TESA (MAMT), highest potential growth policy based on TESA (HPGT), lowest potential growth policy based on TESA (LPGT) and random choice policy based on TESA (RCT)) are presented, and MIMT is chosen as the representative policy through experimental comparison. Finally, five research directions are put forward on future energy management. The results of simulation indicate that, as compared with single threshold (ST) algorithm and minimization of migrations (MM) algorithm, MIMT significantly improves the energy efficiency in data centers. © 2015, Central South University Press and Springer-Verlag Berlin Heidelberg.","2015","2025-10-22 19:07:46","2025-10-22 19:07:46","","974-983","","3","22","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; cloud computing; Cloud computing; Energy utilization; Energy management; Green computing; Virtual machine; Resource utilizations; energy management; Network security; Large scale data; energy efficiency; Experimental comparison; Deployment algorithms; Potential growth; Selection policies; three-threshold; Threshold energy; virtual machine (VM) selection policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2LJPRN3","conferencePaper","2011","Vasić, N.; Bhurat, P.; Novaković, D.; Canini, M.; Shekhar, S.; Kostić, D.","Identifying and using energy-critical paths","","","","10.1145/2079296.2079314","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889750111&doi=10.1145%2f2079296.2079314&partnerID=40&md5=10e1659fb4a623f3e7641e6fdf07de7a","The power consumption of the Internet and datacenter networks is already significant, and threatens to shortly hit the power delivery limits while the hardware is trying to sustain ever-increasing traffic requirements. Existing energy-reduction approaches in this domain advocate recomputing network configuration with each substantial change in demand. Unfortunately, computing the minimum network subset is computationally hard and does not scale. Thus, the network is forced to operate with diminished performance during the recomputation periods. In this paper, we propose REsPoNse, a framework which overcomes the optimality-scalability trade-off. The insight in REsPoNse is to identify a few energy-critical paths off-line, install them into network elements, and use a simple online element to redirect the traffic in a way that enables large parts of the network to enter a low-power state. We evaluate REsPoNse with real network data and demonstrate that it achieves the same energy savings as the existing approaches, with marginal impact on network scalability and application performance. © 2011 ACM.","2011","2025-10-22 19:07:46","2025-10-22 19:07:46","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Traffic requirements; Application performance; Scalability; Low Power; Experiments; Large parts; Network configuration; Network element; Network scalability; Electric power transmission; Minimum networks; Online elements; Power delivery; Re-computing; Real networks; Recomputation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 7th Conference on Emerging Networking EXperiments and Technologies, CoNEXT'11","","","","","","","","","","","","","","",""
"GDFLVGNC","journalArticle","2017","Khosravi, A.; Andrew, L.L.H.; Buyya, R.","Dynamic VM placement method for minimizing energy and carbon cost in geographically distributed cloud data centers","IEEE Transactions on Sustainable Computing","","","10.1109/TSUSC.2017.2709980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051969893&doi=10.1109%2fTSUSC.2017.2709980&partnerID=40&md5=be7ebd313d414d378d5c862213c43d5c","Cloud data centers consume a large amount of energy that leads to a high carbon footprint. Taking into account a carbon tax imposed on the emitted carbon makes energy and carbon cost play a major role in data centers' operational costs. To address this challenge, we investigate parameters that have the biggest effect on energy and carbon footprint cost to propose more efficient VM placement approaches. We formulate the total energy cost as a function of the energy consumed by servers plus overhead energy, which is computed through power usage effectiveness (PUE) metric as a function of IT load and outside temperature. Furthermore, we consider that data center sites have access to renewable energy sources. This helps to reduce their reliance on 'brown' electricity delivered by off-site providers, which is typically drawn from polluting sources. We then propose multiple VM placement approaches to evaluate their performance and identify the parameters with the greatest impact on the total renewable and brown energy consumption, carbon footprint, and cost. The results show that the approach which considers dynamic PUE, renewable energy sources, and changes in the total energy consumption outperforms the others while still meeting cloud users' service level agreements. © 2016 IEEE.","2017","2025-10-22 19:07:46","2025-10-22 19:07:46","","183-196","","2","2","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Cloud data centers; Energy utilization; Service Level Agreements; Green computing; green computing; Data centers; Carbon footprint; Minimizing energy; energy consumption; Renewable energy resources; Total energy consumption; Emission control; Renewable energy source; data centers; Distributed clouds; VM placements; VM placement; Natural resources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XY7MJ5WG","journalArticle","2014","Möbius, C.; Dargie, W.; Schill, A.","Power consumption estimation models for processors, virtual machines, and servers","IEEE Transactions on Parallel and Distributed Systems","","","10.1109/TPDS.2013.183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901020434&doi=10.1109%2fTPDS.2013.183&partnerID=40&md5=839dc24d2a3a2e2198abe57b81f81200","The power consumption of presently available Internet servers and data centers is not proportional to the work they accomplish. The scientific community is attempting to address this problem in a number of ways, for example, by employing dynamic voltage and frequency scaling, selectively switching off idle or underutilized servers, and employing energy-aware task scheduling. Central to these approaches is the accurate estimation of the power consumption of the various subsystems of a server, particularly, the processor. We distinguish between power consumption measurement techniques and power consumption estimation models. The techniques refer to the art of instrumenting a system to measure its actual power consumption whereas the estimation models deal with indirect evidences (such as information pertaining to CPU utilization or events captured by hardware performance counters) to reason about the power consumption of a system under consideration. The paper provides a comprehensive survey of existing or proposed approaches to estimate the power consumption of single-core as well as multicore processors, virtual machines, and an entire server. © 1990-2012 IEEE.","2014","2025-10-22 19:07:46","2025-10-22 19:07:46","","1600-1614","","6","25","","","","","","","","","","","","","Scopus","","","","","","","","Voltage scaling; Virtual machines; Dynamic frequency scaling; Computer simulation; Dynamic voltage and frequency scaling; energy-efficiency; Scientific community; Hardware performance counters; Energy-aware task scheduling; Power consumption model; Consumption measurement; power consumption estimation; Power consumption estimation; Power consumption models; processor's power consumption; server's power consumption; virtual machine's power consumption","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PV3TKWBC","journalArticle","2017","Forestiero, A.; Mastroianni, C.; Meo, M.; Papuzzo, G.; Sheikhalishahi, M.","Hierarchical Approach for Efficient Workload Management in Geo-Distributed Data Centers","IEEE Transactions on Green Communications and Networking","","","10.1109/TGCN.2016.2603586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044668066&doi=10.1109%2fTGCN.2016.2603586&partnerID=40&md5=144c392d1dd55a8491d0ee597ff1562d","Geographically distributed data centers (DCs) offer promising business opportunities to both big companies that own several sites and multi-owner inter-cloud infrastructures. In these scenarios, workload management is a particularly challenging task, since the autonomy of single DCs should be preserved while global objectives, such as cost reduction and load balance, should be achieved. In this paper, a hierarchical approach for workload management in geographically distributed DCs is presented. The proposed solution is composed of two algorithms devoted to workload assignment and migration. Both algorithms are based on the computation of a simple function that represents the cost of running some workload in the different sites of the distributed DC. The framework requires a very limited exchange of state information among the sites and preserves the autonomy of single DCs and, at the same time, allows for an integrated management of heterogeneous platforms. Performance is analyzed for a specific infrastructure composed of four DCs, with two goals: 1) load balance and 2) energy cost reduction. Results show that the proposed approach smoothly adapts the workload distribution to variations of energy cost and load, while achieving the desired combination of management objectives. © 2017 IEEE.","2017","2025-10-22 19:07:46","2025-10-22 19:07:46","","97-111","","1","1","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Resource allocation; Energy conservation; Business opportunities; Cost saving; energy saving; Cost reduction; Vm migrations; cost saving; load balancing; Work-load distribution; Energy cost reduction; Geographical data; geographical data centers; Heterogeneous platforms; Integrated management; VM migrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QB5UMUQ6","journalArticle","2011","Calheiros, R.N.; Ranjan, R.; Beloglazov, A.; De Rose, C.A.F.; Buyya, R.","CloudSim: A toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms","Software - Practice and Experience","","","10.1002/spe.995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650777991&doi=10.1002%2fspe.995&partnerID=40&md5=e5acc8ba81ccb3bce707222348c8d53b","Cloud computing is a recent advancement wherein IT infrastructure and applications are provided as 'services' to end-users under a usage-based payment model. It can leverage virtualized services even on the fly based on requirements (workload patterns and QoS) varying with time. The application services hosted under Cloud computing model have complex provisioning, composition, configuration, and deployment requirements. Evaluating the performance of Cloud provisioning policies, application workload models, and resources performance models in a repeatable manner under varying system and user configurations and requirements is difficult to achieve. To overcome this challenge, we propose CloudSim: an extensible simulation toolkit that enables modeling and simulation of Cloud computing systems and application provisioning environments. The CloudSim toolkit supports both system and behavior modeling of Cloud system components such as data centers, virtual machines (VMs) and resource provisioning policies. It implements generic application provisioning techniques that can be extended with ease and limited effort. Currently, it supports modeling and simulation of Cloud computing environments consisting of both single and inter-networked clouds (federation of clouds). Moreover, it exposes custom interfaces for implementing policies and provisioning techniques for allocation of VMs under inter-networked Cloud computing scenarios. Several researchers from organizations, such as HP Labs in U.S.A., are using CloudSim in their investigation on Cloud resource provisioning and energy-efficient management of data center resources. The usefulness of CloudSim is demonstrated by a case study involving dynamic provisioning of application services in the hybrid federated clouds environment. The result of this case study proves that the federated Cloud computing model significantly improves the application QoS requirements under fluctuating resource and service demand patterns. Copyright © 2010 John Wiley & Sons, Ltd.","2011","2025-10-22 19:07:46","2025-10-22 19:07:46","","23-50","","1","41","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Cloud computing; resource management; Resource management; Distributed computer systems; Clouds; Natural resources management; Resource allocation; Mathematical models; Performance evaluation; Research; application scheduling; Application scheduling; Computer simulation; modelling and simulation; Modelling and simulations; performance evaluation; Satellite communication systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JU6V9DA","conferencePaper","2009","Voorsluys, W.; Broberg, J.; Venugopal, S.; Buyya, R.","Cost of virtual machine live migration in clouds: A performance evaluation","","","","10.1007/978-3-642-10665-1_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71749095784&doi=10.1007%2f978-3-642-10665-1_23&partnerID=40&md5=ced1b0a8ca8421f33593bb8dd3698095","Virtualization has become commonplace in modern data centers, often referred as ""computing clouds"". The capability of virtual machine live migration brings benefits such as improved performance, manageability and fault tolerance, while allowing workload movement with a short service downtime. However, service levels of applications are likely to be negatively affected during a live migration. For this reason, a better understanding of its effects on system performance is desirable. In this paper, we evaluate the effects of live migration of virtual machines on the performance of applications running inside Xen VMs. Results show that, in most cases, migration overhead is acceptable but cannot be disregarded, especially in systems where availability and responsiveness are governed by strict Service Level Agreements. Despite that, there is a high potential for live migration applicability in data centers serving modern Internet applications. Our results are based on a workload covering the domain of multi-tier Web 2.0 applications. © 2009 Springer-Verlag.","2009","2025-10-22 19:07:46","2025-10-22 19:07:46","","254-265","","","5931 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Datacenter; Performance; Virtualizations; Virtual machines; Migration; Virtual machine; Cloud platforms; Performance evaluation; Performances evaluation; Live migrations; Xen; Systems performance; Computing clouds; Service levels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"YFXBBJYV","journalArticle","2009","Calheiros, R.N.; Ranjan, R.; De Rose, C.A.F.; Buyya, R.","CloudSim: A novel framework for modeling and simulation of cloud computing infrastructures and services","CloudSim: A Novel Framework for Modeling and Simulation of Cloud Computing Infrastructures and Services","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73849141413&partnerID=40&md5=14fe9d9f1b05364d29c089b256061c15","","2009","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GETMEEQ","journalArticle","2017","Mann, Z.Á.; Szabó, M.","Which is the best algorithm for virtual machine placement optimization?","Concurrency and Computation: Practice and Experience","","","10.1002/cpe.4083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016277509&doi=10.1002%2fcpe.4083&partnerID=40&md5=805b2f0a1d8771c5d33845276a07e882","One of the key problems for Infrastructure-as-a-Service providers is finding the optimal allocation of virtual machines on the physical machines available in the provider's data center. Since the allocation has significant impact on operational costs as well as on the performance of the accommodated applications, several algorithms have been proposed for the virtual machine placement problem. So far, no objective comparison of the proposed algorithms has been provided; therefore, it is not known which one works best or what factors influence the performance of the algorithms. In this paper, we present an environment and methodology for such comparisons and compare 7 different algorithms using the proposed environment and methodology. Our results showcase differences of up to 66% between the effectiveness of different algorithms on the same real-world workload traces, thus underlining the importance of objectively comparing the performance of competing algorithms. Copyright © 2017 John Wiley & Sons, Ltd.","2017","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","10","29","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; Infrastructure as a service (IaaS); Virtual machine; Data centers; Network security; VM consolidation; data center; Virtual machine placements; VM placements; VM placement; Competing algorithms; Infrastructure-as-a-Service; Optimal allocation; Real-world; virtual machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFRHU9WA","journalArticle","2021","Wang, S.; Guo, Y.; Zhang, N.; Yang, P.; Zhou, A.; Shen, X.","Delay-Aware Microservice Coordination in Mobile Edge Computing: A Reinforcement Learning Approach","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2019.2957804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100825426&doi=10.1109%2fTMC.2019.2957804&partnerID=40&md5=5d00c7389a242d200734018ecee0b0e6","As an emerging service architecture, microservice enables decomposition of a monolithic web service into a set of independent lightweight services which can be executed independently. With mobile edge computing, microservices can be further deployed in edge clouds dynamically, launched quickly, and migrated across edge clouds easily, providing better services for users in proximity. However, the user mobility can result in frequent switch of nearby edge clouds, which increases the service delay when users move away from their serving edge clouds. To address this issue, this article investigates microservice coordination among edge clouds to enable seamless and real-time responses to service requests from mobile users. The objective of this work is to devise the optimal microservice coordination scheme which can reduce the overall service delay with low costs. To this end, we first propose a dynamic programming-based offline microservice coordination algorithm, that can achieve the globally optimal performance. However, the offline algorithm heavily relies on the availability of the prior information such as computation request arrivals, time-varying channel conditions and edge cloud's computation capabilities required, which is hard to be obtained. Therefore, we reformulate the microservice coordination problem using Markov decision process framework and then propose a reinforcement learning-based online microservice coordination algorithm to learn the optimal strategy. Theoretical analysis proves that the offline algorithm can find the optimal solution while the online algorithm can achieve near-optimal performance. Furthermore, based on two real-world datasets, i.e., the Telecom's base station dataset and Taxi Track dataset from Shanghai, experiments are conducted. The experimental results demonstrate that the proposed online algorithm outperforms existing algorithms in terms of service delay and migration costs, and the achieved performance is close to the optimal performance obtained by the offline algorithm.  © 2002-2012 IEEE.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","939-951","","3","20","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Migration; Edge clouds; Optimal systems; Web services; Mobile edge computing; computation offloading; Reinforcement learning; Markov processes; Dynamic programming; Delay; On-line algorithms; mobile edge computing; migration; Service delays; delay; Optimal performance; coordination; Coordination; Coordination algorithms; Off-line algorithm; Taxicabs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LY9Q4KLA","conferencePaper","2022","Simanjuntak, E.; Surantha, N.; Isa, S.M.","Evaluation of time-series database on microservice architecture for health monitoring system","","","","10.1109/ISESD56103.2022.9980618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146216621&doi=10.1109%2fISESD56103.2022.9980618&partnerID=40&md5=74b1b68edd7e869cff161f1d99bbe56d","Recently, the research on daily health monitoring using a wearable sensor has been continually evolving. In the future, when this system is actually implemented, a vast amount of data transmission will be conducted from multiple sensors to the cloud server. A system capable of transmitting, storing, processing, and visualizing massive volumes of data is necessary for health monitoring. This research aims to develop a health monitoring system that can accommodate a high amount of data with high performance. The proposed techniques include numerous modifications to system architecture and technology. In the system architecture, a multi-database is proposed to enhance the reliability of the system. As an enhancement to the technology aspect, a time series database and MQTT server are proposed. As the result, the proposed system achieves significantly better performance in terms of throughput, database-writing speed, and database-reading speed compared to the existing system.  © 2022 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Performance; Internet of things; Computer architecture; Architecture; Database systems; Time series; Cloud servers; Health monitoring; Data-transmission; Digital health; Digital Health; Health Monitoring; Health monitoring system; Internet-of-Things; Multiple sensors; Systems architecture; Time Series Database; Time-series database; Wearable sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ISESD 2022 - 2022 International Symposium on Electronics and Smart Devices, Proceeding","","","","","","","","","","","","","","",""
"E5IVCWF7","journalArticle","2015","Prometheus, M.","Open-source systems monitoring and alerting toolkit","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219497659&partnerID=40&md5=6bd26e1b0f55acc6cd4ca23aa22fb2f9","","2015","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQWUXRCR","journalArticle","2020","Redis team, A.","An in-memory database that persists on disk","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219501042&partnerID=40&md5=f1dbfeed68d9b97dd005d266b0ded871","","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWAV5F53","journalArticle","2020","Zhang, Q.; Gui, L.; Hou, F.; Chen, J.; Zhu, S.; Tian, F.","Dynamic Task Offloading and Resource Allocation for Mobile-Edge Computing in Dense Cloud RAN","IEEE Internet of Things Journal","","","10.1109/JIOT.2020.2967502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081559496&doi=10.1109%2fJIOT.2020.2967502&partnerID=40&md5=1253c1482d5dec255243e46247d5a6a8","With the unprecedented development of smart mobile devices (SMDs), e.g., Internet-of-Things devices and smartphones, various computation-intensive applications are explosively increasing in ultradense networks (UDNs). Mobile-edge computing (MEC) has emerged as a key technology to alleviate the computation workloads of SMDs and decrease service latency for computation-intensive applications. With the benefits of network function virtualization, MEC can be integrated with the cloud radio access network (C-RAN) in UDNs for computation and communication cooperation. However, with stochastic computation task arrivals and time-varying channel states, it is challenging to offload computation tasks online with energy-efficient computation and radio resource management. In this article, we investigate the task offloading and resource allocation problem in MEC-enabled dense C-RAN, aiming at optimizing network energy efficiency. A stochastic mixed-integer nonlinear programming problem is formulated to jointly optimize the task offloading decision, elastic computation resource scheduling, and radio resource allocation. To tackle the problem, the Lyapunov optimization theory is introduced to decompose the original problem into four individual subproblems which are solved by convex decomposition methods and matching game. We theoretically analyze the tradeoff between energy efficiency and service delay. Extensive simulations evaluate the impacts of system parameters on both energy efficiency and service delay. The simulation results also validate the superiority of the proposed task offloading and resource allocation scheme in dense C-RAN. © 2014 IEEE.","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","3282-3299","","4","7","","","","","","","","","","","","","Scopus","","","","","","","","Internet protocols; Energy efficiency; Edge computing; Computation theory; Radio access networks; Resource allocation; Integer programming; Network function virtualization; Stochastic systems; task offloading; Nonlinear programming; resource allocation; mobile-edge computing (MEC); Radio; Resource allocation problem; Computation intensives; Radio resource allocation; Cloud radio access network (C-RAN); Lyapunov optimization; Mixed integer non-linear programming problems; Radio resource management; Resource allocation schemes; Site selection; Stochastic computations; Time-varying channel state; ultradense network (UDN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MR4JF9QS","journalArticle","2023","Rezaei Nasab, A.; Shahin, M.; Hoseyni Raviz, S.A.; Liang, P.; Mashmool, A.; Lenarduzzi, V.","An empirical study of security practices for microservices systems","Journal of Systems and Software","","","10.1016/j.jss.2022.111563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144630737&doi=10.1016%2fj.jss.2022.111563&partnerID=40&md5=fd7865e9b51a9f61b4d2a72af4e4dfb2","Despite the numerous benefits of microservices systems, security has been a critical issue in such systems. Several factors explain this difficulty, including a knowledge gap among microservices practitioners on properly securing a microservices system. To (partially) bridge this gap, we conducted an empirical study. We first manually analyzed 861 microservices security points, including 567 issues, 9 documents, and 3 wiki pages from 10 GitHub open-source microservices systems and 306 Stack Overflow posts concerning security in microservices systems. In this study, a microservices security point is referred to as “a GitHub issue, a Stack Overflow post, a document, or a wiki page that entails 5 or more microservices security paragraphs”. Our analysis led to a catalog of 28 microservices security practices. We then ran a survey with 74 microservices practitioners to evaluate the usefulness of these 28 practices. Our findings demonstrate that the survey respondents affirmed the usefulness of the 28 practices. We believe that the catalog of microservices security practices can serve as a valuable resource for microservices practitioners to more effectively address security issues in microservices systems. It can also inform the research community of the required or less explored areas to develop microservices-specific security practices and tools. © 2022 Elsevier Inc.","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","198","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Open systems; Empirical studies; Security systems; Security; Critical issues; Empirical study; Practice; Practitioner; Practitioners; Security point; Security Practice; Stack overflow; System security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UBPQSB56","journalArticle","2024","Calagna, A.; Yu, Y.; Giaccone, P.; Chiasserini, C.F.","Design, Modeling, and Implementation of Robust Migration of Stateful Edge Microservices","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2023.3331750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177080673&doi=10.1109%2fTNSM.2023.3331750&partnerID=40&md5=8fa1775eedd8f19b5808eda7a56ca2ac","Stateful migration has emerged as the key solution to support latency-sensitive microservices at the edge while ensuring a satisfying experience for mobile users. In this paper, we address two relevant issues affecting stateful migration, namely, the migration of containerized microservices and that of the associated data connection. We do so by first introducing a novel network solution, based on OvS, that permits to preserve the established connection with mobile end users upon migrating a microservice. Then, using Podman and CRIU, we experimentally characterize the fundamental migration KPIs, i.e., migration duration and microservice downtime, and we devise an analytical model that, accounting for all the relevant real-world aspects of stateful migration, provides an accurate upper bound on such KPIs. We validate our model using real-world microservices, namely, MQTT Broker and Memcached, and show that it can predict KPIs values with an error that is up to 99.7% smaller than that yielded by the state of the art. Finally, we consider a UAV controller as relevant microservice use case and demonstrate how our model can be exploited to effectively configure the system parameters so that the required QoE level is met. © 2004-2012 IEEE.","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","1877-1893","","2","21","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Containers; Microservice; microservices; Virtual reality; Migration; Transfer functions; Iterative methods; Network function virtualization; Modeling; Microservice architecture; Experimental analysis; modeling; Quality of experience; network function virtualization; Real-world; Design implementation; Design models; experimental analysis; Image reconstruction; Socket","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5N5T87Q","journalArticle","2018","Garg, S.; Singh, A.; Batra, S.; Kumar, N.; Yang, L.T.","UAV-Empowered Edge Computing Environment for Cyber-Threat Detection in Smart Vehicles","IEEE Network","","","10.1109/MNET.2018.1700286","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048335823&doi=10.1109%2fMNET.2018.1700286&partnerID=40&md5=ac7585fdceaa29e9ae06b26c0362cd8b","Over the last few years, we have witnessed an exponential increase in the computing and storage capabilities of smart devices that has led to the popularity of an emerging technology called edge computing. Compared to the traditional cloud-computing- based infrastructure, computing and storage facilities are available near end users in edge computing. Moreover, with the widespread popularity of unmanned aerial vehicles (UAVs), huge amounts of information will be shared between edge devices and UAVs in the coming years. In this scenario, traffic surveillance using UAVs and edge computing devices is expected to become an integral part of the next generation intelligent transportation systems. However, surveillance in ITS requires uninterrupted data sharing, cooperative decision making, and stabilized network formation. Edge computing supports data processing and analysis closer to the deployed machines (i.e., the sources of the data). Instead of simply storing data and missing the opportunity to capitalize on it, edge devices can analyze data to gain insights before acting on them. Transferring data from the vehicle to the edge for real-time analysis can be facilitated by the use of UAVs, which can act as intermediate aerial nodes between the vehicles and edge nodes. However, as the communication between UAVs and edge devices is generally done using an open channel, there is a high risk of information leakage in this environment. Keeping our focus on all these issues, in this article, we propose a data-driven transportation optimization model where cyber-threat detection in smart vehicles is done using a probabilistic data structure (PDS)- based approach. A triple Bloom filter PDS- based scheduling technique for load balancing is initially used to host the real-time data coming from different vehicles, and then to distribute/collect the data to/from edges in a manner that minimizes the computational effort. The results obtained show that the proposed system requires comparatively less computational time and storage for load sharing, authentication, encryption, and decryption of data in the considered edge-computing-based smart transportation framework. © 1986-2012 IEEE.","2018","2025-10-22 19:07:47","2025-10-22 19:07:47","","42-51","","3","32","","","","","","","","","","","","","Scopus","","","","","","","","Data structures; Edge computing; Emerging technologies; Decision making; Digital storage; Cryptography; Computing environments; Scheduling techniques; Authentication; Intelligent systems; Intelligent vehicle highway systems; Antennas; Unmanned aerial vehicles (UAV); Aircraft detection; Computational time and storage; Cooperative decision making; Data processing and analysis; Highway traffic control; Intelligent transportation systems; Transportation optimizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"58HH43D9","journalArticle","2018","Furda, A.; Fidge, C.; Zimmermann, O.; Kelly, W.; Barros, A.","Migrating Enterprise Legacy Source Code to Microservices: On Multitenancy, Statefulness, and Data Consistency","IEEE Software","","","10.1109/MS.2017.440134612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038819187&doi=10.1109%2fMS.2017.440134612&partnerID=40&md5=1dbc4fe57ed5beb49221566eebb5d3ae","Microservice migration is a promising technique to incrementally modernize monolithic legacy enterprise applications and enable them to exploit the benefits of cloud-computing environments. This article elaborates on three challenges of microservice migration: Multitenancy, statefulness, and data consistency. The authors show how to identify each of these challenges in legacy code and explain refactoring and architectural pattern-based migration techniques relevant to microservice architectures. They explain how multitenancy enables microservices to be utilized by different organizations with distinctive requirements, why statefulness affects both the availability and reliability of a microservice system, and why data consistency challenges are encountered when migrating legacy code that operates on a centralized data repository to microservices operating on decentralized data repositories. They also explain the interdependencies between multitenancy, statefulness, and data consistency. © 1984-2012 IEEE.","2018","2025-10-22 19:07:47","2025-10-22 19:07:47","","63-72","","3","35","","","","","","","","","","","","","Scopus","","","","","","","","Codes (symbols); Cloud computing; microservices; Distributed computer systems; Refactorings; software development; software engineering; Software engineering; User interfaces; Communication; Computer systems organization; Emerging technologies; Computation theory; Computer software; Web services; Websites; Database systems; Object recognition; Scalability; Information services; Service oriented architecture (SOA); Services Architectures; refactoring; Architectural pattern; Logic gates; Services computing; Multi tenancies; Object oriented programming; Industry; architectural patterns; data consistency; general; multitenancy; Pattern recognition systems; principles of services; Stateful web services; statefulness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LATQSDRS","journalArticle","2020","Iorio, M.; Palesandro, A.; Risso, F.","CrownLabs - A Collaborative Environment to Deliver Remote Computing Laboratories","IEEE Access","","","10.1109/ACCESS.2020.3007961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088692482&doi=10.1109%2fACCESS.2020.3007961&partnerID=40&md5=b597a2bbacc990d990c70da758580a02","The coronavirus pandemic hit the entire education sector hard. All students were sent home and lectures started to be delivered through video-conferencing systems. CrownLabs is an open-source project providing an answer to the problem of delivering remote computing laboratories. Simplicity is one of its main characteristics, requiring nothing but a simple web browser to interact with the system and being all heavyweight computations performed at the university premises. Cooperation and mentoring are also encouraged through parallel access to the same remote desktop. The entire system is built up using components from the Kubernetes ecosystem, to replicate a 'cloud grade' infrastructure, coupled with custom software implementing the core business logic. To this end, most of the complexity has been delegated to the infrastructure, to speed up the development process and reduce the maintenance burden. An extensive evaluation has been performed in both real and simulated scenarios to validate the overall performance: the results are encouraging, as well as the feedback from the early adopters of the system. © 2013 IEEE.","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","126428-126442","","","8","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Open systems; Petroleum reservoir evaluation; software architecture; kubernetes; Open source projects; Video conferencing; Collaborative environments; Collaborative software; computer science education; Core business; Development process; Education sectors; Entire system; laboratories; learning systems; platform virtualization; Remote computing; Telecommuting; Video conferencing system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3FS4USU","journalArticle","2023","Li, B.; Liu, W.; Xie, W.; Li, X.","Energy-efficient task offloading and trajectory planning in UAV-enabled mobile edge computing networks","Computer Networks","","","10.1016/j.comnet.2023.109940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165908841&doi=10.1016%2fj.comnet.2023.109940&partnerID=40&md5=8c6050f9d3493143ae238febe461928a","In order to meet the double-sided challenges brought by the shortage of computation resources and energy of users, we investigate in this paper the optimization of energy efficiency (EE) in an unmanned aerial vehicle (UAV)-assisted wireless network, where UAV is functioned as a flying energy station and edge server to provide charging and computing services for ground users. We aim to maximize the average EE of the mobile edge computing network by the joint design of user transmit power, user computing frequency, UAV transmit power, bandwidth allocation, and UAV trajectory planning under strict energy and power constraints. In order to solve such challenging problem, we first elaborately construct a Markov decision process to model task offloading and resource allocation by learning from past experiences. Then, an average EE maximization method relying on deep reinforcement learning (DRL) is designed to efficiently adjust task offloading policy, where the policy of agent can be gradually improved by interacting with the environment and collecting the experience for learning. Finally, the EE-maximization proximal policy optimization (EE-PPO) algorithm is proposed to train the DRL agent and thereby solve this optimization problem. Numerical results are given to indicate that the proposed EE-PPO method has the properties of both fast convergence and well performance. © 2023 Elsevier B.V.","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","234","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Deep learning; Energy efficient; Computation offloading; Mobile edge computing; Deep reinforcement learning; Reinforcement learning; Reinforcement learnings; Markov processes; Aerial vehicle; Antennas; Unmanned aerial vehicle; Unmanned aerial vehicles (UAV); Energy harvesting; Task offloading; Average energy; Efficiency maximization; Trajectory Planning; Transmit power","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"II8LVNW8","journalArticle","2024","Amanatidis, P.; Karampatzakis, D.; Michailidis, G.; Lagkas, T.; Iosifidis, G.","Adaptive reverse task offloading in edge computing for AI processes","Computer Networks","","","10.1016/j.comnet.2024.110844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206344272&doi=10.1016%2fj.comnet.2024.110844&partnerID=40&md5=c26274779dedc87d98de3faa0177f0e1","Nowadays, we witness the proliferation of edge IoT devices, ranging from smart cameras to autonomous vehicles, with increasing computing capabilities, used to implement AI-based services in users’ proximity, right at the edge. As these services are often computationally demanding, the popular paradigm of offloading their tasks to nearby cloud servers has gained much traction and been studied extensively. In this work, we propose a new paradigm that departs from the above typical edge computing offloading idea. Namely, we argue that it is possible to leverage these end nodes to assist larger nodes (e.g., cloudlets) in executing AI tasks. Indeed, as more and more end nodes are deployed, they create an abundance of idle computing capacity, which, when aggregated and exploited in a systematic fashion, can be proved beneficial. We introduce the idea of reverse offloading and study a scenario where a powerful node splits an AI task into a group of subtasks and assigns them to a set of nearby edge IoT nodes. The goal of each node is to minimize the overall execution time, which is constrained by the slowest subtask, while adhering to predetermined energy consumption and AI performance constraints. This is a challenging MINLP (Mixed Integer Non-Linear Problem) optimization problem that we tackle with a novel approach through our newly introduced EAI-ARO (Edge AI-Adaptive Reverse Offloading) algorithm. Furthermore, a demonstration of the efficacy of our reverse offloading proposal using an edge computing testbed and a representative AI service is performed. The findings suggest that our method optimizes the system's performance significantly when compared with a greedy and a baseline task offloading algorithm. © 2024","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","255","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Edge computing; Computation offloading; Resource allocation; Computing capability; Optimisations; Resources allocation; Cloud servers; Task offloading; Smart cameras; Mixed-integer linear programming; AI process; AI processes; Autonomous Vehicles; Integer linear programming; Subtask","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6EV2IBXM","journalArticle","2024","Yang, Q.; Chu, S.-C.; Hu, C.-C.; Kong, L.; Pan, J.-S.","A Task Offloading Method Based on User Satisfaction in C-RAN With Mobile Edge Computing","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2023.3275580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162912214&doi=10.1109%2fTMC.2023.3275580&partnerID=40&md5=0f8e674dc10f22de02c864cd587a02f4","With the continuous development of the communication service industry, users pay more attention to the quality of network service. Previous studies on offloading problems, especially in the Cloud Radio Access Network (C-RAN) architecture with Mobile Edge Computing (MEC), are primarily focused on the economic perspective, with little consideration given to user-oriented satisfaction problems. To fill this gap, this article proposes a mathematical model for maximizing user satisfaction in the C-RAN architecture with multi-layer MEC. The problem is divided into two stages for solution. The first stage addresses the optimal connection problem between users and Remote Radio Heads (RRHs). The second stage then schedules user tasks reasonably based on the solution obtained in the first stage. The two-stage problems are all proved to be NP-Hard. Two efficient approximation algorithms, namely User-to-RRH Association Algorithm (URAA) and Maximum Satisfaction Algorithm (MSA), are proposed to solve the problems in different stages. This article proves and analyzes the theoretical performance of the two algorithms. Finally, the performance of the proposed algorithms is verified by simulation experiments. The experimental results demonstrate that the two proposed algorithms can achieve reasonable solutions to the problems, and the user satisfaction level can be maintained at a high level. © 2002-2012 IEEE.","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","3452-3465","","4","23","","","","","","","","","","","","","Scopus","","","","","","","","Computer architecture; Network architecture; Radio access networks; Mobile edge computing; Approximation algorithms; Job analysis; Task analysis; Users' satisfactions; Delay; task offloading; Continuous development; mobile edge computing; Mobile handsets; Task offloading; Approximation algorithm; cloud radio access network; Cloud radio access network; Remote radio heads; user statisfaction; User statisfaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F7Z5QVRT","journalArticle","2022","Bitnami, M.","Redis helm chart","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219496574&partnerID=40&md5=69d5ed82e7eeb07c76a5afd52d4b0a5b","","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W8VFHQFI","conferencePaper","2021","Mateus-Coelho, N.; Cruz-Cunha, M.; Ferreira, L.G.","Security in microservices architectures","","","","10.1016/j.procs.2021.01.320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105682499&doi=10.1016%2fj.procs.2021.01.320&partnerID=40&md5=51eebd544c9029f7af4b795b9df60018","A Microservice is a small or even micro independent process that communicates, acts, and returns via messages through lightweight mechanisms like Thrift, HTTP or RESTAPI. Microservices Architecture is amateur evolution of the Monolithic Architecture. Observing it in afunctional way, it is correct to claim that it breaks down complex applications into a simpler abstraction. As this research demonstrates, Microservices Architecture is intrinsically connected as a symbiosis with container-based deployment, because these containers have no need for embedded operating systems and calls are made for OS resources, via an application programming interface. It is safe to claim that this technology is currently the focus of modern developers nowadays. Semantically speaking, Microservices functionally deconstruct larger applications into smaller, discrete services, and containers are viewed as a natural compute platform for this architecture [1]. A single service is and can be represented by multiple containers in a Microservices cluster, each single service is designed to provide a specific set of functions while services act to makeup the entire application. It's common in large application the decomposition into multiple arms of more than twenty services, although less can be commonly found as well [1]. The main objective of Microservices Architecture is to disassemble the core components of a given type of application [2]. This study could be done in multiple ways, all of them different because practically everybody has their specific way of looking at Microservices, but one aspect is the same cross mentalities, Security. So, the focus of this research is to expose the main security aspects of this specific architecture, in this cost-effective era. © 2021 The Authors. Published by Elsevier B.V.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","1225-1236","","","181","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Embedded systems; Architecture; Complex applications; Application programming interfaces (API); Cost effectiveness; Monolithic architecture; Core components; Simple++; Applications programming interfaces; Break down; Elsevier; Embedded operating systems; Multiple arms; Security aspects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Procedia Computer Science","","","","","","","","","","","","","","",""
"49C5PGN9","journalArticle","2012","Gilbert, S.; Lynch, N.","Perspectives on the CAP theorem","Computer","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869219414&partnerID=40&md5=fd5eb1ba6815c1913d7d006a510df35b","","2012","2025-10-22 19:07:47","2025-10-22 19:07:47","","30-36","","2","45","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGKLZEVM","conferencePaper","2021","Kulkarni, U.; Sheoran, A.; Fahmy, S.","The Cost of Stateless Network Functions in 5G","","","","10.1145/3493425.3502749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124120008&doi=10.1145%2f3493425.3502749&partnerID=40&md5=883b8fad229c1558ac13eee9a88d0348","The adoption of a cloud-native architecture in 5G networks has facilitated rapid deployment and update of cellular services. An important part of this architecture is the implementation of 5G network functions statelessly. However, statelessness and its associated serialization and de-serialization of data and database interaction significantly increase latency. In this work, we take the first steps towards quantifying the cost of statelessness in a cloud-native 5G system. We compare the cost of different state management paradigms, and propose a number of optimizations to reduce this cost. Our preliminary results indicate that sharing user state among 5G functions reduces the overall cost by on an average of 10% in experiments with 100 to 1000 simultaneous requests. Optimizations such as non-blocking calls and custom database APIs also reduce cost, albeit to a lower extent. We believe that the paradigms proposed in this paper can aid operators and software vendors as they design cloud-native 5G networks.  © 2021 Owner/Author.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","73-79","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer architecture; Network functions; 5G mobile communication systems; Transfer functions; Network function virtualization; Rapid deployments; Optimisations; Cost reduction; Queueing networks; 5G; Cellular network; Cellular networks; Cellular services; Cloud-native architecture; Cloud-native architectures; Data interactions; Database interactions; State management; Stateless network function; Stateless Network Functions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ANCS 2021 - Proceedings of the 2021 Symposium on Architectures for Networking and Communications Systems","","","","","","","","","","","","","","",""
"FG9XR785","conferencePaper","2024","Akbari, M.; Bolla, R.; Bruschi, R.; Davoli, F.; Lombardo, C.; Siccardi, B.","A Monitoring, Observability and Analytics Framework to Improve the Sustainability of B5G Technologies","","","","10.1109/ICCWorkshops59551.2024.10615948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202432426&doi=10.1109%2fICCWorkshops59551.2024.10615948&partnerID=40&md5=34eec1c64c72d41eb7624a1924f8abd6","As mobile generations advance, blurring the lines between physical and digital worlds, the deployment of ultra-dense networks poses challenges in resource allocation and energy efficiency. This article revolves around the environmental sustainability of Fifth Generation (5G) and Beyond 5G (B5G) mobile networks as cloud-native technologies, highlighting the use phase. It aims to represent a monitoring, observability and analytical framework to devise a feature selection methodology within well-known monitoring tools, aligning with environmental sustainability objectives. Notable open-source monitoring applications (e.g., Kepler and Scaphandre) are employed to collect data on resource utilization and energy consumption for containers and physical servers. Dependence criteria indexes, Hilbert-Schmidt Independence Criterion (HSIC) and Pearson, identify interdependencies among timeseries from different tools. Addressing challenges, the paper resolves inconsistent dataset lengths, highlights the Pearson-HSIC trade-off, and underscores the need for alignment in feature selection with compatibility to resource utilization. Key findings include Scaphandre's underestimation of memory impact on power consumption, Kepler's limitations in host metrics. Finally, the results enable the development of an anomaly detection mechanism. © 2024 IEEE.","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","969-975","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; monitoring; Energy; 5G mobile communication systems; Resource allocation; Resources utilizations; anomaly detection; Anomaly detection; energy efficiency; Environmental sustainability; B5G; Beyond 5g; Digital world; feature reduction; Features reductions; Features selection; Hilbert-schmidt independence criterions; observability; Physical world","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2024 IEEE International Conference on Communications Workshops, ICC Workshops 2024","","","","","","","","","","","","","","",""
"S9FD34GM","journalArticle","2022","McEnroe, P.; Wang, S.; Liyanage, M.","A Survey on the Convergence of Edge Computing and AI for UAVs: Opportunities and Challenges","IEEE Internet of Things Journal","","","10.1109/JIOT.2022.3176400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130441199&doi=10.1109%2fJIOT.2022.3176400&partnerID=40&md5=2dc9b4aa36de54eb5cb6dd4019b21d86","The latest 5G mobile networks have enabled many exciting Internet of Things (IoT) applications that employ unmanned aerial vehicles (UAVs/drones). The success of most UAV-based IoT applications is heavily dependent on artificial intelligence (AI) technologies, for instance, computer vision and path planning. These AI methods must process data and provide decisions while ensuring low latency and low energy consumption. However, the existing cloud-based AI paradigm finds it difficult to meet these strict UAV requirements. Edge AI, which runs AI on-device or on edge servers close to users, can be suitable for improving UAV-based IoT services. This article provides a comprehensive analysis of the impact of edge AI on key UAV technical aspects (i.e., autonomous navigation, formation control, power management, security and privacy, computer vision, and communication) and applications (i.e., delivery systems, civil infrastructure inspection, precision agriculture, search and rescue (SAR) operations, acting as aerial wireless base stations (BSs), and drone light shows). As guidance for researchers and practitioners, this article also explores UAV-based edge AI implementation challenges, lessons learned, and future research directions.  © 2014 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","15435-15459","","17","9","","","","","","","","","","","","","Scopus","","","","","","","","Cloud-computing; Energy utilization; Internet of things; Edge computing; Green computing; Mobile edge computing; 5G mobile communication systems; Data privacy; edge computing; Job analysis; Task analysis; Internet of Things (IoT); Internet of thing; Computer vision; edge intelligence; Edge intelligence; MEC; Antennas; Artificial intelligence technologies; Air navigation; Artificial intelligence (AI); Artificial intelligence methods; Computer control systems; Drones; edge AI; Edge artificial intelligence; MEC.; Motion planning; unmanned aerial vehicle (UAV)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UF25LBA4","journalArticle","2018","O-RAN Alliance, U.","","O-RAN WhitePaper - Building the Next Generation RAN","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124786808&partnerID=40&md5=473ae733b223d48caebfbd9cf4746259","","2018","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SIU3Y9M6","journalArticle","2024","Ferreira, L.M.M.; Coelho, F.; Pereira, J.","Databases in Edge and Fog Environments: A Survey","ACM Computing Surveys","","","10.1145/3666001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199680091&doi=10.1145%2f3666001&partnerID=40&md5=3cb4befc9a3c21a53a367a046f6d6a0d","While a significant number of databases are deployed in cloud environments, pushing part or all data storage and querying planes closer to their sources (i.e., to the edge) can provide advantages in latency, connectivity, privacy, energy, and scalability. This article dissects the advantages provided by databases in edge and fog environments by surveying application domains and discussing the key drivers for pushing database systems to the edge. At the same time, it also identifies the main challenges faced by developers in this new environment and analyzes the mechanisms employed to deal with them. By providing an overview of the current state of edge and fog databases, this survey provides valuable insights into future research directions. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","11","56","","","","","","","","","","","","","Scopus","","","","","","","","Cloud environments; Edge computing; Energy; fog computing; Digital storage; Fog computing; Database systems; 'current; Fog; Future research directions; Query processing; Applications domains; Data querying; Data storage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N93M289J","conferencePaper","2023","Amaral, M.; Chen, H.; Chiba, T.; Nakazawa, R.; Choochotkaew, S.; Lee, E.K.; Eilam, T.","Kepler: A Framework to Calculate the Energy Consumption of Containerized Applications","","","","10.1109/CLOUD60044.2023.00017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174254307&doi=10.1109%2fCLOUD60044.2023.00017&partnerID=40&md5=ad9611593dafbcf59292d9d1201e3478","Energy accounting is crucial in data centers for optimizing power provisioning, capping, and tuning. This paper introduces the Kepler framework, which estimates power consumption at the process, container, and Kubernetes pod levels. Kepler offers a set of power models applicable to various architectures and metrics. In this study, we propose a generic power model that utilizes hardware counters (HC) and realtime system power metrics (e.g., running average power limit (RAPL)) as independent variables in a regression model. Unlike previous approaches that rely on aggregate power consumption, our methodology measures individual process power consumption to train the power model. We provide step-by-step instructions to measure process power consumption in a controlled environment, considering the activation constant and load-dependent dynamic power consumption in different executions. By following the Greenhouse Gas (GHG) Protocol, our approach ensures the fair distribution of constant power among the user's processes. The results demonstrate significantly improved accuracy with a mean squared error (MSE) as low as 0.010 for the proposed method, compared with an MSE of 0.16 for a simple ratio approach and 0.92 when training the model using aggregated workload power. © 2023 IEEE.","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","69-71","","","2023-July","","","","","","","","","","","","","Scopus","","","","","","","","Energy accounting; Electric power utilization; Containers; Power modeling; Power; Kubernetes; Energy-consumption; Green computing; RAPL; Average power limit; Greenhouse gases; Sustainable development; kubernetes; Sustainability; Regression analysis; eBPF; container power modeling; Container power modeling; EBPF; Electric power distribution; energy accounting; Mean square error; Mean squared error; Running average power limit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"BJMURSWT","journalArticle","2021","Bonati, L.; D'Oro, S.; Polese, M.; Basagni, S.; Melodia, T.","Intelligence and Learning in O-RAN for Data-Driven NextG Cellular Networks","IEEE Communications Magazine","","","10.1109/MCOM.101.2001120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119879211&doi=10.1109%2fMCOM.101.2001120&partnerID=40&md5=0f6ae2132eb84a71b604dec46ee77b2d","Next generation (NextG) cellular networks will be natively cloud-based and built on programmable, virtualized, and disaggregated architectures. The separation of control functions from the hardware fabric and the introduction of standardized control interfaces will enable the definition of custom closed-control loops, which will ultimately enable embedded intelligence and real-time analytics, thus effectively realizing the vision of autonomous and self-optimizing networks. This article explores the disaggregated network architecture proposed by the O-RAN Alliance as a key enabler of NextG networks. Within this architectural context, we discuss the potential, the challenges, and the limitations of data-driven optimization approaches to network control over different timescales. We also present the first large-scale integration of O-RAN-compliant software components with an open source full-stack softwarized cellular network. Experiments conducted on Colosseum, the world's largest wireless network emulator, demonstrate closed-loop integration of real-time analytics and control through deep reinforcement learning agents. We also show the feasibility of radio access network (RAN) control through xApps running on the near-real-time RAN intelligent controller to optimize the scheduling policies of coexisting network slices, leveraging the O-RAN open interfaces to collect data at the edge of the network.  © 1979-2012 IEEE.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","21-27","","10","59","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Real-time analytics; Deep learning; Open systems; Network architecture; Mobile telecommunication systems; Radio access networks; Wireless networks; Reinforcement learning; Cloud-based; Closed control loop; Closed loop control systems; Control functions; Control interfaces; Data driven; Embedded intelligence; Network-control; Next generation cellular networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K8FZ8GHW","journalArticle","2013","Etcd team, A.","","etcd: A distributed, reliable key-value store for the most critical data of a distributed system","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219502077&partnerID=40&md5=c407b9ff6cc6b305736f8461fa6e5978","","2013","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"39TNXN8F","journalArticle","2024","Dong, S.; Tang, J.; Abbas, K.; Hou, R.; Kamruzzaman, J.; Rutkowski, L.; Buyya, R.","Task offloading strategies for mobile edge computing: A survey","Computer Networks","","","10.1016/j.comnet.2024.110791","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204212918&doi=10.1016%2fj.comnet.2024.110791&partnerID=40&md5=5417d9fd58a03a25f50fc0da0856d2db","With the wide adoption of 5G technology and the rapid development of 6G technology, a variety of new applications have emerged. A multitude of compute-intensive and time-sensitive applications deployed on terminal equipment have placed increased demands on Internet delay and bandwidth. Mobile Edge Computing (MEC) can effectively mitigate the issues of long transmission times, high energy consumption, and data insecurity. Task offloading, as a key technology within MEC, has become a prominent research focus in this field. This paper presents a comprehensive review of the current research progress in MEC task offloading. Firstly, it introduces the fundamental concepts, application scenarios, and related technologies of MEC. Secondly, it categorizes offloading decisions into five aspects: reducing delay, minimizing energy consumption, balancing energy consumption and delay, enabling high-computing offloading, and addressing different application scenarios. It then critically analyzes and compares existing research efforts in these areas. © 2024 Elsevier B.V.","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","254","","","","","","","","","","","","","Scopus","","","","","","","","Application scenario; Edge computing; Computation offloading; MEC; Task offloading; New applications; Internet delay; Offloading decision; Task offloading algorithm; Terminal equipment; Time sensitive applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9WHIHJL7","journalArticle","2022","Bréhon–Grataloup, L.; Kacimi, R.; Beylot, A.-L.","Mobile edge computing for V2X architectures and applications: A survey","Computer Networks","","","10.1016/j.comnet.2022.108797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124200551&doi=10.1016%2fj.comnet.2022.108797&partnerID=40&md5=e563c8b630a53cbc5ba4d308d3c444c1","In mobile environments, with the help of larger bandwidths and cloud computing solutions, any task can be offloaded from a mobile user equipment to be handled remotely. However, even though this process is accelerated with every cellular generation, with 5G being no exception, offloading to a faraway centralized cloud implies non-negligible delay. To tackle this issue concerning delay-sensitive applications, mobile edge computing, now denominated as multi-access edge computing (MEC), was brought to light. With cloud resources brought closer to the edge of the network, MEC greatly reduces task offloading delay, thereby striving to satisfy the constraints of real-time applications. As highly demanding mobile applications, vehicular networks are a target to be addressed in terms of performance, especially communication and computation delay. In this article, we establish the specificities of MEC when applied to the Internet of Vehicles (IoV), and survey recent papers studying implementations of MEC relevant to real-time vehicular considerations. We categorize these latest V2X architectures so as to unveil the mechanisms behind their improved performance: network availability and coverage, reliability and loss of network connectivity, large data handling and task offloading. This survey not only provides an initial understanding of the state-of-the-art advancements in the field of MEC-enabled vehicular networks, but also raises open issues and challenges that need to be addressed before enjoying the full benefits of this paradigm. © 2022","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","206","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Quality-of-service; Computer architecture; Network architecture; Edge computing; Surveys; Mobile edge computing; 5G mobile communication systems; Multiaccess; Data handling; Multi-access edge computing; Delay-sensitive applications; Internet of Vehicles; Cellular network; Task offloading; Cellular networks; Cache management; IEEE-802.11p; Internet of vehicle; Vehicle to Everything; Vehicular edge computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43I4LUYQ","conferencePaper","2022","Muradova, G.; Hematyar, M.; Jamalova, J.","Advantages of Redis in-memory database to efficiently search for healthcare medical supplies using geospatial data","","","","10.1109/AICT55583.2022.10013544","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147541038&doi=10.1109%2fAICT55583.2022.10013544&partnerID=40&md5=5a5b566a61d1aa2b9df544fc5db07cef","According to diagnostic criteria, a patient can find clinics he needs depending on the symptoms of disease. The paper shows an effective solution that allows rapid access to information about clinic using Redis in memory database technology. In this paper using Redis help us to collect a wide array of geospatial capabilities finding the best way and build out this type of functionality. Redis has the capability to store by Redis intelligent optimized systems in their native format, and update and serve them with minimal computing infrastructure needed to implement these algorithms at scale. Also, our approach is to study the effect of the databases on system's working speed, comparing Redis and MS SQL. © 2022 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Big data; Diagnosis; Digital transformation; Metadata; Healthcare; Health care; Geo-spatial; Geo-spatial data; Geolocation provider; geolocation providers; Geolocations; geospatial capabilities; Geospatial capability; geospatial data; Health care providers; healthcare; healthcare providers; MS SQL; public health digital transformation; Public health digital transformation; Redis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","16th IEEE International Conference on Application of Information and Communication Technologies, AICT 2022 - Proceedings","","","","","","","","","","","","","","",""
"E2XHGQ2Y","journalArticle","2022","Liu, G.; Shi, H.; Kiani, A.; Khreishah, A.; Lee, J.; Ansari, N.; Liu, C.; Yousef, M.M.","Smart Traffic Monitoring System Using Computer Vision and Edge Computing","IEEE Transactions on Intelligent Transportation Systems","","","10.1109/TITS.2021.3109481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115724008&doi=10.1109%2fTITS.2021.3109481&partnerID=40&md5=d6b9b67665d8d89beb37aa75b55099da","Traffic management systems capture tremendous video data and leverage advances in video processing to detect and monitor traffic incidents. The collected data are traditionally forwarded to the traffic management center (TMC) for in-depth analysis and may thus exacerbate the network paths to the TMC. To alleviate such bottlenecks, we propose to utilize edge computing by equipping edge nodes that are close to cameras with computing resources (e.g., cloudlets). A cloudlet, with limited computing resources as compared to TMC, provides limited video processing capabilities. In this paper, we focus on two common traffic monitoring tasks, congestion detection, and speed detection, and propose a two-tier edge computing based model that takes into account of both the limited computing capability in cloudlets and the unstable network condition to the TMC. Our solution utilizes two algorithms for each task, one implemented at the edge and the other one at the TMC, which are designed with the consideration of different computing resources. While the TMC provides strong computation power, the video quality it receives depends on the underlying network conditions. On the other hand, the edge processes very high-quality video but with limited computing resources. Our model captures this trade-off. We evaluate the performance of the proposed two-tier model as well as the traffic monitoring algorithms via test-bed experiments under different weather as well as network conditions and show that our proposed hybrid edge-cloud solution outperforms both the cloud-only and edge-only solutions.  © 2000-2011 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","12027-12038","","8","23","","","","","","","","","","","","","Scopus","","","","","","","","Monitoring; Traffic monitoring; Cloud-computing; Information management; Economic and social effects; Edge computing; Video signal processing; Computational modelling; Traffic congestion; Image edge detection; Edge detection; Cameras; Video analytics; edge-computing; Incident detection; incidents detection; Traffic management centers; video analytic; Video analytic.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRI9YRAD","journalArticle","2019","Yao, M.; Sohul, M.; Marojevic, V.; Reed, J.H.","Artificial Intelligence Defined 5G Radio Access Networks","IEEE Communications Magazine","","","10.1109/MCOM.2019.1800629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063005440&doi=10.1109%2fMCOM.2019.1800629&partnerID=40&md5=3fac456bc85a6cdb23d7fd82c553f6a5","Massive multiple-input multiple-output antenna systems, millimeter-wave communications, and ultra-dense networks have been widely perceived as the three key enablers that facilitate the development and deployment of 5G systems. This article discusses the intelligent agent that combines sensing, learning, and optimizing to facilitate these enablers. We present a flexible, rapidly deployable, and cross-layer artificial intelligence (AI)-based framework to enable the imminent and future demands on 5G and beyond. We present example AI-enabled 5G use cases that accommodate important 5G-specific capabilities and discuss the value of AI for enabling network evolution. © 2019 IEEE.","2019","2025-10-22 19:07:47","2025-10-22 19:07:47","","14-20","","3","57","","","","","","","","","","","","","Scopus","","","","","","","","Radio access networks; 5G mobile communication systems; Artificial intelligence; Antennas; Cross layer; Dense network; G-system; Millimeter waves; Millimeter-wave communication; MIMO systems; Multiple-input-multiple-output antenna systems; Network evolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVGD53AM","journalArticle","2022","Pelle, I.; Szalay, M.; Czentye, J.; Sonkoly, B.; Toka, L.","Cost and Latency Optimized Edge Computing Platform","Electronics (Switzerland)","","","10.3390/electronics11040561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124334818&doi=10.3390%2felectronics11040561&partnerID=40&md5=a8accb2ef73c69e075450ee7183f3107","Latency-critical applications, e.g., automated and assisted driving services, can now be deployed in fog or edge computing environments, offloading energy-consuming tasks from end devices. Besides the proximity, though, the edge computing platform must provide the necessary operation techniques in order to avoid added delays by all means. In this paper, we propose an integrated edge platform that comprises orchestration methods with such objectives, in terms of handling the deployment of both functions and data. We show how the integration of the function orchestration solution with the adaptive data placement of a distributed key–value store can lead to decreased end-to-end latency even when the mobility of end devices creates a dynamic set of requirements. Along with the necessary monitoring features, the proposed edge platform is capable of serving the nomad users of novel applications with low latency requirements. We showcase this capability in several scenarios, in which we articulate the end-to-end latency performance of our platform by comparing delay measurements with the benchmark of a Redis-based setup lacking the adaptive nature of data orchestration. Our results prove that the stringent delay requisites necessitate the close integration that we present in this paper: functions and data must be orchestrated in sync in order to fully exploit the potential that the proximity of edge resources enables. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","4","11","","","","","","","","","","","","","Scopus","","","","","","","","Serverless; Edge computing; FaaS; Function-as-a-Service; Lambda; Redis; Cloud native; Data locality; Distributed data store; Greengrass","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMLTA2HF","journalArticle","2023","Hossain, M.D.; Sultana, T.; Akhter, S.; Hossain, M.I.; Thu, N.T.; Huynh, L.N.T.; Lee, G.-W.; Huh, E.-N.","The role of microservice approach in edge computing: Opportunities, challenges, and research directions","ICT Express","","","10.1016/j.icte.2023.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165079284&doi=10.1016%2fj.icte.2023.06.006&partnerID=40&md5=417afeddf065684b7a62d0e0cb8ddd2e","Edge computing has emerged as a promising computing paradigm that enables real-time data processing and analysis closer to the data source and boosts decision-making applications in a safe manner. On the other hand, the microservice is a new type of architecture that can be dynamically deployed, migrating across edge clouds on demand. Therefore, the combination of these two technologies can provide numerous benefits, including improved performance, reduced latency, and better resource utilization. In this paper, we present a thorough analysis of state-of-the-art research on the use of microservices in edge computing environments. We take into consideration several distinct microservice research directions, including coordination, orchestration, repositories, scheduling, autoscaling, deployment, resource management, and different security issues. Furthermore, we explore the potential applications of microservices in edge computing across various domains. Finally, the unsolved research issues and future directions of emerging trends in this area are also discussed. © 2023 The Author(s)","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","1162-1182","","6","9","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Edge computing; AI; Microservice security; Monolithic architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M955CXCL","conferencePaper","2021","Laigner, R.; Zhou, Y.; Salles, M.A.V.","A distributed database system for event-based microservices","","","","10.1145/3465480.3466919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110335342&doi=10.1145%2f3465480.3466919&partnerID=40&md5=b0f58c3069cd82adc159026594a6dca7","Microservice architectures are an emerging industrial approach to build large scale and event-based systems. In this architectural style, an application is functionally partitioned into several small and autonomous building blocks, so-called microservices, communicating and exchanging data with each other via events. By pursuing a model where fault isolation is enforced at microservice level, each microservice manages their own database, thus database systems are not shared across microservices. Developers end up encoding substantial data management logic in the application-tier and encountering a series of challenges on enforcing data integrity and maintaining data consistency across microservices. In this vision paper, we argue that there is a need to rethink how database systems can better support microservices and relieve the burden of handling complex data management tasks faced by programmers. We envision the design and research opportunities for a novel distributed database management system targeted at event-driven microservices.  © 2021 ACM.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","25-30","","","","","","","","","","","","","","","","Scopus","","","","","","","","Information management; microservices; Software architecture; Research opportunities; Architectural style; Data handling; Building blockes; Distributed database systems; event-driven architecture; Data consistency; database system; Distributed database; Event-based system; Fault isolation; Management tasks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","DEBS 2021 - Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems","","","","","","","","","","","","","","",""
"KUQYZ7J8","journalArticle","2023","Al-Doghman, F.; Moustafa, N.; Khalil, I.; Sohrabi, N.; Tari, Z.; Zomaya, A.Y.","AI-Enabled Secure Microservices in Edge Computing: Opportunities and Challenges","IEEE Transactions on Services Computing","","","10.1109/TSC.2022.3155447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125753164&doi=10.1109%2fTSC.2022.3155447&partnerID=40&md5=6596edb9d44bb1d36a36dcf2e8419632","The paradigm of edge computing has formed an innovative scope within the domain of the Internet of Things (IoT) through expanding the services of the cloud to the network edge to design distributed architectures and securely enhance decision-making applications. Due to the heterogeneous, distributed and resource-constrained essence of edge Computing, edge applications are required to be developed as a set of lightweight and interdependent modules. As this concept aligns with the objectives of microservice architecture, effective implementation of microservices-based edge applications within IoT networks has the prospective of fully leveraging edge nodes capabilities. Deploying microservices at IoT edge faces plenty of challenges associated with security and privacy. Advances in Artificial Intelligence (AI) (especially Machine Learning), and the easy access to resources with powerful computing providing opportunities for deriving precise models and developing different intelligent applications at the edge of network. In this study, an extensive survey is presented for securing edge computing-based AI Microservices to elucidate the challenges of IoT management and enable secure decision-making systems at the edge. We present recent research studies on edge AI and microservices orchestration and highlight key requirements as well as challenges of securing Microservices at IoT edge. We also propose a Microservices-based edge computing framework that provides secure edge AI algorithms as Microservices utilizing the containerization technology to offer automated and secure AI-based applications at the network edge.  © 2008-2012 IEEE.","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","1485-1504","","2","16","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; microservices; Internet of things; Computer architecture; Edge computing; Decision making; Data privacy; Computational modelling; Security; Microservice architecture; Network edges; edge AI; Edge AI; edge privacy; Edge privacy; edge security; Edge security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4J7EXU7","conferencePaper","2014","Ongaro, D.; Ousterhout, J.","In search of an understandable consensus algorithm","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077435090&partnerID=40&md5=662997594757a26b9feaf99dc66d27cc","Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efficient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandability, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety. © Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014. All rights reserved.","2014","2025-10-22 19:07:47","2025-10-22 19:07:47","","305-319","","","","","","","","","","","","","","","","Scopus","","","","","","","","Consensus algorithms; Cluster memberships; Key elements; Leader election; Learn+; New mechanisms; Number of state; Practical systems; Understandability; User study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2014 USENIX Annual Technical Conference, USENIX ATC 2014","","","","","","","","","","","","","","",""
"6LZXYVPP","journalArticle","2021","Liu, Z.; Zhan, C.; Cui, Y.; Wu, C.; Hu, H.","Robust Edge Computing in UAV Systems via Scalable Computing and Cooperative Computing","IEEE Wireless Communications","","","10.1109/MWC.121.2100041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119973828&doi=10.1109%2fMWC.121.2100041&partnerID=40&md5=dfeca8191bfae4e720b61a790149bc80","Unmanned aerial vehicle (UAV) systems are of increasing interest to academia and industry due to their mobility, flexibility, and maneuverability, and are an effective alternative to various uses such as surveillance and mobile edge computing. However, due to their limited computational and communications resources, it is difficult to serve all computation tasks simultaneously. This article tackles this problem by first proposing a scalable aerial computing solution, which is applicable for computation tasks of multiple quality levels, corresponding to different computation workloads and computation results of distinct performance. It opens up the possibility to maximally improve the overall computing performance with limited computational and communications resources. To meet the demands for timely video analysis that exceed the computing power of a UAV, we propose an aerial video streaming enabled cooperative computing solution, namely, UAVideo, which streams videos from a UAV to ground servers. As a complement to scalable aerial computing, UAVideo minimizes the video streaming time under the constraints on UAV trajectory, video features, and communications resources. Simulation results reveal the substantial advantages of the proposed solutions. Furthermore, we highlight relevant directions for future research. © 2021 IEEE.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","36-42","","5","28","","","","","","","","","","","","","Scopus","","","","","","","","Edge computing; Video streaming; Mobile edge computing; Video-streaming; Communication resources; Computing solutions; Computational resources; Antennas; Unmanned aerial vehicles (UAV); Computation tasks; Cooperative computing; Maneuverability; Manoeuvrability; Scalable computing; Unmanned aerial vehicle systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DIKAA2VW","journalArticle","2024","Cloud Native Computing Foundation (CNCF): Environmental Sustainability, M.","Idle power matters: Kepler metrics for public cloud energy efficiency","Idle Power Matters: Kepler Metrics for Public Cloud Energy Efficiency","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219494057&partnerID=40&md5=becc77ee82462f276e1a5fcb068948f3","","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2ELANG5","journalArticle","2022","Bitnami, M.","Etcd helm chart","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219497964&partnerID=40&md5=6383d0e217e6ea5d343224aa70d0e2e7","","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2VWM4WB","conferencePaper","2022","Wang, Y.; Gong, W.; Fang, H.","An NVMe-oF Distributed Storage Design Based on Etcd","","","","10.1109/ICFTIC57696.2022.10075110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152198599&doi=10.1109%2fICFTIC57696.2022.10075110&partnerID=40&md5=5aa37d53683192bb89aa1d490fb8839e","The emerging NVMe-oF (NVMe over Fabrics) protocol provides access to an SSD on another node over the network using NVMe commands, providing performance close to that of an SSD using the NVMe protocol locally. To further improve performance, the SPDK (Storage Performance Development Kit) proposes an NVMe-oF implementation in user mode. Compared to the native NVMe-oF I/O stack provided by the Linux kernel, the SPDK's user mode I/O stack can significantly reduce I/O latency, however, the NVMe-oF implementation in the SPDK only serves as a demonstration and does not implement cluster management and failover features. In this paper, we propose a design of multi-node NVMe-oF distributed storage based on Etcd technology, which enables bulk deployment and management of clusters with the help of Etcd's node discovery and management functions. It also utilizes Etcd's K-V database to persist configuration information for failover and recovery.  © 2022 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","701-705","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Computer operating systems; Distributed storage; Distributed storage system; Distributed Storage System; Etcd; Failover; NVMe; NVMe over fabric; NVMe over Fabrics; SPDK; Storage performance; Storage performance development kit; User mode","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2022 4th International Conference on Frontiers Technology of Information and Computer, ICFTIC 2022","","","","","","","","","","","","","","",""
"68CEHPQ9","journalArticle","2025","Kepler, M.","Kubernetes-based efficient power level exporter","Kubernetes-based Efficient Power Level Exporter","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219494370&partnerID=40&md5=422414ac7344b6bb3607bb2ea9e194ba","","2025","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7AVWQELH","journalArticle","2024","Centofanti, C.; Santos, J.; Gudepu, V.; Kondepu, K.","Impact of power consumption in containerized clouds: A comprehensive analysis of open-source power measurement tools","Computer Networks","","","10.1016/j.comnet.2024.110371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189754287&doi=10.1016%2fj.comnet.2024.110371&partnerID=40&md5=2931318c8c09c272b303cf029696b0e1","Recently, container-based solutions have become de facto compute units of modern cloud-native applications. However, the exponential growth in data traffic and the power consumption of these technologies to handle high data traffic alarm the strong need for energy evaluation approaches in containerized clouds. Furthermore, the proliferation of highly distributed edge clouds raises additional concerns regarding the power consumption of future cloud architectures. This article presents a detailed overview of methods and techniques for monitoring power consumption within popular cloud platforms. The study offers an in-depth evaluation of these approaches, demonstrating variations in measured power consumption based on the chosen technique. A well-known container orchestration platform named Kubernetes (K8s) has been applied in our extensive measurements. This work argues that energy-efficient container clouds will play a vital role in building a more sustainable and eco-friendly digital infrastructure by optimizing power consumption and reducing carbon footprint, paving the way for a greener future. The paper also discusses open challenges and future research directions on energy sustainability, leading to the conclusion, offering lessons learned and prospects on potential solutions to foster sustainable practices within the container ecosystem. © 2024 The Authors","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","245","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Containers; Energy efficiency; Power; Kubernetes; Cloud computing; Cloud-computing; Open-source; Green computing; Computing power; Carbon footprint; Comprehensive analysis; Sustainable development; Sustainability; Service orchestration; Exponential growth; Power consumption; Data traffic; Measurement tools; Traffic alarms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV7N4FSB","journalArticle","2025","Tsampazi, M.; D'oro, S.; Polese, M.; Bonati, L.; Poitau, G.; Healy, M.; Alavirad, M.; Melodia, T.","PandORA: Automated Design and Comprehensive Evaluation of Deep Reinforcement Learning Agents for Open RAN","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2024.3505781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000760440&doi=10.1109%2fTMC.2024.3505781&partnerID=40&md5=79c59f629c2ec55412eb556469f1b6bd","The highly heterogeneous ecosystem of Next Generation (NextG) wireless communication systems calls for novel networking paradigms where functionalities and operations can be dynamically and optimally reconfigured in real time to adapt to changing traffic conditions and satisfy stringent and diverse Quality of Service (QoS) demands. Open Radio Access Network (RAN) technologies, and specifically those being standardized by the O-RAN Alliance, make it possible to integrate network intelligence into the once monolithic RAN via intelligent applications, namely, xApps and rApps. These applications enable flexible control of the network resources and functionalities, network management, and orchestration through data-driven intelligent control loops. Recent work has showed how Deep Reinforcement Learning (DRL) is effective in dynamically controlling O-RAN systems. However, how to design these solutions in a way that manages heterogeneous optimization goals and prevents unfair resource allocation is still an open challenge, with the logic within DRL agents often considered as a opaque system. In this paper, we introduce PandORA, a framework to automatically design and train DRL agents for Open RAN applications, package them as xApps and evaluate them in the Colosseum wireless network emulator. We benchmark 23 xApps that embed DRL agents trained using different architectures, reward design, action spaces, and decision-making timescales, and with the ability to hierarchically control different network parameters. We test these agents on the Colosseum testbed under diverse traffic and channel conditions, in static and mobile setups. Our experimental results indicate how suitable fine-tuning of the RAN control timers, as well as proper selection of reward designs and DRL architectures can boost network performance according to the network conditions and demand. Notably, finer decision-making granularities can improve Massive Machine-Type Communications (mMTC)'s performance by ∼56% and even increase Enhanced Mobile Broadband (eMBB) Throughput by ∼99%.  © 2024 IEEE.","2025","2025-10-22 19:07:47","2025-10-22 19:07:47","","3223-3240","","4","24","","","","","","","","","","","","","Scopus","","","","","","","","Information management; Network performance; Benchmarking; Decision making; Radio access networks; Resource allocation; Deep reinforcement learning; Reinforcement learning; Reinforcement learnings; resource allocation; Resources allocation; open RAN; Decisions makings; network intelligence; Network intelligence; O-radio access network; O-RAN; Open radio access network; Reinforcement learning agent; Traffic conditions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5U3NA9XB","journalArticle","2024","Lacava, A.; Polese, M.; Sivaraj, R.; Soundrarajan, R.; Bhati, B.S.; Singh, T.; Zugno, T.; Cuomo, F.; Melodia, T.","Programmable and Customized Intelligence for Traffic Steering in 5G Networks Using Open RAN Architectures","IEEE Transactions on Mobile Computing","","","10.1109/TMC.2023.3266642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153511847&doi=10.1109%2fTMC.2023.3266642&partnerID=40&md5=5d594173b6733da1ad1c45dd13b15975","5G and beyond mobile networks will support heterogeneous use cases at an unprecedented scale, thus demanding automated control and optimization of network functionalities customized to the needs of individual users. Such fine-grained control of the Radio Access Network (RAN) is not possible with the current cellular architecture. To fill this gap, the Open RAN paradigm and its specification introduce an 'open' architecture with abstractions that enable closed-loop control and provide data-driven, and intelligent optimization of the RAN at the user-level. This is obtained through custom RAN control applications (i.e., xApps) deployed on near-real-time RAN Intelligent Controller (near-RT RIC) at the edge of the network. Despite these premises, as of today the research community lacks a sandbox to build data-driven xApps, and create large-scale datasets for effective Artificial Intelligence (AI) training. In this paper, we address this by introducing ns-O-RAN, a software framework that integrates a real-world, production-grade near-RT RIC with a 3GPP-based simulated environment on ns-3, enabling at the same time the development of xApps, automated large-scale data collection and testing of Deep Reinforcement Learning (DRL)-driven control policies for the optimization at the user-level. In addition, we propose the first user-specific O-RAN Traffic Steering (TS) intelligent handover framework. It uses Random Ensemble Mixture (REM), a Conservative QQ-learning (CQL) algorithm, combined with a state-of-the-art Convolutional Neural Network (CNN) architecture, to optimally assign a serving base station to each user in the network. Our TS xApp, trained with more than 40 million data points collected by ns-O-RAN, runs on the near-RT RIC and controls the ns-O-RAN base stations. We evaluate the performance on a large-scale deployment with up to 126 users with 8 base stations, showing that the xApp-based handover improves throughput and spectral efficiency by an average of 50% over traditional handover heuristics, with less mobility overhead.  © 2002-2012 IEEE.","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","2882-2897","","4","23","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Computer architecture; Network architecture; Radio access networks; 5G mobile communication systems; Base stations; Computer programming; Software testing; Deep neural networks; Deep reinforcement learning; Reinforcement learning; Reinforcement learnings; Optimisations; Convolution; deep reinforcement learning; traffic steering; Ns-3; Convolutional neural network; network intelligence; Network intelligence; O-radio access network; O-RAN; Hand over; ns-3; Traffic steering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMJSBRBJ","journalArticle","2020","Larsson, L.; Tärneberg, W.; Klein, C.; Elmroth, E.; Kihl, M.","Impact of etcd deployment on Kubernetes, Istio, and application performance","Software - Practice and Experience","","","10.1002/spe.2885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089109897&doi=10.1002%2fspe.2885&partnerID=40&md5=b3aa69908375961bf4ec1a6872c4c810","This experience article describes lessons learned as we conducted experiments in a Kubernetes-based environment, the most notable of which was that the performance of both the Kubernetes control plane and the deployed application depends strongly and in unexpected ways on the performance of the etcd database. The article contains (a) detailed descriptions of how networking with and without Istio works in Kubernetes, based on the Flannel Container Networking Interface (CNI) provider in VXLAN mode with IP Virtual Server (IPVS)-backed Kubernetes Services, (b) a comprehensive discussion about how to conduct load and performance testing using a closed-loop workload generator, and (c) an open source experiment framework useful for executing experiments in a shared cloud environment and exploring the resulting data. It also shows that statistical analysis may reveal the data resulting from such experiments to be misleading even when careful preparations are made, and that nondeterministic behavior stemming from etcd can affect both the platform as a whole and the deployed application. Finally, it is demonstrated that using high-performance backing storage for etcd can reduce the occurrence of such nondeterministic behaviors by a statistically significant (P <.05) margin. The implication of this experience article is that systems researchers studying the performance of applications deployed on Kubernetes cannot simply consider their specific application to be under test. Instead, the particularities of the underlying Kubernetes and cloud platform must be taken into account, in particular because their performance can impact that of etcd. © 2020 The Authors. Software: Practice and Experience published by John Wiley & Sons Ltd.","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","1986-2007","","10","50","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; cloud computing; Cloud environments; Digital storage; Cloud platforms; Application performance; distributed systems; performance; C (programming language); Nondeterministic behavior; Deployed applications; Workload generators; Performance testing; etcd; Virtual servers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72RDK3EI","journalArticle","2021","Labriji, I.; Meneghello, F.; Cecchinato, D.; Sesia, S.; Perraud, E.; Strinati, E.C.; Rossi, M.","Mobility Aware and Dynamic Migration of MEC Services for the Internet of Vehicles","IEEE Transactions on Network and Service Management","","","10.1109/TNSM.2021.3052808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099731183&doi=10.1109%2fTNSM.2021.3052808&partnerID=40&md5=4683d23177e7154bebb9d8916d9356e5","Vehicles are becoming connected entities, and with the advent of online gaming, on demand streaming and assisted driving services, are expected to turn into data hubs with abundant computing needs. In this article, we show the value of estimating vehicular mobility as 5G users move across radio cells, and of using such estimates in combination with an online algorithm that assesses when and where the computing services (virtual machines, VM) that are run on the mobile edge nodes are to be migrated to ensure service continuity at the vehicles. This problem is tackled via a Lyapunov-based approach, which is here solved in closed form, leading to a low-complexity and distributed algorithm, whose performance is numerically assessed in a real-life scenario, featuring thousands of vehicles and densely deployed 5G base stations. Our numerical results demonstrate a reduction of more than 50% in the energy expenditure with respect to previous strategies (full migration). Also, our scheme self-adapts to meet any given risk target, which is posed as an optimization constraint and represents the probability that the computing service is interrupted during a handover. Through it, we can effectively control the trade-off between seamless computation and energy consumption when migrating VMs.  © 2004-2012 IEEE.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","570-584","","1","18","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Economic and social effects; Web services; 5G mobile communication systems; Computational complexity; Vehicle to vehicle communications; Vehicles; Computing services; Numerical results; On-line algorithms; 5G; convolutional neural network; Energy expenditure; Lyapunov optimization; Dynamic migration; Electronic assessment; Internet of Vehicles (IoV); Markov chain; mobility estimation; multi-access edge computing (MEC); On-demand streaming; recurrent neural network; Service continuity; service migration; Vehicular mobilities; virtual machine (VM)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CICMZDZG","journalArticle","2023","Polese, M.; Bonati, L.; D'Oro, S.; Basagni, S.; Melodia, T.","Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges","IEEE Communications Surveys and Tutorials","","","10.1109/COMST.2023.3239220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147300222&doi=10.1109%2fCOMST.2023.3239220&partnerID=40&md5=38e8ed5d2706f9c03ead9a8ba022db81","The Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance specifications are poised to revolutionize the telecom ecosystem. O-RAN promotes virtualized RANs where disaggregated components are connected via open interfaces and optimized by intelligent controllers. The result is a new paradigm for the RAN design, deployment, and operations: O-RAN networks can be built with multi-vendor, interoperable components, and can be programmatically optimized through a centralized abstraction layer and data-driven closed-loop control. Therefore, understanding O-RAN, its architecture, its interfaces, and workflows is key for researchers and practitioners in the wireless community. In this article, we present the first detailed tutorial on O-RAN. We also discuss the main research challenges and review early research results. We provide a deep dive of the O-RAN specifications, describing its architecture, design principles, and the O-RAN interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to effectively control and manage 3GPP-defined RANs. Based on this, we discuss innovations and challenges of O-RAN networks, including the Artificial Intelligence (AI) and Machine Learning (ML) workflows that the architecture and interfaces enable, security, and standardization issues. Finally, we review experimental research platforms that can be used to design and test O-RAN networks, along with recent research results, and we outline future directions for O-RAN development.  © 1998-2012 IEEE.","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","1376-1411","","2","25","","","","","","","","","","","","","Scopus","","","","","","","","Computer architecture; Network architecture; Radio access networks; Abstracting; Research challenges; Artificial intelligence; Learning systems; Optimisations; Network security; Security; Controllers; 6G; Work-flows; Specifications; 5G; ITS architecture; O-RAN; 3GPP; cellular; Intelligent control; Intelligent controllers; Open RAN; Precoding; Radiofrequencies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"48BWM6TW","conferencePaper","2022","Niknam, S.; Roy, A.; Dhillon, H.S.; Singh, S.; Banerji, R.; Reed, J.H.; Saxena, N.; Yoon, S.","Intelligent O-RAN for Beyond 5G and 6G Wireless Networks","","","","10.1109/GCWkshps56602.2022.10008676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146878758&doi=10.1109%2fGCWkshps56602.2022.10008676&partnerID=40&md5=e770877fa824071a74f4feb6bccd0507","Building on the principles of openness and intelligence, there has been a concerted global effort from the operators towards enhancing the radio access network (RAN) architecture. The objective is to build an operator-defined RAN architecture (and associated interfaces) on open hardware that provides intelligent radio control for beyond fifth generation (5G) as well as future sixth generation (6G) wireless networks. Specifically, the open-radio access network (O-RAN) alliance has been formed by merging xRAN forum and C-RAN alliance to formally define the requirements that would help achieve this objective. Owing to the importance of O-RAN in the current wireless landscape, this article provides an introduction to the concepts, principles, and requirements of the Open RAN as specified by the O-RAN alliance. In order to illustrate the role of intelligence in O-RAN, we propose an intelligent radio resource management scheme to handle traffic congestion and demonstrate its efficacy on a real-world dataset obtained from a large operator. A high-level architecture of this deployment scenario that is compliant with the O-RAN requirements is also discussed. The article concludes with key technical challenges and open problems for future research and development.  © 2022 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","215-220","","","","","","","","","","","","","","","","Scopus","","","","","","","","Network architecture; Radio access networks; 5G mobile communication systems; Natural resources management; Resource allocation; Wireless networks; Machine learning; machine learning; Machine-learning; 'current; Traffic congestion; 6g; 6G; Radio; Large dataset; beyond 5G; Beyond 5g; Open radio access network; Intelligent controllers; Open RAN; intelligent controller; Open hardware; Radio control; radio resource management; Radio resources managements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2022 IEEE GLOBECOM Workshops, GC Wkshps 2022 - Proceedings","","","","","","","","","","","","","","",""
"9A8WIYVV","conferencePaper","2021","Laigner, R.; Zhou, Y.; Salles, M.A.V.; Liu, Y.; Kalinowski, M.","Data management in microservices: State of the practice, challenges, and research directions","","","","10.14778/3484224.3484232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117280834&doi=10.14778%2f3484224.3484232&partnerID=40&md5=1a6c2a7b1d33c549a29a7a412282c765","Microservices have become a popular architectural style for datadriven applications, given their ability to functionally decompose an application into small and autonomous services to achieve scalability, strong isolation, and specialization of database systems to the workloads and data formats of each service. Despite the accelerating industrial adoption of this architectural style, an investigation of the state of the practice and challenges practitioners face regarding data management in microservices is lacking. To bridge this gap, we conducted a systematic literature review of representative articles reporting the adoption of microservices, we analyzed a set of popular open-source microservice applications, and we conducted an online survey to cross-validate the findings of the previous steps with the perceptions and experiences of over 120 experienced practitioners and researchers. Through this process, we were able to categorize the state of practice of data management in microservices and observe several foundational challenges that cannot be solved by software engineering practices alone, but rather require system-level support to alleviate the burden imposed on practitioners. We discuss the shortcomings of state-of-the-art database systems regarding microservices and we conclude by devising a set of features for microservice-oriented database systems. © 2021, VLDB Endowment. All rights reserved.","2021","2025-10-22 19:07:47","2025-10-22 19:07:47","","3348","","","14","","","","","","","","","","","","","Scopus","","","","","","","","Open source software; Information management; Open systems; Open-source; Architecture; Industrial adoption; Systematic literature review; Architectural style; Database systems; State of the practice; Data-driven applications; Online surveys; Software engineering practices; Specialisation; State of practise","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the VLDB Endowment","","","","","","","","","","","","","","",""
"AUN6DPBN","journalArticle","2024","Calagna, A.; Ravera, S.; Chiasserini, C.F.","Pace","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219496315&partnerID=40&md5=1ca856cba705114264654f47f97d7fc5","","2024","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"47GNV7FL","conferencePaper","2016","Chen, S.; Tang, X.; Wang, H.; Zhao, H.; Guo, M.","Towards scalable and reliable in-memory storage system: A case study with Redis","","","","10.1109/TrustCom.2016.0255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015242440&doi=10.1109%2fTrustCom.2016.0255&partnerID=40&md5=2f7f887b84514110b83c2dbe5bb6131e","In recent years, in-memory key-value storage systems have become more and more popular in solving real-time and interactive tasks. Compared with disks, memories have much higher throughput and lower latency which enables them to process data requests with much higher performance. However, since memories have much smaller capacity than disks, how to expand the capacity of in-memory storage system while maintain its high performance become a crucial problem. At the same time, since data in memories are non-persistent, the data may be lost when the system is down. In this paper, we make a case study with Redis, which is one popular in-memory key-value storage system. We find that although the latest release of Redis support clustering so that data can be stored in distributed nodes to support a larger storage capacity, its performance is limited by its decentralized design that clients usually need two connections to get their request served. To make the system more scalable, we propose a Clientside Key-to-Node Caching method that can help direct request to the right service node. Experimental results show that by applying this technique, it can significantly improve the system's performance by near 2 times. We also find that although Redis supports data replication on slave nodes to ensure data safety, it still gets a chance of losing a part of the data due to a weak consistency between master and slave nodes that its defective order of data replication and request reply may lead to losing data without notifying the client. To make it more reliable, we propose a Master-slave Semi Synchronization method which utilizes TCP protocol to ensure the order of data replication and request reply so that when a client receives an 'OK' message, the corresponding data must have been replicated. With a significant improvement in data reliability, its performance overhead is limited within 5%. © 2016 IEEE.","2016","2025-10-22 19:07:47","2025-10-22 19:07:47","","1660-1667","","","","","","","","","","","","","","","","Scopus","","","","","","","","Big data; Real time systems; Data privacy; Digital storage; Data storage equipment; Scalability; Reliability; Decentralized design; Distributed nodes; In-memory; Key values; Key-to-node caching; Key-value; Node caching; Semi synchronization; Storage capacity; Storage system; Storage systems; Synchronization method; System's performance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 15th IEEE International Conference on Trust, Security and Privacy in Computing and Communications, 10th IEEE International Conference on Big Data Science and Engineering and 14th IEEE International Symposium on Parallel and Distributed Processing with Applications, IEEE TrustCom/BigDataSE/ISPA 2016","","","","","","","","","","","","","","",""
"6Y4CBXBS","conferencePaper","2012","Liu, Z.; Chen, Y.; Bash, C.; Wierman, A.; Gmach, D.; Wang, Z.; Marwah, M.; Hyser, C.","Renewable and cooling aware workload management for sustainable data centers","","","","10.1145/2254756.2254779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864700984&doi=10.1145%2f2254756.2254779&partnerID=40&md5=dfdf71c33e8d6ec1bb243fe5c0840045","Recently, the demand for data center computing has surged, increasing the total energy footprint of data centers worldwide. Data centers typically comprise three subsystems: IT equipment provides services to customers; power infrastructure supports the IT and cooling equipment; and the cooling infrastructure removes heat generated by these subsystems. This work presents a novel approach to model the energy flows in a data center and optimize its operation. Traditionally, supply-side constraints such as energy or cooling availability were treated independently from IT workload management. This work reduces electricity cost and environmental impact using a holistic approach that integrates renewable supply, dynamic pricing, and cooling supply including chiller and outside air cooling, with IT workload planning to improve the overall sustainability of data center operations. Specifically, we first predict renewable energy as well as IT demand. Then we use these predictions to generate an IT workload management plan that schedules IT workload and allocates IT resources within a data center according to time varying power supply and cooling efficiency. We have implemented and evaluated our approach using traces from real data centers and production systems. The results demonstrate that our approach can reduce both the recurring power costs and the use of non-renewable energy by as much as 60% compared to existing techniques, while still meeting the Service Level Agreements. © 2012 ACM.","2012","2025-10-22 19:07:47","2025-10-22 19:07:47","","175-186","","","40","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Optimization; Information management; Service Level Agreements; Information technology; Data centers; Computer systems; Cooling; scheduling; Non-renewable energy; Renewable energies; Cost reduction; Cooling equipment; Power infrastructures; Total energy; Time varying; Air cooling; Cooling efficiency; cooling optimization; Cooling optimization; Data center operations; demand shaping; Dynamic pricing; Electricity costs; Energy flow; Holistic approach; IT equipment; IT resources; Power costs; Power supply; Production system; renewable energy; sustainable data center; Workload management; Workload planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Performance Evaluation Review","","","","","","","","","","","","","","",""
"7QTSUHYY","journalArticle","2022","Schmiedmayer, P.","","Designing evolvable web services","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165971953&partnerID=40&md5=9eaa92bf220714c56e1b17b448fc0ec5","","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USHRWLAF","conferencePaper","2020","Valera, H.H.A.; Dalmau, M.; Roose, P.; Larracoechea, J.; Herzog, C.","DRACeo: A smart simulator to deploy energy saving methods in microservices based networks","","","","10.1109/WETICE49692.2020.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100714002&doi=10.1109%2fWETICE49692.2020.00026&partnerID=40&md5=6dde8162ca929d1cfeb833956e56d257","Nowadays, many researchers work to identify microservices-based application deployments and scheduling solutions to save energy without decreasing functional QoS. In this work, we present DRACeo: A simulator that allows facing this challenge in a simple and efficient way, enabling its users to focus uniquely on microservices deployment/scheduling algorithms and its hardware/software repercussions (load vs. energy consumption) without worrying about low-level network configurations or operating system issues. DRACeo is able to deploy and schedule (move, duplicate, start/stop) microservices and their dependencies on various devices with software and hardware heterogeneity (CPU, bandwidth, RAM, Battery, etc.), taking into account various scheduling heuristics algorithms: centralized vs non-centralized. To do this, DRACeo allows deploying custom network topologies based on client-server schemes or p2p distributions, where devices can (dis)appear, turn on/off obeying random circumstances or user strategies. Finally, the simulator performs relevant operations such as QoS definition, resource monitoring, calculation of energy saved and consumption tracking (at device and network level). We tested some ideas based on our previous work 'Kaligreen' to demonstrate the effectiveness of DRACeo. © 2020 IEEE.","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","94-99","","","2020-September","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Scheduling; microservices; Energy utilization; Energy conservation; CPU; Software and hardwares; Application deployment; energy; middleware; Network topology; consumption; hard disk; network; prototype; simulator; Energy saving methods; Hardware/software; Network configuration; Resource monitoring; Scheduling heuristics; Simulators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE","","","","","","","","","","","","","","",""
"YTHCLCPU","conferencePaper","2022","Vos, S.; Lago, P.; Verdecchia, R.; Heitlager, I.","Architectural Tactics to Optimize Software for Energy Efficiency in the Public Cloud","","","","10.1109/ICT4S55073.2022.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136183770&doi=10.1109%2fICT4S55073.2022.00019&partnerID=40&md5=5176c4ed51d498c58321e5243a1e2818","A promise of cloud computing is the reduction of energy footprint enabled by economies of scale. Unfortunately, little research is available on how cloud consumers can reduce their energy footprint when running software in the public cloud. Moreover, cloud consumers do not have full access to information regarding their cloud infrastructure usage, which is required to understand the impact of design decisions on energy usage. The purpose of our study is to support cloud consumers in developing energy-efficient workloads in the public cloud. To achieve our goal, we collaborated with a large cloud solution provider to discover an initial set of reusable architectural tactics for software energy efficiency. Starting from interviews with 17 practitioners, we reviewed and selected available tactics to improve the energy efficiency of individual workloads in the public cloud, and synthetized the identified tactics in a reusable model. In addition, we conducted a case study to assess the impact of utilizing a tactic, which was selected following a prioritization provided by the practitioners. Our results demonstrate the possibility to architect cloud workloads for energy efficiency through reasoning and estimation of resource optimization. However, the process is not (yet) straightforward due to the current lack of transparency of cloud providers.  © 2022 IEEE.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","77-87","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud-computing; Energy Efficiency; Energy utilization; Edge computing; Energy; Green computing; Cloud infrastructures; Economics; % reductions; Edge Computing; Public clouds; Software Architecture; Computer software reusability; Economy of scale; Design decisions; Tactic; Tactics; Cloud consumers; Public Cloud","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2022 International Conference on ICT for Sustainability, ICT4S 2022","","","","","","","","","","","","","","",""
"PI5EPPB5","journalArticle","2011","Singh, H.","Data center maturity model","Techn. Ber. the Green Grid","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179520942&partnerID=40&md5=c99ad8196ae6196dcf003166faa3e979","","2011","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQZW33YX","conferencePaper","2022","Vitali, M.","Towards Greener Applications: Enabling Sustainable-aware Cloud Native Applications Design","","","","10.1007/978-3-031-07472-1_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132711955&doi=10.1007%2f978-3-031-07472-1_6&partnerID=40&md5=2232e16fe7c76fece1a4f0b3bd31320c","Data centers energy demand is increasing. While a great deal of effort has been made to reduce the amount of CO2 generated by large cloud providers, too little has been done from the application perspective. We claim that application developers can impact the environmental footprint by enhancing the application design with additional features. Following the proposed Sustainable Application Design Process (SADP), the application design is enriched with information that can be leveraged by cloud providers to manage application execution in an energy-aware manner. This exploratory work aims to emphasize the awareness on the sustainability of applications by proposing a methodology for its evaluation. To this end, we first suggest possible actions to enrich the application design towards sustainability, and finally describe how this additional information can be leveraged in the application workflow. We discuss the feasibility of our methodology by referring to existing tools and technologies capable of supporting the design features proposed in a production environment. © 2022, Springer Nature Switzerland AG.","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","93-108","","","13295 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Energy efficiency; Datacenter; Design; Application developers; Energy demands; Green computing; Cloud providers; Energy-efficiency; Sustainable development; Application design; Cloud-native; Sustainability-awareness; Sustainable applications; Workflow design; Environmental footprints; Sustainable application; Workflow designs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","","","","","","","","","","","",""
"XU6TEVRX","journalArticle","2018","Benoit, A.; Lefèvre, L.; Orgerie, A.-C.; Raïs, I.","Reducing the energy consumption of large-scale computing systems through combined shutdown policies with multiple constraints","International Journal of High Performance Computing Applications","","","10.1177/1094342017714530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039869052&doi=10.1177%2f1094342017714530&partnerID=40&md5=16390b43f86e710b523417082387d1fb","Large-scale distributed systems (high-performance computing centers, networks, data centers) are expected to consume huge amounts of energy. In order to address this issue, shutdown policies constitute an appealing approach able to dynamically adapt the resource set to the actual workload. However, multiple constraints have to be taken into account for such policies to be applied on real infrastructures: the time and energy cost of switching on and off, the power and energy consumption bounds caused by the electricity grid or the cooling system, and the availability of renewable energy. In this article, we propose models translating these various constraints into different shutdown policies that can be combined for a multiconstraint purpose. Our models and their combinations are validated through simulations on a real workload trace. © 2017, © The Author(s) 2017.","2018","2025-10-22 19:07:47","2025-10-22 19:07:47","","176-188","","1","32","","","","","","","","","","","","","Scopus","","","","","","","","Distributed computer systems; Energy utilization; Green computing; Energy model; simulation; High performance computing; Energy policy; Multiple constraint; Large-scale distributed system; energy models; Large-scale computing systems; Large-scale distributed systems; Power and energy consumption; shutdown policies; Shutdown policies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ARDHSWTA","journalArticle","2011","Loos, P.; Nebel, W.; Gómez, J.M.; Hasan, H.; Watson, R.T.; Brocke, J.V.; Seidel, S.; Recker, J.","Green IT: A matter of business and information systems engineering?","Business and Information Systems Engineering","","","10.1007/s12599-011-0165-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856547763&doi=10.1007%2fs12599-011-0165-5&partnerID=40&md5=a05fcbd7691c30e7c1bfc3e67ed799de","","2011","2025-10-22 19:07:47","2025-10-22 19:07:47","","245-252","","4","3","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VEH6UFP","journalArticle","2023","","","Google Carbon Footprint Console","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179518463&partnerID=40&md5=c0a3d900fe077c6ae827ed647de70aea","","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BTKDI2U","journalArticle","2010","Fowler, M.","","Domain-Specific Languages","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-51749119047&partnerID=40&md5=8e2e2e0563da2f07ae37e513101b03aa","","2010","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXG57PYM","journalArticle","2020","Lucivero, F.","Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives","Science and Engineering Ethics","","","10.1007/s11948-019-00171-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077193813&doi=10.1007%2fs11948-019-00171-7&partnerID=40&md5=3c4562e342b30f8c1641e0966ddb6eb2","This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives’ environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production. © 2019, The Author(s).","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","1009-1030","","2","26","","","","","","","","","","","","","Scopus","","","","","","","","Big Data; Sustainability; Technology; Environmental impacts; Materiality; Responsibility; technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQEFWY4H","conferencePaper","2020","Schmiedmayer, P.","Apodini: An Internal Domain Specific Language to Design Web Services","","","","10.1145/3429351.3431751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099723133&doi=10.1145%2f3429351.3431751&partnerID=40&md5=1f3ba530a34e3e339f49f66c31cfa18d","Web services use protocols and middleware mechanisms to offer interfaces that enable the interoperability of heterogeneous components. Interface definition languages are used to describe service interfaces derived from system requirements and from system architecture. System designers faces two challenges: To replace an existing middleware and simultaneously supporting multiple types of middleware. This paper describes Apodini, an internal domain specific language to deal with these challenges. Apodini enables system designers to express the nonfunctional requirements and functionality of web service interfaces in a single domain specific language. Apodini is independent of any specific middleware, protocol, or interface definition language to enable extensible system design and implementation.  © 2020 ACM.","2020","2025-10-22 19:07:47","2025-10-22 19:07:47","","47-49","","","","","","","","","","","","","","","","Scopus","","","","","","","","Design and implementations; Middleware; Systems analysis; Web services; Interoperability; Websites; middleware; Domain specific languages; Heterogeneous component; Non-functional requirements; System architectures; domain specific language; interface definition language; Interface definition languages; Middleware mechanisms; Problem oriented languages; Swift; web service; Web service interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Middleware 2020 Doctoral Symposium - Proceedings of the 2020 21st International Middleware Conference Doctoral Symposium, Part of Middleware 2020","","","","","","","","","","","","","","",""
"J4II3LQP","conferencePaper","2017","Papadopoulos, A.V.; Krzywda, J.; Elmroth, E.; Maggio, M.","Power-aware cloud brownout: Response time and power consumption control","","","","10.1109/CDC.2017.8264049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046161925&doi=10.1109%2fCDC.2017.8264049&partnerID=40&md5=e264f54eb60fff423fa1b049bfe670de","Cloud computing infrastructures are powering most of the web hosting services that we use at all times. A recent failure in the Amazon cloud infrastructure made many of the website that we use on a hourly basis unavailable1. This illustrates the importance of cloud applications being able to absorb peaks in workload, and at the same time to tune their power requirements to the power and energy capacity offered by the data center infrastructure. In this paper we combine an established technique for response time control-brownout-with power capping. We use cascaded control to take into account both the need for predictability in the response times (the inner loop), and the power cap (the outer loop). We execute tests on real machines to determine power usage and response times models and extend an existing simulator. We then evaluate the cascaded controller approach with a variety of workloads and both open-and closed-loop client models. © 2017 IEEE.","2017","2025-10-22 19:07:47","2025-10-22 19:07:47","","2686-2691","","","2018-January","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Electric power utilization; Power-aware; Datacenter; Cloud applications; Green computing; Computing power; Cloud infrastructures; Power requirement; Power capacity; Cloud computing infrastructures; Energy-capacity; Power consumption controls; Web hosting services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 IEEE 56th Annual Conference on Decision and Control, CDC 2017","","","","","","","","","","","","","","",""
"QTKJVWGW","journalArticle","2022","","","Cloud Native Computing Foundation Annual Survey 2021","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179510856&partnerID=40&md5=d2ecf1170484f16db0c23042bda8476e","","2022","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZG2UW25","journalArticle","2023","","","Aws Well-Architected Framework","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179510899&partnerID=40&md5=4d8aa54da955fe409930a0f7344daee4","","2023","2025-10-22 19:07:47","2025-10-22 19:07:47","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2D93ICD","journalArticle","2021","Hu, X.; Li, P.; Sun, Y.","Minimizing Energy Cost for Green Data Center by Exploring Heterogeneous Energy Resource","Journal of Modern Power Systems and Clean Energy","","","10.35833/MPCE.2019.000052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100023467&doi=10.35833%2fMPCE.2019.000052&partnerID=40&md5=381fb359c26bf2289314afb380e5b16d","With the deteriorating effects resulting from global warming in many areas, geographically distributed data centers contribute greatly to carbon emissions, because the major energy supply is fossil fuels. Considering this issue, many geographically distributed data centers are attempting to use clean energy as their energy supply, such as fuel cells and renewable energy sources. However, not all workloads can be powered by a single power sources, since different workloads exhibit different characteristics. In this paper, we propose a fine-grained heterogeneous power distribution model with an objective of minimizing the total energy costs and the sum of the energy gap generated by the geographically distributed data centers powered by multiple types of energy resources. In order to achieve these two goals, we design a two-stage online algorithm to leverage the power supply of each energy source. In each time slot, we also consider a chance-constraint problem and use the Bernstein approximation to solve the problem. Finally, simulation results based on real-world traces illustrate that the proposed algorithm can achieve satisfactory performance.  © 2021 State Grid Electric Power Research Institute.","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","148-159","","1","9","","","","","","","","","","","","","Scopus","","","","","","","","Green computing; Data center; energy management; Green data centers; Minimizing energy; Carbon emissions; On-line algorithms; Renewable energy resources; Fossil fuels; Renewable energy source; Global warming; Bernstein approximation; Chance constraint; Distributed data; Fossil fuel power plants; Fuel cells; heterogeneous energy resources; power distribution algorithm; Power distribution modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P4V7SCRL","conferencePaper","2022","Gerostathopoulos, I.; Raibulet, C.; Lago, P.","Expressing the Adaptation Intent as a Sustainability Goal","","","","10.1109/ICSE-NIER55298.2022.9793525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131966980&doi=10.1109%2fICSE-NIER55298.2022.9793525&partnerID=40&md5=9f2acbb436eb02dbdea7dcb872db56ab","Adaptation and sustainability are two key challenges leading the development of software-systems nowadays. Adaptation denotes the capacity of a system to cope with variations and uncertainties at runtime in order to continue providing its functionalities with certain quality levels, notwithstanding change. But how can adaptation and its intent be expressed at design time so that to analyze its possible impact at runtime over a long period of time? To answer this question we look at adaptation from the sustainability point of view. Sustainability denotes the capacity of a system to both endure and preserve its function over time. We propose an approach which uses decision maps to make sustainability-driven decisions for adaptation in a systematic way. The proposed approach is illustrated through two self-adaptive exemplars as illustrative cases.  © 2022 IEEE.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","36-40","","","","","","","","","","","","","","","","Scopus","","","","","","","","Runtimes; Sustainable development; Self-adaptive systems; Adaptive systems; Self-adaptive system; Software-systems; adaptation intent; Adaptation intent; Decision maps; Design time; Quality levels; sustainability goal; Sustainability goal; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"2BRVJL8S","journalArticle","2019","Lottick, K.; Susai, S.; Friedler, S.A.; Wilson, J.P.","Energy usage reports: Environmental awareness as part of algorithmic accountability","Energy usage reports: Environmental awareness as part of algorithmic accountability","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102644245&partnerID=40&md5=2893d7fe594fc83783af1041ab63593a","","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIJVBGCI","journalArticle","2012","Pedram, M.","Energy-efficient datacenters","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","","10.1109/TCAD.2012.2212898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866609789&doi=10.1109%2fTCAD.2012.2212898&partnerID=40&md5=da8813937e1c7f70fcfef51e520f0804","Pervasive use of cloud computing and the resulting rise in the number of datacenters and hosting centers (that provide platform or software services to clients who do not have the means to set up and operate their own computing facilities) have brought forth many concerns, including the electrical energy cost, peak power dissipation, cooling, and carbon emission. With power consumption becoming an increasingly important issue for the operation and maintenance of the hosting centers, corporate and business owners are becoming increasingly concerned. Furthermore, provisioning resources in a cost-optimal manner so as to meet different performance criteria, such as throughput or response time, has become a critical challenge. The goal of this paper is to provide an introduction to resource provisioning and power or thermal management problems in datacenters, and to review strategies that maximize the datacenter energy efficiency subject to peak or total power consumption and thermal constraints, while meeting stipulated service level agreements in terms of task throughput and/or response time. © 2012 IEEE.","2012","2025-10-22 19:07:48","2025-10-22 19:07:48","","1465-1484","","10","31","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Datacenter; resource management; Resource management; green computing; Temperature control; Dynamic Power; dynamic power and thermal management; energy efficient design; Energy-efficient design; enterprise computing; Enterprise computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SXMSAEM","journalArticle","2013","Vom Brocke, J.; Watson, R.T.; Dwyer, C.; Elliot, S.; Melville, N.","Green information systems: Directives for the IS discipline","Communications of the Association for Information Systems","","","10.17705/1cais.03330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892159927&doi=10.17705%2f1cais.03330&partnerID=40&md5=2005e85fdadc1fda6f90a563e1549d00","Green IS offers the promise for IS scholars to make a significant contribution to reducing greenhouse gas emissions and mitigating the effects of global climate change and other environmental problems. While significant achievements have been made in shaping Green IS as a subfield in the IS discipline, the emergence of Green IS is still by far too slow, given the magnitude of the problem. Against this background a panel was organized at ICIS 2012 in order to discuss future directives for the IS discipline. This article, co-authored by the panelists, reports on the major issues raised by this panel. First, the article gives an account of major achievements in the field of Green IS. Second, it presents five specific directives which we agree are important for the future of our discipline. © 2013 by the Association for Information Systems.","2013","2025-10-22 19:07:48","2025-10-22 19:07:48","","509-520","","1","33","","","","","","","","","","","","","Scopus","","","","","","","","Climate change; Gas emissions; Greenhouse gases; Sustainable development; Sustainability; Business transformation; Business transformations; Energy informatics; Environmental problems; Global climate changes; Green information systems; Green is; Green IS; Is disciplines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRZXLYR3","journalArticle","2020","Valderas, P.; Torres, V.; Pelechano, V.","A microservice composition approach based on the choreography of BPMN fragments","Information and Software Technology","","","10.1016/j.infsof.2020.106370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086996899&doi=10.1016%2fj.infsof.2020.106370&partnerID=40&md5=262618c8ab816ad2e63461161ea2c11c","Context: Microservices must be composed to provide users with complex and elaborated functionalities. It seems that the decentralized nature of microservices makes a choreography style more appropriate to achieve such cooperation, where lighter solutions based on asynchronous events are generally used. However, a microservice composition based on choreography distributes the flow logic of the composition among microservices making further analysis and updating difficult, i.e. there is not a big picture of the composition that facilitates these tasks. Business Process Model and Notation (BPMN) is the OMG standard developed to represent Business Processes (BPs), being widely used to define the big picture of such compositions. However, BPMN is usually considered in orchestration-based solutions, and orchestration can be a drawback to achieve the decoupling pursued by a microservice architecture. Objective: Defining a microservice composition approach that allows us to create a composition in a BPMN model, which facilitates further analysis for taking engineering decisions, and execute them through an event-based choreography to have a high degree of decoupling and independence among microservices. Method: We followed a research methodology for information systems that consists of a 5-step process: awareness of the problem, suggestion, development, evaluation, and conclusion. Results: We presented a microservice composition approach based on the choreography of BPMN fragments. On the one hand, we propose to describe the big picture of the composition with a BPMN model, providing a valuable mechanism to analyse it when engineering decisions need to be taken. On the other hand, this model is split into fragments in order to be executed through an event-based choreography form, providing the high degree of decoupling among microservices demanded in this type of architecture. This composition approach is supported by a microservice architecture defined to achieve that both descriptions of a composition (big picture and split one) coexist. A realization of this architecture in Java/Spring technology is also presented. Conclusions: The evaluation that is done to our work allows us to conclude that the proposed approach for composing microservices is more efficient than solutions based on ad-hoc development. © 2020","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","127","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Architecture; Business Process; AND splits; Asynchronous event; BPMN; Business process model and notation (BPMN); Choreography; Composition; Engineering decisions; Event-based; Flow logic; Image analysis; Research methodologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACCG2G2R","conferencePaper","2011","Cappiello, C.; Fugini, M.; Ferreira, A.M.; Plebani, P.; Vitali, M.","Business process co-design for energy-aware adaptation","","","","10.1109/ICCP.2011.6047917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80755125694&doi=10.1109%2fICCP.2011.6047917&partnerID=40&md5=f8c79e0bf9ccbdb071ad01f6414bd3a1","Green IT mainly focuses on techniques to extend the products longevity or to virtualise physical resources as well as the provision of energy efficient hardware infrastructures. Less attention has been paid on the applications that run on the machines and their impact on energy consumption. This paper proposes an approach for enabling an efficient use of energy driven by the design of energy-aware business processes. Energy-awareness is given by an enrichment of a typical Business Process conceptual model with annotations able to support the assessment of the energy consumption of the involved business tasks. This information is the basis for the energy-aware adaptation to enact specific strategies to adapt process execution in case energy consumption needs to be lowered or energy leakages have been identified. © 2011 IEEE.","2011","2025-10-22 19:07:48","2025-10-22 19:07:48","","463-470","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Energy efficiency; Resource management; Energy efficient; Energy utilization; Energy aware; Service Oriented; Wireless sensor networks; Information services; Green IT; Service oriented architecture (SOA); Physical resources; Business Process; Co-designs; Context-Aware; Energy-awareness; Adaptive and context-aware processes; Conceptual model; Efficient use of energy; Energy leakage; Green IT and energy-aware applications; Process execution; Resource management in business process execution; Service-oriented architectures for BPM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing, ICCP 2011","","","","","","","","","","","","","","",""
"MBGL6A39","journalArticle","2017","Garrett-Peltier, H.","Green versus brown: Comparing the employment impacts of energy efficiency, renewable energy, and fossil fuels using an input-output model","Economic Modelling","","","10.1016/j.econmod.2016.11.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007467164&doi=10.1016%2fj.econmod.2016.11.012&partnerID=40&md5=f04db1592f0a96b8c6becba5923b071f","Global carbon emissions have reached unsustainable levels, and transforming the energy sector by increasing efficiency and use of renewables is one of the primary strategies to reduce emissions. Policy makers need to understand both the environmental and economic impacts of fiscal and regulatory policies regarding the energy sector. Transitioning to lower-carbon energy will entail a contraction of the fossil fuel sector, along with a loss of jobs. An important question is whether clean energy will create more jobs than will be lost in fossil fuels. This article presents a method of using Input-Output (I-O) tables to create “synthetic” industries – namely clean energy industries that do not currently exist in I-O tables. This approach allows researchers to evaluate public and private spending in clean energy and compare it to the effects of spending on fossil fuels. Here we focus on employment impacts in the short-to-medium term, and leave aside the long-term comparison of operations and maintenance employment. We find that on average, 2.65 full-time-equivalent (FTE) jobs are created from $1 million spending in fossil fuels, while that same amount of spending would create 7.49 or 7.72 FTE jobs in renewables or energy efficiency. Thus each $1 million shifted from brown to green energy will create a net increase of 5 jobs. © 2016 Elsevier Ltd","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","439-447","","","61","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Renewable energy; Employment multipliers; Fiscal policy; Fossil Fuels; Input-output","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6QDSTKN","journalArticle","2022","Radovanovic, A.; Chen, B.; Talukdar, S.; Roy, B.; Duarte, A.; Shahbazi, M.","Power Modeling for Effective Datacenter Planning and Compute Management","IEEE Transactions on Smart Grid","","","10.1109/TSG.2021.3125275","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118668503&doi=10.1109%2fTSG.2021.3125275&partnerID=40&md5=5fad320ed8e10cd39463a0ee20804373","Over the past decade, there has been a global growth in datacenter capacity, power consumption and the associated costs. Accurate mapping of datacenter resource usage (CPU, RAM, etc.) and hardware configurations (servers, accelerators, etc.) to its power consumption is necessary for efficient long-term infrastructure planning and real-time compute load management. This paper presents two types of statistical power models that relate CPU usage of Google's Power Distribution Units (PDUs, commonly referred to as power domains) to their power consumption. The models are deployed in production and are used for cost- and carbon-aware load management, power provisioning and infrastructure rightsizing. They are simple, interpretable and exhibit uniformly high prediction accuracy in modeling power domains with large diversity of hardware configurations and workload types across Google fleet. A multi-year validation of the deployed models demonstrate that they can predict power with less than 5% Mean Absolute Percent Error (MAPE) for more than 95% diverse PDUs across Google fleet. This performance matches the best reported accuracies coming from studies that focus on specific workload types, hardware platforms and, typically, more complex statistical models. © 2010-2012 IEEE.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","1611-1621","","2","13","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Electric power utilization; Energy efficiency; Power modeling; Datacenter; Green computing; Predictive models; Power demands; Computational modelling; Load modeling; Electric load management; Electric power plant loads; datacenter power efficiency; Datacenter power efficiency.; Datacenter power modeling; Power-efficiency; Statistical power; Statistical power model; statistical power models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7PBF2AB","conferencePaper","2020","Béziers La Fosse, T.; Tisi, M.; Mottu, J.-M.; Sunyé, G.","Annotating executable DSLs with energy estimation formulas","","","","10.1145/3426425.3426930","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097711159&doi=10.1145%2f3426425.3426930&partnerID=40&md5=81c27a72ed30adb5ec3fce4903105aa9","Reducing the energy consumption of a complex, especially cyber-physical, system is a cross-cutting concern through the system layers, and typically requires long feedback loops between experts in several engineering disciplines. Having an immediate automatic estimation of the global system consumption at design-time would significantly accelerate this process, but cross-layer tools are missing in several domains. Executable domain-specific modeling languages (xDSLs) can be used to design several layers of the system under development in an integrated view. By including the behavioral specification for software and physical components of the system, they are an effective source artifact for cross-layer energy estimation. In this paper we propose EEL, a language for annotating xDSL primitives with energy-related properties, i.e. how their execution would contribute to the energy consumption on a specific runtime platform. Given an xDSL, energy specialists create EEL models of that xDSL for each considered runtime platform. The models are used at design time, to predict the energy consumption of the real systems. This avoids the need of energetic analysis by deployment and measurement on all runtime platforms, that is slow and expensive. We augment an existing language workbench for xDSLs with an editor for EEL models and a component that computes energy-consumption estimations during model editing. The evaluation shows that EEL can be used to represent estimation models from literature, and provide useful predictions.  © 2020 ACM.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","22-38","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Real time systems; Modeling languages; cyber-physical systems; DSL; Automatic estimation; Behavioral specification; Computer programming languages; Cross-cutting concerns; Digital subscriber lines; Domain specific modeling languages; energy estimation; Energy specialists; Engineering disciplines; Language workbenches; Physical components; Specification languages; xDSL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SLE 2020 - Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering, Co-located with SPLASH 2020","","","","","","","","","","","","","","",""
"SBFRZB4D","journalArticle","2021","Ajibola, O.O.; El-Gorashi, T.; Elmirghani, J.","Energy efficient placement of workloads in composable data center networks","Journal of Lightwave Technology","","","10.1109/JLT.2021.3063325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102297167&doi=10.1109%2fJLT.2021.3063325&partnerID=40&md5=450f3edf04ce174688cd5b761aa2e04c","This paper studies the energy efficiency of composable data center (DC) infrastructures over network topologies. Using a mixed integer linear programming (MILP) model, we compare the performance of disaggregation at rack-scale and pod-scale over selected electrical, optical and hybrid network topologies relative to a traditional DC. Relative to a pod-scale DC, the results show that physical disaggregation at rack-scale is sufficient for optimal efficiency when the optical network topology is adopted, and resource components are allocated in a suitable manner. The optical network topology also enables optimal energy efficiency in composable DCs. The paper also studies logical disaggregation of traditional DC servers over an optical network topology. Relative to physical disaggregation at rack-scale, logical disaggregation of server resources within each rack enables marginal fall in the total DC power consumption (TDPC) due to improved resource demands placement. Hence, an adaptable composable infrastructure that can support both in memory (access) latency sensitive and insensitive workloads is enabled. We also conduct a study of the adoption of micro-service architecture in both traditional and composable DCs. Our results show that increasing the modularity of workloads improves the energy efficiency in traditional DCs, but disproportionate utilization of DC resources persists. A combination of disaggregation and micro-services achieved up to 23% reduction in the TDPC of the traditional DC by enabling optimal resources utilization and energy efficiencies. Finally, we propose a heuristic for energy efficient placement of workloads in composable DCs which replicates the trends produced by the MILP model formulated in this paper.  © 1983-2012 IEEE.","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","3037-3063","","10","39","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Energy efficient; Green computing; Integer programming; Data center networks; Resource demands; Resources utilizations; Topology; Composable infrastructures; Network topology; DC power consumption; Energy efficient data centers; Fiber optic networks; Micro-services; Milp; Mixed integer linear programming model; Optical networks; Optimal efficiency; Rack-scale data center; Software defined infrastructures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQRAHRFZ","journalArticle","2012","Nowak, A.; Binz, T.; Fehling, C.; Kopp, O.; Leymann, F.; Wagner, S.","Pattern-driven green adaptation of process-based applications and their runtime infrastructure","Computing","","","10.1007/s00607-012-0188-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864571412&doi=10.1007%2fs00607-012-0188-x&partnerID=40&md5=8636a305081456245beee386c74a5f77","Business processes are a key aspect of modern organization. In recent years, business process management and optimization has been applied to different cross-cutting concerns such as security, compliance, or Green IT, for example. Based on the ecological characteristics of a business process, proper environmentally sustainable adaptation strategies can be chosen to improve the total environmental impact of the business process. We use ecological sustainable adaptation strategies that are described as green business process patterns. The application of such a green business process pattern, however, affects the business process layer, the application component and the infrastructure layer. This implies that changes in the application infrastructure also need to be considered. Hence, we use best practices of cloud application architectures which are described as Cloud patterns. To guide developers through the adaptation process we propose a pattern-based approach in this work. We correlate Cloud patterns relevant for sustainable business processes to green business process patterns and organize them within a classification. To provide concrete implementation supportwe further annotate these Cloud patterns to application component models that are described with the topology and orchestration specification for cloud applications (TOSCA). Using these annotations, we describe a method that provides the means to optimize business processes based on green business process patterns through adapting the implementation of application components with concrete TOSCA implementation models. © Springer-Verlag 2012.","2012","2025-10-22 19:07:48","2025-10-22 19:07:48","","463-487","","6","94","","","","","","","","","","","","","Scopus","","","","","","","","Optimization; Information technology; Cloud pattern; Green IT; Sustainable development; Business Process; Adaptation of applications; Ecological sustainable business processes; Ecology; Enterprise resource management; Green business process pattern; Sustainable business; TOSCA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YXNRCI3K","journalArticle","2019","Gill, S.S.; Buyya, R.","A taxonomy and future directions for sustainable cloud computing: 360 degree view","ACM Computing Surveys","","","10.1145/3241038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060525188&doi=10.1145%2f3241038&partnerID=40&md5=d3f40eea5104992aa1dda08cc14c583b","The cloud-computing paradigm offers on-demand services over the Internet and supports a wide variety of applications. With the recent growth of Internet of Things (IoT)–based applications, the use of cloud services is increasing exponentially. The next generation of cloud computing must be energy efficient and sustainable to fulfill end-user requirements, which are changing dynamically. Presently, cloud providers are facing challenges to ensure the energy efficiency and sustainability of their services. The use of a large number of cloud datacenters increases cost as well as carbon footprints, which further affects the sustainability of cloud services. In this article, we propose a comprehensive taxonomy of sustainable cloud computing. The taxonomy is used to investigate the existing techniques for sustainability that need careful attention and investigation as proposed by several academic and industry groups. The current research on sustainable cloud computing is organized into several categories: application design, sustainability metrics, capacity planning, energy management, virtualization, thermal-aware scheduling, cooling management, renewable energy, and waste heat utilization. The existing techniques have been compared and categorized based on common characteristics and properties. A conceptual model for sustainable cloud computing has been presented along with a discussion on future research directions. © 2018 Association for Computing Machinery.","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","5","51","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Scheduling; Energy efficiency; Datacenter; Cloud computing; Cloud-computing; Virtualization; Internet of things; Virtualizations; Quality-of-service; Energy management; Green computing; Web services; Carbon footprint; Distributed database systems; Sustainable development; Renewable energies; Application design; Capacity planning; Cloud datacenter; Sustainability; Waste management; Renewable energy; Cloud datacenters; And waste heat utilization; Cooling management; Holistic management; Sustainable cloud computing; Sustainable cloud datacenter; Sustainable cloud datacenters; Sustainable metric; Sustainable metrics; Thermal-aware scheduling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9CYVUW7W","journalArticle","2009","","","Business Process Model and Notation (BPMN)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957994724&partnerID=40&md5=9f5862f053a504beb84804c136c403e9","","2009","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJEV2G85","journalArticle","2020","Knight, W.","","AI Can Do Great Things-if It Doesn't Burn the Planet","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109274656&partnerID=40&md5=48623e1a31d1ab6b8ccc435d9e1709b5","","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AI28ZNZT","journalArticle","2019","Pierson, J.-M.; Baudic, G.; Caux, S.; Celik, B.; Da Costa, G.; Grange, L.; Haddad, M.; Lecuivre, J.; Nicod, J.-M.; Philippe, L.; Rehn-Sonigo, V.; Roche, R.; Rostirolla, G.; Sayah, A.; Stolf, P.; Thi, M.-T.; Varnier, C.","Datazero: Datacenter with zero emission and robust management using renewable energy","IEEE Access","","","10.1109/ACCESS.2019.2930368","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076226061&doi=10.1109%2fACCESS.2019.2930368&partnerID=40&md5=7b284126f13bafd903b5e1137bd6f5dc","As the need for cloud services has been growing steadily, the size and energy consumption of datacenters have increased significantly over the past years. Due to economic and environmental constraints, energy efficiency in datacenters and greenhouse emissions have become a major concern. Renewable energy is widely seen as a promising solution to supply datacenters using local energy, without greenhouse gas emissions. However, the intermittent power generation resulting from the use of renewable energy imposes a paradigm change in the way energy and computation activities are managed. On the one hand, service placement and scheduling may be used on the IT (information technologies) side to adapt to the available power. On the other hand, the storage units may be used to lessen power generation variations. Existing literature and actual deployment mainly design optimization algorithms including the entire system (from cloud service to electrical management, the latter often being neglected or simplified). Conversely to these approaches, we propose a solution where each side optimizes its own objectives, both interacting through a negotiation loop process to reach a common agreement. In this paper, we present DATAZERO, a project developing this idea to ensure high availability of IT services, avoiding unnecessary redundancies, under the constraints due to the intermittent nature of electrical and cloud services flows. © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","103209-103230","","","7","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Optimization; Energy utilization; Middleware; Green computing; Web services; High availability; Gas emissions; Greenhouse gases; Renewable energies; Greenhouse emissions; Service placements; Use of renewable energies; Negotiation; Cloud datacenters; Common agreement; Design optimization; Environmental constraints; Power models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUS6ZD86","conferencePaper","2013","Goiri, Í.; Katsak, W.; Le, K.; Nguyen, T.D.; Bianchini, R.","Parasol and greenswitch: Managing datacenters powered by renewable energy","","","","10.1145/2451116.2451123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875681902&doi=10.1145%2f2451116.2451123&partnerID=40&md5=45dbcae6059c770dd9afad66d3c8ff26","Several companies have recently announced plans to build ""green"" datacenters, i.e. datacenters partially or completely powered by renewable energy. These datacenters will either generate their own renewable energy or draw it directly from an existing nearby plant. Besides reducing carbon footprints, renewable energy can potentially reduce energy costs, reduce peak power costs, or both. However, certain renewable fuels are intermittent, which requires approaches for tackling the energy supply variability. One approach is to use batteries and/or the electrical grid as a backup for the renewable energy. It may also be possible to adapt the workload to match the renewable energy supply. For highest benefits, green datacenter operators must intelligently manage their workloads and the sources of energy at their disposal. In this paper, we first discuss the tradeoffs involved in building green datacenters today and in the future. Second, we present Parasol, a prototype green datacenter that we have built as a research platform. Parasol comprises a small container, a set of solar panels, a battery bank, and a grid-tie. Third, we describe GreenSwitch, our model-based approach for dynamically scheduling the workload and selecting the source of energy to use. Our real experiments with Parasol, GreenSwitch, and MapReduce workloads demonstrate that intelligent workload and energy source management can produce significant cost reductions. Our results also isolate the cost implications of peak power management, storing energy on the grid, and the ability to delay the MapReduce jobs. Finally, our results demonstrate that careful workload and energy source management can minimize the negative impact of electrical grid outages. Categories and Subject Descriptors C.m [Computer Systems Organization]: Miscellaneous; D.4.1 [Operating Systems]: Process Management-Scheduling. Copyright © 2013 ACM.","2013","2025-10-22 19:07:48","2025-10-22 19:07:48","","51-63","","","","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Datacenter; Datacenters; Renewable energies; Batteries; Energy supplies; Battery; Renewable energy; Electrical grids; Sources of energy; Energy source; Map-reduce; Peak power; Source management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS","","","","","","","","","","","","","","",""
"LRMDLVN9","journalArticle","2023","","","Cloud Carbon Footprint Tool","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179503064&partnerID=40&md5=8bbe00d3d506a9496db6d11fd78d98d7","","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V8ZCXJR9","journalArticle","2021","Fontana de Nardin, I.; da Rosa Righi, R.; Lima Lopes, T.R.; André da Costa, C.; Yeom, H.Y.; Köstler, H.","On revisiting energy and performance in microservices applications: A cloud elasticity-driven approach","Parallel Computing","","","10.1016/j.parco.2021.102858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117368062&doi=10.1016%2fj.parco.2021.102858&partnerID=40&md5=cd2fc1322467a84cd684103e180284ac","Monolithic applications are a subject that includes several knowledge areas. Sometimes it can be a challenge to optimize CPU or IO requirements because it is not trivial to recognize the problem itself and improve it. There are many approaches to resolve this situation, where a trending one is the microservices. As a variant of the service-oriented architecture, microservices is a technique that arranges an application as a collection of loosely coupled services. This decomposition enables better software management in cloud-based environments since we can replicate each part individually using cloud elasticity to avoid execution bottlenecks. Also, since elasticity mitigates resource overprovisioning, it favors better energy consumption: the cloud owner can redistribute finite available resources among different tenants, and users can pay less to use the infrastructure. However, elasticity tuning is not trivial and depends on several factors, such as user experience, application architecture, and parameter modeling. Today, we observe a lack of initiatives in the literature that address both performance and energy perspectives to support the execution of microservices applications in the cloud. Concerning this context, this article introduces Elergy as a lightweight proactive elasticity model that provides resource reorganization for a cloud-based microservices application. Its differential approach appears in improving energy consumption by periodically handling the most appropriate amount of resources to execute an application while maintaining or yet improving the performance of CPU-bound applications. Elergy performs these functions proactively, in such a way of preventing future problems related to either resource under- or overprovisioning. The results showed energy consumption reduction and a competitive cost (application time x consumed resources) when comparing Elergy with a non-elastic scenario. Elergy obtained savings from 1.93% to 27.92% for energy consumption. © 2021 Elsevier B.V.","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","108","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Cloud computing; Cloud-computing; Performance; Energy utilization; Elasticity; Energy; Energy-consumption; Green computing; Over provisioning; Information services; Service oriented architecture (SOA); Cloud-based; Monolithics; Cloud elasticities; Knowledge areas","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHGKNJLL","journalArticle","2020","Masanet, E.; Shehabi, A.; Lei, N.; Smith, S.; Koomey, J.","Recalibrating global data center energy-use estimates: Growth in energy use has slowed owing to efficiency gains that smart policies can help maintain in the near term","Science","","","10.1126/science.aba3758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080913294&doi=10.1126%2fscience.aba3758&partnerID=40&md5=e714910a4e298ff7a30d72190beae6c0","","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","984-986","","6481","367","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; power supply; energy efficiency; policy; priority journal; energy; data processing; electricity; information technology; calibration; client server application; data assimilation; energy use; funding; information storage; internet protocol; investment; policy making; power usage effectiveness; Review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTIX46TE","conferencePaper","2020","Thi, M.-T.; Pierson, J.-M.; Da Costa, G.","Game-based negotiation between power demand and supply in green datacenters","","","","10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108028950&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom51426.2020.00112&partnerID=40&md5=3b71c813352ce106a7569fb763e4acbc","The power consumption of datacenters is growing rapidly and becoming a major concern. For reducing carbon footprint and increasing energy efficiency, a promising solution is to locally supply datacenters with renewable energies. However, a challenging problem in building such green datacenter is the coordinating between the power demand and the intermittent power supply. To address this problem, we propose to model the green datacenter as two subsystems, namely, Information Technology (IT) subsystem which consumes energy, and electrical subsystem which supplies energy. Then we aim to find an efficient compromise between the power supply and power demand, taking into account the constraints of both subsystems. Based on buyer-supplier game, we introduce a negotiation approach, in which the two subsystems are modeled as the energy buyer and energy supplier. A negotiation algorithm is proposed, allowing the two subsystems to negotiate and reach an efficient trade-off, while respecting their own utility/monetary gain. The algorithm is evaluated in our middleware of renewable energies-powered datacenter. The experimental results show that the proposed algorithm allows the negotiation process to reach stable points. This algorithm also obtains significant improvement in the datacenter's utility and quality of service (QoS), compared to the algorithms in which joint IT-energy management is not considered. © 2020 IEEE.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","690-697","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Electric power utilization; Energy efficiency; Big data; Cloud computing; Economic and social effects; Middleware; Game theory; Green computing; Power demands; Commerce; Social networking (online); Carbon footprint; Renewable energies; Power supply; Electric power systems; Electrical subsystems; Energy suppliers; Green Datacenter; Negotiation; Negotiation algorithm; Negotiation process; Stable points","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE International Symposium on Parallel and Distributed Processing with Applications, 2020 IEEE International Conference on Big Data and Cloud Computing, 2020 IEEE International Symposium on Social Computing and Networking and 2020 IEEE International Conference on Sustainable Computing and Communications, ISPA-BDCloud-SocialCom-SustainCom 2020","","","","","","","","","","","","","","",""
"L46PPGKN","journalArticle","2020","Gholipour, N.; Arianyan, E.; Buyya, R.","A novel energy-aware resource management technique using joint VM and container consolidation approach for green computing in cloud data centers","Simulation Modelling Practice and Theory","","","10.1016/j.simpat.2020.102127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086469770&doi=10.1016%2fj.simpat.2020.102127&partnerID=40&md5=f6c07590171b1d1c04d2407d84f70c54","Cloud computing is being rapidly adopted for managing IT services as a notable solution due to diverse beneficiaries such as automatically optimized resource management as well as modern service delivery models. The container as a service has been recently introduced by cloud providers as a new service apart from traditional cloud services. Containers enable applications to run and deploy on isolated virtual space, and the operating system kernel is shared among them. Also, containerization has some attributes such as scalability, highly portable properties, and lightweight, for those reasons, it is applied for running isolated applications. Reducing energy consumption, as well as their CO2 emissions, are great deals for cloud providers. In this direction, consolidation is recommended as a vital energy-aware approach in cloud data centers. Previously, independent virtual machine migration or container migration was proposed in the literature for green computing in cloud data centers. However, this paper proposes a new cloud resource management procedure based on a multi-criteria decision-making method that takes advantage of a joint virtual machine and container migration approach concurrently. The results of simulations using ContainerCloudsim simulator validates the applicability of the proposed approach which shows notable reductions in energy consumption, SLA violation, and number of migrations in comparison with the state-of-the-art algorithms. © 2020 Elsevier B.V.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","104","","","","","","","","","","","","","Scopus","","","","","","","","Power management; Containers; Datacenter; Cloud computing; Information management; Resource management; Energy utilization; Decision making; Green computing; Containerization; Energy consumption; Natural resources management; Resource allocation; Virtual machine; Network security; Reducing energy consumption; State-of-the-art algorithms; Consolidation; Computer aided software engineering; Virtual machine migrations; Resource management techniques; Energy aware approaches; Multi-criteria decision making methods; Operating system kernel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZLXVFW2","journalArticle","2022","Souza, A.; Bashir, N.","","Ecovisor: A Virtual Energy System for Carbon-efficient Applications","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179523438&partnerID=40&md5=413ec0637a84a68c003b35671169313d","","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MA8ER2Y4","journalArticle","2023","","","Azure Emissions Impact Dashboard","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179519572&partnerID=40&md5=c16d417e84300f715a1bd9d1615a8f6e","","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRXRWU5T","journalArticle","2004","Bruegge, B.; Dutoit, A.H.","","Object-Oriented Software Engineering Using UML, Patterns, and Java","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003984986&partnerID=40&md5=c2fd5ef3e7d01eea418ca6aaa0e50808","","2004","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPYS2CF8","journalArticle","2023","","","AWS customer carbon footprint tool","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179510119&partnerID=40&md5=74c5854553d60b000a0b3a740acaba9e","","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z3QLCJN8","journalArticle","2022","Saboor, A.; Mahmood, A.K.; Omar, A.H.; Hassan, M.F.; Shah, S.N.M.; Ahmadian, A.","Enabling rank-based distribution of microservices among containers for green cloud computing environment","Peer-to-Peer Networking and Applications","","","10.1007/s12083-021-01218-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112841408&doi=10.1007%2fs12083-021-01218-y&partnerID=40&md5=ee57caac17e75a71c6e3bdd06f31114e","Microservices architecture is a functional software design methodology that promises the redefinition of the architectural style that aims to create a single application as a suite of tiny, loosely coupled services or components, each performing its own tasks and interacting with each other. The cloud services widely shifted from monoliths to microservices and gained the popularity for use in scalable cloud application. The usage of microservices involved intensive network communication to call number of interdependent microservices running inside the cloud nodes. It provides flexibility in the delivery of service but also increases energy usage and poor service efficiency which results in increased carbon emissions. To solve these issues, the prevailing technologies were designed for single unit monolithic cloud applications, and not tailored for the chain oriented service delivery. This study addresses the dynamic provisioning of containers and respective microservices in cloud computing environment by building rank-based profiles and using those profiles for allocation of web application’s microservices along with containers to the cloud data centers. The MicroRanker service is proposed to rank all of the participating microservices and distribute them across different nodes even before the execution of the cloud services. Further, the MicroRanker service is utilized to dynamically update the container placement due to continuous DevOps actions. The proposed solution was tested using custom built simulation environment. The achieved results showed that the distribution of containers along with respective microservices in accordance with MicroRanker service resulted in less energy consumption (i.e. between 81.6 kWh-87.7 kWh compared to 88.9 kWh-95.7 kWh) and significantly lowered the emission of carbon (i.e. between 5.92 kg-33.31 kg compared to 17.2 kg-47.35 kg) due to higher utilization of renewable energy. The use of rank-based microservices distribution also decreased response time (i.e. between 29 ms-142 ms compared to 106 ms-217 ms) due to the availability of the container along with microservice within the same data center region. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","77-91","","1","15","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Containers; Optimization; Microservices; Cloud computing; Cloud data centers; Energy utilization; Software design; Green computing; Web services; Architectural style; Cloud computing environments; Simulation environment; High performance computing; Carbon; Dynamic provisioning; Network communications; Ranking; Renewable energies; Software design methodologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSBFLS3H","journalArticle","2011","Swan, G.","How green is my cloud?","Cio","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179515540&partnerID=40&md5=1d61b66316e92c6a9b04ba544ec57eb2","","2011","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPDFYW9Y","journalArticle","2017","Kratzke, N.; Quint, P.-C.","Understanding cloud-native applications after 10 years of cloud computing - A systematic mapping study","Journal of Systems and Software","","","10.1016/j.jss.2017.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009186306&doi=10.1016%2fj.jss.2017.01.001&partnerID=40&md5=00833465689b49e90c3ae3861f0862ab","It is common sense that cloud-native applications (CNA) are intentionally designed for the cloud. Although this understanding can be broadly used it does not guide and explain what a cloud-native application exactly is. The term “cloud-native” was used quite frequently in birthday times of cloud computing (2006) which seems somehow obvious nowadays. But the term disappeared almost completely. Suddenly and in the last years the term is used again more and more frequently and shows increasing momentum. This paper summarizes the outcomes of a systematic mapping study analyzing research papers covering “cloud-native” topics, research questions and engineering methodologies. We summarize research focuses and trends dealing with cloud-native application engineering approaches. Furthermore, we provide a definition for the term “cloud-native application” which takes all findings, insights of analyzed publications and already existing and well-defined terminology into account. © 2017 Elsevier Inc.","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","1-16","","","126","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Cloud computing; Mapping; Systematic mapping studies; Systematic mapping study; Cloud-native application; CNA; Elastic platform; Pattern; Self service; Softwareization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TF5QIAIW","journalArticle","2021","Radovanovic, A.; Koningstein, R.; Schneider, I.; Chen, B.; Duarte, A.; Roy, B.; Xiao, D.; Haridasan, M.; Hung, P.; Care, N.","Carbon-aware computing for datacenters","Carbon-aware computing for datacenters","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115135925&partnerID=40&md5=9021d768febdcbc0a73844b7efd23ce9","","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVKWR9T6","journalArticle","2022","Ali, A.; Iqbal, M.M.","A Cost and Energy Efficient Task Scheduling Technique to Offload Microservices Based Applications in Mobile Cloud Computing","IEEE Access","","","10.1109/ACCESS.2022.3170918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129650903&doi=10.1109%2fACCESS.2022.3170918&partnerID=40&md5=bbe4705e536aabb149df2254dbbbe6be","The number of smartphone users and mobile devices has increased significantly. The Mobile Cloud Applications based on cloud computing have also been increased. The mobile apps can be used in Augmented Reality, E-Transportation, 2D/3-D Games, E-Healthcare, and Education. The modern cloud-based frameworks provide such services on Virtual Machines. The existing frameworks worked well, but these suffered the problems such as overhead, resource utilization, lengthy boot-time, and cost of running Mobile Applications. This study addresses these problems by proposing a Dynamic Decision-Based Task Scheduling Technique for Microservice-based Mobile Cloud Computing Applications (MSCMCC). The MSCMCC runs delay-sensitive applications and mobility with less cost than existing approaches. The study focused on Task Scheduling problems on heterogeneous Mobile Cloud servers. We further propose Task Scheduling and Microservices based Computational Offloading (TSMCO) framework to solve the Task Scheduling in steps, such as Resource Matching, Task Sequencing, and Task Scheduling. Furthermore, the experimental results elaborate that the proposed MSCMCC and TSMCO enhance the Mobile Server Utilization. The proposed system effectively minimizes the cost of healthcare applications by 25%, augmented reality by 23%, E-Transport tasks by 21%, and 3-D games tasks by 19%, the average boot-time of microservices applications by 17%, resource utilization by 36%, and tasks arrival time by 16%.  © 2013 IEEE.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","46633-46651","","","10","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Multitasking; Microservice; Cloud computing; Cloud-computing; microservices; Mobile cloud computing; mobile cloud computing; Augmented reality; Costs; Scheduling algorithms; Cost benefit analysis; Job analysis; Processor scheduling; Task analysis; Microservice architecture; task scheduling; task offloading; Tasks scheduling; Delay-sensitive applications; Mobile handsets; mHealth; task sequencing; Task offloading; Task sequencing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAFTKTAP","journalArticle","2018","Acton, M.; Bertoldi, P.; Booth, J.; Newcombe, L.; Rouyer, A.; Tozer, R.","2018 Best Practice Guidelines for the EU Code of Conduct on Data Centre Energy Efficiency","Best Practice Guidelines for the EU Code of Conduct on Data Centre Energy Efficiency","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060207119&partnerID=40&md5=fa589630dad8c227e70c8ecff6fd0320","","2018","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V94FSZY2","bookSection","2021","Andrikopoulos, V.; Lago, P.","Software Sustainability in the Age of Everything as a Service","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104134021&doi=10.1007%2f978-3-030-73203-5_3&partnerID=40&md5=9dbb5e649567d314bea19d4024dee983","The need for acknowledging and managing sustainability as an essential quality of software systems has been steadily increasing over the past few years, in part as a reaction to the implications of “software eating the world”. Especially the widespread adoption of the Everything as a Service (*aaS) model of delivering software and (virtualized) hardware through cloud computing has put two sustainability dimensions upfront and center. On the one hand, services must be sustainable on a technical level by ensuring continuity of operations for both providers and consumers despite, or even better, while taking into account their evolution. On the other hand, the prosuming of services must also be financially sustainable for the involved stakeholders. In this work, we discuss the need for a software architecting approach that encompasses in a holistic manner the other two dimensions of software sustainability as well, namely the social and environmental aspects of services. We highlight relevant works and identify key challenges still to be addressed in the context of software systems operating across different models for cloud delivery and deployment. We then present our vision for an architecting framework that allows system stakeholders to work in tandem towards improving a set of sustainability indicators specifically tailored for the *aaS model. © 2021, Springer Nature Switzerland AG.","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","35-47","","","12521 LNCS","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Software architecture; Software systems; Computer software; Sustainable development; Software sustainability; *aaS; Architecting frameworks; Quality of softwares; Social and environmental; Software architecting; Sustainability dimensions; Sustainability indicators; Technical levels; Vision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52BLJSU4","journalArticle","2020","Brondolin, R.; Santambrogio, M.D.","A Black-box Monitoring Approach to Measure Microservices Runtime Performance","ACM Transactions on Architecture and Code Optimization","","","10.1145/3418899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097221697&doi=10.1145%2f3418899&partnerID=40&md5=a35a5b1cfd13bccdec489a30d18ccd45","Microservices changed cloud computing by moving the applications' complexity from one monolithic executable to thousands of network interactions between small components. Given the increasing deployment sizes, the architectural exploitation challenges, and the impact on data-centers' power consumption, we need to efficiently track this complexity. Within this article, we propose a black-box monitoring approach to track microservices at scale, focusing on architectural metrics, power consumption, application performance, and network performance. The proposed approach is transparent w.r.t. the monitored applications, generates less overhead w.r.t. black-box approaches available in the state-of-the-art, and provides fine-grain accurate metrics. © 2020 ACM.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","4","17","","","","","","","","","","","","","Scopus","","","","","","","","Electric power utilization; Microservices; cloud computing; Run-time performance; State of the art; Green computing; Data centers; Application performance; Complex networks; kubernetes; docker; network performance monitoring; performance monitoring; power attribution; Black box approach; Monitoring approach; Network interaction; Small components","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M3A8LIFQ","journalArticle","2017","Gannon, D.; Barga, R.; Sundaresan, N.","Cloud-Native Applications","IEEE Cloud Computing","","","10.1109/MCC.2017.4250939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038610210&doi=10.1109%2fMCC.2017.4250939&partnerID=40&md5=198ead132dc790dd17c30a4142e93127","The term 'cloud-native' refers to a set of technologies and design patterns that have become the standard for building large-scale cloud applications. In this editorial we describe basic properties of successful cloud applications including dynamic scalability, extreme fault tolerance, seamless upgradeability and maintenance and security. To make it possible to build applications that meet these requirements we describe the microservice architecture and serverless computing foundation that are central to cloud-native design. © 2017 IEEE.","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","16-21","","5","4","","","","","","","","","","","","","Scopus","","","","","","","","cloud computing; Cloud computing; microservices; Cloud applications; Distributed computer systems; serverless; Fault tolerance; Design Patterns; cloud-native; distributed computing; Upgradeability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPAV3AAY","conferencePaper","2019","Schneider, J.; Basalla, M.; Seidel, S.","Principles of green data mining","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084268601&partnerID=40&md5=71404958600ace3dbea27590a8995f59","This paper develops a set of principles for green data mining, related to the key stages of business understanding, data understanding, data preparation, modeling, evaluation, and deployment. The principles are grounded in a review of the Cross Industry Standard Process for Data mining (CRISP-DM) model and relevant literature on data mining methods and Green IT. We describe how data scientists can contribute to designing environmentally friendly data mining processes, for instance, by using green energy, choosing between make-or-buy, exploiting approaches to data reduction based on business understanding or pure statistics, or choosing energy friendly models. © 2019 IEEE Computer Society. All rights reserved.","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","2065-2074","","","2019-January","","","","","","","","","","","","","Scopus","","","","","","","","Data mining; Green energy; Business understanding; Cross industry; Data mining methods; Data mining process; Data preparation; Data understanding; Green manufacturing; Make-or-buy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the Annual Hawaii International Conference on System Sciences","","","","","","","","","","","","","","",""
"XSYIERQG","journalArticle","","","","Introducing the Website Carbon Rating System","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218919009&partnerID=40&md5=98207cc5196ae939820fcd87be59505a","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PSGY5L4N","journalArticle","","","","Carbon footprint reporting-customer carbon footprint tool-amazon web services","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163845871&partnerID=40&md5=c5fd5048a46cf53bdd56b301ce89de0b","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAJLPGHS","journalArticle","","","","Carbon Footprint — Reporting Methodology - Carbon Footprint Documentation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199329343&partnerID=40&md5=4c611d4d5a6baef095ba9cb6ac12cb67","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VT4A4JRP","conferencePaper","2015","Aggarwal, K.; Hindle, A.; Stroulia, E.","GreenAdvisor: A tool for analyzing the impact of software evolution on energy consumption","","","","10.1109/ICSM.2015.7332477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961670071&doi=10.1109%2fICSM.2015.7332477&partnerID=40&md5=7934db344282dbc065f2e634177812ce","Change-impact analysis, namely 'identifying the potential consequences of a change' is an important and well studied problem in software evolution. Any change may potentially affect an application's behaviour, performance, and energy consumption profile. Our previous work demonstrated that changes to the system-call profile of an application correlated with changes to the application's energy-consumption profile. This paper evaluates and describes GreenAdvisor, a first of its kind tool that systematically records and analyzes an application's system calls to predict whether the energy-consumption profile of an application has changed. The GreenAdvisor tool was distributed to numerous software teams, whose members were surveyed about their experience using GreenAdvisor while developing Android applications to examine the energy-consumption impact of selected commits from the teams' projects. GreenAdvisor was evaluated against commits of these teams' projects. The two studies confirm the usefulness of our tool in assisting developers analyze and understand the energy-consumption profile changes of a new version. Based on our study findings, we constructed an improved prediction model to forecast the direction of the change, when a change in the energy-consumption profile is anticipated. This work can potentially be extremely useful to developers who currently have no similar tools. © 2015 IEEE.","2015","2025-10-22 19:07:48","2025-10-22 19:07:48","","311-320","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Embedded systems; Energy efficiency; Forecasting; Energy utilization; System calls; Computer software; Software Evolution; Intrusion detection; energy efficiency; Computer aided software engineering; Android applications; Computer software maintenance; Prediction model; application software; Change impact analysis; Software energy consumption; Software teams; software tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings","","","","","","","","","","","","","","",""
"5MDGXLXC","journalArticle","","","","Greenframe-cli","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218915307&partnerID=40&md5=7dafb2a2ac942376edb27e9a0265ee4a","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FSFBHLB","conferencePaper","2013","Oliner, A.J.; Iyer, A.P.; Stoica, I.; Lagerspetz, E.; Tarkoma, S.","Carat: Collaborative energy diagnosis for mobile devices","","","","10.1145/2517351.2517354","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905676511&doi=10.1145%2f2517351.2517354&partnerID=40&md5=1834b8bf85324e3eaf7669a17e06a53f","We aim to detect and diagnose energy anomalies, abnormally heavy battery use. This paper describes a collaborative black-box method, and an implementation called Carat, for diagnosing anomalies on mobile devices. A client app sends intermittent, coarse-grained measurements to a server, which correlates higher expected energy use with client properties like the running apps, device model, and operating system. The analysis quantifies the error and confidence associated with a diagnosis, suggests actions the user could take to improve battery life, and projects the amount of improvement. During a deployment to a community of more than 500,000 devices, Carat diagnosed thousands of energy anomalies in the wild. Carat detected all synthetically injected anomalies, produced no known instances of false positives, projected the battery impact of anomalies with 95% accuracy, and, on average, increased a user's battery life by 11% after 10 days (compared with 1.9% for the control group).","2013","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Electric batteries; Embedded systems; Mobile devices; Energy; Diagnosis; Mobile; Analytics; Battery; Collaborative","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","SenSys 2013 - Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems","","","","","","","","","","","","","","",""
"UQA5CCW6","conferencePaper","2022","Humberto Alvarez Valera, H.; Dalmau, M.; Roose, P.; Larracoechea, J.; Herzog, C.","PISCO: A smart simulator to deploy energy saving methods in microservices based networks","","","","10.1109/IE54923.2022.9826775","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136004987&doi=10.1109%2fIE54923.2022.9826775&partnerID=40&md5=d4709e1da2c1de3afc149006c04bedf6","Nowadays, many researchers work to identify microservices-based application deployments and scheduling solutions to save energy without decreasing functional QoS. In this work, we present PISCO: A simulator that allows facing this challenge in a simple and efficient way, enabling its users to focus uniquely on microservices deployment/scheduling algorithms and its hardware/software repercussions (load vs. energy consumption) without worrying about low-level network configurations or operating system issues. PISCO is able to deploy and schedule (move, duplicate, start/stop) microservices and their dependencies on various devices with software and hardware heterogeneity (CPU, bandwidth, RAM, Battery, etc.), taking into account various scheduling heuristics algorithms: centralized vs non-centralized. To do this, PISCO allows deploying custom network topologies based on client-server schemes or p2p distributions, where devices can (dis)appear, turn on/off obeying random circumstances or user strategies.Finally, the simulator performs relevant operations such as QoS definition, resource monitoring, calculation of energy saved and consumption tracking (at device and network level). We tested some ideas based on our previous work 'Kaligreen' to demonstrate the effectiveness of PISCO.  © 2022 IEEE.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Scheduling; Microservice; microservices; Energy utilization; Middleware; Energy; Energy conservation; CPU; Scheduling algorithms; Application scheduling; energy; middleware; Network; Centralised; consumption; hard disk; network; prototype; simulator; Energy saving methods; Simulators; Peer to peer networks; Consumption; Hard disc; Prototype","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2022 18th International Conference on Intelligent Environments, IE 2022 - Proceedings","","","","","","","","","","","","","","",""
"RCKKSG5V","conferencePaper","2022","Noureddine, A.","PowerJoular and JoularJX: Multi-Platform Software Power Monitoring Tools","","","","10.1109/IE54923.2022.9826760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136040656&doi=10.1109%2fIE54923.2022.9826760&partnerID=40&md5=5b3a65ad6dd9d140eb3a7edfaf97c36f","Monitoring the power consumption of applications and source code is an important step in writing green software. In this paper, we propose PowerJoular and JoularJX, our software power monitoring tools. We aim to help software developers in understanding and analyzing the power consumption of their programs, and help system administrators and automated tools in monitoring the power consumption of large numbers of heterogeneous devices.  © 2022 IEEE.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Electric power utilization; Software developer; Source codes; Energy analysis; Monitoring tools; Measurement; System administrators; Power Consumption; Power monitoring; Application codes; Energy Analysis; Help systems; Multi-platform; Power Monitoring; Program systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2022 18th International Conference on Intelligent Environments, IE 2022 - Proceedings","","","","","","","","","","","","","","",""
"38PX7M82","journalArticle","2024","Larracoechea, J.A.; Ilarri, S.; Roose, P.","A Proposal of Behavior-Based Consumption Profiles for Green Software Design","Applied Sciences (Switzerland)","","","10.3390/app14177456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203852902&doi=10.3390%2fapp14177456&partnerID=40&md5=764572cb721393b46c5d6d5cbbf1be5c","Despite the increase in the efficiency of energy consumption in information and communication technology, software execution and its constraints are responsible for how energy is consumed in hardware hosts. Consequently, researchers have promoted the development of sustainable software with new development methods and tools to lessen its hardware demands. However, the approaches developed so far lack cohesiveness along the stages of the software development life cycle (SDLC) and exist outside of a holistic method for green software development (GSD). In addition, there is a severe lack of approaches that target the analysis and design stages of the SDLC, leaving software architects and designers unsupported. In this article, we introduce our behavior-based consumption profile (BBCP) external Domain-Specific Language (DSL), aimed at assisting software architects and designers in modeling the behavior of software. The models generated with our external DSL contain multiple sets of properties that characterize features of the software’s behavior. In contrast to other modeling languages, our BBCP emphasizes how time and probability are involved in software execution and its evolution over time, helping its users to gather an expectation of software usage and hardware consumption from the initial stages of software development. To illustrate the feasibility and benefits of our proposal, we conclude with an analysis of the model of a software service created using the BBCP, which is simulated using Insight Maker to obtain an estimation of hardware consumption and later translated to energy consumption. © 2024 by the authors.","2024","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","17","14","","","","","","","","","","","","","Scopus","","","","","","","","Software design; software engineering; Energy-consumption; Software architects; SOA; behavior with software; Behavior with software; Behavior-based; Green development; green software; Green software; Program translators; software behavior; Software behavior; Software development life-cycle; Software execution; software profiling; Software profiling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZB5VVR5","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218978256&partnerID=40&md5=b0a71f39575d3a14932bf1bb0c1f0cab","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2KVQW9EZ","conferencePaper","2021","Larracoechea, J.A.; Roose, P.; Ilarri, S.; Cardinale, Y.; Laborie, S.; González, M.J.","Towards Services Profiling for Energy Management in Service-oriented Architectures","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146200750&partnerID=40&md5=95366b38f0d161158badb32d4e8a0817","Even though hardware architects have managed to incrementally mitigate energy consumption in information and communication technology devices, it will always be a requisite for software execution. This has motivated researchers to develop a limited amount of methodologies that promote green software development and its philosophy, with new assessment methods for calculating the energetic costs of software development and software execution. In spite of this, they have been acknowledged and adopted with limited success, as they try to address highly-volatile variables (like human behavior) and environments with specific hardware/software platforms and language-centric solutions. This has created a conflict between theory and practice where, otherwise, a generic and adaptive approach could manage the discord. In this paper, we present a brief review of available selected research in relation to services' requirements definition and profiling for energy management, as well as the limitations and advantages of existing proposals in relation to green software development. Furthermore, we present our progress towards a series of properties to define services' requirements and their resource consumption behavior. Our final goal is to create a proper approach for energy management from the analysis and design phases of the Software Development Life Cycle using Service- Oriented Architectures as a platform for our work. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","209-216","","","2021-October","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Information management; Energy utilization; Software design; Energy management; Computation theory; Energy-consumption; Green computing; Life cycle; Information services; Information and Communication Technologies; Energy Management; ICT; Service oriented architecture (SOA); Green software; Software execution; Service requirements; Mobile-computing; Energetic costs; Green Software; Human environment; Mobile Computing; Service-oriented Architecture; Soa (serviceoriented architecture)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","International Conference on Web Information Systems and Technologies, WEBIST - Proceedings","","","","","","","","","","","","","","",""
"M5KRGS6G","journalArticle","","","","PowerJoular","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218973261&partnerID=40&md5=1bf964a5f4f416faec8ff38cdba4f43c","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIQQ9LGM","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218919452&partnerID=40&md5=e34b3ece610bb510ecc5288285293f3d","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKIYXSQR","journalArticle","","","","Visualize - CodeCarbon documentation","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199360300&partnerID=40&md5=80d1416c8c15151a5d097d19a4224563","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VKH7E29X","journalArticle","","","","Calculating My Carbon Footprint - Microsoft Sustainability","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199386338&partnerID=40&md5=baada82c0562424570efa26d3379de99","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7EUGT8VD","conferencePaper","2014","Hindle, A.; Wilson, A.; Rasmussen, K.; Barlow, E.J.; Campbell, J.C.; Romansky, S.","GreenMiner: A hardware based mining software repositories software energy consumption framework","","","","10.1145/2597073.2597097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938780683&doi=10.1145%2f2597073.2597097&partnerID=40&md5=c9e2899691445bb728bdb85a9db1a8dd","Green Mining is a field of MSR that studies software energy consumption and relies on software performance data. Unfortunately there is a severe lack of publicly available software power use performance data. This means that green mining researchers must generate this data themselves by writing tests, building multiple revisions of a product, and then running these tests multiple times (10+) for each software revision while measuring power use. Then, they must aggregate these measurements to estimate the energy consumed by the tests for each software revision. This is time consuming and is made more difficult by the constraints of mobile devices and their OSes. In this paper we propose, implement, and demonstrate Green Miner: the first dedicated hardware mining software repositories testbed. The Green Miner physically measures the energy consumption of mobile devices (Android phones) and automates the testing of applications, and the reporting of measurements back to developers and researchers. The Green Miner has already produced valuable results for commercial Android application developers, and has been shown to replicate other power studies' results. Copyright is held by the author/owner(s). Publication rights licensed to ACM.","2014","2025-10-22 19:07:48","2025-10-22 19:07:48","","12-21","","","","","","","","","","","","","","","","Scopus","","","","","","","","Dedicated hardware; Energy utilization; Software testing; Android; Software performance; Android applications; Software energy consumption; Android (operating system); Miners; Mining software repositories; Software change; Software revisions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","11th Working Conference on Mining Software Repositories, MSR 2014 - Proceedings","","","","","","","","","","","","","","",""
"WSP3ED22","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218974675&partnerID=40&md5=3b3225e5da3c52a2135fca7e19eda144","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"629Z6TQY","journalArticle","","Larracoechea, J.; Roose, P.; Ilarri, S.; Cardinale, Y.; Laborie, S.; Vara, O.","Behavior-Based Consumption Profiles for the Approximation of the Energy Consumption of Services","Proceedings of the International Conference on Information Systems Development (ISD)","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203860904&partnerID=40&md5=2e7376a66b60abe8388dda1642faa0d9","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D2UAPWK8","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218931022&partnerID=40&md5=3cf04f0a58d5edf9f3903830ea018e2d","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPHWLT5X","journalArticle","","","","Methodology - Cloud Carbon Footprint","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199349781&partnerID=40&md5=44706c59696e4284af4dc56a76c4b2d0","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WNX6MTK4","conferencePaper","2017","Jagroep, E.; Broekman, J.; Van Der Werf, J.M.E.M.; Brinkkemper, S.; Lago, P.; Blom, L.; Van Vliet, R.","Awakening awareness on energy consumption in software engineering","","","","10.1109/ICSE-SEIS.2017.10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025819050&doi=10.1109%2fICSE-SEIS.2017.10&partnerID=40&md5=331c876afe2f7c9e9fe8285c0525c478","Software producing organizations have the ability to address the energy impact of their ICT solutions during the development process. However, while industry is convinced of the energy impact of hardware, the role of software has mostly been acknowledged by researchers in software engineering. Strengthened by the limited practical knowledge to reduce the energy consumption, organizations have less control over the energy impact of their products and lose the contribution of software towards energy related strategies. Consequently, industry risks not being able to meet customer requirements or even fulfillcorporate sustainability goals. In this paper we perform an exploratory case study on how to create and maintain awareness on an energy consumption perspective for software among stakeholders involved with the development of software products. During the study, we followed the development process of two commercial software products and provided direct feedback to the stakeholders on the effects of their development efforts, specifically concerning energy consumption and performance, using an energy dashboard. Multiple awareness measurements allowed us to keep track of changes over time on specific aspects affecting software development. Our results show that, despite a mixed sentiment towards the dashboard, changed awareness has triggered discussion on the energy consumption of software. © 2017 IEEE.","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","76-85","","","","","","","","","","","","","","","","Scopus","","","","","","","","Energy utilization; Software design; Software engineering; Software products; Development process; Software energy consumption; Awareness; Awareness measurement; Commercial software products; Customer requirements; Energy consumption perspective; Exploratory case studies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Society Track, ICSE-SEIS 2017","","","","","","","","","","","","","","",""
"L7SSRZ3U","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218940533&partnerID=40&md5=3b5d0748ff8c9ef0857c4cf03268ab0f","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RP5A8DD7","journalArticle","","","","Mlco2/codecarbon","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218932193&partnerID=40&md5=4a1183dfb641a7fc4acba8c2eb6c91aa","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRVFVR86","journalArticle","","","","Overview | Cloud Carbon Footprint","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218923535&partnerID=40&md5=2f85ad18d1ed42455434d7e2c8e14fab","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQELVCX4","journalArticle","2023","Gelenbe, E.","Electricity Consumption by ICT: Facts, trends, and measurements","Ubiquity","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197041776&partnerID=40&md5=7348dc3b4c10032368d4ce69c820cc01","","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","1-15","","August","2023","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFKXY3NY","journalArticle","","Roose, P.; Sergio, I.; Larracoechea, J.A.; Cardinale, Y.; Laborie, S.","Towards an Integrated Full-Stack Green Software Development Methodology","Proceedings of the 29th International Conference on Information Systems Development","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203850899&partnerID=40&md5=36c6f68557686700d736a2330696cd51","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LFLY99E","journalArticle","2016","Pang, C.; Hindle, A.; Adams, B.; Hassan, A.E.","What Do Programmers Know about Software Energy Consumption?","IEEE Software","","","10.1109/MS.2015.83","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968902060&doi=10.1109%2fMS.2015.83&partnerID=40&md5=783696f1bd63fb00affeec5dfd446470","Traditionally, programmers received a range of training on programming languages and methodologies, but they rarely receive training on software energy consumption. Yet, the popularity of mobile devices and cloud computing requires increased awareness of software energy consumption. On mobile devices, battery life often limits computation. Under the demands of cloud computing, datacenters struggle to reduce energy consumption through virtualization and datacenter-infrastructure-management systems. Efficient software energy consumption is increasingly becoming an important nonfunctional requirement for programmers. However, are programmers knowledgeable enough about software energy consumption? Do they base their implementation decision on popular beliefs? Researchers surveyed more than 100 programmers regarding their knowledge of software energy consumption. They found that the programmers had limited knowledge of energy efficiency, lacked knowledge of the best practices to reduce software energy consumption, and were often unsure about how software consumes energy. These results highlight the need for better training and education on energy consumption and efficiency. © 2016 IEEE.","2016","2025-10-22 19:07:48","2025-10-22 19:07:48","","83-89","","3","33","","","","","","","","","","","","","Scopus","","","","","","","","Energy efficiency; Cloud computing; Distributed computer systems; Energy utilization; Virtualizations; Mobile devices; Reduce energy consumption; Power usage; energy efficiency; Non-functional requirements; Best practices; Software energy consumption; Infrastructure management system; power usage; software energy consumption; software power consumption; Training and education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"53MCEMFY","journalArticle","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218969261&partnerID=40&md5=57894daa490d623cac1c7abe9ed9c6eb","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HTR4JSX","conferencePaper","2014","Manotas, I.; Pollock, L.; Clause, J.","SEEDS: A software engineer's energy-optimization decision support framework","","","","10.1145/2568225.2568297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994139877&doi=10.1145%2f2568225.2568297&partnerID=40&md5=21c1add538c0945f0fe450fe640a2dea","Reducing the energy usage of software is becoming more important in many environments, in particular, battery-powered mobile devices, embedded systems and data centers. Recent empirical studies indicate that software engineers can support the goal of reducing energy usage by making design and implementation decisions in ways that take into consideration how such decisions impact the energy usage of an application. However, the large number of possible choices and the lack of feedback and information available to software engineers necessitates some form of automated decision-making support. This paper describes the first known automated support for systematically optimizing the energy usage of applications by making code-level changes. It is effective at reducing energy usage while freeing developers from needing to deal with the low-level, tedious tasks of applying changes and monitoring the resulting impacts to the energy usage of their application. We present a general framework, SEEDS, as well as an instantiation of the framework that automatically optimizes Java applications by selecting the most energy-efficient library implementations for Java's Collections API. Our empirical evaluation of the framework and instantiation show that it is possible to improve the energy usage of an application in a fully automated manner for a reasonable cost. © 2014 ACM.","2014","2025-10-22 19:07:48","2025-10-22 19:07:48","","503-514","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Design and implementations; Embedded systems; Energy efficiency; Automation; Java programming language; Software engineering; Mobile devices; Decision making; Energy optimization; Software optimization; Empirical evaluations; Energy usage; Decision support systems; Automated decision making; analysis framework; Analysis frameworks; Decision support framework; Engineers; software optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - International Conference on Software Engineering","","","","","","","","","","","","","","",""
"YGBR7SSR","conferencePaper","2023","Amaral, M.; Chen, H.; Chiba, T.; Nakazawa, R.; Choochotkaew, S.; Lee, E.K.; Eilam, T.","Kepler: A Framework to Calculate the Energy Consumption of Containerized Applications","","","","10.1109/CLOUD60044.2023.00017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174254307&doi=10.1109%2fCLOUD60044.2023.00017&partnerID=40&md5=ad9611593dafbcf59292d9d1201e3478","Energy accounting is crucial in data centers for optimizing power provisioning, capping, and tuning. This paper introduces the Kepler framework, which estimates power consumption at the process, container, and Kubernetes pod levels. Kepler offers a set of power models applicable to various architectures and metrics. In this study, we propose a generic power model that utilizes hardware counters (HC) and realtime system power metrics (e.g., running average power limit (RAPL)) as independent variables in a regression model. Unlike previous approaches that rely on aggregate power consumption, our methodology measures individual process power consumption to train the power model. We provide step-by-step instructions to measure process power consumption in a controlled environment, considering the activation constant and load-dependent dynamic power consumption in different executions. By following the Greenhouse Gas (GHG) Protocol, our approach ensures the fair distribution of constant power among the user's processes. The results demonstrate significantly improved accuracy with a mean squared error (MSE) as low as 0.010 for the proposed method, compared with an MSE of 0.16 for a simple ratio approach and 0.92 when training the model using aggregated workload power. © 2023 IEEE.","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","69-71","","","2023-July","","","","","","","","","","","","","Scopus","","","","","","","","Energy accounting; Electric power utilization; Containers; Power modeling; Power; Kubernetes; Energy-consumption; Green computing; RAPL; Average power limit; Greenhouse gases; Sustainable development; kubernetes; Sustainability; Regression analysis; eBPF; container power modeling; Container power modeling; EBPF; Electric power distribution; energy accounting; Mean square error; Mean squared error; Running average power limit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"SZYPSAGE","journalArticle","2017","Acar, H.","","Software Development Methodology in a Green IT Environment","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087679908&partnerID=40&md5=9c871a65a452a417239820c89f8861b9","","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAQ8NN7G","journalArticle","","","","The green web foundation/green-cost-explorer","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218957202&partnerID=40&md5=1fd19e3bd3dee5dcd36e755ab0affe33","","","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAD5LN8K","journalArticle","2022","Camilli, M.; Janes, A.; Russo, B.","Automated test-based learning and verification of performance models for microservices systems","Journal of Systems and Software","","","10.1016/j.jss.2022.111225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124274286&doi=10.1016%2fj.jss.2022.111225&partnerID=40&md5=5f4a1691c78038edaca0ea24e420f6f2","Effective and automated verification techniques able to provide assurances of performance and scalability are highly demanded in the context of microservices systems. In this paper, we introduce a methodology that applies specification-driven load testing to learn the behavior of the target microservices system under multiple deployment configurations. Testing is driven by realistic workload conditions sampled in production. The sampling produces a formal description of the users’ behavior through a Discrete Time Markov Chain. This model drives multiple load testing sessions that query the system under test and feed a Bayesian inference process which incrementally refines the initial model to obtain a complete specification from run-time evidence as a Continuous Time Markov Chain. The complete specification is then used to conduct automated verification by using probabilistic model checking and to compute a configuration score that evaluates alternative deployment options. This paper introduces the methodology, its theoretical foundation, and the toolchain we developed to automate it. Our empirical evaluation shows its applicability, benefits, and costs on a representative microservices system benchmark. We show that the methodology detects performance issues, traces them back to system-level requirements, and, thanks to the configuration score, provides engineers with insights on deployment options. The comparison between our approach and a selected state-of-the-art baseline shows that we are able to reduce the cost up to 73% in terms of number of tests. The verification stage requires negligible execution time and memory consumption. We observed that the verification of 360 system-level requirements took ∼1 minute by consuming at most 34 KB. The computation of the score involved the verification of ∼7k (automatically generated) properties verified in ∼72 seconds using at most ∼50 KB. © 2022 The Author(s)","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","187","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Automation; Learning systems; Markov processes; Bayesian networks; Performance Modeling; Inference engines; Specifications; Model checking; Continuous time systems; Load testing; Automated test; Automated verification; Markov modeling; Markov models; Model learning; Performance testing; Statistical tests; System-level requirements; Test-based model learning; Verification techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D8XNGVXK","conferencePaper","2020","Eismann, S.; Bezemer, C.-P.; Shang, W.; Okanović, D.; Van Hoorn, A.","Microservices: A performance tester's dream or nightmare?","","","","10.1145/3358960.3379124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085919253&doi=10.1145%2f3358960.3379124&partnerID=40&md5=455a9f26d3dbf08578fe068636b995e1","In recent years, there has been a shift in software development towards microservice-based architectures, which consist of small services that focus on one particular functionality. Many companies are migrating their applications to such architectures to reap the benefits of microservices, such as increased flexibility, scalability and a smaller granularity of the offered functionality by a service. On the one hand, the benefits of microservices for functional testing are often praised, as the focus on one functionality and their smaller granularity allow for more targeted and more convenient testing. On the other hand, using microservices has their consequences (both positive and negative) on other types of testing, such as performance testing. Performance testing is traditionally done by establishing the baseline performance of a software version, which is then used to compare the performance testing results of later software versions. However, as we show in this paper, establishing such a baseline performance is challenging in microservice applications. In this paper, we discuss the benefits and challenges of microservices from a performance tester's point of view. Through a series of experiments on the TeaStore application, we demonstrate how microservices affect the performance testing process, and we demonstrate that it is not straightforward to achieve reliable performance testing results for a microservice application. © 2020 ACM.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","138-149","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Performance; DevOps; Software design; Software testing; Performance testing; Base-line performance; Functional testing; Increased flexibility; Regression testing; Reliable performance; Software versions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2020 - Proceedings of the ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"XAXJMP6C","conferencePaper","2016","Ueda, T.; Nakaike, T.; Ohara, M.","Workload characterization for microservices","","","","10.1109/IISWC.2016.7581269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994792149&doi=10.1109%2fIISWC.2016.7581269&partnerID=40&md5=4d5176224c8f26bb71dad3e667e46e66","The microservice architecture is a new framework to construct a Web service as a collection of small services that communicate with each other. It is becoming increasingly popular because it can accelerate agile software development, deployment, and operation practices. As a result, cloud service providers are expected to host an increasing number of microservices that can generate significant resource pressure on the cloud infrastructure. We want to understand the characteristics of microservice workloads to design an infrastructure optimized for microservices. In this paper, we used Acme Air, an open-source benchmark for Web services, and analyzed the behavior of two versions of the benchmark, microservice and monolithic, for two widely used language runtimes, Node.js and Java. We observed a significant overhead due to the microservice architecture; the performance of the microservice version can be 79.2% lower than the monolithic version on the same hardware configuration. On Node.js, the microservice version consumed 4.22 times more time in the libraries of Node.js than the monolithic version to process one user request. On Java, the microservice version also consumed more time in the application server than the monolithic version. We explain these performance differences from both hardware and software perspectives. We discuss the network virtualization in Docker, an infrastructure for microservices that has nonnegligible impact on performance. These findings give clues to develop optimization techniques in a language runtime and hardware for microservice workloads. © 2016 IEEE.","2016","2025-10-22 19:07:48","2025-10-22 19:07:48","","85-94","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer hardware; Hardware; Open source software; Containers; Docker; Microservices; Container; Java programming language; Network architecture; Software design; Software engineering; Web services; Websites; Reconfigurable hardware; Microservice architecture; Characterization; Java; Node.js; WebSphere Liberty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the 2016 IEEE International Symposium on Workload Characterization, IISWC 2016","","","","","","","","","","","","","","",""
"KGK395VV","journalArticle","2010","Armbrust, M.; Fox, A.; Griffith, R.; Joseph, A.D.; Katz, R.; Konwinski, A.; Lee, G.; Patterson, D.; Rabkin, A.; Stoica, I.; Zaharia, M.","A view of cloud computing","Communications of the ACM","","","10.1145/1721654.1721672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950347409&doi=10.1145%2f1721654.1721672&partnerID=40&md5=6164f58679f057d5164d1f8f31d3f125","CLOUD COMPUTING, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1,000 servers for one hour costs no more than using one server for 1,000. © 2010 ACM.","2010","2025-10-22 19:07:48","2025-10-22 19:07:48","","50-58","","4","53","","","","","","","","","","","","","Scopus","","","","","","","","Cloud computing; Internet; Servers; Capital outlay; Innovative ideas; Internet services; IT industry; Large parts; Potential customers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YT83SYG2","journalArticle","1996","Shaw, M.; Garlan, D.","Software architecture: Perspectives on an emerging discipline","Pearson Us Imports & PHIPEs","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893250361&partnerID=40&md5=f9d571027f167ace2e5ddb70ec2cb7e5","","1996","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6PPM5H9","journalArticle","2018","Bucchiarone, A.; Dragoni, N.; Dustdar, S.; Larsen, S.T.; Mazzara, M.","From Monolithic to Microservices: An Experience Report from the Banking Domain","IEEE Software","","","10.1109/MS.2018.2141026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046855472&doi=10.1109%2fMS.2018.2141026&partnerID=40&md5=d07fd2c213749afdf2f2fc900fa8adc4","Microservices have seen their popularity blossoming with an explosion of concrete applications in real-life software. Several companies are currently involved in a major refactoring of their back-end systems in order to improve scalability. This article presents an experience report of a real-world case study, from the banking domain, in order to demonstrate how scalability is positively affected by reimplementing a monolithic architecture into microservices. The case study is based on the FX Core system for converting from one currency to another. FX Core is a mission-critical system of Danske Bank, the largest bank in Denmark and one of the leading financial institutions in Northern Europe. © 1984-2012 IEEE.","2018","2025-10-22 19:07:48","2025-10-22 19:07:48","","50-55","","3","35","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Microservices; microservices; Software architecture; Software design; software development; software engineering; Software engineering; Scalability; Monolithic architecture; Financial institution; Mission critical systems; scalability; software architecture; Concrete applications; Danske Bank; Experience report; FX Core","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8U38FU58","conferencePaper","2017","Fan, C.-Y.; Ma, S.-P.","Migrating Monolithic Mobile Application to Microservice Architecture: An Experiment Report","","","","10.1109/AIMS.2017.23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032264331&doi=10.1109%2fAIMS.2017.23&partnerID=40&md5=ab113a2950bd047d43bece5f8a51f8d4","The microservice architecture (MSA) is an emerging cloud software system, which provides fine-grained, self-contained service components (microservices) used in the construction of complex software systems. DevOps techniques are commonly used to automate the process of development and operation through continuous integration and continuous deployment. Monitoring software systems created by DevOps, makes it possible for MSA to obtain the feedback necessary to improve the system quickly and easily. Nonetheless, systematic, SDLC-driven methods (SDLC: software development life cycle) are lacking to facilitate the migration of software systems from a traditional monolithic architecture to MSA. Therefore, this paper proposes a migration process based on SDLC, including all of the methods and tools required during design, development, and implementation. The mobile application, EasyLearn, was used as an illustrative example to demonstrate the efficacy of the proposed migration process. We believe that this paper could provide valuable references for other development teams seeking to facilitate the migration of existing applications to MSA. © 2017 IEEE.","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","109-112","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Software design; Software engineering; Mobile applications; Mobile computing; Migration; Mobile telecommunication systems; Computer software; Life cycle; Continuous integrations; Microservice architecture; Monolithic architecture; Development and operations; Complex software systems; Software development life cycle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE 6th International Conference on AI and Mobile Services, AIMS 2017","","","","","","","","","","","","","","",""
"HH57D4JL","journalArticle","1968","McIlroy, M.D.","Mass produced software components","Software Engineering","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002099505&partnerID=40&md5=d4e1e673f968392ab038c58c3fd8096e","","1968","2025-10-22 19:07:48","2025-10-22 19:07:48","","138-155","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VY8RYU9D","journalArticle","2019","Newman, S.","","Monolith to Microservices: Evolutionary Patterns to Transform Your Monolith","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085744999&partnerID=40&md5=dc75f6331fe52756b87a41af7426af17","","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCYEJJBZ","conferencePaper","2017","Mazlami, G.; Cito, J.; Leitner, P.","Extraction of Microservices from Monolithic Software Architectures","","","","10.1109/ICWS.2017.61","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032372980&doi=10.1109%2fICWS.2017.61&partnerID=40&md5=76deccb11538edbd7866455f17f937cf","Driven by developments such as mobile computing, cloud computing infrastructure, DevOps and elastic computing, the microservice architectural style has emerged as a new alternative to the monolithic style for designing large software systems. Monolithic legacy applications in industry undergo a migration to microservice-oriented architectures. A key challenge in this context is the extraction of microservices from existing monolithic code bases. While informal migration patterns and techniques exist, there is a lack of formal models and automated support tools in that area. This paper tackles that challenge by presenting a formal microservice extraction model to allow algorithmic recommendation of microservice candidates in a refactoring and migration scenario. The formal model is implemented in a web-based prototype. A performance evaluation demonstrates that the presented approach provides adequate performance. The recommendation quality is evaluated quantitatively by custom microservice-specific metrics. The results show that the produced microservice candidates lower the average development team size down to half of the original size or lower. Furthermore, the size of recommended microservice conforms with microservice sizing reported by empirical surveys and the domain-specific redundancy among different microservices is kept at a low rate. © 2017 IEEE.","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","524-531","","","","","","","","","","","","","","","","Scopus","","","","","","","","microservices; Distributed computer systems; Migration patterns; Web services; Graphic methods; Architectural style; Websites; Large software systems; Extraction; Quality control; Legacy applications; Formal methods; Cloud computing infrastructures; coupling; Couplings; extraction; graph-based clustering; Graph-based clustering; Web-based prototype","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE 24th International Conference on Web Services, ICWS 2017","","","","","","","","","","","","","","",""
"EPKJHVNM","journalArticle","2016","Montesi, F.; Weber, J.","Circuit breakers, discovery, and API gateways in microservices","Circuit Breakers, Discovery, and API Gateways in Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020536128&partnerID=40&md5=27b5165dbed31f0c460fe5d1d6ee6e64","","2016","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C432HJI6","journalArticle","2015","Jiang, Z.M.; Hassan, A.E.","A Survey on Load Testing of Large-Scale Software Systems","IEEE Transactions on Software Engineering","","","10.1109/TSE.2015.2445340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961770650&doi=10.1109%2fTSE.2015.2445340&partnerID=40&md5=9f8caec0055ae5f398b9c5177af0751b","Many large-scale software systems must service thousands or millions of concurrent requests. These systems must be load tested to ensure that they can function correctly under load (i.e., the rate of the incoming requests). In this paper, we survey the state of load testing research and practice. We compare and contrast current techniques that are used in the three phases of a load test: (1) designing a proper load, (2) executing a load test, and (3) analyzing the results of a load test. This survey will be useful for load testing practitioners and software engineering researchers with interest in the load testing of large-scale software systems. © 2015 IEEE.","2015","2025-10-22 19:07:48","2025-10-22 19:07:48","","1091-1118","","11","41","","","","","","","","","","","","","Scopus","","","","","","","","Software engineering; Surveys; Computer software; Software testing; survey; Surveying; Load testing; Computer software selection and evaluation; software quality; Software Quality; Concurrent requests; large-scale software systems; Large-scale software systems; load testing; Three phasis; Under loads","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32L6VRZQ","journalArticle","2005","Sevcik, P.","Defining the application performance index","Business Communications Review","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74549130451&partnerID=40&md5=94525950f83a09dc3c014e666b40b896","","2005","2025-10-22 19:07:48","2025-10-22 19:07:48","","8-10","","","20","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79BI44SK","journalArticle","2018","Beyer, B.; Murphy, N.R.; Rensin, D.K.; Kawahara, K.; Thorne, S.","","The Site Reliability Workbook: Practical Ways to Implement SRE","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059833122&partnerID=40&md5=1c1f88f43b69e1feae072b440ff93275","","2018","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4KE6W7X","journalArticle","2018","Finnigan, K.","","Enterprise Java Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080616922&partnerID=40&md5=822f83c2c0a97c265329a42c1325de60","","2018","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPR3XJNF","conferencePaper","1987","Garcia-Molina, H.; Salem, K.","Sagas","","","","10.1145/38713.38742","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899882908&doi=10.1145%2f38713.38742&partnerID=40&md5=0cc78c81d986553a91ca13780f9c899b","Long lived transactions (LLTs) hold on to database resources for relatively long periods of time, significantly delaying the termination of shorter and more common transactions. To alleviate these problems we propose the notion of a saga. A LLT is a saga if it can be written as a sequence of transactions that can be interleaved with other transactions. The database management system guarantees that either all the transactions in a saga are successfully completed or compensating transactions are run to amend a partial execution. Both the concept of saga and its implementation are relatively simple, but they have the potential to improve performance significantly. We analyze the various implementation issues related to sagas, including how they can be run on an existing system that does not directly support them. We also discuss techniques for database and LLT design that make it feasible to break up LLTs into sagas. © 1987 ACM.","1987","2025-10-22 19:07:48","2025-10-22 19:07:48","","249-259","","","","","","","","","","","","","","","","Scopus","","","","","","","","Database systems; Existing systems; Simple++; Break-up; Improve performance; Partial executions; Transaction design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","","","","","","","","","","","",""
"Y7V7V58Y","journalArticle","2018","Richardson, C.","Microservices patterns: With examples in Java","Simon and Schuster","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122634128&partnerID=40&md5=5f491e2324dd6b42da804b1c24efc666","","2018","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LZ5KX9Z","journalArticle","2020","Avritzer, A.; Ferme, V.; Janes, A.; Russo, B.; Hoorn, A.V.; Schulz, H.; Menasché, D.; Rufino, V.","Scalability Assessment of Microservice Architecture Deployment Configurations: A Domain-based Approach Leveraging Operational Profiles and Load Tests","Journal of Systems and Software","","","10.1016/j.jss.2020.110564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080916968&doi=10.1016%2fj.jss.2020.110564&partnerID=40&md5=c88d1e94be06f1c2496ff9e6c0f0d2c0","Microservices have emerged as an architectural style for developing distributed applications. Assessing the performance of architecture deployment configurations — e.g., with respect to deployment alternatives — is challenging and must be aligned with the system usage in the production environment. In this paper, we introduce an approach for using operational profiles to generate load tests to automatically assess scalability pass/fail criteria of microservice configuration alternatives. The approach provides a Domain-based metric for each alternative that can, for instance, be applied to make informed decisions about the selection of alternatives and to conduct production monitoring regarding performance-related system properties, e.g., anomaly detection. We have evaluated our approach using extensive experiments in a large bare metal host environment and a virtualized environment. First, the data presented in this paper supports the need to carefully evaluate the impact of increasing the level of computing resources on performance. Specifically, for the experiments presented in this paper, we observed that the evaluated Domain-based metric is a non-increasing function of the number of CPU resources for one of the environments under study. In a subsequent series of experiments, we investigate the application of the approach to assess the impact of security attacks on the performance of architecture deployment configurations. © 2020","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","165","","","","","","","","","","","","","Scopus","","","","","","","","Virtualized environment; Virtual reality; Architecture; Architectural style; Distributed applications; Scalability; Anomaly detection; Computing resource; Production environments; Load testing; Increasing functions; Operational profile; Production monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C4687GSJ","conferencePaper","2000","Bondi, A.B.","Characteristics of scalability and their impact on performance","","","","10.1145/350391.350432","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034592897&doi=10.1145%2f350391.350432&partnerID=40&md5=711bb72b0448ee75a205d3ad50fa4fe5","Scalability is a desirable attribute of a network, system, or process. Poor scalability can result in poor system performance, necessitating the reengineering or duplication of systems. While scalability is valued, its characteristics and the characteristics that undermine it are usually only apparent from the context. Here, we attempt to define different aspects of scalability, such as structural scalability and load scalability. Structural scalability is the ability of a system to expand in a chosen dimension without major modifications to its architecture. Load scalability is the ability of a system to perform gracefully as the offered traffic increases. It is argued that systems with poor load scalability may exhibit it because they repeatedly engage in wasteful activity, because they are encumbered with poor scheduling algorithms, because they cannot fully take advantage of parallelism, or because they are algorithmically inefficient. We qualitatively illustrate these concepts with classical examples from the literature of operating systems and local area networks, as well as an example of our own. Some of these are accompanied by rudimentary delay analysis.","2000","2025-10-22 19:07:48","2025-10-22 19:07:48","","195-203","","","","","","","","","","","","","","","","Scopus","","","","","","","","Performance; Algorithms; Computer operating systems; Data structures; Parallel processing systems; Computer networks; Load scalability; Structural and space scalability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings Second International Workshop on Software and Performance WOSP 2000","","","","","","","","","","","","","","",""
"VJIJX57P","journalArticle","2014","Lewis, J.; Fowler, M.","","Richardson Maturity Model","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210251216&partnerID=40&md5=979f8116dbbb317bdf356751c3348e58","","2014","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7FSXFIAH","journalArticle","2015","Newman, S.","","Building Microservices","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950338538&partnerID=40&md5=aec25db8f81564a4ab82f370c5e620cc","","2015","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6DGDJC3U","conferencePaper","2019","Jindal, A.; Podolskiy, V.; Gerndt, M.","Performance modeling for cloud microservice applications","","","","10.1145/3297663.3310309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064819069&doi=10.1145%2f3297663.3310309&partnerID=40&md5=bd1cc7d512919b877b7240a6ffc95011","Microservices enable a fine-grained control over the cloud applications that they constitute and thus became widely-used in the industry. Each microservice implements its own functionality and communicates with other microservices through language- and platform-agnostic API. The resources usage of microservices varies depending on the implemented functionality and the workload. Continuously increasing load or a sudden load spike may yield a violation of a service level objective (SLO). To characterize the behavior of a microservice application which is appropriate for the user, we define a MicroService Capacity (MSC) as a maximal rate of requests that can be served without violating SLO. The paper addresses the challenge of identifying MSC individually for each microservice. Finding individual capacities of microservices ensures the flexibility of the capacity planning for an application. This challenge is addressed by sandboxing a microservice and building its performance model. This approach was implemented in a tool Terminus. The tool estimates the capacity of a microservice on different deployment configurations by conducting a limited set of load tests followed by fitting an appropriate regression model to the acquired performance data. The evaluation of the microservice performance models on microservices of four different applications shown relatively accurate predictions with mean absolute percentage error (MAPE) less than 10%. The results of the proposed performance modeling for individual microservices are deemed as a major input for the microservice application performance modeling. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","25-32","","","","","","","","","","","","","","","","Scopus","","","","","","","","Kubernetes; Service level objective; Application performance; Performance modeling; Regression analysis; Performance Model; Load testing; Accurate prediction; Fine-grained control; Mean absolute percentage error; Microservice capacity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ICPE 2019 - Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering","","","","","","","","","","","","","","",""
"9FFUHYTU","conferencePaper","2021","Agarwal, S.; Sinha, R.; Sridhara, G.; Das, P.; Desai, U.; Tamilselvam, S.; Singhee, A.; Nakamuro, H.","Monolith to Microservice Candidates using Business Functionality Inference","","","","10.1109/ICWS53863.2021.00104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123207360&doi=10.1109%2fICWS53863.2021.00104&partnerID=40&md5=57a101ce3da88b221b96c8e85427fb50","In this paper, we propose a novel approach for monolith decomposition, that maps the implementation structure of a monolith application to a functional structure that in turn can be mapped to business functionality. First, we infer the classes in the monolith application that are distinctively representative of the business functionality in the application domain. This is done using formal concept analysis on statically determined code flow structures in a completely automated manner. Then, we apply a clustering technique, guided by the inferred representatives, on the classes belonging to the monolith to group them into different types of partitions, mainly: 1) functional groups representing microservice candidates, 2) a utility class group, and 3) a group of classes that require significant refactoring to enable a clean microservice architecture. This results in microservice candidates that are naturally aligned with the different business functions exposed by the application. A detailed evaluation on four publicly available applications show that our approach is able to determine better quality microservice candidates when compared to other existing state of the art techniques. We also conclusively show that clustering quality metrics like modularity are not reliable indicators of microservice candidate goodness. © 2021 IEEE.","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","758-763","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality control; Business function inference; Business Function Inference; Business functionality; Business Functionality; Business functions; Concept lattice; Concept Lattices; Domain entities; Domain Entity; Entrypoint specification; EntryPoint Specification; Formal concept analysis; Function inference; Information analysis; Microservice recommendation; Mono2micro; Mono2Micro; Monolith decomposition; Monolith Decomposition; Seed expansion; Seed Expansion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2021 IEEE International Conference on Web Services, ICWS 2021","","","","","","","","","","","","","","",""
"D4HDZ2RA","conferencePaper","2022","Berry, V.; Castelltort, A.; Pelissier, C.; Rousseau, M.; Tibermacine, C.","ShellOnYou: Learning by Doing Unix Command Line","","","","10.1145/3502718.3524753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134432493&doi=10.1145%2f3502718.3524753&partnerID=40&md5=5cdc5a9a2e8f84c9d90822bab80f9d4e","We present ShellOnYou, a new Computer Science education tool, and analyze its use with four successive student cohorts. Developed to help instructors manage numerous students, this web application offers auto-graded exercises to acquire practical knowledge of Unix-like operating systems from the command line. For each answer, and almost instantly, students receive a score and detailed feedback. This reactive and iterative process encourages students to resubmit answers and progressively expand their procedural knowledge. The tool can also deliver individualized statements, thereby allowing students to improve their skills by combining personal research and peer learning. As an online tool, ShellOnYou affords students access flexibility, and also easily fits in distance learning programs. We found it particularly useful when teaching students with heterogeneous Unix backgrounds. The tool is available on request. We placed four successive student cohorts in a learning situation involving this tool, and asked them to fill a survey at the end of the learning period. We combine qualitative and quantitative methods to analyze their answers to the survey. We attempt to characterize their acquisition of procedural knowledge and the building of group dynamics. Several dimensions emerge: the benefits of using the tool in a learning situation, the learning process iteration as a catalyst for renewed commitment, the tool's entertaining format and its scoring system as a motivation for regular studying, and the inherent customization of the learning pace.  © 2022 ACM.","2022","2025-10-22 19:07:48","2025-10-22 19:07:48","","379-385","","","1","","","","","","","","","","","","","Scopus","","","","","","","","Surveys; Iterative methods; Learning systems; Command line; Engineering education; autograder; Autograder; automated feedback; Automated feedback; Education computing; learning by doing; Learning situation; Learning-by-doing; practical knowledge; Practical knowledge; Procedural knowledge; Student perceptions; Students; students' perception; UNIX command; unix command line interface; Unix command line interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE","","","","","","","","","","","","","","",""
"U6RVR3DI","journalArticle","1999","Freeman, E.; Hupfer, S.; Arnold, K.","JavaSpaces: Principles, patterns, and practice","JavaSpaces Principles, Patterns, and Practice","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003400120&partnerID=40&md5=e8ca496fcaf57ed2ed7b6db66250191c","","1999","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3CGP8IG","conferencePaper","2017","Gouigoux, J.-P.; Tamzalit, D.","From monolith to microservices: Lessons learned on an industrial migration to a web oriented architecture","","","","10.1109/ICSAW.2017.35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025592012&doi=10.1109%2fICSAW.2017.35&partnerID=40&md5=5f601d6922482948f79fa4c45f45d76d","MGDIS SA is a software editing company that underwent a major strategic and technical change during the past three years, investing 17 300 man. Days rewriting its core business software from monolithic architecture to a Web Oriented Architecture using microservices. The paper presents technical lessons learned during and from this migration by addressing three crucial questions for a successful context-adapted migration towards a Web Oriented Architecture: how to determine (i) the most suitable granularity of micro-services, (ii) the most appropriate deployment and (iii) the most efficient orchestration? © 2017 IEEE.","2017","2025-10-22 19:07:48","2025-10-22 19:07:48","","62-65","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Software architecture; Migration; Monolithic architecture; Core business; Technical change; Web Oriented Architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2017 IEEE International Conference on Software Architecture Workshops, ICSAW 2017: Side Track Proceedings","","","","","","","","","","","","","","",""
"III5D8A7","journalArticle","2003","Bass, L.; Clements, P.; Kazman, R.","","Software Architecture in Practice","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0004025223&partnerID=40&md5=5033f9948ca9ba9361258afb3c821863","","2003","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","","","","","","","","","","","","","","Scopus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VD449CB","conferencePaper","2019","Song, Z.; Tilevich, E.","Equivalence-enhanced microservice workflow orchestration to efficiently increase reliability","","","","10.1109/ICWS.2019.00076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072786259&doi=10.1109%2fICWS.2019.00076&partnerID=40&md5=279088611b89191dec2f2432e661d111","The applicability of the microservice architecture has extended beyond traditional web services, making steady inroads into the domains of IoT and edge computing. Due to dissimilar contexts in different execution environments and inherent mobility, edge and IoT applications suffer from low execution reliability. Replication, traditionally used to increase service reliability and scalability, is inapplicable in these resource-scarce environments. Alternately, programmers can orchestrate the parallel or sequential execution of equivalent microservices-microservices that provide the same functionality by different means. Unfortunately, the resulting orchestrations rely on parallelization, synchronization, and failure handing, all tedious and error-prone to implement. Although automated orchestration shifts the burden of generating workflows from the programmer to the compiler, existing programming models lack both syntactic and semantic support for equivalence. In this paper, we enhance compiler-generated execution orchestration with equivalence to efficiently increase reliability. We introduce a dataflow-based domain-specific language, whose dataflow specifications include the implicit declarations of equivalent microservices and their execution patterns. To automatically generate reliable workflows and execute them efficiently, we introduce new equivalence workflow constructs. Our evaluation results indicate that our solution can effectively and efficiently increase the reliability of microservice-based applications. © 2019 IEEE.","2019","2025-10-22 19:07:48","2025-10-22 19:07:48","","426-433","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; Data flow analysis; Program compilers; Microservice; Internet of things; Web services; Websites; Execution environments; Semantics; Reliability; Domain specific languages; Service reliability; Problem oriented languages; Dataflow specifications; Functional equivalence; Sequential execution; Workflow orchestration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2019 IEEE International Conference on Web Services, ICWS 2019 - Part of the 2019 IEEE World Congress on Services","","","","","","","","","","","","","","",""
"7RTU5Q9E","conferencePaper","2020","Tizzei, L.P.; Azevedo, L.; Soares, E.; Thiago, R.; Costa, R.","On the Maintenance of a Scientific Application based on Microservices: An Experience Report","","","","10.1109/ICWS49710.2020.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099276336&doi=10.1109%2fICWS49710.2020.00021&partnerID=40&md5=192c6da76cc1563b84c48016e06e588e","Microservices Architecture has been adopted by several companies to develop applications and replace monolithic ones. Several works point out that this approach supports the design of maintainable software systems. However, none of them presents a quantitative empirical study on the extent of the maintenance support in a real-world application. This work assesses how Microservices Architecture supports software maintenance through an empirical quantitative study of a scientific application built from scratch. We collected data from January 2016 (the beginning of the project) to December 2019, and analyzed 19 microservices, 34 repositories, and 15,408 commits. Then, we present the lessons learned during the project that allowed reaching the assessment results. Our findings may assist practitioners in making architectural decisions and pointing out research opportunities for academics.  © 2020 IEEE.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","102-109","","","","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; microservices; Software systems; Web services; Research opportunities; Websites; software architecture; Scientific applications; Maintenance; software evolution; Architectural decision; Experience report; Maintenance supports; Quantitative empirical studies; Quantitative study; scientific software; software maintenance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2020 IEEE 13th International Conference on Web Services, ICWS 2020","","","","","","","","","","","","","","",""
"P7T7BEVV","conferencePaper","2016","Amaral, M.; Polo, J.; Carrera, D.; Mohomed, I.; Unuvar, M.; Steinder, M.","Performance evaluation of microservices architectures using containers","","","","10.1109/NCA.2015.49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963600252&doi=10.1109%2fNCA.2015.49&partnerID=40&md5=6c7edd04e0d0c3f878d5a3fd4d126855","Micro services architecture has started a new trend for application development for a number of reasons: (1) to reduce complexity by using tiny services, (2) to scale, remove and deploy parts of the system easily, (3) to improve flexibility to use different frameworks and tools, (4) to increase the overall scalability, and (5) to improve the resilience of the system. Containers have empowered the usage of micro services architectures by being lightweight, providing fast start-up times, and having a low overhead. Containers can be used to develop applications based on monolithic architectures where the whole system runs inside a single container or inside a micro services architecture where one or few processes run inside the containers. Two models can be used to implement a micro services architecture using containers: master-slave, or nested-container. The goal of this work is to compare the performance of CPU and network running benchmarks in the two aforementioned models of micro services architecture hence provide a benchmark analysis guidance for system designers. © 2015 IEEE.","2016","2025-10-22 19:07:48","2025-10-22 19:07:48","","27-34","","","","","","","","","","","","","","","","Scopus","","","","","","","","Containers; Microservices; Computer architecture; Network architecture; Benchmarking; Complex networks; Monolithic architecture; Fast start-up; Application development; System designers; Benchmark analysis; Networking; Performance Evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2015 IEEE 14th International Symposium on Network Computing and Applications, NCA 2015","","","","","","","","","","","","","","",""
"MRGKHQN8","conferencePaper","2023","Lourenco, J.; Silva, A.R.","Monolith Development History for Microservices Identification: a Comparative Analysis","","","","10.1109/ICWS60048.2023.00019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173810444&doi=10.1109%2fICWS60048.2023.00019&partnerID=40&md5=36c5ba01812a0afa8826638be566112a","Recent research has proposed different approaches on the automated identification of candidate microservices on monolith systems, which vary on the monolith representation, similarity criteria, and quality metrics used. On the other hand, they are generally limited in the number of codebases and decompositions evaluated, and few comparisons between approaches exist. Considering the emerging trend in software engineering in techniques based on the analysis of codebases' evolution, we compare a representation based on the monolith code structure, in particular the sequences of accesses to domain entities, with representations based on the monolith development history (file changes and changes authorship). From the analysis on a total of 468k decompositions of 28 codebases, using five quality metrics that evaluate modularity, minimization of the number of transactions per functionality, and reduction of teams and communication, we conclude that the changes authorship representation of codebases with many authors achieves comparable or better results than the sequences of accesses representation of codebases with few authors with respect to minimization of the number of transactions per functionality and the reduction of teams. © 2023 IEEE.","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","50-56","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; Microservices; Software engineering; % reductions; Quality control; Minimisation; Architecture migration; Architecture Migration; Comparative analyzes; Development history; Microservice identification; Microservices Identification; Monolith; Quality metrices; Repository mining; Repository Mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2023 IEEE International Conference on Web Services, ICWS 2023","","","","","","","","","","","","","","",""
"VPTNNUM6","conferencePaper","2018","Zhu, H.; Wang, H.; Bayley, I.","Formal Analysis of Load Balancing in Microservices with Scenario Calculus","","","","10.1109/CLOUD.2018.00133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057467049&doi=10.1109%2fCLOUD.2018.00133&partnerID=40&md5=8eb2fad15017aa7eaf34f5d6e8ac532b","Load balancing plays a crucial role in realising the benefits of microservices, especially to achieve elastic scalability and performance optimisation. However, it is different from load balancing for virtual machines, because workloads on microservices are harder to predict and the number of services in the systems is large. In this paper, we formalise load balance as an emergent property of the microservices ecosystem, and employ scenario calculus to formally analyse the impact of scheduling on service capability and scalability. We discovered that elastic round robin scheduling is highly scalable but the service capability is limited by the slowest microservice instance. In contrast, shortest waiting queue scheduling is less scalable, but the service capability is higher. © 2018 IEEE.","2018","2025-10-22 19:07:48","2025-10-22 19:07:48","","908-911","","","2018-July","","","","","","","","","","","","","Scopus","","","","","","","","Scheduling; Microservices; Cloud computing; Balancing; Scheduling algorithms; Scalability; Load balance; Scheduling policies; Calculations; Scenario calculus; Service capability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","IEEE International Conference on Cloud Computing, CLOUD","","","","","","","","","","","","","","",""
"48VZNHRX","conferencePaper","2023","Wang, T.; He, X.; Shi, H.; Wang, Z.","EvolutionSim: An Extensible Simulation Toolkit for Microservice System Evolution","","","","10.1109/ICWS60048.2023.00018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173848072&doi=10.1109%2fICWS60048.2023.00018&partnerID=40&md5=70f4834f2a76ac9f9fe9be1ae10f98d2","Recently, microservices architecture has become the mainstream software development and deployment architecture for most enterprises, with the advantages of continuous delivery/deployment. However, the inability of microservices systems to meet changing user requirements and other external factors can lead to a degradation of quality of service (QoS), necessitating microservice evolution to ensure QoS stability by adjusting the deployment structure and configuration of microservices through evolutionary means such as redeployment. In order to study different evolutionary problems, simulation of microservice evolution is critical because the flexibility and diversity of the simulation environment can provide a more prosperous experimental environment for the researchers involved compared single physical experiments and numerical experiments. However, existing simulators have limitations when it comes to simulating microservice evolution. They either lack the capability to support the simulation of microservice evolution or only provide simulation for specific evolutionary means, which limits their extensibility. To address this issue, this paper designs and implements a simulation toolkit EvolutionSim for MSS evolution based on discrete event. It aimes to simulate the running and evolution process of MSSs with the support of several evolutionary means. In addition, Experiments were carried out to compare the simulated results with the actual results, and the distribution was found to be similar by ADF test, which indicates that EvolutionSim can provide valid results. Moreover, three experimental scenarios were conducted to simulate three mainstream evolutionary means, and the results indicate that EvolutionSim can accurately simulate the effects of different evolutionary means on MSS. © 2023 IEEE.","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","43-49","","","","","","","","","","","","","","","","Scopus","","","","","","","","Quality of service; cloud computing; Cloud-computing; Quality-of-service; Software design; simulation; Microservice system; Satellites; Simulation; evolution; Deployment architecture; Evolution; microservice modeling; Microservice modeling; microservice system; Simulation toolkits; System evolution; User requirements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - 2023 IEEE International Conference on Web Services, ICWS 2023","","","","","","","","","","","","","","",""
"TLM4LCNY","journalArticle","2021","Li, S.; Zhang, H.; Jia, Z.; Zhong, C.; Zhang, C.; Shan, Z.; Shen, J.; Babar, M.A.","Understanding and addressing quality attributes of microservices architecture: A Systematic literature review","Information and Software Technology","","","10.1016/j.infsof.2020.106449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097144108&doi=10.1016%2fj.infsof.2020.106449&partnerID=40&md5=12a7fa386b4fdce447ce3bfda55806de","Context: As a rapidly adopted architectural style in software engineering, Microservices Architecture (MSA) advocates implementing small-scale and independently distributed services, rather than binding all functions into one monolith. Although many initiatives have contributed to the quality improvement of microservices-based systems, there is still a lack of a systematic understanding of the Quality Attributes (QAs) associated with MSA. Objective: This study aims to investigate the evidence-based state-of-the-art of QAs of microservices-based systems. Method: We carried out a Systematic Literature Review (SLR) to identify and synthesize the relevant studies that report evidence related to QAs of MSA. Results: Based on the data extracted from the 72 selected primary studies, we portray an overview of the six identified QAs most concerned in MSA, scalability, performance, availability, monitorability, security, and testability. We identify 19 tactics that architecturally address the critical QAs in MSA, including two tactics for scalability, four for performance, four for availability, four for monitorability, three for security, and two for testability. Conclusion: This SLR concludes that for MSA-based systems: 1) Although scalability is the commonly acknowledged benefit of MSA, it is still an indispensable concern among the identified QAs, especially when trading-off with other QAs, e.g., performance. Apart from the six identified QAs in this study, other QAs for MSA like maintainability need more attention for effective improvement and evaluation in the future. 3) Practitioners need to carefully make the decision of migrating to MSA based on the return on investment, since this architectural style additionally cause some pains in practice. © 2020","2021","2025-10-22 19:07:48","2025-10-22 19:07:48","","","","","131","","","","","","","","","","","","","Scopus","","","","","","","","Microservices; Architecture; Software engineering; State of the art; Systematic literature review; Architectural style; Scalability; Systematic literature review (SLR); Distributed service; Quality attributes; Monolith; Evidence-based; Quality improvement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKXISPU4","journalArticle","2023","Velepucha, V.; Flores, P.","A Survey on Microservices Architecture: Principles, Patterns and Migration Challenges","IEEE Access","","","10.1109/ACCESS.2023.3305687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168269805&doi=10.1109%2fACCESS.2023.3305687&partnerID=40&md5=6a49ba1cdabc871eb5aa5bb54da30852","Microservices architecture is a new trend embraced by many organizations as a way to modernize their legacy applications. However, although there is work related to the migration process, there is a gap in the body of knowledge related to the principles they should adopt when implementing a microservices architecture. This work presents a comprehensive survey, gathering literature that explores the fundamental principles underlying the object-oriented approach and how these concepts are related to monolithic and microservices architectures. In addition, our research encompasses both monolithic architectures and microservices, along with an investigation into the design patterns and principles utilized within microservices. Our contribution is present a list of patterns used in microservices architecture, the comparation between the principles expounded by the experts in the decomposition of microservices architectures, Martin Fowler and Sam Neuman, and the forerunner of the Principle of Information Hiding, David Parnas, who discusses modularization as a mechanism to improve flexibility and understanding of a system. Additionally, we expose the advantages and disadvantages of monolithic and microservices architectures obtained from the literature review carried out in summary form, which can help as a reference for researchers from academia and industry and finally reveal the trends of microservices architectures today. © 2013 IEEE.","2023","2025-10-22 19:07:48","2025-10-22 19:07:48","","88339-88358","","","11","","","","","","","","","","","","","Scopus","","","","","","","","Behavioral research; Microservice; Microservices; Software architecture; Migration; Complexity theory; Software; Microservice architecture; Modular construction; patterns; migration; Monolithics; Decomposition; Object oriented programming; Pattern; Behavioral science; decomposition; monolithic; Objectoriented programming (OOP); Principle; principles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NS9HDRCY","conferencePaper","2020","Waseem, M.; Liang, P.; Marquez, G.; Salle, A.D.","Testing microservices architecture-based applications: A systematic mapping study","","","","10.1109/APSEC51365.2020.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102372417&doi=10.1109%2fAPSEC51365.2020.00020&partnerID=40&md5=073007603c5ccc92e3b41f66c95a5980","Microservices is an architectural style that provides several benefits to develop applications as small, independent, and modular services. Building Microservices Architecture (MSA)-based applications is immensely supported by using software testing fundamentals. With the increasing interest in the development of MSA-based applications, it is important to systematically identify, analyze, and classify the publication trends, research themes, approaches, tools, and challenges in the context of testing MSA-based applications. The search yielded 2, 481 articles, and 33 articles were finally selected as the primary studies with snowballing. The key findings are that (i) 5 research themes characterize testing approaches in MSA-based applications; (ii) integration and unit testing are the most popular testing approaches; and (iii) addressing the challenges in automated and inter-communication testing is gaining the interest of the community. Additionally, it emerges that there is a lack of dedicated tools to support testing for MSA-based applications, and the reasons and solutions behind the challenges in testing MSA-based applications need to be further explored.  © 2020 IEEE.","2020","2025-10-22 19:07:48","2025-10-22 19:07:48","","119-128","","","2020-December","","","","","","","","","","","","","Scopus","","","","","","","","Application programs; Microservices; Systematic mapping studies; Architectural style; Testing; Architecture-based; Dedicated tools; Integration testing; Inter-communication; Microservices Architecture based Application; Support testing; Systematic Mapping Study; Unit testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings - Asia-Pacific Software Engineering Conference, APSEC","","","","","","","","","","","","","","",""
"EVW863A4","journalArticle","1972","Parnas, D.L.","On the criteria to be used in decomposing systems into modules","Communications of the ACM","","","10.1145/361598.361623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0015482049&doi=10.1145%2f361598.361623&partnerID=40&md5=5ad203b48ffeba294b79df1fd0cbb8be","This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a “modularization” is dependent upon the criteria used in dividing the system into modules. A system design problem is presented and both a conventional and unconventional decomposition are described. It is shown that the unconventional decompositions have distinct advantages for the goals outlined. The criteria used in arriving at the decompositions are discussed. The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. An alternative approach to implementation which does not have this effect is sketched. © 1972, ACM. All rights reserved.","1972","2025-10-22 19:07:48","2025-10-22 19:07:48","","1053-1058","","12","15","","","","","","","","","","","","","Scopus","","","","","","","","software engineering; software; modularity; software design; COMPUTER PROGRAMMING; KWIC index; modules","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLKEW8EX","conferencePaper","2018","Al-Debagy, O.; Martinek, P.","A Comparative Review of Microservices and Monolithic Architectures","","","","10.1109/CINTI.2018.8928192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077783518&doi=10.1109%2fCINTI.2018.8928192&partnerID=40&md5=ee6c0f01b783ae6cb6b72fef1b67a020","Microservices' architecture is getting attention in the academic community and the industry, and mostly is compared with monolithic architecture. Plenty of the results of these research papers contradict each other regarding the performance of these architectures. Therefore, these two architectures are compared in this paper, and some specific configurations of microservices' applications are evaluated as well in the term of service discovery. Monolithic architecture in concurrency testing showed better performance in throughput by 6% when compared to microservices architecture. The load testing scenario did not present significant difference between the two architectures. Furthermore, a third test comparing microservices applications built with different service discovery technologies such as Consul and Eureka showed that applications with Consul presented better results in terms of throughput. © 2018 IEEE.","2018","2025-10-22 19:07:49","2025-10-22 19:07:49","","149-154","","","","","","","","","","","","","","","","Scopus","","","","","","","","Architecture; Artificial intelligence; Research papers; Monolithic architecture; Service discovery; Microservices Architecture; Load testing; Performance Evaluation; Academic community; Different services; Monolithic Architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","18th IEEE International Symposium on Computational Intelligence and Informatics, CINTI 2018 - Proceedings","","","","","","","","","","","","","","",""
"MDJNALDN","journalArticle","2016","Febrero, F.; Calero, C.; Moraga, M.Á.","Software reliability modeling based on ISO/IEC SQuaRE","Information and Software Technology","","","10.1016/j.infsof.2015.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949431570&doi=10.1016%2fj.infsof.2015.09.006&partnerID=40&md5=58b53227f2f7b77494e50288eb98c3ad","Context: The increasing dependence of our society on software driven systems has led Software Reliability to become a key factor as well as making it a highly active research area with hundreds of works being published every year. It would, however, appear that this activity is much more reduced as regards how to apply representative international standards on Product Quality to industrial environments, with just a few works on Standard Based software reliability modeling (SB-SRM). This is surprising given the relevance of such International Standards in industry. Objective: To identify and analyze the existing works on the modeling of Software Reliability based on International Standards as the starting point for a reliability assessment proposal based on ISO/IEC-25000 ""Software Product Quality Requirements and Evaluation"" (SQuaRE) series. Method: The work methodology is based on the guidelines provided in Evidence Based Software Engineering for Systematic Literature Reviews (SLR). Results: A total of 1820 works were obtained as a result of the SLR search, more than 800 primary studies were selected after data filtering. After scrutiny, over thirty of those were thoroughly analyze, the results obtained show a very limited application of SB-SRM particularly to industrial environment. Conclusion: Our analysis point to the complexity of the proposed models together with the difficulties involved in applying them to the management of engineering activities as a root cause to be considered for such limited application. The various stakeholder needs are also a point of paramount importance that should be better covered if the industrial applicability of the proposed models is to be increased. © 2015 Elsevier B.V. All rights reserved.","2016","2025-10-22 19:07:49","2025-10-22 19:07:49","","18-29","","","70","","","","","","","","","","","","","Scopus","","","","","","","","Standards; Software engineering; Systematic literature review (SLR); Quality control; Reliability; Software reliability; Software quality; Computer software selection and evaluation; Software Quality; Evidence Based Software Engineering; Industrial environments; International standard; International standards; Software product quality; Software reliability modeling; Software reliability models; SQuaRE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8A7SNKP","conferencePaper","2023","Okrój, S.; Jatkiewicz, P.","Differences in performance, scalability, and cost of using microservice and monolithic architecture","","","","10.1145/3555776.3578725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162891826&doi=10.1145%2f3555776.3578725&partnerID=40&md5=f9cca2c591f4f4c8e8befc72561fb71d","A microservices-based architecture is a set of small components that communicate with each other using a programming language-independent API [1]. It has been gaining popularity for more than a decade. One of its advantages is greater agility in software development and following modern, agile software development practices [2]. The article presents an experimental study. Two applications with the same business logic and different architecture were developed. Both applications were tested using prepared test cases on the local computer of one of the authors and the Microsoft Azure platform. The results were collected and compared using the JMeter tool. In almost all cases, the monolithic architecture proved to be more efficient. The comparable performance of both architectures occurred when queries were handled by the business logic layer for a relatively long time.  © 2023 Owner/Author(s).","2023","2025-10-22 19:07:49","2025-10-22 19:07:49","","1038-1041","","","","","","","","","","","","","","","","Scopus","","","","","","","","Microservice; cloud computing; Cloud computing; Cloud-computing; microservices; Performance; Performance costs; Software design; Benchmarking; Computation theory; Application programming interfaces (API); Windows operating system; Scalability; benchmarking; Monolithic architecture; scalability; software architecture; performance; Small components; Computer circuits; Monolith; azure; Azure; Language independents; monolith; Performance scalability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Proceedings of the ACM Symposium on Applied Computing","","","","","","","","","","","","","","",""
"CKZVFV4P","book","2012","Wohlin, C.; Runeson, P.; Höst, M.; Ohlsson, M.C.; Regnell, B.; Wesslén, A.","Experimentation in software engineering","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949178783&doi=10.1007%2f978-3-642-29044-2&partnerID=40&md5=22cfcf448329dc928057c3f13bb130a2","Like other sciences and engineering disciplines, software engineering requires a cycle of model building, experimentation, and learning. Experiments are valuable tools for all software engineers who are involved in evaluating and choosing between different methods, techniques, languages and tools. The purpose of Experimentation in Software Engineering is to introduce students, teachers, researchers, and practitioners to empirical studies in software engineering, using controlled experiments. The introduction to experimentation is provided through a process perspective, and the focus is on the steps that we have to go through to perform an experiment. The book is divided into three parts. The first part provides a background of theories and methods used in experimentation. Part II then devotes one chapter to each of the five experiment steps: scoping, planning, execution, analysis, and result presentation. Part III completes the presentation with two examples. Assignments and statistical material are provided in appendixes. Overall the book provides indispensable information regarding empirical studies in particular for experiments, but also for case studies, systematic literature reviews, and surveys. It is a revision of the authors' book, which was published in 2000. In addition, substantial new material, e.g. concerning systematic literature reviews and case study research, is introduced. The book is self-contained and it is suitable as a course book in undergraduate or graduate studies where the need for empirical studies in software engineering is stressed. Exercises and assignments are included to combine the more theoretical material with practical aspects. Researchers will also benefit from the book, learning more about how to conduct empirical studies, and likewise practitioners may use it as a ""cookbook"" when evaluating new methods or techniques before implementing them in their organization. © Springer-Verlag Berlin Heidelberg 2012. All rights are reserved.","2012","2025-10-22 19:07:49","2025-10-22 19:07:49","","","1","","9783642290442","","","","Experimentation in Software Engineering","","","","","","","","","Scopus","","","","","","","","Software engineering; Systematic literature review; Controlled experiment; Empirical studies; Education; Engineering education; Case-studies; Engineering disciplines; Case study research; Graduate studies; Reviews; Scoping; Teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHCUMCWP","conferencePaper","1967","Amdahl, G.M.","Validity of the single processor approach to achieving large scale computing capabilities","","","","10.1145/1465482.1465560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060036181&doi=10.1145%2f1465482.1465560&partnerID=40&md5=9ed463e7a30c37b9801df9f3dca544f6","For over a decade prophets have voiced the contention that the organization of a single computer has reached its limits and that truly significant advances can be made only by interconnection of a multiplicity of computers in such a manner as to permit cooperative solution. Variously the proper direction has been pointed out as general purpose computers with a generalized interconnection of memories, or as specialized computers with geometrically related memory interconnections and controlled by one or more instruction streams. © 1967 ACM.","1967","2025-10-22 19:07:49","2025-10-22 19:07:49","","483-485","","","","","","","","","","","","","","","","Scopus","","","","","","","","Computer science; Computers; Large-scale computing; General purpose computers; Instruction streams; Single computer; Single processors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","AFIPS Conference Proceedings - 1967 Spring Joint Computer Conference, AFIPS 1967","","","","","","","","","","","","","","",""